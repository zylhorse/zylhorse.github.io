[{
    "title": "Hugo评论系统-Gitalk",
    "date": "",
    "description": "",
    "body": "  注册GitHub OAuth application\n  配置config.toml\n[params.gitalk]\renable = true\rclientId = \u0026quot;\u0026quot;\rclientSecret = \u0026quot;\u0026quot;\rrepo = \u0026quot;\u0026quot; # 保存评论的repo\rowner = \u0026quot;\u0026quot; //app 所有者\radmin = \u0026quot;\u0026quot; //app 所有者\rperPage = 20 # 每页评论条数，最大100\rpagerDirection = \u0026quot;last\u0026quot; # 评论排序方式： 最新：last， 最早：first\r  配置comments.html 在layouts/_default/comments.html中添加一下代码：\n{{- if .Site.Params.valine.gitalk -}} \u0026lt;div id=\u0026quot;gitalk-container\u0026quot; class=\u0026quot;gcomments\u0026quot;\u0026gt;\u0026lt;/div\u0026gt;\r\u0026lt;link rel=\u0026quot;stylesheet\u0026quot; href=\u0026quot;https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css\u0026quot;\u0026gt;\r\u0026lt;script src=\u0026quot;https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt;\r\u0026lt;script\u0026gt;\rconst gitalk = new Gitalk({\rclientID: {{ .Site.Params.gitalk.clientId }},\rclientSecret: {{ .Site.Params.gitalk.clientSecret }},\rrepo: {{ .Site.Params.gitalk.repo }},\rowner: {{ .Site.Params.gitalk.owner }},\radmin: [{{ .Site.Params.gitalk.admin }}],\rid: location.pathname,\rlabels: {{ .Params.categories }},\rperPage: {{ .Site.Params.gitalk.perPage }},\rpagerDirection: {{ .Site.Params.gitalk.pagerDirection }},\r});\rgitalk.render('gitalk-container');\r\u0026lt;/script\u0026gt;\r{{ end }}\r  配置single.html 在layouts/_default/comments.html中添加一下代码：\n{{ if not ( eq .Params.comments false) }}\r{{ .Render \u0026quot;comments\u0026quot; }}\r{{ end }}     Gitalk 会申请授权者所有公共仓库的读写权限 静态网站会暴露OAuth Application的ID和密钥 Issue labels 会添加location.pathname(本站添加此字段)   ",
    "ref": "/blog/hugo/gitalk/"
  },{
    "title": "Hugo评论系统-Utteranc",
    "date": "",
    "description": "",
    "body": "  安装Utteranc\n 进入Utteranc GitHub App 在页面中选择你要添加的repo,进行安装    配置config.toml\n## Utterances\r[params.utterances]\renable = true\rrepo = \u0026quot;zylhorse/zylhorse.github.io\u0026quot; // 这里替换为你的github repo\rissueTerm = \u0026quot;title\u0026quot; // issue 标题， 基于当前文章标题/路径..\rtheme = \u0026quot;github-light\u0026quot; // 风格\rthemeDark = \u0026quot;photon-dark\u0026quot;\r 参考： https://utteranc.es/\n   配置comments.html 在layouts/_default/comments.html中添加一下代码：\n{{ if .Site.Params.utterances.enable }}\r\u0026lt;label\u0026gt;{{ jsonify .Params.categories }}\u0026lt;/label\u0026gt;\r\u0026lt;article class=\u0026quot;ucomments\u0026quot;\u0026gt;\r\u0026lt;script src=\u0026quot;https://utteranc.es/client.js\u0026quot;\rrepo={{ .Site.Params.utterances.repo }}\rissue-term={{ .Site.Params.utterances.issueTerm }}\rlabel={{ jsonify .Params.categories }} // 以categories作为issue的labels\rtheme={{ .Site.Params.utterances.theme }}\rcrossorigin=\u0026quot;anonymous\u0026quot;\rasync\u0026gt;\r\u0026lt;/script\u0026gt;\r\u0026lt;/article\u0026gt;\r{{ end }}\r  配置single.html 在layouts/_default/comments.html中添加一下代码：\n{{ if not ( eq .Params.comments false) }}\r{{ .Render \u0026quot;comments\u0026quot; }}\r{{ end }}   ",
    "ref": "/blog/hugo/utteranc/"
  },{
    "title": "Hugo评论系统-Valine",
    "date": "",
    "description": "",
    "body": "  注册LeanCloud开发版\n 创建LeanCloud应用 获取appId和appKey,用于以下配置    配置config.toml\n # Valine.\r# You can get your appid and appkey from https://leancloud.cn\r# more info please open https://valine.js.org\r[params.valine]\renable = true\rappId = \u0026quot;appId\u0026quot;\rappKey = 'appKey'\rnotify = false # 邮件通知\rverify = false # 是否需要验证码\ravatar = \u0026quot;\u0026quot; # 空字符串默认使用Gravatar头像\rplaceholder = '说点什么吧...'\rvisitor = true\r  配置comments.html 在layouts/_default/comments.html中添加一下代码：\n{{- if .Site.Params.valine.enable -}}\r\u0026lt;!-- id 将作为查询条件 --\u0026gt;\r\u0026lt;div id=\u0026quot;vcomments\u0026quot; style=\u0026quot;border: #4d99bf\u0026quot;\u0026gt;\u0026lt;/div\u0026gt;\r\u0026lt;script src=\u0026quot;//cdn1.lncld.net/static/js/3.0.4/av-min.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt;\r\u0026lt;script src='//unpkg.com/valine/dist/Valine.min.js'\u0026gt;\u0026lt;/script\u0026gt;\r\u0026lt;script type=\u0026quot;text/javascript\u0026quot;\u0026gt;\rnew Valine({\rel: '#vcomments' ,\rappId: '{{ .Site.Params.valine.appId }}',\rappKey: '{{ .Site.Params.valine.appKey }}',\rnotify: '{{ .Site.Params.valine.notify }}',\rverify: '{{ .Site.Params.valine.verify }}',\ravatar:'{{ .Site.Params.valine.avatar }}',\rplaceholder: '{{ .Site.Params.valine.placeholder }}',\rvisitor: '{{ .Site.Params.valine.visitor }}'\r});\r\u0026lt;/script\u0026gt;\r  配置single.html 在layouts/_default/comments.html中添加一下代码：\n{{ if not ( eq .Params.comments false) }}\r{{ .Render \u0026quot;comments\u0026quot; }}\r{{ end }}    评论时填写Gravatar注册邮箱，自动索引头像\nValine 评论通知和管理配置相对复杂，深度依赖Leancloud\n ",
    "ref": "/blog/hugo/valine/"
  },{
    "title": "Hugo评论系统",
    "date": "",
    "description": "",
    "body": "评论系统 Hugo自带Disqus评论系统，无法在国内加载。本系统采用Utterances。国内推荐以下评论系统：\n   名称 简介 优缺点     Valine 诞生于2017年8月7日，是一款基于LeanCloud的无后端评论系统 1.样式简洁,有回复功能 2. LeanCloud免费容器无法24小时在线，需要配置定时器，防止服务休眠3. Valine-Admin 可以实现评论管理，配置复杂度较高   Utterances 基于Github Issue的评论系统 1. 配置简单 2. 无回复功能 3. 基于Github Issue，可以进行评论管理   Gitalk 基于GitHub Issue和Preact开发的评论插件 1. 配置简单\n2. 有回复功能 3. 基于Github Issue，可以进行评论管理    ",
    "ref": "/blog/hugo/comments/"
  },{
    "title": "Hugo使用手册",
    "date": "",
    "description": "记录Hugo使用过程中遇到的问题",
    "body": "画图工具 https://app.diagrams.net/\nhttp://asciiflow.com/\nbind ip 使本地可被其他机器访问： hugo --bind x.x.x.x\n x.x.x.x 可以是0.0.0.0 也可以是本机ip\n 添加文章引用 Hugo 提供了两种 shortcode 用来在文档中插入引用链接地址： ref 和 relref ，语法如下：\n relref 插入被引用文档的相对链接地址，而 ref 则插入被引用文档的完整链接地址。 ref 和 relref 的唯一参数是文档路径+锚点组成的字符串，并且文档路径和锚点都是可选的  当参数中只含有文档路径时，会插入被引用文档的链接地址； 当参数中只含有锚点时，会插入当前文档的锚点链接地址； 当参数中二者都存在时，会插入被引用文档的锚点链接地址。     锚点是文档标题，如果标题有空格则将空格替换成中划线-\n ",
    "ref": "/blog/hugo/hugo/"
  },{
    "title": "Protocol Buffers - FAQ",
    "date": "",
    "description": "",
    "body": "本文讨论一些Protocol Buffers 开源项目的一些常见问题。 如果你有一些问题，这里没有回答，请加入讨论组并提问。\n普通问题 为什么发布Protocol Buffers？\n有以下几个原因:\n Protocol Buffers 在Google中几乎被每个人使用。我们有许多想要开源发布的项目在使用protocol buffers, 因此我们需要首先发布protocol bufeers。事实上，一些技术已经可以在开源项目中找到 - 如果你深入Google AppEngine 代码，你会发现它们。 我们愿意提供接收protocol buffers和XML的公共API, 因为这非常高效，而且我们只是把XML转换成protocol buffers。 我们认为Google之外的人会发现protocol buffers会很有用 将protocol buffers变成我们乐意发布的形式是有趣20%的项目。  为什么首次发布版本2？版本1发生了什么？\nprotocol buffers的初始版本(亦名Proto1)最早在2001年在Google内开始开发，经过多年的发展，当有人需要并且愿意自己做，就会萌生出新的特性。 就像任何以这种方式创造出来的东西一样，它有点混乱。我们得出的结论是，按照现在的样子发布代码是不可行的。\n版本2(Proto2)是一个完全重写的版本，尽管它保留了大部分的设计并使用了许多来自Proto1的实现思想。添加了一些功能，删除了一些。 然而，最重要的是，代码被清理干净，并且没有任何依赖于尚未开放源码的Google库。\n为什么命名为\u0026quot;Protocol Buffers\u0026quot;？\n这个名称源于该格式的早期，那时还没有协议缓冲区编译器来为我们生成类。 当时，有一个名为ProtocolBuffer的类，它实际上充当了单个方法的缓冲区。 用户可以通过调用AddValue(tag, value)等方法将tag/value对分别添加到这个缓冲区。 原始字节被存储在一个缓冲区中，一旦消息被构造好，这个缓冲区就可以被写出来。\n从那时起，名称中的“buffers”部分就失去了意义，但它仍然是我们使用的名称。今天，人们通常使用术语“protocol message”来指抽象意义上的message， “protocol buffer”指消息的序列化副本，“protocol message object”指表示已解析消息的内存对象。\nGoogle还有Protocol Buffers的任何专利吗？\nGoogle目前没有关于Protocol Buffers的授权专利，我们很高兴解决人们可能有的关于协议缓冲区和专利的任何担忧。\n技术类问题  Similar Technologies\n Protocol Buffers 和 XML 有什么不同?\n答案见概述页\nProtocol Buffers和ASN.1,COM,CORBA,Thrift,etc 有什么不同？\n我们认为所有这些系统都有优点和缺点。Google内部依赖protocol buffers，并且它是我们成功的重要组成部分， 但是这并不意味着它是所有问题的理想解决方案。你应该在自己项目中评估以上每一个选项。\n但是，值得注意的是，这些技术中有几种同时定义了交换格式和RPC(远程过程调用)协议。协议缓冲区只是一种交换格式。 它们可以很容易地用于RPC——实际上，它们对定义RPC services 的支持是有限的——但是它们没有绑定到任何一个RPC实现或协议。\n贡献  Contributing\n 我可以为Protocol Buffers添加对新语言的支持吗? 当然!实际上，协议缓冲区编译器的设计使编写自己的编译器变得很容易。查看CommandLineInterface类， 它是libprotoc库的一部分。\n我们鼓励您为新语言创建代码生成器和运行时库。 你应该开始你自己的，独立的项目-这样，你将有自由根据自己的需求来管理你的项目，而不会被我们的发布过程所阻碍。 也请加入Protocol Buffers 讨论组，让我们知道您的项目; 我们将很高兴链接到它，并帮助您解决设计问题。\n我可以为Protocol Buffers提供补丁吗？\n当然!请加入Protocol Buffers 讨论组和我们共同探讨。\n我可以为Protocol Buffers添加新功能吗？ 也许吧。我们总是喜欢建议，但我们对添加东西非常谨慎。多年来我们学到的一件事是，很多人对新功能都有有趣的想法。 这些特性中的大多数在特定的情况下是非常有用的，但是如果我们接受所有这些特性，Protocol Buffers就会变得臃肿，混乱。 所以，我们必须非常挑剔。在评估新特性时，我们会寻找那些非常有用或非常简单，或者希望两者兼而有之的新特性。 我们经常拒绝Google员工增加功能。我们甚至经常拒绝自己团队成员添加的功能。\n话虽如此，我们还是想听听你的想法。加入Protocol Buffers 讨论组并让我们知道。 我们或许能够帮助您找到一种方法，在不改变底层库的情况下完成您想做的事情。 或者，也许我们会决定你的功能是如此有用或如此简单，所以应该添加它。\n",
    "ref": "/blog/data-structure/protocol-buffers/faq/"
  },{
    "title": "Protocol Buffers - Version 3指南",
    "date": "",
    "description": "",
    "body": "本指南描述如何使用Protocol Buffers语言来构建Protocol Buffers数据结构。 包括.proto文件语法以及如何从.proto文件生成数据访问类。\n 所有示例指定语言为Go\n[PB2] 表示pb version2 的指南\n[PB3] 表示pb version3 的指南\n 定义Message  Defining A Message Type\n 首先看一个简单的例子。这里我们定义一个搜索请求的message格式，每条搜索请求包含查询字符串，整数页码和每页结果条数。\n示例:\n[PB2]\rsyntax = \u0026quot;proto2\u0026quot;;\rmessage SearchRequest {\rrequired string query = 1;\roptional int32 page_number = 2;\roptional int32 result_per_page = 3;\r}\r[PB3]\rsyntax = \u0026quot;proto3\u0026quot;;\rmessage SearchRequest {\rstring query = 1;\rint32 page_number = 2;\rint32 result_per_page = 3;\r}\rSearchRequest 定义了三个字段, 每个字段包含：type name = filed number; (参考规范)\n [PB3] .proto文件的首行指定当前使用的是proto3语法: 如果未指定，则PB编译器默认使用proto2。因此.proto文件的首行必须是非空、未注释。\n[PB3] 去掉label(required, optional)修饰，仅保留repeated。\n 生成结构:\n[PB2]\rtype SearchRequest struct {\rstate protoimpl.MessageState\rsizeCache protoimpl.SizeCache\runknownFields protoimpl.UnknownFields\rQuery *string `protobuf:\u0026quot;bytes,1,req,name=query\u0026quot; json:\u0026quot;query,omitempty\u0026quot;`\rPageNumber *int32 `protobuf:\u0026quot;varint,2,opt,name=page_number,json=pageNumber\u0026quot; json:\u0026quot;page_number,omitempty\u0026quot;`\rResultPerPage *int32 `protobuf:\u0026quot;varint,3,opt,name=result_per_page,json=resultPerPage\u0026quot; json:\u0026quot;result_per_page,omitempty\u0026quot;`\r}\r[PB3]\rtype SearchRequest struct {\rstate protoimpl.MessageState\rsizeCache protoimpl.SizeCache\runknownFields protoimpl.UnknownFields\rQuery string `protobuf:\u0026quot;bytes,1,opt,name=query,proto3\u0026quot; json:\u0026quot;query,omitempty\u0026quot;`\rPageNumber int32 `protobuf:\u0026quot;varint,2,opt,name=page_number,json=pageNumber,proto3\u0026quot; json:\u0026quot;page_number,omitempty\u0026quot;`\rResultPerPage int32 `protobuf:\u0026quot;varint,3,opt,name=result_per_page,json=resultPerPage,proto3\u0026quot; json:\u0026quot;result_per_page,omitempty\u0026quot;`\r}\r  [PB3] tag增加proto3版本说明 [PB3] string/int 等字段类型由指针转换变为非指针   字段类型  Specifying Field Types\n 上述示例，所有字段都是scalar-标量类型: 两个整数类型(page_number,result_per_page)和一个字符串类型(query).\n当然，你也可以指定复合类型的字段，包括枚举等更多类型。\n字段编号  Assigning Field Numbers\n 上述示例， message定义中的每个字段都指定了唯一编号。\n 编号用于标识message二进制格式中的字段，并且在使用message类型后不允许修改。 编号在1-15之间的字段，使用单字节编码，包含字段编号和字段类型。 编号在16-2047之间的字段，使用双字节编码。 保留1-15编号给经常使用的字段，为将来可能添加的经常使用的字段预留空间。 编号可以被指定的最小值为1，最大为2^29 -1或者536,870,911。 编号19000-19999保留给Protocol Buffers内部使用，如果这些编号被使用，编译器会报错。 同样不能使用早先的reserved字段编号  字段规则  Specifying Field Rules\n message中字段规则如下：\n singular:表示该字段是单数规则。 repeated:表示该字段是复数规则，保留重复值的顺序。   proto3语法默认字段是singular规则\nproto3中scalar数字类型默认使用packed 编码\n 新加message  Adding More Message Types\n 多个message可以定义在单个.proto文件中。这对定义多个关联message是有用的。 例如: 我们想定义请求应答message,可以将其添加到相同的.proto文件中:\nmessage SearchRequest {\rstring query = 1;\rint32 page_number = 2;\rint32 result_per_page = 3;\r}\rmessage SearchResponse {\r...\r}\r增加注释  Adding Comments\n .proto文件中添加注释，使用C/C++风格的//或者/* ... */。\n/* SearchRequest represents a search query, with pagination options to\r* indicate which results to include in the response. */\rmessage SearchRequest {\rstring query = 1;\rint32 page_number = 2; // Which page number do we want?\rint32 result_per_page = 3; // Number of results to return per page.\r}\rreserved字段  Reserved Fields\n 通过删除或注释字段，修改message数据结构， 将来修改该message时，是可以复用这些字段编号的。\n如果后续加载该.proto文件的旧版本，会引起严重问题，包括数据损坏、隐私漏洞等。\nreserved这些删除字段的编号或名称(名称同样会引起JSON序列化的问题)可以解决该问题。\n protocol buffers编译器会拒绝其它字段使用这些reserved的编号和名称。\n message Foo {\rreserved 2, 15, 9 to 11;\rreserved \u0026quot;foo\u0026quot;, \u0026quot;bar\u0026quot;;\r}\r 不能将字段名称和字段编号混合在一条reserved语句中\n .proto生成什么  What\u0026rsquo;s Generated From Your .proto?\n 当我们使用protocol buffer编译器编译.proto文件时，将会编译生成指定语言的文件， 包括message数据结构，getting和setting字段，序列化和反序列化message。\n C++: 编译生成.h和.cc文件，包含为每个message指定一个class; Java: 编译生成.java文件，包含为每个message指定一个class,包含创建message类实例的Builder类； Go: 编译生成.pb.go文件,在文件中为每个message指定一个类型 \u0026hellip;  可以根据所选语言的教程了解更多有关如何使用每种语言的api的信息。更多的API细节，请参阅相关的参考。\n标量类型  Scalar Value Types\n message中的标量字段可以是以下类型(下表展示.proto字段类型和自动生成类中对应的类型)\n   .proto Type Notes C++ Type Java Type Python Type[2] Go Type Ruby Type C# Type PHP Type Dart Type     double  double double float float64 Float double float double   float  float float float float32 Float float float double   int32 使用变长编码。编码负数效率低下，如果字段可能有负值，使用sint32 int32 int int int32 Fixnum or Bignum (as required) int integer int   int64 使用变长编码。编码负数效率低下，如果字段可能有负值，使用sint64 int64 long int/long[3] int64 Bignum long integer/string[5] Int64   uint32 使用变长编码 uint32 int[1] int/long[3] uint32 Fixnum or Bignum (as required) uint integer int   uint64 使用变长编码 uint64 long[1] int/long[3] uint64 Bignum ulong integer/string[5] Int64   sint32 使用变长编码。有符号整数。比常规的int32对负数的编码效率更高 int32 int int int32 Fixnum or Bignum (as required) int integer int   sint64 使用变长编码。有符号整数。比常规的int64对负数的编码效率更高 int64 long int/long[3] int64 Bignum long integer/string[5] Int64   fixed32 4字节定长编码。如果数值大于2^28则编码效率比uint32。 uint32 int[1] int/long[3] uint32 Fixnum or Bignum (as required) uint integer int   fixed64 8字节定长编码。如果数值大于2^56则编码效率比uint64。 uint64 long[1] int/long[3] uint64 Bignum ulong integer/string[5] Int64   sfixed32 4字节定长编码。 int32 int int int32 Fixnum or Bignum (as required) int integer int   sfixed64 8字节定长编码。 int64 long int/long[3] int64 Bignum long integer/string[5] Int64   bool  bool boolean bool bool TrueClass/FalseClass bool boolean bool   string 字符串必须始终包含UTF-8编码或7位ASCII文本，长度不能超过2^32 string String str/unicode[4] string String (UTF-8) string string String   bytes 包含长度不超过2^32的任意字节序列 string ByteString str []byte String (ASCII-8BIT) ByteString string List     可以在Protocol Buffer Encoding中了解更多序列化message时字段类型是怎样编码的。\n  Java中,unsigned 32和64 位整数使用对应的类型表示， 高位仅保存在有符号位。 在所有情况下，为字段设置值时都要执行类型检查，确认其有效性。 64位或unsigned 32位整数在解码时总是表示为long，但是如果在设置时指定int，则可以表示int。在所有情况下，值必须符合设置时表示的类型。参看[2] Python中，string在解码时表示为unicode，但如果指定了ASCII string则可以为str Integer在64位机器上使用，string在32位机器上使用。  默认值  Default Values\n 当解析message时，如果编码的message不包含某个元素时，则解析对象中对应的字段被设置为该字段的默认值。默认值为一下类型:\nstrings =\u0026gt; 空string bytes =\u0026gt; 空bytes bools =\u0026gt; false numerics =\u0026gt; 0 enums =\u0026gt; enum中首个值，必须时0 message =\u0026gt; 取决于语言依赖 repeated =\u0026gt; 空(多数语言中为空列表)  一旦message被解析，就没有方法来知道一个字段是否被明确的设置为默认值(例如一个boolean值，是否设置为false)或者根本没设置：这点在定义message时要牢记。\n例如： 如果你不希望某些行为在默认情况下也发生，不要在boolean被设置为false时，开启某些行为。 同时如果message中的字段被设置为默认值，则其值在网络传输中不会被序列化。\n 有关默认值在生成代码中的使用详细说明，请参考指定语言的指南\n枚举类型  Enumerations\n 当您定义消息类型时，您可能希望它的一个字段只有一个预定义的值列表。\n例如，假设您想为每个SearchRequest添加一个语料库字段，其中的语料库可以是通用的、WEB、图像、本地的、新闻、产品或视频。 为此，您可以非常简单地向消息定义添加一个枚举，该枚举为每个可能的值添加一个常量。\n在下面的例子中，我们添加了一个名为Corpus的枚举，包含所有可能的值，以及一个类型为Corpus的字段:\nmessage SearchRequest {\rstring query = 1;\rint32 page_number = 2;\rint32 result_per_page = 3;\renum Corpus {\rUNIVERSAL = 0;\rWEB = 1;\rIMAGES = 2;\rLOCAL = 3;\rNEWS = 4;\rPRODUCTS = 5;\rVIDEO = 6;\r}\rCorpus corpus = 4;\r}\r如上所见，Corpus枚举的第一个常量映射为0: 每个枚举类型都需要将其第一个元素映射为0.因为:\n 必须有一个0值，因此可以使用0作为数字默认值 0值必须是第一个元素，为了兼容proto2的规范，枚举的第一个值作为默认值。  可以通过给enum中的不同常量设置相同值来定义别名。如果这样做，需要设置option allow_alias = true, 否则编译器编译时会报错。\nmessage MyMessage1 {\renum EnumAllowingAlias {\roption allow_alias = true;\rUNKNOWN = 0;\rSTARTED = 1;\rRUNNING = 1;\r}\r}\rmessage MyMessage2 {\renum EnumNotAllowingAlias {\rUNKNOWN = 0;\rSTARTED = 1;\r// RUNNING = 1; // Uncommenting this line will cause a compile error inside Google and a warning message outside.\r}\r}\r 枚举类型中的常量值必须是32位的整数范围。 enum在网络传输中使用变长编码，使用负数是低效的， 因此不推荐\n  将enum定义在一个message的结构中，如上述示例。  可以在其它message中，使用该语法定义字段： _MessageType_._EnumType_   将enum定义在message结构之外-enum可以被.proto文件中所有的message引用。  当编译包含enum的.proto文件时，生成代码中会有对应语言(Java/C++)的枚举类型。 一个特殊的Python枚举描述符类，用于在运行时生成的类中创建一组带有整数值的符号常量\n 警告: 生成代码中enum数量，受对应语言的限制(可能低于1000)。 请确定使用语言的限制。\n 反序列化时，未识别的enum值将被保留在message中， 尽管反序列化message时如何表示该值取决于语言。\n 在支持open enum类型的语言中，超出指定符号范围的enum值，比如C++和Go语言中，未识别的enum值直接作为整数类型保存。 在closed enum类型的语言中，比如Java，enum中的大小写表示无法识别的值，使用指定的访问器可以访问该值。  无论哪种情况，在message序列化时，未识别的enum值，仍然与message一起序列化。\n有关enum使用方法的更多信息，请参考指定语言的generated code guide\n保留值  Reserved Values\n 通过删除或注释enum中的元素，来修改enum, 将来修改enum时， 是可以复用这些元素对应的数值的。\n如果后续加载该.proto文件的旧版本，会引起严重问题，包括数据损坏、隐私漏洞等。\nreserved这些删除元素对应的值或名称(名称同样会引起JSON序列化的问题)可以解决该问题。\n protocol buffers编译器会拒绝其它enum元素使用这些reserved的标识符。\n 也可以使用max关键字指定reserved的数值区间为最大值。\nenum Foo {\rreserved 2, 15, 9 to 11, 40 to max;\rreserved \u0026quot;FOO\u0026quot;, \u0026quot;BAR\u0026quot;;\r}\r 不能将元素名称和数值混合在一条reserved语句中\n 使用其它message类型  Using Other Message Types\n 可以将其它message类型，定义为当前message的字段。\n例如： 我们需要在每一个SearchResponse message中包含Result message,则可以将这两个message定义到一个.proto文件中:\nmessage SearchResponse {\rrepeated Result results = 1;\r}\rmessage Result {\rstring url = 1;\rstring title = 2;\rrepeated string snippets = 3;\r}\r导入定义  Importing Definitions\n  此特性Java中不可用\n 在上述示例中，Reslut message和SearchResponse message定义在同一个.proto文件中。 如果想要使用的message已经在其它.proto文件中定义。怎么办？\n我们可以使用import语句来导入其它的.proto文件。import语句需要添加到.proto文件的头部：\nimport \u0026quot;project/other_protos.proto\u0026quot;;\r通常我们通过直接improt来使用其它message。但是，有些时候会移动.proto文件位置。 为了避免.proto文件移动时，需要修改所有导入它的.proto文件，我们可以在原有位置放置一个虚拟的.proto文件， 使用import public语法将所有的improt指向新的位置。任何包含import public语句的文件都可以传递依赖。\n示例： new.proto\n// All definitions are moved here\rsyntax = \u0026quot;proto3\u0026quot;;\rpackage newpkg;\roption go_package = \u0026quot;project/newpkg\u0026quot;;\rmessage OtherMessage {\r...\r}\rold.proto\n// This is the proto that all clients are importing.\rsyntax = \u0026quot;proto3\u0026quot;;\rpackage oldpkg;\roption go_package = \u0026quot;project/oldpkg\u0026quot;;\rimport public \u0026quot;project/newpkg/new.proto\u0026quot;;\rimport \u0026quot;project/other.proto\u0026quot;;\rclient.proto\nimport \u0026quot;project/oldpro/old.proto\u0026quot;;\r// You use definitions from old.proto and new.proto, but not other.proto\rmessage ClientMessage {\rnewpkg.OtherMessage OthMsg = 1;\r}\r编译器根据命令行参数-I/\u0026ndash;proto_path 指定的一组目录来搜索导入的.proto文件。如果未指定参数，则在调用编译器的目录搜索。 通常需要指定\u0026ndash;proto_path为项目的根目录并且包含所有import文件的全路径。\n示例：\nprotoc --proto_path=\u0026quot;src\u0026quot; \\\r--proto_path=\u0026quot;src/project\u0026quot; \\\r--go_out=build/gen \\\r--go_opt=paths=source_relative \\\rclient.proto message类型proto2  Using proto2 Message Types\n 可以在proto3 message中导入proto2 message类型，反之亦然。 但是在proto3的语法中不能直接使用proto2 enum(如果导入的proto2 message中使用enum是没问题的)。\n嵌套类型  Nested Types\n 可以在其它message中定义和使用message。以下示例中，Result在SearchResponse中定义:\nmessage SearchResponse {\rmessage Result {\rstring url = 1;\rstring title = 2;\rrepeated string snippets = 3;\r}\rrepeated Result results = 1;\r}\r如果想在其它message中复用Result, 语法为_Parent_._Type_:\nmessage OtherMessage {\rSearchResponse.Result result = 1;\r}\r一般消息可以随意嵌套:\nmessage Outer { // Level 0\rmessage MiddleAA { // Level 1\rmessage Inner { // Level 2\rint64 ival = 1;\rbool booly = 2;\r}\r}\rmessage MiddleBB { // Level 1\rmessage Inner { // Level 2\rint32 ival = 1;\rbool booly = 2;\r}\r}\r}\r更新message  Updating A Message Type\n 如果现有的message不再满足你所有需求，例如，你希望message格式有一个额外的字段，但是仍想要使用旧代码格式创建它。 。不要担心，可以很简单的修改message,而不需要修改现有代码。 只要遵守以下规则:\n  不要修改现有字段的编号。\n  新增字段\n 使用旧代码格式序列化的message,仍然可以被新的代码解析。你需要记住这些字段的默认值，以便 新代码可以与旧代码生成的message准确的交互。 同样的新代码生成的message可以被旧代码解析：旧代码在解析时直接忽略新字段。参见未知字段    字段可以被删除，只要在更新的message中不在使用该字段编号。你想要重命名字段，可以添加前缀OBSOLETE_，或者reserved字段编号。 这样你的.proto用户就不会意外的复用这个编号了。\n  int32,uint32,int64,uint64,bool都是兼容的，这意味着你可以将字段从一个类型修改为另一种类型，而不会打破向前或向后的兼容性。 如果从网络传输中解析的数字不匹配相应的类型，你会得到与在C++中将数字转换成该类型同样的效果(e.g. 如果64位数字被读取为int32,它将被截取为32位)。\n  sint32,sint64是相互兼容的，但是不兼容其它的整数类型。\n  string,bytes是兼容的，只要bytes是有效的UTF-8\n  内嵌message和bytes是兼容的，只要bytes包含message的编码版本。\n  fixed32和sfixed32是兼容的，fixed64和sfixed64是兼容的。\n  string,bytes和message字段，这些数据的optional和repeated是兼容的。输入一个repeated字段的序列化数据，希望字段是optional的客户端， 将获取最后一个输入值(如果字段是原始类型)或者合并所有的输入元素(如果字段是message类型)。\n 这对于数字类型包括bool和enum，通常是不安全的。 数字类型的repeated字段可以使用packed格式序列化，当期望是optional字段时，可能会解析错误。\n   enum和int32,uint32,int64,uint64是兼容的(如果不匹配，值会被截取)。但是需要注意，当反序列化message时，客户端代码对它们有不同的处理：\n例如，无法识别的proto3 enum类型将保存在message中，但是反序列化message时,如何表示该类型依赖具体的语言实现。Int字段总是保留他们的值。\n  修改单个值作为新的oneof的成员是安全，且二进制兼容的。\n 移动多个字段到新的oneof中是安全的，如果你确定代码不会同时设置多个。 移动任意的字段到已经存在的oneof中是不安全的。    未知字段  Unknown Fields\n 未知字段是格式良好的protocol buffer数据，表示解析器无法识别的字段。例如： 当旧代码解析新代码生成的带有新字段的数据时， 这些新字段在旧的代码中编程未知字段。\n最初的，proto3 message在解析时，总是丢弃未知字段。但是在3.5版本，重新提出要保留未知字段，用以匹配proto2的行为。 在3.5及后续版本，未知字段在解析时被保留，并且包含在序列化输出中。\nAny类型  Any\n Any message 类型允许你将message作为嵌入类型使用，不需要import它们的.proto。Any包含任意序列化message,以及 描述序列化message类型唯一标识的URL。使用Any类型，需要import google/protobuf/any.proto：\nimport \u0026quot;google/protobuf/any.proto\u0026quot;;\rmessage ErrorStatus {\rstring message = 1;\rrepeated google.protobuf.Any details = 2;\r}\r给定message类型的默认URL为：type.googleapis.com/_packagename_._messagename_。\n不同类型的语言实现将支持运行时库助手，以类型安全的方式封装和解封Any数据。例如： Java中，Any类型包含指定的pack()和unpack()访问器， C++中包含PackFrom()和UnpackTo()方法:\n// Storing an arbitrary message type in Any.\rNetworkErrorDetails details = ...;\rErrorStatus status;\rstatus.add_details()-\u0026gt;PackFrom(details);\r// Reading an arbitrary message from Any.\rErrorStatus status = ...;\rfor (const Any\u0026amp; detail : status.details()) {\rif (detail.Is\u0026lt;NetworkErrorDetails\u0026gt;()) {\rNetworkErrorDetails network_error;\rdetail.UnpackTo(\u0026amp;network_error);\r... processing network_error ...\r}\r}\rGo中包含ptypes.MarshalAny()和ptypes.UnmarshalAny():\n// .proto file\rmessage SomeMessage {\rgoogle.protobuf.Any am = 1;\r}\rmessage OtherMessage {\rrepeated string ss = 1;\r}\r//Storing an arbitrary message type in Any.\rom := proto2.OtherMessage{\rSs: []string{\u0026quot;hello\u0026quot;, \u0026quot;world\u0026quot;},\r}\ram, _ := ptypes.MarshalAny(\u0026amp;om)\rsm := proto2.SomeMessage{\rAm: am,\r}\rtm, _ := proto.Marshal(\u0026amp;sm)\r// Reading an arbitrary message from Any.\romm := proto2.OtherMessage{}\rsmm := proto2.SomeMessage{}\rproto.Unmarshal(tm, \u0026amp;smm)\rptypes.UnmarshalAny(smm.GetAm(), \u0026amp;omm)\r目前处理Any类型的运行时库正在开发中。\n如果你已经熟悉proto2语法，Any可以保存任意proto3 message,类似于proto2 message允许extension。\noneof类型  Oneof\n 如果你的message有很多字段， 同时最多设置某一个字段，你可以使用oneof特性来强制执行此行为和节约内存。\noneof字段和常规字段一样，除了所有字段都在oneof共享内存中和同时最多设置一个字段。设置oneof的任意成员，会自动清理其它所有成员。 你可以使用case()和WhichOneOf()方法，检查oneof中的哪一个值被设置了，这依赖于你选择的语言。\noneof使用  Using Oneof\n 在.proto文件中定义oneof:\nmessage SampleMessage {\roneof test_oneof {\rstring name = 4;\rSubMessage sub_message = 9;\r}\r}\r除了map和repeated等类型，oneof定义中可以添加任何其它类型的字段。\n在生成的代码中，oneof字段和常规字段一样有setter和getter。同时还有一个指定的方法检查oneof中哪个值被设置。 在相关的API reference中， 你可以找到关于所选语言的oneof API的更多信息。\noneof特性  Oneof Features\n   设置oneof字段会自动清理oneof中的所有其它成员。因此如果你设置多个oneof字段，只有你最后设置的字段有值。\nSampleMessage message;\rmessage.set_name(\u0026quot;name\u0026quot;);\rCHECK(message.has_name());\rmessage.mutable_sub_message(); // Will clear name field.\rCHECK(!message.has_name());\r  如果解析器遇到通信中同一个oneof被设置多个成员，在解析后的message中只有最后看到的成员被使用。\n  oneof 不能是repeated\n  反射API适用于oneof字段\n  如果设置oneof字段为默认值(比如，设置一个int32类型的oneof字段为0)，将设置其中一个字段，并且该值会在网络传输中会被序列化。\n  如果你使用的是C++,确保你的代码不会引起内存崩溃。以下示例代码会崩溃，因为sub_message已经被删除了，通过调用set_name()方法。\nSampleMessage message;\rSubMessage* sub_message = message.mutable_sub_message();\rmessage.set_name(\u0026quot;name\u0026quot;); // Will delete sub_message\rsub_message-\u0026gt;set_... // Crashes here\r  同样在C++中，如果你Swap()包含oneof字段的message, 每个message都将以对方的oneof结尾。以下示例， msg1有sub_message，msg2有name:\nSampleMessage msg1;\rmsg1.set_name(\u0026quot;name\u0026quot;);\rSampleMessage msg2;\rmsg2.mutable_sub_message();\rmsg1.swap(\u0026amp;msg2);\rCHECK(msg1.has_sub_message());\rCHECK(msg2.has_name());\r  向后兼容性问题  Backwards-compatibility issues\n 在增加或删除oneof字段时，需要注意。如果检查oneof的值返回None/NOT_SET，这可能意味着oneof还没有被设置 或者被设置成oneof的不同版本。没有方法能区分不同，因为无法区分网络传输的未知字段是否是oneof的成员。\nTag复用问题\n Tag Reuse Issues\n  从oneof移入或移出字段：在message被序列化和解析后，你会丢失一些信息(某些字段被清理)。但是，移动单个字段到新的oneof中是安全的， 并且如果已知只设置其中一个字段，是可以移动多个字段的。 删除一个oneof字段，并将它重新添加回来：在message序列化和解析后，会清除你当前设置的oneof字段。 切分或合并oneof: 这与移动常规字段有同样的问题。  Maps 如果想要创建一个map作为数据定义的一部分，protocol buffer提供了简单快捷的语法:\nmap\u0026lt;key_type, value_type\u0026gt; map_field = N;\rkey_type可以是任意的整数或字符串类型(除了浮点和bytes以外的所有标量类型)。enum不是有效的key_type。 value_type可以是除其它map外的任意类型。\n例如，你想要创建一个projects的map，其中每项Project message和string键关联，可以这样定义：\nmap\u0026lt;string, Project\u0026gt; projects = 3;\r Map字段不能是repeated 网络格式顺序和map迭代器对map的排序是未知的，因此你不能期待map中的项以特定顺序排序。 当.proto生成文本格式时，maps对key进行排序。 数字类型的key按数字排序。 当从网络数据上解析或合并时，如果有重复的map key，使用最后看到的key。当从文本格式解析map时，如果有重复的key解析可能会报错。 如果你为map字段提供一个key但是没值，该字段的序列化结果依赖具体的语言实现。在C++,Java,Python,Go中，默认值会被序列化，其它语言可能不会。  生成map API目前适用于所有proto3支持的语言。\n向后兼容  Backwards compatibility\n 在网络上，map语法等价于下面的语法，因此不支持map的protocol buffers实现，依然可以处理你的数据：\nmessage MapFieldEntry {\rkey_type key = 1;\rvalue_type value = 2;\r}\rrepeated MapFieldEntry map_field = N;\r任何支持map的protocol buffers实现，必须生成和接收上述定义可以接受的数据。\nPackages 你可以为.proto文件添加可选的package说明符，防止message类型之间的命名冲突。\npackage foo.bar;\rmessage Open { ... }\r然后你可以在定义message类型的字段时，使用上述的package描述符\nmessage Foo {\r...\rfoo.bar.Open open = 1;\r...\r}\rpackage说明符影响生成代码的方式取决于你选择的语言:\n C++,生成class被包装在C++的命名空间中(namespace)。例如Open会在命名空间foo::bar中。 Java,package被用作Java package, 除非你在.proto文件中，明确的提供java_package可选项。 Python,package指令被忽略，因为Python模块是根据它们在文件系统中的位置来组织的。 Go,package被用作Go package名，除非你在.proto文件中，明确的提供go_package可选项。 Ruby,生成的class被包装在内嵌的Ruby命名空间中，生成的类被包装在嵌套的Ruby名称空间中， 并转换为所需的Ruby大写风格(首字母大写;如果第一个字符不是字母，前缀为PB_)。例如，Open应该在命名空间Foo::Bar中。 C#,这个包在转换为PascalCase之后被用作命名空间，除非您在.proto文件中显式地提供了一个选项csharp_namespace。 例如，Open应该在名称空间Foo.Bar中。  Package和名称解析  Packages and Name Resolution\n protocol buffer语言中的名称解析，工作类似于C++: 首先搜索最内层的范围，然后搜索下一个最内层的范围， 以此类推，每个包都被认为是其父包的“内部”。.开头(例如:`.foo.bar.Baz)意味着从最外层的作用域开始查找。\nprotocol buffer编译器通过解析导入的.proto文件来解析所有类型名。每种语言的代码生成器都知道如何引用该语言中的每种类型，即使它有不同的作用域规则。\n服务定义  Defining Services\n 如果你想在RPC(Remote Procedure Call)系统中使用你的message类型, 你可以在.proto文件中定义RPC service接口， protocol buffer编译器会生成你指定语言的service接口代码和stubs。例如，你想要定义一个带有一个方法的RPC service， 方法可以接收SerachRequest并返回SerachResponse。你可以在.proto文件中定义它，如下所示：\nservice Searchservice {\rrpc Search(SearchRequest) returns (SearchResponse);\r}\r与协议缓冲区一起使用的最直接的RPC系统是gRPC:Google开发的语言和平台无关的开源RPC系统。 gRPC在协议缓冲区方面工作得特别好，它允许你使用一个特殊的protocol buffer编译器插件，直接从你的.proto文件中生成相关的RPC代码。\n如果您不想使用gRPC，也可以在您自己的RPC实现中使用protocol buffer。 你可以在Proto2 Language Guide中找到更多。\n还有许多正在进行的第三方项目为protocol buffer开发RPC实现。有关我们所知项目的链接列表， 请参阅第三方附加组件wiki页面。\nJSON映射  JSON Mapping\n proto3支持JSON格式的规范编码，使它在系统之间共享数据更简单。下表中，根据类型逐一描述编码。\n如果JSON编码的数据中缺少值或者值为null，在解析为protocol buffer时，它将被解析为适当的默认值。 如果protocol buffer中的字段时默认值，默认情况下，在JSON编码数据中它将被忽略，用来节省空间。具体的实现可以提供选项，以便默认值字段在JSON编码输出中。\n   proto3 JSON JSON example Notes     message object {\u0026ldquo;fooBar\u0026rdquo;: v, \u0026ldquo;g\u0026rdquo;: null, …} 生成JSON对象。message字段名被映射成小驼峰，并成为JSON对象的key。如果字段选项json_name被指定，指定的值将被用作key。解析器接收小驼峰名称(或者通过json_name选项指定的名称)和原始的proto字段名。null是所有的字段类型可接受的值并且作为相应字段类型的默认值处理。   enum string \u0026ldquo;FOO_BAR\u0026rdquo; 使用proto中指定的enum值的名称。解析器接受enum名称和整数值。   map\u0026lt;K,V\u0026gt; object {\u0026ldquo;k\u0026rdquo;: v, …} 所有key值都转换为string类型。   repeated V array [v, …] null被接受为空列表 [].   bool true, false true, false    string string \u0026ldquo;Hello World!\u0026rdquo;    bytes base64 string \u0026ldquo;YWJjMTIzIT8kKiYoKSctPUB+\u0026rdquo; JSON值将是带填充的标准base64编码的字符串数据。包含或不包含填充的标准或URL安全的base64编码都可以接受。   int32, fixed32, uint32 number 1, -10, 0 JSON值将是十进制数字。数字或字符串可以接受。   int64, fixed64, uint64 string \u0026ldquo;1\u0026rdquo;, \u0026ldquo;-10\u0026rdquo; JSON值将是十进制字符串。数字或字符串可以接受。   float, double number 1.1, -10.0, 0, \u0026ldquo;NaN\u0026rdquo;, \u0026ldquo;Infinity\u0026rdquo; JSON值将是数字或者以下指定的字符串值: NaN, Infinity,-Infinity。数字或字符串都可以接受。指数技法也接受。-0认定等于0。   Any object {\u0026quot;@type\u0026quot;: \u0026ldquo;url\u0026rdquo;, \u0026ldquo;f\u0026rdquo;: v, … } 如果Any包含指定的JSON映射值，则转换为:{\u0026quot;@type\u0026quot;: xxx, \u0026ldquo;value\u0026rdquo;: yyy}。否则，如果转换成JSON对象，@type字段会被插入，用来表明真正的数据类型。   Timestamp string \u0026ldquo;1972-01-01T10:00:20.021Z\u0026rdquo; 参考RFC 3339, 生成Z规格的输出，并且使用0,3,6,9小数位数。除Z以外的偏移量都可以接受。   Duration string \u0026ldquo;1.000340012s\u0026rdquo;, \u0026ldquo;1s\u0026rdquo; 生成的输出总是包含0、3、6或9个小数位数, 根据所需的精度，后面加上后缀“s”。接受任何小数位数(也为none)，只要它们符合纳秒精度，并且需要后缀“s”   Struct object { … } JSON struct 对象. 参考struct.proto   Wrapper types various types 2, \u0026ldquo;2\u0026rdquo;, \u0026ldquo;foo\u0026rdquo;, true, \u0026ldquo;true\u0026rdquo;, null, 0, … 包装器在JSON中使用与包装原始类型相同的表示，除了null之外，在数据转换和传输期间允许并保留。   FieldMask string \u0026ldquo;f.fooBar,h\u0026rdquo; 参考field_mask.proto   ListValue array [foo, bar, …]    Value value  任意JSON值。参考google.protobuf.Value   NullValue null  null   Empty object {} 空JSON对象    JSON选项  JSON options\n proto3 JSON的实现可能提供以下选项：\n 输出默认值: 默认值字段在proto3 JSON输出中，默认是忽略的。具体实现需要提供一个选项来覆盖此行为，并用它们的默认值输出字段。 忽略未知字段：Proto3 JSON解析器默认拒绝未知字段，但是需要提供一个选项，在解析时忽略未知字段。 使用proto字段名代替驼峰命名: 默认情况，proto3 JSON 打印器将字段名转换为驼峰格式，并且使用它作为JSON名称。 具体实现需要提供一个用proto字段名替换JSON名称的选项。proto3 JSON解析器需要同时接受转换后的驼峰命名和proto字段名。 输出enum值为整型而不是字符串类型: Emit enum values as integers instead of strings: enum值的名称用作JSON输出的默认值。需要提供一个用整数替换enum值名的选项。  Options .proto文件中的个人定义，可以用一组option注解。option不会改变定义的总体含义，但可能影响在特定上下文中处理定义的方式。 可用option的完整定义列表在文件google/protobuf/descriptor.proto中\n一些option是文件级别的，意味着它们应该写在顶级作用域，不应该在任何message,enum或service定义中。\n一些option是message级别的， 意味着它们应该写在messgee定义中。\n一些option是字段字节的，意味着它们应该卸载字段定义中。\noption也可以写在enum类型,enum值，oneof字段，service类型和service方法中。 但是目前它们没有可用的选项。\n以下是一些常用的option：\n  java_package(文件选项):希望用于生成的Java类的包。如果在.proto文件中没有给出显式的java_package选项， 那么默认情况下将使用proto包(使用.proto文件中的“package”关键字指定)。然而，proto包通常不能成为好的Java包， 因为proto包不希望以反向域名开始。如果不生成Java代码，则此选项将不起作用。\noption java_package = \u0026quot;com.example.foo\u0026quot;;\r  java_outer_classname (文件选项): 希望生成的最外层Java类的类名(因此是文件名)。如果在.proto文件中没有指定显式的java_outer_classname， 则将通过将.proto文件名转换为驼鹿大小写(因此foo_bar.classname)来构造类名。原型成为FooBar.java)。如果不生成Java代码，则此选项将不起作用\noption java_outer_classname = \u0026quot;Ponycopter\u0026quot;;\r  java_multiple_files (文件选项): 如果为false，则只会为这个.proto文件生成一个.Java文件，以及所有的Java类/枚举/等等。 为顶级消息、服务和枚举生成的文件将嵌套在一个外部类中(请参阅java_outer_classname)。如果为true，将为每个Java类/枚举/等生成单独的.Java文件。 为顶级消息、服务和枚举生成的Java“外部类”，以及为这个.proto文件生成的Java“外部类”将不包含任何嵌套类/枚举/等等。 这是一个布尔选项，默认为false。如果不生成Java代码，则此选项将不起作用。\noption java_multiple_files = true;\r  optimize_for (文件选项): 可以是SPEED,CODE_SIZE或LITE_RUNTIME。这将以以下方式影响c++和Java代码生成器(可能还有第三方生成器):\n SPEED(默认): protocol buffer编译器将生成用以序列化，解析和对message执行其它的常规操作的代码。这段代码是高度优化的。 CODE_SIZE: protocol buffer编译器将生成最小类，并依赖于共享的、基于反射的代码实现序列化，解析和其它操作。 这样生成代码的体积将会比SPEED小很多，但是操作会变慢。类将生成和SPEED模式相同的公共API。这种模式对于有很多.proto文件的应用程序很有用， 并不需要所有.proto文件都盲目的快。 LITE_RUNTIME: protocol buffer编译器将生成仅依赖\u0026quot;lite\u0026quot;运行时库的类(libprotobuf-lite替代libprotobuf)。 lite运行时比完整库要小得多(大约小一个数量级)，但省略了某些特性，如描述符和反射。这对于运行在手机等受限平台上的应用程序特别有用。 编译器仍然会像在SPEED模式下一样生成所有方法的快速实现。生成的类将只在每种语言中实现MessageLite接口，它只提供完整Message接口的方法子集。  option optimize_for = CODE_SIZE;\r  cc_enable_arenas (文件选项): 为c++生成的代码启用竞技场分配\n  objc_class_prefix (文件选项): 设置Objective-C类的前缀，它会被所有Objective-C生成的类和这个.proto中的枚举所前缀。不存在违约。 你应该使用Apple推荐的3-5个大写字母之间的前缀。注意，所有2个字母的前缀都由苹果保留。\n  deprecated (字段选项): 如果设置为true，表明这个字段是废弃的，并且不应该在新的代码中使用。在大多数语言中这个选项无实际用处。 Java中，它编程@Deprecated注解。将来，其他特定于语言的代码生成器可能会在字段的访问器上生成弃用注释，这反过来会在编译试图使用该字段的代码时发出警告。 如果该字段没有被任何人使用，并且您希望防止新用户使用它，请考虑用reserved语句替换该字段定义。\nint32 old_field = 6 [deprecated = true];\r  自定义选项  Custom Options\n protocol buffers允许你定义和使用自己的option。这是一个大多数人不需要的高级特性。 如果需要请参考Proto2 指南。 注意，创建自定义选项需要使用扩展，而在proto3中，只有自定义选项才允许使用扩展。\n生成自己的类  Generating Your Classes\n 要生成Java、Python、c++、Go、Ruby、Objective-C或c#代码，您需要使用.proto文件中定义的message类型，您需要在.proto文件上运行protocol buffer编译器。 如果您还没有安装编译器，请下载该包并按照README中的说明进行操作。 对于Go，你还需要为编译器安装一个特殊的代码生成器插件:你可以在GitHub上的golang/protobuf存储库中找到这个插件和安装说明。\nprotocol buffer编译器调用命令如下：\nprotoc --proto_path=IMPORT_PATH --cpp_out=DST_DIR --java_out=DST_DIR --python_out=DST_DIR --go_out=DST_DIR --ruby_out=DST_DIR --objc_out=DST_DIR --csharp_out=DST_DIR path/to/file.proto\r IMPORT_PATH指定在解析import指令时查找.proto文件的目录。如果忽略，使用当前目录。\n可以通过传递多次--proto_path来指定多个import目录;\n它们将会按顺序查找； -I=IMPORT_PATH可以被用作--proto_path的简写。 你可以提供一个或多个输出目录:  \u0026ndash;cpp_out 生成C++代码到DST_DIR。参考 \u0026ndash;java_out 生成C++代码到DST_DIR。参考 \u0026ndash;python_out 生成C++代码到DST_DIR。参考 \u0026ndash;go_out 生成C++代码到DST_DIR。参考 \u0026ndash;ruby_out 生成C++代码到DST_DIR。 \u0026ndash;objc_out 生成C++代码到DST_DIR。参考 \u0026ndash;csharp_out 生成C++代码到DST_DIR。参考 \u0026ndash;php_out 生成C++代码到DST_DIR。参考 为了方便起见，如果DST_DIR以.zip或.JAR结尾，编译器会将输出写入一个给定名称的zip格式存档文件。注意，如果输出存档已经存在， 它将被覆盖;编译器不够智能，无法向现有存档添加文件。   你必须提供一个或多个.proto文件作为输入。多个.proto文件可以一次指定。尽管文件的命名相对于当前目录， 但每个文件必须驻留在一个IMPORT_PATH中，以便编译器可以确定其规范名称。  ",
    "ref": "/blog/data-structure/protocol-buffers/guide/"
  },{
    "title": "Protocol Buffers - 技巧",
    "date": "",
    "description": "",
    "body": "本文描述处理protocol buffer的一些常用设计模式。你也可以发送设计和使用问题到Protocol Buffers 讨论组\n流化多个Message  Streaming Multiple Messages\n 如果你想要写多个message到单个文件或流中，由你确定跟踪一个message结束位置和下一个message开始的位置。protocol buffer格式不是自定义的， 因此protocol buffer解析器无法自行确定消息的结束位置。解决这个问题最简单的方法是在写message之前，先写message大小。 当你读入message时，先读大小，然后读取字节到一个单独的缓冲区，再从缓冲区解析。(如果你想要避免拷贝字节到一个独立的缓冲区， 请检查CodedInputStrem类(C++和Java中)，它可以告知将读取限制为特定的字节数)\n大数据集  Large Data Sets\n protocol buffer不是为处理大型message而设计的。根据一般经验，如果每个处理的message都大于1M字节, 那么需要考虑替代方案。\n这就是说，protocol buffer非常适合处理大型数据集中的单个message。通常，大型数据集实际上只是小块的集合，其中每小块可能是结构化的数据块。 尽管protocol buffer不能一次处理整个集合，使用protocol buffer来编码每块可以大大简化你的问题: 现在你只需要处理一组字节字符串，而不是一组结构。\nprotocol buffer不包含对大数据集的内置支持，因为不同的情况需要不同的解决方案。有些时候一个简单的记录列表就可以， 而其它时候你需要一个类似数据库的东西。每一种解决方案应该作为单独的库来开发，这样只有需要它的人才需要支付成本。\n自描述Message  Self-describing Messages\n protocol buffer不包含它们自己类型的描述。因此，只给出一条原始message，而没有定义其类型的对应的.proto文件，这很难提取出任何有用的数据。\n但是，注意，.proto文件的内容本身可以使用protocol buffer表示。src/google/protobuf/descriptor.proto文件定义了所涉及的message类型。 protoc可以输出一个FileDescriptorSet－表示一组.proto文件－使用--descriptor_set_out选项。这样，你可以像以下定义一个自描述的message：\nsyntax = \u0026quot;proto3\u0026quot;;\rimport \u0026quot;google/protobuf/any.proto\u0026quot;;\rimport \u0026quot;google/protobuf/descriptor.proto\u0026quot;;\rmessage SelfDescribingMessage {\r// Set of FileDescriptorProtos which describe the type and its dependencies.\rgoogle.protobuf.FileDescriptorSet descriptor_set = 1;\r// The message and its type, encoded as an Any message.\rgoogle.protobuf.Any message = 2;\r}\r通过使用DynamicMessage(在c++和Java中可用)这样的类，您可以编写可以操作selfdescripbingmessages的工具。\n尽管如此，这个功能之所以没有包含在协议缓冲区库中，是因为我们从未在Google中使用过它。\n此技巧需要使用描述符支持动态message。请再使用自描述message前，检查你的平台是否支持此特性。\n",
    "ref": "/blog/data-structure/protocol-buffers/techniques/"
  },{
    "title": "Protocol Buffers - 简介",
    "date": "",
    "description": "",
    "body": "概述 Protocol Buffers 是一种语言无关、平台无关，可扩展的序列化结构数据的机制。- 类似XML，但是更小、更快、更简单。 只需定义一次数据结构，就可以生成指定的源代码，使用不同的语言向数据流读取和写入结构数据。\nProtocol Buffers目前支持生成Java、Python、Objective-C和C++等语言的代码。 在proto3版本中，新增Dart、Go、Ruby和C#等更多语言。\n",
    "ref": "/blog/data-structure/protocol-buffers/instroduction/"
  },{
    "title": "Protocol Buffers - 编码规范",
    "date": "",
    "description": "",
    "body": "这篇文章讲述.proto文件的编写规范。根据以下约定，将会使你的protocol buffer messgae定义和它们对应的类保持一致并易于阅读。\n注意，protocol buffer规范是随着时间改变的，因此你可能会看到用不同的约定或格式编写的.proto文件。 当你修改这些文件的时候，请尊重现有的格式。保持一致就好。但是当你创建新的.proto文件时，最好采用当前的格式。\n标准文件格式  Standard file formatting\n  保持每一行长度限制在80字符内 使用2个空格缩进 字符串最好使用双引号  文件结构  File structure\n 文件应该命名为: lower_snake_case.proto\n所有的文件应该按照以下习惯排列：\n License header File overview(文件概述) Syntax Package Imports (需要排序) File options(文件选项) Everything else (其它声明)  Packages package名称应该时小写，并且应该对应目录层级。e.g.,如果文件在my/package中，那么package名字应该是my.package。\nMessage和字段名  Message and field names\n message: 使用驼峰命名法(首字母大写),例如: SongServerRequest.\n字段: 使用underscore_separated_names命名(包括oneof和extension),例如: song_name。 Use CamelCase (with an initial capital) for message names – for example, SongServerRequest. Use underscore_separated_names for field names (including oneof field and extension names) – for example, song_name.\nmessage SongServerRequest {\rrequired string song_name = 1;\r}\r对字段名使用这种命名约定，会得到以下访问器:\nC++:\rconst string\u0026amp; song_name() { ... }\rvoid set_song_name(const string\u0026amp; x) { ... }\rJava:\rpublic String getSongName() { ... }\rpublic Builder setSongName(String v) { ... }\rGo:\rSongServerRequest.SongName = ...\rfunc (x *SongServerRequest) GetSongName() string {...}\r如果你的字段名包含数字，数字应该跟在字母后面而不是下划线后面。e.g.,使用song_name1而不是song_name_1。\nRepeated字段  Repeated fields\n repeated字段使用复数名称:\n repeated string keys = 1;\r...\rrepeated MyMessage accounts = 17;\r枚举  Enums\n 使用驼峰(首字母大写)命名enum类型名称\n使用CAPITALS_WITH_UNDERSCORES命名成员名:\nenum FooBar {\rFOO_BAR_UNSPECIFIED = 0;\rFOO_BAR_FIRST_VALUE = 1;\rFOO_BAR_SECOND_VALUE = 2;\r}\r每个enum值后面以分号;结尾，而不是逗号,。 首选前缀命名，而不是将enum包含在message中。 0值应该拼接后缀UNSPECIFIED。\n服务  Services\n 如果你的.proto文件定义了RPC service，你应该使用驼峰(首字母大写)命名service名称和RPC方法名。\nservice FooService {\rrpc GetSomething(FooRequest) returns (FooResponse);\r}\r避免一些事情  Required字段 (仅在proto2中使用) Groups (尽在proto2中使用)  ",
    "ref": "/blog/data-structure/protocol-buffers/style_guide/"
  },{
    "title": "Protocol Buffers - 规范",
    "date": "",
    "description": "",
    "body": "本文是Protocol Buffers语言规范的参考文档。语法使用EBNF.\n [PB2] 表示pb version2 的规范\n[PB3] 表示pb version3 的规范\n | alternation\r() grouping\r[] option (zero or one time)\r{} repetition (any number of times)\r词法元素  Lexical elements\n 字母和数字  Letters and digits\n letter = \u0026quot;A\u0026quot; … \u0026quot;Z\u0026quot; | \u0026quot;a\u0026quot; … \u0026quot;z\u0026quot;\r[PB2] capitalLetter = \u0026quot;A\u0026quot; … \u0026quot;Z\u0026quot;\rdecimalDigit = \u0026quot;0\u0026quot; … \u0026quot;9\u0026quot;\roctalDigit = \u0026quot;0\u0026quot; … \u0026quot;7\u0026quot;\rhexDigit = \u0026quot;0\u0026quot; … \u0026quot;9\u0026quot; | \u0026quot;A\u0026quot; … \u0026quot;F\u0026quot; | \u0026quot;a\u0026quot; … \u0026quot;f\u0026quot;\r标识符  Identifiers\n ident = letter { letter | decimalDigit | \u0026quot;_\u0026quot; }\rfullIdent = ident { \u0026quot;.\u0026quot; ident }\rmessageName = ident\renumName = ident\rfieldName = ident\roneofName = ident\rmapName = ident\rserviceName = ident\rrpcName = ident\r[PB2] streamName = ident\rmessageType = [ \u0026quot;.\u0026quot; ] { ident \u0026quot;.\u0026quot; } messageName\renumType = [ \u0026quot;.\u0026quot; ] { ident \u0026quot;.\u0026quot; } enumName\r[PB2] groupName = capitalLetter { letter | decimalDigit | \u0026quot;_\u0026quot; }\r整数  Integer literals\n intLit = decimalLit | octalLit | hexLit\rdecimalLit = ( \u0026quot;1\u0026quot; … \u0026quot;9\u0026quot; ) { decimalDigit }\roctalLit = \u0026quot;0\u0026quot; { octalDigit }\rhexLit = \u0026quot;0\u0026quot; ( \u0026quot;x\u0026quot; | \u0026quot;X\u0026quot; ) hexDigit { hexDigit }\r浮点数  Floating-point literals\n floatLit = ( decimals \u0026quot;.\u0026quot; [ decimals ] [ exponent ] | decimals exponent | \u0026quot;.\u0026quot;decimals [ exponent ] ) | \u0026quot;inf\u0026quot; | \u0026quot;nan\u0026quot;\rdecimals = decimalDigit { decimalDigit }\rexponent = ( \u0026quot;e\u0026quot; | \u0026quot;E\u0026quot; ) [ \u0026quot;+\u0026quot; | \u0026quot;-\u0026quot; ] decimals 布尔值  Boolean\n boolLit = \u0026quot;true\u0026quot; | \u0026quot;false\u0026quot; 字符串  String literals\n strLit = ( \u0026quot;'\u0026quot; { charValue } \u0026quot;'\u0026quot; ) | ( '\u0026quot;' { charValue } '\u0026quot;' )\rcharValue = hexEscape | octEscape | charEscape | /[^\\0\\n\\\\]/\rhexEscape = '\\' ( \u0026quot;x\u0026quot; | \u0026quot;X\u0026quot; ) hexDigit hexDigit\roctEscape = '\\' octalDigit octalDigit octalDigit\rcharEscape = '\\' ( \u0026quot;a\u0026quot; | \u0026quot;b\u0026quot; | \u0026quot;f\u0026quot; | \u0026quot;n\u0026quot; | \u0026quot;r\u0026quot; | \u0026quot;t\u0026quot; | \u0026quot;v\u0026quot; | '\\' | \u0026quot;'\u0026quot; | '\u0026quot;' )\rquote = \u0026quot;'\u0026quot; | '\u0026quot;'\r空语句  EmptyStatement\n emptyStatement = \u0026quot;;\u0026quot;\r常量  Constant\n constant = fullIdent | ( [ \u0026quot;-\u0026quot; | \u0026quot;+\u0026quot; ] intLit ) | ( [ \u0026quot;-\u0026quot; | \u0026quot;+\u0026quot; ] floatLit ) |\rstrLit | boolLit Syntax语句 syntax 语句用来定义protobuf的版本。\nsyntax = \u0026quot;syntax\u0026quot; \u0026quot;=\u0026quot; quote \u0026quot;proto2\u0026quot; quote \u0026quot;;\u0026quot;\rImport语句  Import Statement\n Import语句用来导入另一个.proto。\nimport = \u0026quot;import\u0026quot; [ \u0026quot;weak\u0026quot; | \u0026quot;public\u0026quot; ] strLit \u0026quot;;\u0026quot; 示例:\nimport public \u0026quot;other.proto\u0026quot;;\rPackage语句  Package\n 包语句用以避免proto中message命名冲突\npackage = \u0026quot;package\u0026quot; fullIdent \u0026quot;;\u0026quot;`\r示例:\npackage foo.bar;\rOption语句  Option\n option可以在proto文件，message，enum，service中使用。\noption可以是protobuf规范定义的或自定义。更多信息，参考 Protocol Buffers-Version 2指南\noption = \u0026quot;option\u0026quot; optionName \u0026quot;=\u0026quot; constant \u0026quot;;\u0026quot;\roptionName = ( ident | \u0026quot;(\u0026quot; fullIdent \u0026quot;)\u0026quot; ) { \u0026quot;.\u0026quot; ident }\r示例：\noption java_package = \u0026quot;com.example.foo\u0026quot;;\rFields语句  Fields\n Fields 是message结构中的基本元素。\n[PB2] Fields可以是普通Fields，group，oneof，map等。 单个Field由 标签 类型 字段编号组成。 [PB3] Fields可以是普通Fields，oneof，map等。 单个Field由 类型 字段编号组成。\n[PB2] label = \u0026quot;required\u0026quot; | \u0026quot;optional\u0026quot; | \u0026quot;repeated\u0026quot;\rtype = \u0026quot;double\u0026quot; | \u0026quot;float\u0026quot; | \u0026quot;int32\u0026quot; | \u0026quot;int64\u0026quot; | \u0026quot;uint32\u0026quot; | \u0026quot;uint64\u0026quot;\r| \u0026quot;sint32\u0026quot; | \u0026quot;sint64\u0026quot; | \u0026quot;fixed32\u0026quot; | \u0026quot;fixed64\u0026quot; | \u0026quot;sfixed32\u0026quot; | \u0026quot;sfixed64\u0026quot;\r| \u0026quot;bool\u0026quot; | \u0026quot;string\u0026quot; | \u0026quot;bytes\u0026quot; | messageType | enumType\rfieldNumber = intLit;\r普通field  Normal field\n [PB2] 每个field定义由label，type，name，field number组成。 还可能有 field options。 [PB3] 每个field定义由type，name，field number组成。 还可能有 field options。\n[PB2] field = label type fieldName \u0026quot;=\u0026quot; fieldNumber [ \u0026quot;[\u0026quot; fieldOptions \u0026quot;]\u0026quot; ] \u0026quot;;\u0026quot;\r[PB3] field = [\u0026quot;repeated\u0026quot;] type fieldName \u0026quot;=\u0026quot; fieldNumber [ \u0026quot;[\u0026quot; fieldOptions \u0026quot;]\u0026quot; ] \u0026quot;;\u0026quot;\rfieldOptions = fieldOption { \u0026quot;,\u0026quot; fieldOption }\rfieldOption = optionName \u0026quot;=\u0026quot; constant\r示例:\n[PB2] optional foo.bar nested_message = 2;\r[PB3] foo.bar nested_message = 2;\rrepeated int32 samples = 4 [packed=true];\r[PB2]组field  Group field\n  注意：[PB3]该特性被废弃，在创建新的message类型时，应当使用嵌套message结构。\n Group是在message定义中嵌套消息的一种方法。Group名称必须大写字母开头。\ngroup = label \u0026quot;group\u0026quot; groupName \u0026quot;=\u0026quot; fieldNumber messageBody\r示例:\nrepeated group Result = 1 {\rrequired string url = 2;\roptional string title = 3;\rrepeated string snippets = 4;\r}\rOneof  Oneof and oneof field\n [PB2] oneof由oneof fields和oneof名称组成。oneof fields 没有label。 [PB3] oneof由oneof fields和oneof名称组成。\noneof = \u0026quot;oneof\u0026quot; oneofName \u0026quot;{\u0026quot; { option | oneofField | emptyStatement } \u0026quot;}\u0026quot;\roneofField = type fieldName \u0026quot;=\u0026quot; fieldNumber [ \u0026quot;[\u0026quot; fieldOptions \u0026quot;]\u0026quot; ] \u0026quot;;\u0026quot;\r示例:\noneof foo {\rstring name = 4;\rSubMessage sub_message = 9;\r}\r映射field  Map field\n map field 由key 类型，value类型，名称 和 字段编号组成。 key的类型可以是任意的整数和字符串类型。\n [PB2] key 类型不能是 enum\n mapField = \u0026quot;map\u0026quot; \u0026quot;\u0026lt;\u0026quot; keyType \u0026quot;,\u0026quot; type \u0026quot;\u0026gt;\u0026quot; mapName \u0026quot;=\u0026quot; fieldNumber [ \u0026quot;[\u0026quot; fieldOptions \u0026quot;]\u0026quot; ] \u0026quot;;\u0026quot;\rkeyType = \u0026quot;int32\u0026quot; | \u0026quot;int64\u0026quot; | \u0026quot;uint32\u0026quot; | \u0026quot;uint64\u0026quot; | \u0026quot;sint32\u0026quot; | \u0026quot;sint64\u0026quot; |\r\u0026quot;fixed32\u0026quot; | \u0026quot;fixed64\u0026quot; | \u0026quot;sfixed32\u0026quot; | \u0026quot;sfixed64\u0026quot; | \u0026quot;bool\u0026quot; | \u0026quot;string\u0026quot;\r示例:\nmap\u0026lt;string, Project\u0026gt; projects = 3;\r扩展和保留  Extensions and Reserved\n 扩展和保留是定义字段编号和字段名范围的message元素。\n[PB2]扩展  Extensions\n 扩展定义message中字段编号的范围，可用于第三方扩展。\n其他人可以在他们自己的.proto文件中使用这些数字标记为message类型定义新的field，而不必编辑原始文件。\nextensions = \u0026quot;extensions\u0026quot; ranges \u0026quot;;\u0026quot;\rranges = range { \u0026quot;,\u0026quot; range }\rrange = intLit [ \u0026quot;to\u0026quot; ( intLit | \u0026quot;max\u0026quot; ) ]\r示例:\nextensions 100 to 199;\rextensions 4, 20 to max;\r保留  Reserved\n 保留定义message中的字段编号或字段名称不能使用的范围。\nreserved = \u0026quot;reserved\u0026quot; ( ranges | fieldNames ) \u0026quot;;\u0026quot;\rfieldNames = fieldName { \u0026quot;,\u0026quot; fieldName }\r示例:\nreserved 2, 15, 9 to 11;\rreserved \u0026quot;foo\u0026quot;, \u0026quot;bar\u0026quot;;\r顶级定义  Top Level definitions\n Enum定义 [PB2] enum由名称和enum主体组成。 enum主体由fields和option组成。 [PB3] enum由名称和enum主体组成。 enum主体由fields和option组成。enum 定义必须以enum 0值开始。\nenum = \u0026quot;enum\u0026quot; enumName enumBody\renumBody = \u0026quot;{\u0026quot; { option | enumField | emptyStatement } \u0026quot;}\u0026quot;\renumField = ident \u0026quot;=\u0026quot; [ \u0026quot;-\u0026quot; ] intLit [ \u0026quot;[\u0026quot; enumValueOption { \u0026quot;,\u0026quot; enumValueOption } \u0026quot;]\u0026quot; ]\u0026quot;;\u0026quot;\renumValueOption = optionName \u0026quot;=\u0026quot; constant\r示例:\nenum EnumAllowingAlias {\roption allow_alias = true;\rUNKNOWN = 0;\rSTARTED = 1;\rRUNNING = 2 [(custom_option) = \u0026quot;hello world\u0026quot;];\r}\r[PB2]Extend定义  Extend\n 如果在相同或导入的.proto文件中的message保留了extensions范围，则该message可以被extend。\nextend = \u0026quot;extend\u0026quot; messageType \u0026quot;{\u0026quot; {field | group | emptyStatement} \u0026quot;}\u0026quot;\r示例:\nextend Foo {\roptional int32 bar = 126;\r}\rMessage定义  Message definition\n [PB2] message由名称和message 主体组成。 message主体由field，嵌套enum，嵌套message，extend，extensions， reserved，groups，options，oneofs，map [PB3] message由名称和message 主体组成。 message主体由field，嵌套enum，嵌套message， reserved，options，oneofs，map\nmessage = \u0026quot;message\u0026quot; messageName messageBody\r[PB2]messageBody = \u0026quot;{\u0026quot; { field | enum | message | extend | extensions | group |\roption | oneof | mapField | reserved | emptyStatement } \u0026quot;}\u0026quot;\r[PB3]messageBody = \u0026quot;{\u0026quot; { field | enum | message |\roption | oneof | mapField | reserved | emptyStatement } \u0026quot;}\u0026quot;\r示例:\nmessage Outer {\roption (my_option).a = true;\rmessage Inner { // Level 2\r[PB2] required int64 ival = 1;\r[PB3] int64 ival = 1;\r}\rmap\u0026lt;int32, string\u0026gt; my_map = 2;\r[PB2] extensions 20 to 30;\r}\rService定义  Service definition\n [PB2]\rservice = \u0026quot;service\u0026quot; serviceName \u0026quot;{\u0026quot; { option | rpc | stream | emptyStatement } \u0026quot;}\u0026quot;\rrpc = \u0026quot;rpc\u0026quot; rpcName \u0026quot;(\u0026quot; [ \u0026quot;stream\u0026quot; ] messageType \u0026quot;)\u0026quot; \u0026quot;returns\u0026quot; \u0026quot;(\u0026quot; [ \u0026quot;stream\u0026quot; ] messageType \u0026quot;)\u0026quot; (( \u0026quot;{\u0026quot; { option | emptyStatement } \u0026quot;}\u0026quot; ) | \u0026quot;;\u0026quot; )\rstream = \u0026quot;stream\u0026quot; streamName \u0026quot;(\u0026quot; messageType \u0026quot;,\u0026quot; messageType \u0026quot;)\u0026quot; (( \u0026quot;{\u0026quot; { option | emptyStatement } \u0026quot;}\u0026quot;) | \u0026quot;;\u0026quot; )\r[PB3]\rservice = \u0026quot;service\u0026quot; serviceName \u0026quot;{\u0026quot; { option | rpc | emptyStatement } \u0026quot;}\u0026quot;\rrpc = \u0026quot;rpc\u0026quot; rpcName \u0026quot;(\u0026quot; [ \u0026quot;stream\u0026quot; ] messageType \u0026quot;)\u0026quot; \u0026quot;returns\u0026quot; \u0026quot;(\u0026quot; [ \u0026quot;stream\u0026quot; ] messageType \u0026quot;)\u0026quot; (( \u0026quot;{\u0026quot; {option | emptyStatement } \u0026quot;}\u0026quot; ) | \u0026quot;;\u0026quot;)\r示例:\nservice SearchService {\rrpc Search (SearchRequest) returns (SearchResponse);\r}\rProto文件  Proto file\n PB2 proto = syntax { import | package | option | topLevelDef | emptyStatement }\rtopLevelDef = message | enum | extend | service\r示例:\nsyntax = \u0026quot;proto2\u0026quot;;\rimport public \u0026quot;other.proto\u0026quot;;\roption java_package = \u0026quot;com.example.foo\u0026quot;;\renum EnumAllowingAlias {\roption allow_alias = true;\rUNKNOWN = 0;\rSTARTED = 1;\rRUNNING = 2 [(custom_option) = \u0026quot;hello world\u0026quot;];\r}\rmessage Outer {\roption (my_option).a = true;\rmessage Inner { // Level 2\rrequired int64 ival = 1;\r}\rrepeated Inner inner_message = 2;\roptional EnumAllowingAlias enum_field = 3;\rmap\u0026lt;int32, string\u0026gt; my_map = 4;\rextensions 20 to 30;\r}\rmessage Foo {\roptional group GroupMessage {\roptional a = 1;\r}\r}\rPB3 proto = syntax { import | package | option | topLevelDef | emptyStatement }\r[PB2] topLevelDef = message | enum | extend | service\r[PB3] topLevelDef = message | enum | service\r示例:\nsyntax = \u0026quot;proto3\u0026quot;;\rimport public \u0026quot;other.proto\u0026quot;;\roption java_package = \u0026quot;com.example.foo\u0026quot;;\renum EnumAllowingAlias {\roption allow_alias = true;\rUNKNOWN = 0;\rSTARTED = 1;\rRUNNING = 2 [(custom_option) = \u0026quot;hello world\u0026quot;];\r}\rmessage Outer {\roption (my_option).a = true;\rmessage Inner { // Level 2\rint64 ival = 1;\r}\rrepeated Inner inner_message = 2;\rEnumAllowingAlias enum_field = 3;\rmap\u0026lt;int32, string\u0026gt; my_map = 4;\r}\r",
    "ref": "/blog/data-structure/protocol-buffers/reference/"
  },{
    "title": "Prometheus-Pushgateway",
    "date": "",
    "description": "",
    "body": "为什么Push Pushgateway是一个中间服务，用于接收无法直接抓取的服务推送的metrics\n建议 仅建议再有限的情况下使用Pushgateway。与Promethues的pull模式收集metrics相比， Pushgateway有以下几个问题:\n 当通过单个Pushgateway监控多个实例时， 它既是单点故障也是性能瓶颈 失去Prometheus对实例自动的健康监测(通过up metrics) Pushgateway永远不会丢弃push给它的数据，暴露所有数据给Prometheus除非你调用Pushgateway的接口手动删除。  部署 docker  命令 sudo docker run -d -p 9091:9091 -v /opt/prometheus/pushgateway.yml:/etc/prometheus/pushgateway.yml --name pushgateway prom/pushgateway --web.enable-admin-api --web.config.file=/etc/prometheus/pushgateway.yml\r pushgateway.yml  basic_auth_users:\rusername: $2y$10$OhmMjosTa7QjcjFKZyFCw.wixAen5yGsvsIRoGenvxjFwRG.fkGn2\r 配置basic_auth_users  安装htpasswd：sudo apt install apache2-utils 生成密码: htpasswd -nBC 10 \u0026quot;\u0026quot; | tr -d ':\\n'    ",
    "ref": "/blog/prometheus/pushgateway/"
  },{
    "title": "Prometheus-Job和Instance",
    "date": "",
    "description": "",
    "body": "在Prometheus的术语中，可以观测的终端称为instance，通常对应的是单个进程。\n一组具有相同目的的instance，例如: 为了可靠性或扩展性而复制的进程， 称为job。\n如下， 一个job和四个instance:\n job: api-server  instance 1: 1.2.3.4:5670 instance 2: 1.2.3.4:5671 instance 3: 5.6.7.8:5670 instance 4: 5.6.7.8:5671    自动生成labels和时间序列\n当Prometheus采集目标节点数据时，会自动附加一些labels到时间序列上，用以标识采集的目标：\n job: 配置的job名称 instance：目标节点URL部分中的\u0026lt;host\u0026gt;:\u0026lt;port\u0026gt;  如果这些label已经存在于采集的数据中，则取决于配置项honor_labels。 具体参考scrape configuration\n对于每一个instance， Prometheus在以下的每个时间序列中都保存一个样本:\n up{job=\u0026quot;\u0026lt;job-name\u0026gt;\u0026quot;, instance=\u0026quot;\u0026lt;instance-id\u0026gt;\u0026quot;}:1标识instance是健康的，0标识prometheus采集失败 scrape_duration_seconds{job=\u0026quot;\u0026lt;job-name\u0026gt;\u0026quot;, instance=\u0026quot;\u0026lt;instance-id\u0026gt;\u0026quot;}: 采集的频率 scrape_samples_post_metric_relabeling{job=\u0026quot;\u0026lt;job-name\u0026gt;\u0026quot;, instance=\u0026quot;\u0026lt;instance-id\u0026gt;\u0026quot;}: metric重新设置label后剩余的样本数量 scrape_samples_scraped{job=\u0026quot;\u0026lt;job-name\u0026gt;\u0026quot;, instance=\u0026quot;\u0026lt;instance-id\u0026gt;\u0026quot;}: 目标节点暴露的样本数量 scrape_series_added{job=\u0026quot;\u0026lt;job-name\u0026gt;\u0026quot;, instance=\u0026quot;\u0026lt;instance-id\u0026gt;\u0026quot;}: 本次采集中新时间序列的大致数量  ",
    "ref": "/blog/prometheus/jobinstance/"
  },{
    "title": "Prometheus-metric类型",
    "date": "",
    "description": "",
    "body": "Prometheus的client库提供四个核心的metric类型。它们目前只在client库和传输协议中有区别。 Prometheus的server 还没有使用这些信息类型，并将所有的数据扁平化为无类型的时间序列。将来这种处理方式可能会改变。\nCounter counter是一个累加的metric,表示单个单调递增的计数器， 它只能累加或者在重启时重置为0. 例如，你可以使用counter表示 请求服务、完成任务或产生错误的数量。\n不要使用counter表示可能发生递减的metric。例如, 不要用counter表示当前正在运行的进程的数量，用gauge表示。\nGauge gauge表示一个数值可以增加或减少的metric。\ngauge通常用于表示测量值，比如温度或者当前内存的使用情况。也用来计数，这些计数可以增加或减少，比如并发请求的数量。\nHistogram histogram用于对观测结果进行抽样(通常是请求延时或响应数据大小),并在配置的buckets中进行计数。同时提供所有观测值的总和。\nhistogram有一个基础名称\u0026lt;basename\u0026gt;,在收集期间暴露多个时间序列:\n 观测bucket的计数器,暴露为\u0026lt;basename\u0026gt;_bucket{le=\u0026quot;上边界值\u0026quot;} 所有观测值的总和，暴露为\u0026lt;basename\u0026gt;_sum 所有观测事件的计数，暴露为\u0026lt;basename\u0026gt;_count(同: \u0026lt;basename\u0026gt;_count{le=\u0026quot;+Inf\u0026quot;})  使用函数histogram_quantile()可以计算整个histogram甚至histogram的每个集合的分位数。 当操作bucket时，histogram是累加的。\nSummary 类似于histogram， summary对观测结果进行抽样(通常是请求延时或响应数据大小)。 它同样提供了观测的总次数和观测值的总和。 它通过滑动时间窗口来计算分位数。\nsummary有一个基础名称\u0026lt;basename\u0026gt;,在收集期间暴露多个时间序列:\n 观测事件的分位数(0 ≤ φ ≤ 1), 暴露为： \u0026lt;basename\u0026gt;{quantile=\u0026quot;\u0026lt;φ\u0026gt;\u0026quot;} 所有观测值的总和，暴露为\u0026lt;basename\u0026gt;_sum 所有观测事件的计数，暴露为\u0026lt;basename\u0026gt;_count  ",
    "ref": "/blog/prometheus/metrictypes/"
  },{
    "title": "Prometheus-数据模型",
    "date": "",
    "description": "",
    "body": "Prometheus本质上将数据存储为时间序列(以时间顺序索引的一系列的数据点): 带有时间戳的数据流属于 同一metrics和labels集合的维度。\n除了存储时间序列，Prometheus还会生成临时的时间序列作为查询的结果。\n名字和标签 每个时间序列，都由metrics名字和可选的labels唯一标识。\nmetrics名称\n 指定要测量系统的一般特性(e.g. http_requests_total: 表示HTTP接收的所有请求数量) 命名格式包含ASICC字母和数字，也可以有下划线和冒号。格式需要匹配正则表达式：[a-zA-Z_:][a-zA-Z0-9_:]*   冒号保留给用户自定义的记录规则。它们不能被导出者或直接仪器使用\n labels\n 开启Prometheus的维度数据模型：指定任意组合的labels给相同名称的metrics,表示该metrics的一个特殊维度实例。 例如: http_requests_total{method: \u0026quot;POST\u0026quot;, handler: \u0026quot;/api/tracks\u0026quot;} 查询语句允许根据这些维度进行过滤和聚合 修改任意label的值，包含添加和删除， 将会创建一个新的时间序列 命名格式包含ASICC字母，数字，也可以有下划线。 格式需要匹配正则表达式: [a-zA-Z_][a-zA-Z0-9_]。 以_开头的label名称，保留为内部使用。 label值可以包含任意Unicode字符 label值为空，被视为无此标签  样本 样本组成了实际的时间序列数据。 每个样本由以下组成:\n 一个float64值 一个毫秒精度的时间戳  表示法 给定一个metrics名和一组labels， 时间序列一般使用下面的表示法:\n\u0026lt;metric name\u0026gt;{\u0026lt;label name\u0026gt;=\u0026lt;label value\u0026gt;, ...}\r例如: 一个时间序列，metrics名字是api_http_requests_total，labels是method=\u0026quot;POST\u0026quot;和handler=\u0026quot;/messages\u0026quot;, 可以用以下表示法:\napi_http_requests_total{method=\u0026quot;POST\u0026quot;, handler=\u0026quot;/messages\u0026quot;}\r",
    "ref": "/blog/prometheus/datamodel/"
  },{
    "title": "Prometheus-简介",
    "date": "",
    "description": "",
    "body": "Prometheus是一个开源的系统监控和报警工具，最初由SoundCloud构建。 从2012年开始编写，2015年开源后很多公司和组织采用Prometheus, 该项目有很多活跃的开发者和用户社区。现在Prometheus作为独立的开源项目， 独立于任何的公司。 为了强调这一点，并阐明该项目的组织结构， Prometheus在2016年加入CNCF,成为继Kubernetes后的第二个成员。\n了解更多的Prometheus信息，可以参考Awesome\n特性  多维数据模型，其时间序列数据由metric名称和labels键值对构成 PromQL是一种灵活的查询语句，来利用这个维度 不依赖分布式存储；单服务器节点是自治的， 支持local和remote多种模式 通过http协议的pull模式，采集时序数据 支持通过中间网关推送时序 监控目标，采用服务发现或者静态配置 支持多模式的图形和仪表盘展现  组件 Prometheus生态由很多组件组成，它们大多数是可选的：\n Prometheus server，它负责时序数据的收集和存储 Client libraries,对接Prometheus server，上报和查询数据 push gateway, 用于短期业务的监控数据推送 exporters, 用于指定服务的exporter，e.g., node exporter, redis exporter, mysql exporter alertmanager, 用于告警通知管理  架构 下图说明了Prometheus的基础架构和生态系统中的一些组件:\n从上图可以看到：\n 监控目标, 可以是静态配置或者服务发现 获取metrics, 可以直接从监控目标拉取，或者拉取监控目标推送到push gateway的数据 当采样的数据大于配置的缓存区大小时，Prometheus将数据持久化到local或remote 当配置alert rules时， Prometheus会定时查询数据，当规则被触发的时候，生成alert并推送到Alertmanager Alertmanager收到alert， 根据配置对alert去重，聚合，降噪， 通过email,pagerduty等途径进行告警 使用Prometheus web ui,Grafana或API等对收集的数据进行可视化  适用于 Prometheus记录纯数字的时序数据。既适用于以机器为中心的监控，也适用于面向服务架构的监控。在微服务的世界里， 其优势是支持对多维数据的收集和查询。\nPrometheus是为可靠性设计的， 当系统在运行时出现问题时，可以帮助你快速的定位问题。每个Prometheus服务都是独立的， 不依赖于任何网络、存储或其它远程服务。 当其他基础设施出现问题时，你可以依赖它，并且使用Prometheus不需要安装额外的基础设施。\n不适用于 Prometheus的值是可靠的。可以随时查看你系统的可用统计信息，即使在故障的条件下。如果你需要100%的精确度，例如每个请求的计费， Prometheus不是一个很好的选择，因为其收集的信息不够详细和完整， 仅收集某个时间段的数据。在这种情况下，你最好使用专门的审计系统。\n总结 Prometheus:\n 作为一站式的监控告警平台， 依赖少， 功能完备。 支持对容器和服务的监控， 大多数监控平台主要是针对主机的监控 PromQL语句简洁，内置强大的统计函数 在数据存储及持久性上没有InfluxDB等时序数据库强大。  ",
    "ref": "/blog/prometheus/introduction/"
  },{
    "title": "Prometheus-部署",
    "date": "",
    "description": "",
    "body": "本文讲解Prometheus的docker部署方式\n服务器网路配置 monitor.service.com\n   服务 开放端口     prometheus 9089   pushgateway 9091   grafana 3030    prometheus 配置  创建文件 /opt/prometheus/prometheus.yml global:\rscrape_interval: 60s\revaluation_interval: 60s\rscrape_configs:\r- job_name: pushgateway\rhonor_labels: true\rstatic_configs:\r- targets: ['monitor.service.com:9091']\rlabels:\rinstance: pushgateway\rbasic_auth:\rusername: admin\rpassword: 123456\r 配置nginx  cd /etc/nginx/conf.d 生成密码文件:htpasswd -c ./.htpasswd admin, 输入密码: 123456 创建配置文件prometheus.conf server {\rserver_name monitor.service.com;\rlisten 9089;\rlisten [::]:9089;\rlocation /{\rauth_basic \u0026quot;Prometheus\u0026quot;;\rauth_basic_user_file /etc/nginx/conf.d/.htpasswd;\rproxy_pass http://localhost:9090/;\r}\r}\r    pushgateway配置  创建配置文件/opt/prometheus/pushgateway.yml basic_auth_users:\radmin: $2y$10$OhmMjosTa7QjcjFKZyFCw.wixAen5yGsvsIRoGenvxjFwRG.fkGn2\r  grafana配置   创建配置文件/opt/grafana/grafana.ini\n 主要修改标准文件中的smtp配置为zylhorse@126.com 邮箱\n #################################### SMTP / Emailing ##########################\r[smtp]\renabled = true\rhost = smtp.126.com:25\ruser = zylhorse@126.com\r# If the password contains # or ; you have to wrap it with triple quotes. Ex \u0026quot;\u0026quot;\u0026quot;#password;\u0026quot;\u0026quot;\u0026quot;\rpassword = GBHODFDQLRUJJBNO\r;cert_file =\r;key_file =\rskip_verify = true\rfrom_address = zylhorse@126.com\rfrom_name = Grafana\r# EHLO identity in SMTP dialog (defaults to instance_name)\r;ehlo_identity = dashboard.example.com\r# SMTP startTLS policy (defaults to 'OpportunisticStartTLS')\r;startTLS_policy = NoStartTLS\r[emails]\r;welcome_email_on_sign_up = false\r;templates_pattern = emails/*.html\r  执行启动脚本： ```\r#!/bin/bash sudo docker run -d -p 9090:9090 -v /opt/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml --name prometheus prom/prometheus --web.enable-admin-api --config.file=/etc/prometheus/prometheus.yml --web.external-url=http://localhost:9089 --web.route-prefix=\u0026quot;/\u0026quot;\rsudo docker run -d -p 9091:9091 -v /opt/prometheus/pushgateway.yml:/etc/prometheus/pushgateway.yml --name pushgateway prom/pushgateway --web.enable-admin-api --web.config.file=/etc/prometheus/pushgateway.yml\rsudo docker run -d -p 3030:3000 -v /opt/grafana/grafana.ini:/etc/grafana/grafana.ini --name grafana grafana/Grafana\r```\r ",
    "ref": "/blog/prometheus/deploy/"
  },{
    "title": "分布式监控系统-Tracing、Metrics、Logging",
    "date": "",
    "description": "",
    "body": "Metrics、Tracing、Logging都是针对全局的，肯定会有重叠的部分。因此思考 使用维恩图(Venn diagram)描述三个概念的定义，用以确定三者不同的部分:\nMetrics: 统计指标是可计量的，它们是在一段时间内组成单个逻辑gauge，counter，histogram的原子。 例如：\n队列的当前深度可以被定义为一个gauge，根据last-writer-win原则更新总计\nHTTP请求的数量可以被定义为计数器，根据简单的累加更新总计\n请求时长可以被定义为一个柱状图，更新总计到时间段并产生统计摘要\nLogging：用于处理离散(偶发)事件。\n例如:\n应用程序的debug/error信息通过syslog的滚动文件描述符，转存到ELK中\n审计踪迹事件通过Kafka，存储到像BigTable这样的数据库中\n特定请求的元数据信息，从服务请求中剥离，并发送给异常收集服务器，如:NewRelic\nTracing: 用于处理请求范围内的信息。任何数据或者元数据都可以绑定到系统的单个事务对象的生命周期上。\n例如:\n出站RPC到远程服务请求时长\n发送到数据库的SQL查询文本\n入站HTTP请求的关联ID\n根据上述定义，可以标记重叠部分: 对于cloud-native应用来说，大部分instrumentation的典型特征是以请求范围结束，因此讨论tracing的上下文是有意义的。 但是我们可以观察到不是所有的instrumentation都绑定到请求的生命周期上：e.g. 逻辑组件的诊断信息或进程生命周期信息，与任何离散请求是正交关系。 因此不是所有(至少未经处理)的metrics或logs信息都可以硬塞进tracing系统。\n我们应该意识到metrics统计数据，对应用监控有很大帮助，比如：Prometheus生态，可以展现应用的实时监控视图。 相反的，如果将metrics信息硬塞进logging系统处理，会让我们丢失一些特性。\n至此，我们可以对现有系统进行分类。如：\nPrometheus系统，起始是作为专一的metrics系统，慢慢的可能会向tracing系统发展，从而进行请求范围的metrics。但是不会向logging系统领域深入。\nELK生态提供日志的记录、滚动和聚合，也在其它领域不停的积累，并慢慢的集成进来。\n在这三个领域中Metrics需要最少的管理资源，Logging的资源负荷往往是递增的。\n由此我们可以形成容量或操作开销梯度图，又低到高，可以看出Tracing的开销居于前两者之间：\n",
    "ref": "/blog/distribution-system/%E5%88%86%E5%B8%83%E5%BC%8F%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F/"
  },{
    "title": "OpenTracing-系统集成",
    "date": "",
    "description": "",
    "body": "概述 这里讲解集成OpenTracing到你的系统中，需要做的工作。\n服务端修改\n 过滤器，拦截器，中间件等处理入站请求的组件 Span的载体 tracer的配置：开启/采样率/日志等  客户端修改\n 过滤器，拦截器，中间件等处理出站请求的组件 tracer的配置：开启/采样率/日志等  提醒 操作名(operation name) 每个Span被创建时，都需要指定其操作名。操作名需要遵循一定的规范。\n一些默认命名示例：\n 请求处理方法名称 web资源名称 RPC服务和方法连接名称  确认需要追踪的方法 有些系统需要追踪所有请求， 有些系统需要追踪特定请求。 程序应该提供配置，满足这两种场景，允许用户设置。\n追踪请求属性 程序有时需要记录请求的一些属性。一般避免手动设置Span的Tag信息， 有以下两种方式：\n gRPC的Span Decorator // SpanDecorator binds a function that decorates gRPC Spans.\rfunc SpanDecorator(decorator SpanDecoratorFunc) Option {\rreturn func(o *options) {\ro.decorator = decorator\r}\r}\r 添加属性配置列表TRACED_REQUEST_ATTRIBUTES, 在追踪过滤器中确认需要添加的Tags for attr in settings.TRACED_REQUEST_ATTRIBUTES:\rif hasattr(request, attr):\rpayload = str(getattr(request, attr))\rSpan.set_tag(attr, payload)\r  服务端追踪 服务端追踪的目的是追踪请求在这个服务器内部的全生命周期的情况，并保证能够和前置的客户端追踪信息连接起来。 你可以在服务器收到请求时，创建Span，并在服务器完成请求处理后，关闭这些Span。追踪一个服务端请求的流程如下：\n 服务器接收到请求  从网络请求（跨进程的调用：HTTP等）获取当前的追踪链状态 创建一个新的Span 保存当前的追踪状态   服务器完成请求处理 / 返回响应  结束上面创建的Span 由于调用流程决定于请求的处理情况，所以你需要知道如果修改框架的请求和响应处理——是否需要通过修改过滤器、中间件、配置栈或者其他机制。    SpanContext存储  如果框架有请求Context，可以将SpanContext存储到请求Context中 def filter(request):\rspan = # extract / start span from request\rwith (ctx.active_span = span):\rprocess_request(request)\rspan.finish()\r 在请求处理的任何阶段都可以通过ctx.active_span获取当前Span\n  否则，需要建立request和span的映射, 其中一种实现为封装全局Tracer class MyFrameworkTracer:\rdef __init__(opentracing_tracer):\rself.internal_tracer = opentracing_tracer\rself.active_spans = {}\rdef add_span(request, span):\rself.active_spans[request] = span\rdef get_span(request):\rreturn self.active_spans[request]\rdef finish_span(request):\rspan = self.active_spans[request]\rspan.finish()\rdel self.active_spans[request]\r使用：\rdef process_request(request):\rspan = # extract / start span from request\rtracer.add_span(request, span)\rdef process_response(request, response):\rtracer.finish_span(request)\r  确保request和span的映射表是线程安全的 在处理response时，请确保request实例的可用性(也可以不使用request对象，使用其他标识来做映射)     客户端追踪 当框架有一个客户端组件的时候，需要在初始化request的时候，开启客户端的追踪。这样做是为了将生成的Span放到请求头中， 这样Span才能请求随着请求，传递到服务端。类似于服务端追踪，你需要知道如何修改你的客户端代码，来发送请求，和接收相应。 当客户端完成修改，就可以完成端到端的追踪了。\n追踪一个客户端请求的流程如下：\n 准备请求对象  读取现在的追踪状态 新建一个Span 将Span注入(Inject)到请求中   发送请求 接收响应  完成并关闭Span    读取现有的Trace/新建 正如服务端一样，我们必须知道是应该开启一个新的追踪或者链接一个已有的追踪。 例如,一个基于微服务架构分布式架构中，一个应用可能即是服务端又是客户端。一个服务的提供方同时又是另一个服务的发起方，这个东西需要被联系起来。 如果存在一个活跃的Trace，你需要把它的Span作为父级Span，创建ChildOf Span。否则，需要新建没有父级的Span。\n完成并关闭Span  如果设计过滤器封装了请求处理 def filter(request, response):\rspan = # start span from the current trace state\rtracer.inject(span, opentracing.Format.HTTP_HEADERS, request.headers)\rresponse = send_request(request)\rif response.error:\rspan.set_tag(opentracing., true)\rspan.finish()\r 否则，请求和响应被分开处理,需要自行扩展Tracer，用以封装request-span的映射 def process_request(request):\rspan = # start span from the current trace state\rtracer.inject(span. opentracing.Format.HTTP_HEADERS, request.headers)\rtracer.add_client_span(request, span)\rdef process_response(request, response):\rtracer.finish_client_span(request)\r  Span\u0026amp;\u0026amp;Relationships  Spans\nSpan是分布式系统中的逻辑工作单元，根据定义，它们都有名称、开始时间和持续时间。在Tracing中，Span与生成它们的分布式系统组件相关联。\n Relationships\n标识Span之间的连接，一个Span可以和N个Span关联。这种关系可以描述系统运行和延迟业务的关键路径。   我们希望为所有代码组织Span及其Relationship。当你为自己的分布式系统构建Tracing时，最好的方式是，从服务框架或与其他组件有广泛交互的组件开始。\n专注高价值区域 如上所述，从RPC和Web框架开始搭建Tracing是一个良好的开端。这两层有很大的覆盖范围和并涉及大量的事务。\n接下来，你应该检查服务器框架中未被基础设施覆盖的区域。提供足够的代码组件，为高价值事务的关键路径创建Trace。\n你监控的首要目标，是基于关键路径上的Span，寻找最耗时的操作，为优化操作提供最重要的数据支持。 例如，对于只占用事务时间1%的操作（一个大粒度的span）增加更细粒度的监控，对于你理解端到端的延迟（性能问题）不会有太大意义。\n逐步完善 当我们在为系统构建Trace时，需要权衡高价值事务的追踪与代码覆盖率。尽可能的为高价值的事务生成端到端的Trace，这会帮助我们进一步的识别哪些区域需要细粒度的Trace。\n一旦建立了端到端的Trace，我们很容易评估哪些区域需要增加投入，进行更细粒度的Trace，用以确定工作的优先级。\n示例 该示例表述： 用户通过客户端向服务发起一个HTTP请求，服务产生一系列的调用： client (HTTP) → web tier (RPC) → auth service (RPC) → billing service (RPC) → resource request (API) → response to web tier (API) → response to client (HTTP) 然后我们为Web和RPC进行Trace后，可以得到用户请求的完整Trace视图：\n基于Trace，我们可以为服务建立明确的SLO(段限原点 (segment limit origin)),用于寻找耗时较长的事务。\n",
    "ref": "/blog/opentracing/integration/"
  },{
    "title": "OpenTracing-Jaeger Demo",
    "date": "",
    "description": "",
    "body": "Jaeger ENV JAEGER_SERVICE_NAME\tThe service name.\nJAEGER_AGENT_HOST\tThe hostname for communicating with agent via UDP (default localhost).\nJAEGER_AGENT_PORT\tThe port for communicating with agent via UDP (default 6831).\nJAEGER_ENDPOINT\tThe HTTP endpoint for sending spans directly to a collector, i.e. http://jaeger-collector:14268/api/traces. If specified, the agent host/port are ignored.\nJAEGER_USER\tUsername to send as part of \u0026ldquo;Basic\u0026rdquo; authentication to the collector endpoint.\nJAEGER_PASSWORD\tPassword to send as part of \u0026ldquo;Basic\u0026rdquo; authentication to the collector endpoint.\nJAEGER_REPORTER_LOG_SPANS\tWhether the reporter should also log the spans\u0026quot; true or false (default false).\nJAEGER_REPORTER_MAX_QUEUE_SIZE\tThe reporter\u0026rsquo;s maximum queue size (default 100).\nJAEGER_REPORTER_FLUSH_INTERVAL\tThe reporter\u0026rsquo;s flush interval, with units, e.g. 500ms or 2s (valid units; default 1s).\nJAEGER_REPORTER_ATTEMPT_RECONNECTING_DISABLED\tWhen true, disables udp connection helper that periodically re-resolves the agent\u0026rsquo;s hostname and reconnects if there was a change (default false).\nJAEGER_REPORTER_ATTEMPT_RECONNECT_INTERVAL\tControls how often the agent client re-resolves the provided hostname in order to detect address changes (valid units; default 30s).\nJAEGER_SAMPLER_TYPE\tThe sampler type: remote, const, probabilistic, ratelimiting (default remote). See also https://www.jaegertracing.io/docs/latest/sampling/.\nJAEGER_SAMPLER_PARAM\tThe sampler parameter (number).\nJAEGER_SAMPLER_MANAGER_HOST_PORT\t(deprecated) The HTTP endpoint when using the remote sampler.\nJAEGER_SAMPLING_ENDPOINT\tThe URL for the sampling configuration server when using sampler type remote (default http://127.0.0.1:5778/sampling).\nJAEGER_SAMPLER_MAX_OPERATIONS\tThe maximum number of operations that the sampler will keep track of (default 2000).\nJAEGER_SAMPLER_REFRESH_INTERVAL\tHow often the remote sampler should poll the configuration server for the appropriate sampling strategy, e.g. \u0026ldquo;1m\u0026rdquo; or \u0026ldquo;30s\u0026rdquo; (valid units; default 1m).\nJAEGER_TAGS\tA comma separated list of name=value tracer-level tags, which get added to all reported spans. The value can also refer to an environment variable using the format ${envVarName:defaultValue}.\nJAEGER_DISABLED\tWhether the tracer is disabled or not. If true, the opentracing.NoopTracer is used (default false).\nJAEGER_RPC_METRICS\tWhether to store RPC metrics, true or false (default false).\nDemo  创建web工程  code几个简单的调用点： // Acts as our index page\rfunc indexHandler(w http.ResponseWriter, r *http.Request) {\rw.Write([]byte(`\u0026lt;a href=\u0026quot;/home\u0026quot;\u0026gt; Click here to start a request \u0026lt;/a\u0026gt;`))\r}\rfunc homeHandler(w http.ResponseWriter, r *http.Request) {\rw.Write([]byte(\u0026quot;Request started\u0026quot;))\rgo func() {\rhttp.Get(\u0026quot;http://localhost:8080/async\u0026quot;)\r}()\rhttp.Get(\u0026quot;http://localhost:8080/service\u0026quot;)\rtime.Sleep(time.Duration(rand.Intn(200)) * time.Millisecond)\rw.Write([]byte(\u0026quot;Request done!\u0026quot;))\r}\r// Mocks a service endpoint that makes a DB call\rfunc serviceHandler(w http.ResponseWriter, r *http.Request) {\r// ...\rhttp.Get(\u0026quot;http://localhost:8080/db\u0026quot;)\rtime.Sleep(time.Duration(rand.Intn(200)) * time.Millisecond)\r// ...\r}\r// Mocks a DB call\rfunc dbHandler(w http.ResponseWriter, r *http.Request) {\rtime.Sleep(time.Duration(rand.Intn(200)) * time.Millisecond)\r// here would be the actual call to a DB.\r}\r main中启动 func main() {\rport := 8080\raddr := fmt.Sprintf(\u0026quot;:%d\u0026quot;, port)\rmux := http.NewServeMux()\rmux.HandleFunc(\u0026quot;/\u0026quot;, indexHandler)\rmux.HandleFunc(\u0026quot;/home\u0026quot;, homeHandler)\rmux.HandleFunc(\u0026quot;/async\u0026quot;, serviceHandler)\rmux.HandleFunc(\u0026quot;/service\u0026quot;, serviceHandler)\rmux.HandleFunc(\u0026quot;/db\u0026quot;, dbHandler)\rfmt.Printf(\u0026quot;Go to http://localhost:%d/home to start a request!\\n\u0026quot;, port)\rlog.Fatal(http.ListenAndServe(addr, mux))\r}\r   引入Opentracing监控应用程序  在入口处创建span func homeHandler(w http.ResponseWriter, r *http.Request) {\rspan := opentracing.StartSpan(\u0026quot;/home\u0026quot;) // Start a span using the global, in this case noop, tracer\rdefer span.Finish()\r// ... the rest of the function\r}\r 设置一些tags和logs // The ext package provides a set of standardized tags available for use.\rimport \u0026quot;github.com/opentracing/opentracing-go/ext\u0026quot;\rfunc homeHandler(w http.ResponseWriter, r *http.Request) {\r// ...\r// We record any errors now.\r_, err := http.Get(\u0026quot;http://localhost:8080/service\u0026quot;)\rif err != nil {\rext.LogError(span, err) // Log the span and Tag the span as errored\r}\r// ...\r}\r 当然你也可以添加其他事件信息，如： 发生的重要事件，用户Id，浏览器类型\n  将Span注入到request中 func homeHandler(w http.ResponseWriter, r *http.Request) {\rw.Write([]byte(\u0026quot;Request started\u0026quot;))\rspan := opentracing.StartSpan(\u0026quot;/home\u0026quot;)\rdefer span.Finish()\r// Since we have to inject our span into the HTTP headers, we create a request\rasyncReq, _ := http.NewRequest(\u0026quot;GET\u0026quot;, \u0026quot;http://localhost:8080/async\u0026quot;, nil)\r// Inject the span context into the header\rerr := span.Tracer().Inject(span.Context(),\ropentracing.TextMap,\ropentracing.HTTPHeaderTextMapCarrier(asyncReq.Header))\rif err != nil {\rlog.Fatalf(\u0026quot;Could not inject span context into header: %v\u0026quot;, err)\r}\rgo func() {\rif _, err := http.DefaultClient.Do(asyncReq); err != nil {\rext.LogError(span, err)\r}\r}()\r// Repeat for the /service call.\r// ....\r}\r 从request中提取Span func serviceHandler(w http.ResponseWriter, r *http.Request) {\rvar sp opentracing.Span\ropName := r.URL.Path\r// Attempt to join a trace by getting trace context from the headers.\rwireContext, err := opentracing.GlobalTracer().Extract(\ropentracing.TextMap,\ropentracing.HTTPHeaderTextMapCarrier(r.Header))\rif err != nil {\r// If for whatever reason we can't join, go ahead an start a new root span.\rsp = opentracing.StartSpan(opName)\r} else {\rsp = opentracing.StartSpan(opName, opentracing.ChildOf(wireContext))\r}\rdefer sp.Finish()\r// ... rest of the function\r 连接到追踪系统 import (\r\u0026quot;github.com/opentracing/opentracing-go\u0026quot;\r\u0026quot;github.com/opentracing/opentracing-go/ext\u0026quot;\r\u0026quot;github.com/uber/jaeger-client-go\u0026quot;\rjaegercfg \u0026quot;github.com/uber/jaeger-client-go/config\u0026quot;\r)\rfunc main() {\rconst (\r// environment variable names\renvServiceName = \u0026quot;JAEGER_SERVICE_NAME\u0026quot;\renvDisabled = \u0026quot;JAEGER_DISABLED\u0026quot;\renvRPCMetrics = \u0026quot;JAEGER_RPC_METRICS\u0026quot;\renvTags = \u0026quot;JAEGER_TAGS\u0026quot;\renvSamplerType = \u0026quot;JAEGER_SAMPLER_TYPE\u0026quot;\renvSamplerParam = \u0026quot;JAEGER_SAMPLER_PARAM\u0026quot;\renvSamplerManagerHostPort = \u0026quot;JAEGER_SAMPLER_MANAGER_HOST_PORT\u0026quot; // Deprecated by envSamplingEndpoint\renvSamplingEndpoint = \u0026quot;JAEGER_SAMPLING_ENDPOINT\u0026quot;\renvSamplerMaxOperations = \u0026quot;JAEGER_SAMPLER_MAX_OPERATIONS\u0026quot;\renvSamplerRefreshInterval = \u0026quot;JAEGER_SAMPLER_REFRESH_INTERVAL\u0026quot;\renvReporterMaxQueueSize = \u0026quot;JAEGER_REPORTER_MAX_QUEUE_SIZE\u0026quot;\renvReporterFlushInterval = \u0026quot;JAEGER_REPORTER_FLUSH_INTERVAL\u0026quot;\renvReporterLogSpans = \u0026quot;JAEGER_REPORTER_LOG_SPANS\u0026quot;\renvReporterAttemptReconnectingDisabled = \u0026quot;JAEGER_REPORTER_ATTEMPT_RECONNECTING_DISABLED\u0026quot;\renvReporterAttemptReconnectInterval = \u0026quot;JAEGER_REPORTER_ATTEMPT_RECONNECT_INTERVAL\u0026quot;\renvEndpoint = \u0026quot;JAEGER_ENDPOINT\u0026quot;\renvUser = \u0026quot;JAEGER_USER\u0026quot;\renvPassword = \u0026quot;JAEGER_PASSWORD\u0026quot;\renvAgentHost = \u0026quot;JAEGER_AGENT_HOST\u0026quot;\renvAgentPort = \u0026quot;JAEGER_AGENT_PORT\u0026quot;\r)\ros.Setenv(envServiceName, \u0026quot;test\u0026quot;)\ros.Setenv(envDisabled, \u0026quot;false\u0026quot;)\ros.Setenv(envSamplerType, \u0026quot;const\u0026quot;)\ros.Setenv(envSamplerParam, \u0026quot;1\u0026quot;)\ros.Setenv(envReporterLogSpans, \u0026quot;true\u0026quot;)\ros.Setenv(envAgentHost, \u0026quot;jarger-agent addr\u0026quot;)\ros.Setenv(envAgentPort, \u0026quot;6831\u0026quot;)\rcfg, err := jaegercfg.FromEnv()\rif err != nil {\r// parsing errors might happen here, such as when we get a string where we expect a number\rfmt.Println(\u0026quot;Could not parse Jaeger env vars: %s\u0026quot;, err.Error())\rreturn\r}\rtracer, closer, err := cfg.NewTracer(jaegercfg.Logger(jaeger.StdLogger))\rif err != nil {\rfmt.Println(\u0026quot;Could not initialize jaeger tracer: %s\u0026quot;, err.Error())\rreturn\r}\rdefer closer.Close()\ropentracing.SetGlobalTracer(tracer)\rport := 8080\raddr := fmt.Sprintf(\u0026quot;:%d\u0026quot;, port)\rmux := http.NewServeMux()\rmux.HandleFunc(\u0026quot;/\u0026quot;, indexHandler)\rmux.HandleFunc(\u0026quot;/home\u0026quot;, homeHandler)\rmux.HandleFunc(\u0026quot;/async\u0026quot;, serviceHandler)\rmux.HandleFunc(\u0026quot;/service\u0026quot;, serviceHandler)\rmux.HandleFunc(\u0026quot;/db\u0026quot;, dbHandler)\rfmt.Printf(\u0026quot;Go to http://localhost:%d/home to start a request!\\n\u0026quot;, port)\rfmt.Println(http.ListenAndServe(addr, mux))\r}\r    ",
    "ref": "/blog/opentracing/jaeger/"
  },{
    "title": "OpenTracing-概念和关键字",
    "date": "",
    "description": "",
    "body": "Span   Example Span\n t=0 operation name: db_query t=x\r+-----------------------------------------------------+\r| · · · · · · · · · · Span · · · · · · · · · · |\r+-----------------------------------------------------+\rTags:\r- db.instance:\u0026quot;customers\u0026quot;\r- db.statement:\u0026quot;SELECT * FROM mytable WHERE foo='bar'\u0026quot;\r- peer.address:\u0026quot;mysql://127.0.0.1:3306/customers\u0026quot;\rLogs:\r- message:\u0026quot;Can't connect to mysql server on '127.0.0.1'(10061)\u0026quot;\rSpanContext:\r- trace_id:\u0026quot;abc123\u0026quot;\r- span_id:\u0026quot;xyz789\u0026quot;\r- Baggage Items:\r- special_id:\u0026quot;vsid1738\u0026quot;\r  Span 是分布式追踪系统的主要构成模块，表示分布式系统中单个独立的工作单元\n  分布式系统中的每个组件都创建一个Span\n  Spans可以包含其他的Spans，这允许将多个Spans组装成一个完整的Trace\n  每个Span根据OpenTracing规范封装以下状态：\n 操作名 开始和结束时间戳 Span Tags集合 Span Logs集合 SpanContext    Span Operate Name 每个Span都有一个操作名，操作名需要简洁明确。其他具体的描述可以使用Span Tags。\n例如，获取假设用户信息接口：\n   操作名 建议     get 太抽象   get_count/392 太具体   get_count 合理    Span Tags  Tags是键值对数据类型， 使用用户定义的Spans注释来查询、筛选、理解追踪数据。 Span Tags应用于整个Span，因此Tags适用于Span的整个时间范围，而不是特定时间戳的特定时刻。  常规Span Tags表 semantic_conventions.md中列出了常见场景中的常规Span Tags\n   Span tag name 数据类型 注释和样例     component string 生成相关Span的软件包、框架、库或模块. E.g., \u0026ldquo;grpc\u0026rdquo;, \u0026ldquo;django\u0026rdquo;, \u0026ldquo;JDBI\u0026rdquo;.   db.instance string 数据库实例名. E.g., jdbc.url=\u0026ldquo;jdbc:mysql://127.0.0.1:3306/customers\u0026rdquo;, 实例名是\u0026quot;customers\u0026quot;.   db.statement string 给定类型的数据库语句. E.g., db.type=\u0026ldquo;sql\u0026rdquo;,语句可能是 \u0026ldquo;SELECT * FROM wuser_table\u0026rdquo;; db.type=\u0026ldquo;redis\u0026rdquo;, 语句可能是\u0026quot;SET mykey \u0026lsquo;WuValue\u0026rsquo;\u0026quot;.   db.type string 数据库类型. 所有的关系型数据库都是\u0026quot;sql\u0026quot;. 其他数据库类型(小写字母), e.g. \u0026ldquo;cassandra\u0026rdquo;, \u0026ldquo;hbase\u0026rdquo;, or \u0026ldquo;redis\u0026rdquo;.   db.user string 访问数据库的用户名. E.g., \u0026ldquo;readonly_user\u0026rdquo; or \u0026ldquo;reporting_user\u0026rdquo;   error bool 当且仅当应用程序认为Span表示的操作失败时，为true   http.method string 请求关联Span的HTTP方法. E.g., \u0026ldquo;GET\u0026rdquo;, \u0026ldquo;POST\u0026rdquo;   http.status_code integer 关联Span的HTTP响应状态码. E.g., 200, 503, 404   http.url string Trace中正在被处理的请求URL. E.g., \u0026ldquo;https://domain.net/path/to?resource=here\u0026quot;   message_bus.destination string 消息主体的描述. E.g. 一条Kafka记录的\u0026quot;topic nam\u0026rdquo; 可以被生产者和消费者提取并使用此tag存储   peer.address string 远程网络访问访问地址. 可以是 \u0026ldquo;ip:port\u0026rdquo;, \u0026ldquo;hostname\u0026rdquo;, FQDN, 甚至是一个JDBC的字串: \u0026ldquo;mysql://prod-db:3306\u0026rdquo;   peer.hostname string 远程访问主机名 E.g., \u0026ldquo;opentracing.io\u0026rdquo;, \u0026ldquo;internal.dns.name\u0026rdquo;   peer.ipv4 string 远程访问IPv4地址. E.g., \u0026ldquo;127.0.0.1\u0026rdquo;   peer.ipv6 string 远程访问IPv6地址. E.g., \u0026ldquo;2001:0db8:85a3:0000:0000:8a2e:0370:7334\u0026rdquo;   peer.port integer 远程访问端口. E.g., 80   peer.service string 远程访问服务名. E.g., \u0026ldquo;elasticsearch\u0026rdquo;, \u0026ldquo;a_custom_microservice\u0026rdquo;, \u0026ldquo;memcache\u0026rdquo;   sampling.priority integer 如果大于0，则提示跟踪程序尽力捕获Trace。如果为0，则提示跟踪不要捕获Trace。如果没有，跟踪程序应该使用其默认的采样机制   span.kind string 在RPC中是\u0026quot;client\u0026quot;或\u0026quot;server\u0026quot;,在消息应用中是\u0026quot;producer\u0026quot;或\u0026quot;consumer\u0026quot;    一些特定应用场景   RPC\n span.kind: 为 \u0026ldquo;client\u0026rdquo; 或 \u0026ldquo;server\u0026rdquo;. 在Span开始时需要提供这个Tag, 因为这会影响内部ID的生成. peer.address, peer.hostname, peer.ipv4, peer.ipv6, peer.port, peer.service: 可选 tags 用于描述RPC对端信息 (通常在内部无法评估的情况下使用)    Message Bus\n 消息总线是异步的，因此用于连接Consumer Span和Produce Span的关系类型将会从Spans之间的引用\n  message_bus.destination: 如上表所述：消息主体的描述 span.kind: 为 \u0026ldquo;producer\u0026rdquo; 或 \u0026ldquo;consumer\u0026rdquo;. 在Span开始时需要提供这个Tag, 因为这会影响内部ID的生成. peer.address, peer.hostname, peer.ipv4, peer.ipv6, peer.port, peer.service: 可选 tags 用于描述Message Bus 代理 (通常在内部无法评估的情况下使用)    Database\n db.type, db.instance, db.user, and db.statement: 如上表所述 peer.address, peer.hostname, peer.ipv4, peer.ipv6, peer.port, peer.service: 可选 tags 用于描述数据库对端信息 span.kind: \u0026ldquo;client\u0026rdquo;    Span Logs  Logs是键值对数据类型， 用于捕获特定Span的日志消息和应用自身的其他调试和信息输出。 Logs用于记录Span中特定时刻或事件， 于Tags应用于整个Span相反。  常规Span Logs semantic_conventions.md中列出了常见场景中的常规Span Logs\n   Span Logs字段名 数据类型 描述和样例     error.kind string 错误类型或种类 (仅在 event=\u0026ldquo;error\u0026rdquo; 的日志时). E.g., \u0026ldquo;Exception\u0026rdquo;, \u0026ldquo;OSError\u0026rdquo;   error.object object 对于支持的语言(e.g., Java, Python), 可以是 Throwable/Exception/Error 这些对象. E.g., java.lang.UnsupportedOperationException, python exceptions.NameError   event string 标识Span生命周期中某个值得注意的时刻。例如, 一个互斥锁的获得或释放或者描述web页面加载过程中的events. E.g., Zipkin：\u0026ldquo;cs\u0026rdquo;, \u0026ldquo;sr\u0026rdquo;, \u0026ldquo;ss\u0026rdquo;, or \u0026ldquo;cr\u0026rdquo;. 更普遍的是：\u0026ldquo;initialized\u0026rdquo; or \u0026ldquo;timed out\u0026rdquo;. 如果是错误项，则是： \u0026ldquo;error\u0026rdquo;   message string 对event简洁明了的描述，一般是单行. E.g., \u0026ldquo;Could not connect to backend\u0026rdquo;, \u0026ldquo;Cache invalidation succeeded\u0026rdquo;   stack string 平台常规的堆栈跟踪信息; 或许与错误相关. E.g., \u0026ldquo;File \u0026quot;example.py\u0026quot;, line 7, in \u0026lt;module\u0026gt;\\ncaller()\\nFile \u0026quot;example.py\u0026quot;, line 5, in caller\\ncallee()\\nFile \u0026quot;example.py\u0026quot;, line 2, in callee\\nraise Exception(\u0026quot;Yikes\u0026quot;)\\n\u0026rdquo;     Span 和 log errors  有必要区分错误的Spans和Span执行期间记录的错误 每个Span要么以错误状态结束要么不是，使用\u0026quot;error=true\u0026quot; Tag来区分这两种情况。    记录应用级错误 记录在Span的生命周期中突然出现的应用级错误是有意义的。因为在这些情况，Span日志更合适，因为错误有时间戳。\n根据程序语言的不同，Opentracing使用不同的方式描述Logged errors。其中一些特定的字段是指定给errors的(e.g., event/message)\n 对于那些使用error object封装堆栈追踪和类型信息的程序语言，记录以下日志： event=\u0026quot;error\u0026quot;\rerror.object=\u0026lt;error object instance\u0026gt;\r 对于其他语言，或者以上方案不可行时： event=\u0026quot;error\u0026quot;\rmessage=\u0026quot;...\u0026quot;\rstack=\u0026quot;...\u0026quot; (optional)\rerror.kind=\u0026quot;...\u0026quot; (optional)\r 这种方案允许追踪器从error object中提取需要的信息   一个Span可能是在错误的状态且没有错误日志，反之亦然.\n SpanContext SpanContext携带跨进程的数据。有两个主要组成部分:\n 标记Trace中Span的状态数据：eg: trace_id/span_id Baggage  键值对集合 跨进程数据，在一条追踪链路上的所有Spans内全局传输 在整个Trace过程中传输有用数据   由于Baggage全局传输，如果包含数据量太大，会降低系统的吞吐量或增加RPC延迟\n   Scope 在任何线程中都有一个\u0026quot;active\u0026quot; Span主要负责周围代码完成的工作。\nOpenTracing API 只允许当前线程在任何时间只有一个ActiveSpan。\n使用Scope管理和控制Span的activation和deactivation。其他在同一线程中相关的Span需要满足以下条件:\n Started Not finished Not active  举例说明，一个线程可以存在多个Span，这些Span正在:\n 等待I/O 在子Span上阻塞 脱离关键路径   如果创建新的Span时存在Scope，则其作为新Span的parent，除非明确指定parent context或者在buildSpan()时调用ignoreActiveSpan();\n ScopeManager 访问ActiveSpan 由于手动在函数中传递ActiveSpan不方便。OpenTracing要求每个Tracer需要包含一个ScopeManager。\nScopeManger实现通过Scope访问ActiveSpan。因此开发者可以通过Scope访问任何ActiveSpan。\n线程间移动Span 使用ScopeManger，开发者可以在不同的线程间传递Span。因此一个Span的生命周期可能在一个线程中开始，在另一个线程中结束。\nScopeManager允许Span在线程或callback中传递，但是不支持Scope的传递。\nTracer Tracer用于记录Span并将其发布到某处。\nTracer实例可以用于创建Span或者将其传给框架和库现有的插桩程序。\nTracer设置 Tracer实例可以直接在应用中使用，也可以保存到GlobalTracer全局实例中，在任何地方使用。\n no-nop Tracer 不提供任何操作，不会出错无副作用。  创建新的Trace 每当创建不引用Parent Span的新Span时就会创建新的Trace。\n访问ActiveSpan Tracer可以访问ActiveSpan\nTracer Inject/Extract OpenTracing 要求提供Inject和Extract方法将SpanContext编码到请求载体中和从请求在提供解吗，流程如下图:\n",
    "ref": "/blog/opentracing/concepts/"
  },{
    "title": "OpenTracing-示例练习",
    "date": "",
    "description": "",
    "body": "Tracing函数 func TopLevelFunc() {\rspan1 := opentracing.GlobalTracer().StartSpan(\u0026quot;TopLevelFunc\u0026quot;)\rdefer span1.Finish()\r... // 业务逻辑\r} 后续，作为上述业务逻辑一部分，我们调用了function2，也想tracing。为了将此函数也附着在正在进行的trace上， 我们需要一个获取span1的方法，后续我们再讨论如何实现，现在我们假设有这样一个方法GetCurrentSpan可以获取span1:\nfunc function2(){\rspan1 := GetCurrentSpan()\rif span1 != nil {\rspan2 := opentracing.GlobalTracer().StartSpan(\u0026quot;function2\u0026quot;, opentracing.ChildOf(span1.Context())) defer span2.Finish() } ... //业务逻辑\r}\r 假设调用者没有启动tracing，也不想在function2中创建新的tracing，需要考虑GetCurrentSpan可能返回nil\n 通常情况下，开发者不希望追踪的代码混在业务代码中，而是用其他方式。 如：注解. 参考function decorator in Python: \r@traced_function\rdef top_level_function():\r... # business logic\r\nTracing服务端 当服务想tracing一个请求的执行，需要以下几步:\n 尝试从request中获取SpanContext(防止tracing已经在客户端开始)，如果无法获取request中的SpanContext则新开始一个tracing 将新创建的Span保存到request context中，request context会跟随应用程序代码或RPC框架在整个系统中传播。 最后，当服务完成请求处理后，使用span.finish()关闭Span  从请求中提取SpanContext 假设我们有一个HTTP服务，并且SpanContext已经通过HTTP headers，从客户端传递到服务器，可以通过req.Headers访问到:\nextractedCtx := opentracing.GlobalTracer().Extract(\ropentracing.HTTP_HEADER_FORMAT, opentracing.HTTPHeadersCarrier(req.Headers)\r 这里我们使用headers作为载体，Tracer对象知道读取哪些headers，并将tracer数据和Baggage解构。\n 继续请求中已经存在的trace或者创建新的trace 由于request client没有发起trace，上述提取的extractedCtx对象有可能为空，此情况需要考虑创建新的trace。\nvar span opentracing.Span\rextractedCtx := opentracing.GlobalTracer().Extract(\ropentracing.HTTP_HEADER_FORMAT, opentracing.HTTPHeadersCarrier(req.Headers)\rif extractedCtx === nil {\rspan = opentracing.GlobalTracer().StartSpan(\u0026quot;operation_name\u0026quot;)\r} else {\rspan = opentracing.GlobalTracer().StartSpan(\u0026quot;operation_name\u0026quot;, opentracing.ChildOf(extractedCtx))\r}\rspan.SetTag(\u0026quot;http.method\u0026quot;, req.Method)\rspan.SetTag(\u0026quot;http.url\u0026quot;, req.URL)\r SetTag 在Span上记录关于request的附加信息\n 上述operation_name是Span的名称。例如: 一个HTTP POST请求(url:/save_user/123), operation_name可以命名为post:/save_user/。 实际OpenTracing没有规定此命名规则。\n进程内Context传递 request context传递指的是应用程序将某个context与请求绑定，这样应用中在同一进程中的所有层都可以访问这个context。\n通过context，提供某些指定值给应用层，例如:userId, token, timestamp。当然也可以传递当前的trace span。\n目前有两种context传递方式:\n 隐式传递\n在隐式传递技术中，context存储在平台特定的位置，允许在应用程序的任何位置检索。 通常RPC框架利用thread-local或continuation-local存储,或者全局变量(单线程进程)等机制来使用context。 显示传递 在显示传递技术中，程序代码显示的传递context对象。 func HandleHttp(w http.ResponseWriter, req *http.Request) {\rctx := context.Background()\r...\rBusinessFunction1(ctx, arg1, ...)\r}\rfunc BusinessFunction1(ctx context.Context, arg1...) {\r...\rBusinessFunction2(ctx, arg1, ...)\r}\rfunc BusinessFunction2(ctx context.Context, arg1...) {\rparentSpan := opentracing.SpanFromContext(ctx)\rchildSpan := opentracing.StartSpan(\r\u0026quot;...\u0026quot;, opentracing.ChildOf(parentSpan.Context()), ...)\r...\r}\r context显示传递的缺点是，它会将基础设施的问题泄漏到程序代码中。\n   Tracing客户端 一个RPC client，在发起request之前，将发起一个新的tracing，并将Span绑定到该request上：\nfunc makeSomeRequest() {\rspan := opentracing.StartSpan(\u0026quot;makeSomeRequest\u0026quot;, opentracing.StartTime(time.Now()))\rdefer span.Finish()\rhttpClient := \u0026amp;http.Client{}\rhttpReq, _ := http.NewRequest(\u0026quot;GET\u0026quot;, \u0026quot;http://myservice/xxx/\u0026quot;, nil)\rext.HTTPMethod.Set(span, http.MethodGet)\rext.HTTPUrl.Set(span, \u0026quot;/xxx/\u0026quot;)\rspan.SetBaggageItem(\u0026quot;reqId\u0026quot;, \u0026quot;snowId\u0026quot;)\rspan.BaggageItem(\u0026quot;reqId\u0026quot;)\r// Transmit the span's TraceContext as HTTP headers on our\r// outbound request.\ropentracing.GlobalTracer().Inject(\rspan.Context(),\ropentracing.HTTPHeaders,\ropentracing.HTTPHeadersCarrier(httpReq.Header))\rresp, err := httpClient.Do(httpReq)\rif err != nil {\rext.LogError(span, err)\r} else {\rext.HTTPStatusCode.Set(span, uint16(resp.StatusCode))\rif resp.StatusCode != http.StatusOK {\rext.LogError(span, errors.New(resp.Status))\r}\r}\r}\r 如果请求出错，我们在span中记录错误\n Baggage/SpanContext应用 以上示例中的client和server通过request传递Span/Trace,包括Baggage。 client使用Baggage传递附加数据到server及其下游所有server:\n``` // client side snowId := \u0026hellip; span.SetBaggageItem(\u0026ldquo;reqId\u0026rdquo;, snowId)\n// server side (多级服务)\rreqId := span.BaggageItem(\u0026quot;reqId\u0026quot;)\r```\r Logging Event 我们已经在上述client Span应用示例中使用log功能。在Span中log，不会产生额外的负载，而且可以在Span创建或结束之外的流程执行log。 例如，应用在业务执行的过程中，通过获取当前的Span，记录事件：\nspan := get_current_span()\rext.LogError(span, errors.New(\u0026quot;cache-miss\u0026quot;))\r  log自动记录事件发生的时间戳， 这点和tags不同 log允许事件设置外部时间戳， e.g. Log(Go)   设置Span的外部时间戳 span := opentracing.StartSpan(\u0026quot;operation_name\u0026quot;, opentracing.StartTime(time.Now()))\rdefer func() {\rspan.FinishWithOptions(opentracing.FinishOptions{\rFinishTime: time.Now(),\r})\r}\r设置采样优先级 多数分布式系统，通过采样来降低trace的数据量。有时，研发人员需要一种方式来确定指定的流程被trace， e.g. 可以在HTTP请求参数中添加特殊参数，如： debug=true。\nOpenTracing API标准化一些有用的tag，其中sampling priority：精确的语义由实现者决定， 但是任何大于0(默认)的值都表示当前trace的高优先级。\n为了将debug属性应用到追踪系统，需要在trace开始前，做以下预处理:\nif query.get(\u0026quot;debug\u0026quot;) == \u0026quot;true\u0026quot; {\rspan := opentracing.StartSpan(\u0026quot;operation_name\u0026quot;, opentracing.StartTime(time.Now()))\rext.SamplingPriority.Set(span, 1)\r}\rTracing 消息总线 消息总线的类型分为两种： 消息队列和发布/订阅。\n从Tracing角度出发，只关注与producer绑定的SpanContext被传递到多个consumers。\nconsumer负责创建Span，用以记录消息的处理并且创建SpanContext的FollowsFrom引用\n与RPC client相同， producer在发送消息前创建新的Span，并且SpanContext跟随消息进行传递。 此Span，将会在消息被发布后结束。具体看下面示例：\ndef traced_send(message, operation):\r# retrieve current span from propagated message context\rparent_span = get_current_span()\r# start a new span to represent the message producer\rspan = tracer.start_span(\roperation_name=operation,\rchild_of=parent_span.context,\rtags={'message.destination': message.destination}\r)\r# propagate the Span via message headers\rtracer.inject(\rspan.context,\rformat=opentracing.TEXT_MAP_FORMAT,\rcarrier=message.headers)\rwith span:\rmessaging_client.send(message)\rexcept Exception e:\r...\rraise\rconsumer检查输入消息是否包含SpanContext，如果存在，则关联该Span：\nextracted_context = tracer.extract(\rformat=opentracing.TEXT_MAP_FORMAT,\rcarrier=message.headers\r)\rspan = tracer.start_span(operation_name=operation, references=follows_from(extracted_context))\rspan.set_tag('message.destination', message.destination)\r消息队列的同步请求-响应 一些消息队列的平台，支持消息头包含应答地址。当consumer处理完消息后，需要给消息队列返回应答。\n这种模式可以模拟同步请求-响应，在这种情况下，consumer和producer的Span关系是互为ChildOf。\n从跟踪的角度，建议忽略该模式(请求-响应)， 将其作为两个独立的消息交换，即两个Span。\n",
    "ref": "/blog/opentracing/practices/"
  },{
    "title": "OpenTracing-简介",
    "date": "",
    "description": "",
    "body": "为什么Tracing  研发团队因为系统组件的水平扩展、开发团队小型化、解耦各种需求等，正在使用微服务架构替换老旧的单体系统。 这个过程中需要面临一系列的问题：由于没有内存调用和堆栈追踪，怎样在复杂的网络环境中调试和监测分布式事务。 分布式追踪系统旨在解决这些问题  模式 大多数追踪系统的Mental Model来源于这篇论文(Google\u0026rsquo;s Dapper paper)。 OpenTracing使用相似的关键词和定义。\n Trace: 在分布式系统中运行的事务的描述 Span: 工作流中的一部分被命名和定时的操作  Spans 接受k:v 标签，以及细粒度、时间戳、结构化日志附加到指定的Span实例中\n  Span Context: 伴随分布式事务的追踪信息，包含它在服务间传递的时间  Span Context包含traceId，SpanId，以及追踪系统需要传递给下游服务器的其他任何数据\n   追踪系统划分  从应用层分布式追踪系统的角度看，软件系统如下图：\n 软件系统中的组件可以被分成以下三类：  应用和业务逻辑(自己的代码) 第三方库 第三方服务   这三类组件有不同的需求，并且推动了分布式追踪系统的设计，用于监控应用程序。最终的设计产生四个重要部分：  追踪API 通信协议 数据格式 分析系统: 用于处理追踪数据的数据库和交互式UI    OpenTracing   OpenTracing通过提供标准的、厂商无关的工具框架\n  如果开发人员尝试不同的分布式跟踪系统，只需要简单的修改追踪器的配置，而不是修改整个系统的trace代码。\n  OpenTracing是轻量级标准化层， 位于程序/类库和监控系统之间。\n +-------------+ +---------+ +----------+ +------------+\r| Application | | Library | | OSS | | RPC/IPC |\r| Code | | Code | | Services | | Frameworks |\r+-------------+ +---------+ +----------+ +------------+\r| | | |\r| | | |\rv v v v\r+-----------------------------------------------------+\r| · · · · · · · · · · OpenTracing · · · · · · · · · · |\r+-----------------------------------------------------+\r| | | |\r| | | |\rv v v v\r+-----------+ +-------------+ +-------------+ +-----------+\r| Tracing | | Logging | | Metrics | | Tracing |\r| System A | | Framework B | | Framework C | | System D |\r+-----------+ +-------------+ +-------------+ +-----------+\r上述模块简介:\n Application Code\n编写Application Code的开发者，可以使用OpenTracing描述因果关系，控制流程以及在此过程中增加细粒度的日志信息。 Library Code\n类似原因，对请求进行中间控制的Library Code，可以集成OpenTracing。如: web中间件Library，可以使用OpenTracing为请求处理流程创建Span。 或者ORM Library，可以使用OpenTracing描述高级ORM语义并度量指定SQL查询语句的执行情况。 OSS Services\n与嵌入式Library比，整个OSS服务与分布式trace系统集成，在更大的分布式系统中初始化或传播到其它进程。如：HTTP负载均衡器使用OpenTracing来修饰请求。 或者分布式键值数据库使用OpenTracing来解释读写性能。 RPC/IPC Frameworks\n任何跨进程边界的子系统，使用OpenTracing来标准化注入或提取(请求协议或其他载体中)tracing数据的格式。   以上所有模块需要使用OpenTracing来描述和传播分布式Tracing，而不需要理解OpenTracing的底层实现。\n   因为在OpenTracing上层有更多的程序员和应用程序，所以API和用例的易用性也更倾向于它们。\n  支持OpenTracing API的编程语言 GO/JavaScript/Java/Python/Ruby/PHP/Objective-c/C++/C#\n",
    "ref": "/blog/opentracing/introduction/"
  },{
    "title": "OpenTracing-语义规范",
    "date": "",
    "description": "",
    "body": "OpenTracing Data Model 在OpenTracing中，Trace是由Span隐式定义的。 Trace可以看作是Spans的有向无环图(DAG)，Spans之间的边界称之为References.\n例如以下的Trace由8个Spans组成：\nCausal relationships between Spans in a single Trace\r[Span A] ←←←(the root span)\r|\r+------+------+\r| |\r[Span B] [Span C] ←←←(Span C is a `ChildOf` Span A)\r| |\r[Span D] +---+-------+\r| |\r[Span E] [Span F] \u0026gt;\u0026gt;\u0026gt; [Span G] \u0026gt;\u0026gt;\u0026gt; [Span H]\r↑\r↑\r↑\r(Span G `FollowsFrom` Span F)\r使用时间轴对Trace进行可视化表示看起来更直观些:\nTemporal relationships between Spans in a single Trace\r––|–––––––|–––––––|–––––––|–––––––|–––––––|–––––––|–––––––|–\u0026gt; time\r[Span A···················································]\r[Span B··············································]\r[Span D··········································]\r[Span C········································]\r[Span E·······] [Span F··] [Span G··] [Span H··]\rSpan Reference Span可以被其他Span引用， 因此多个Span存在因果关系。 OpenTracing定义了以下两种关系:\n  ChildOf\n新创建的Span可以指定其Parent Span， 并且Parent Span依赖于新Span， 则新Span和Parent Span是ChildOf关系。\n以下时序图简单表述Spans ChildOf关系：\n [-Parent Span---------]\r[-Child Span----]\r[-Parent Span--------------]\r[-Child Span A----]\r[-Child Span B----]\r[-Child Span C----]\r[-Child Span D---------------]\r[-Child Span E----]\r  FollowFrom\n用以表示新Span独立于Parent Span， 例如：在异步进程中\n以下时序图可以简单的表述Spans FollowFrom关系:\n[-Parent Span-] [-Child Span-]\r[-Parent Span--]\r[-Child Span-]\r[-Parent Span-]\r[-Child Span-]\r  The OpenTracing API Tracer interface 创建Spans并且实现注入和提取跨进程传递的元素据。有以下功能:\n 创建新的Span 注入SpanContext到进程间数据的载体中 从进程间数据的载体中提取SpanContext  Injection/Extration 编码格式 OpenTracing规定SpanContext在注入载体和从载体提取时，需要确定其编码格式。有以下几种:\n Text Map: 任意的string-to-string map结构 HTTP Headers: 适合在HTTP Headers中使用的string-to-string map结构 Binary: SpanContext的二进制编码  一个端到端的injector和extractor示例 为了让描述更具体，考虑如下的流程：\n 一个客户端进程有一个SpanContext实例，并准备进行通过自制的HTTP协议，进行一次RPC调用 客户端进程调用Tracer.Inject(\u0026hellip;)，传入SpanContext实例，Format, 载体实例，三个参数 根据Format对SpanContext进行编码，并将数据注入到载体中（如：添加到HTTP头中） 进行HTTP调用，将数据进行跨进程传输 服务端进程调用Tracer.Extract(\u0026hellip;)，传入需要的操作名（operation name），Format，以及载体数据 不考虑数据丢失，和其他错误，服务端现在有了和客户端追踪上下文中，一样的SpanContext。  Span Interface Span 接口功能:\n Get SpanContext Finish Span Set Tag Add Log Set Baggage Item Get Baggage Item  ",
    "ref": "/blog/opentracing/specification/"
  },{
    "title": "gRPC over HTTP2",
    "date": "",
    "description": "",
    "body": "",
    "ref": "/blog/grpc/protocol-http2/"
  },{
    "title": "gRPC-Introduction",
    "date": "",
    "description": "",
    "body": "gRPC 是开源的高性能RPC框架，可以运行在任何环境。它可以高效的连接数据中心或跨数据中心的服务， 支持可插拔的load balaning,tracing,health checking和authentication. 它同样适用于分布式计算的最后一英里，连接设备，手机app，浏览器到后端服务。\n本章介绍gRPC 和 protocol buffers。 gRPC使用protocol buffers作为IDL(接口定义语言)和底层信息交换格式。\n概述 在gRPC的架构中，client app可以像本地调用一样，直接调用一个远程server app方法，这使得创建分布式应用和服务更便捷。 与其他RPC系统相似， gRPC也是基于服务化的思想， 暴露方法，使其可以被远程调用。server端，实现这些方法并启动gRPC服务来处理client调用。 client端，stub提供与server端相同的方法，来被client端调用。\ngRPC clients和servers可以在多种环境中运行和通信，并且可以用任何gRPC支持的语言编写。 例如：使用Java编写server，使用GO/Python/Ruby等编写client。 此外最新的API将有gRPC 版本号的支持。\nProtocol Buffers gRPC默认使用Protocol Buffers序列化数据(当然也可以使用其它数据格式，如：JSON)。\n动机 十年来，Google一直使用名为Stubby的单一通用RPC基础设施来连接数据中心或跨数据中心的微服务。Google的内部很早就采用当下流行的微服务架构。 使用统一的，跨平台的RPC基础设施，在效率、安全性、可靠性和行为分析方面进行全范围的改进，用以支撑业务的快速增长。\nStubby有许多强大的特性，但是它不基于任何标准并且与Google内部基础设施紧密耦合，因此不适合公开发布。 随着SPDY、HTTP/2和QUIC等具有相同特性的公共标准出现，包含Stubby没有提供的一些特性。很明显，是时候利用这些标准化来改造Stubby， 并扩展应用到mobile,loT和Cloud等场景。\n原则和需求 Services not Objects, Messages not References 提倡在系统之间进行粗粒度信息交换的微服务设计理念，同时避免分布式对象的陷阱 和忽略网络错误\nCoverage \u0026amp; Simplicity 这个堆栈应该对所有流行的平台是可用的，并且用户可以轻松的为其选择的平台进行构建。它应该能在CPU和内存有限的设备上使用。\nFree \u0026amp; Open 使其基本功能对所有人免费使用。以开放源码的方式发布所有组件，并使用许可，应当促使而不是阻碍使用。\n",
    "ref": "/blog/grpc/introduction/"
  },{
    "title": "gRPC-platform",
    "date": "",
    "description": "",
    "body": "",
    "ref": "/blog/grpc/platform/"
  },{
    "title": "gRPC-基准测试",
    "date": "",
    "description": "",
    "body": "",
    "ref": "/blog/grpc/benchmarking/"
  },{
    "title": "gRPC-身份认证",
    "date": "",
    "description": "",
    "body": "gRPC设计上允许使用多种身份认证机制，\n",
    "ref": "/blog/grpc/authentication/"
  },{
    "title": "gRPC-错误处理",
    "date": "",
    "description": "",
    "body": "本文讲述gRPC的身份认证，包括内置的身份认证机制，以及如何插入自己的认证系统。\ngRPC被设计为\n",
    "ref": "/blog/grpc/errorhandling/"
  },{
    "title": "gRPC核心概念，架构，生命周期",
    "date": "",
    "description": "",
    "body": "本文介绍gRPC的主要概念，架构和生命周期\n服务定义 与其它RPC系统类似，gRPC基于服务定义的概念，指定可以远程调用(使用自定义参数和返回值)的方法。 默认情况下，gRPC使用protocol buffers作为IDL，用以描述服务接口和负载信息的结构。当然，如果需要，你可以使用其它方式替代。\nservice HelloService {\rrpc SayHello (HelloRequest) returns (HelloResponse);\r}\rmessage HelloRequest {\rstring greeting = 1;\r}\rmessage HelloResponse {\rstring reply = 1;\r}\rgRPC提供四种定义服务的方法:\n Unary RPC, client发送单个请求到server并返回单个响应： rpc SayHello(HelloRequest) returns (HelloResponse);\r Server Stream RPC，client发送单个请求,server返回一个流，用以读取返回的一系列信息。 client从流中读取数据直到没有更多的信息。gRPC保证单个RPC调用中的信息顺序。 rpc LotsOfReplies(HelloRequest) returns (stream HelloResponse);\r Client Stream RPC, client写入一系列的信息并使用流发送它们到服务器。一旦client结束写信息， 就会等待server读取并返回响应。gRPC保证打个RPC调用中的信息顺序。 rpc LotsOfGreetings(stream HelloRequest) returns (HelloResponse);\r Bidirectional Stream RPC, client和server都会使用一个读写流发送一系列的信息。这两个流是独立运行的， 因此client和server可以任意的读写数据。例如:sever会在接收完所有的client信息后返回响应信息, 或者交替的接收一个client信息后返回一个响应信息，或者其它方式。 每个流中信息的顺序被保留。 rpc BidiHello(stream HelloRequest) returns (stream HelloResponse);\r  API使用 gRPC提供的protocol buffer插件,使用.proto文件中定义的service生成client-server代码。 用户通常在client端调用这些API，并在server端实现对应的API。\n 在server端,server实现service中声明的方法，并运行gRPC server处理client调用。 gRPC基础设施解码传入的请求，调用service方法并且编码service响应。 在client端,client有一个本地对象stub，它实现了与service相同的方法。 client可以在本地调用这些方法, 包装请求参数为对应的protocol buffer信息类型， gRPC发送请求到server并返回protocol buffer类型的响应信息。  同步vs异步 阻塞同步RPC直到接收服务器返回响应，是最接近RPC期望实现的过程调用的抽象。另一方面，网络本质是异步的， 并且在许多场景中，希望RPC能够不阻塞当前线程。\n大多数语言实现的gRPC API都有同步和异步两种模式。这些可以到相应语言的教程和参考文档中查看。\nRPC生命周期 本节中，可以更近一步的了解gRPC client调用 server方法的细节。\nUnary-RPC 首先我们考虑最简单的RPC调用类型，client发送单个请求并且获取单个响应。\n 一旦client调用stub中的方法，server就会被通知client正在使用元数据，方法名， 超时时间进行RPC。 然后server可以马上返回自己的初始元数据(必须在任何响应之前发送)，或者等待clien请求信息。哪个先发生，应该根据具体的应用。 一旦server接收到client的请求信息，它将执行必要的工作并创建响应信息。响应信息(成功时返回)，状态详情(状态码和状态信息)， 可选的元数据会一并返回给client。 如果响应状态是正确的，client会获取到响应，client端完成处理过程。  Server-Streaming-RPC server-streaming RPC 和unary RPC类似，希望client请求时返回流信息。等到所有的信息都返回完成， server再将状态详情(状态码和状态信息)，可选的元数据会一并返回给client，server端完成处理过程。 client在接收到所有的server端信息后，client端完成处理过程。\nClient-Streaming-RPC client-streaming RPC和unary RPC类似，希望client请求时发送流信息到server。 server返回单个信息(包含状态详情和可选的元素据)，不一定等到server接收完所有的client信息。\nBidirectional-Streaming-RPC bidirectional-streaming RPC,调用的发起是由client调用方法和server接收client元数据、方法名、超时时间。 server可以选择返回它的初始元数据或等待client发送流信息。\nclient端和server端流处理应该根据具体的应用。由于这两个流是独立的，client和server可以以任意顺序读写信息。 例如： server可以等接收完所有的client消息后再写自己的信息或者client和server互发ping-pong (server获取请求后返回响应，然后客户端根据该响应信息发送另一个请求)。\nDeadlines/Timeouts gRPC允许client指定在RPC中断(返回错误DEADLINE_EXCEEDED)前等待RPC完成的时间。 在server端，服务可以查看某个RPC是否超时， 或者该RPC操作完成还需要多久。　指定deadline或timeout是语言相关的: 一些语言使用timeout(时间段),一些语言使用deadline(时间点)\nRPC中断 client和server独立维护和决策gRPC的调用结果，因此它们的结果可能不一致。这表示，例如：\n 在server端获取RPC成功的结果(已经发送所有的响应)，但是再client端获取到失败的结果(响应在deadline后到达)。 server端有同样的问题，server在接收完client端所有的请求前中断。  取消RPC client和server可以在任何时间点取消一个RPC。取消操作会立刻中断RPC，并停止后续工作。\n 取消操作之前所作的修改不会进行回滚\n Metadata metadata是关于一个RPC调用的信息说明(例如: 权限明细),以key-value列表的表单形式表示， key是string类型， value是string或binary data类型。\nmetadata对于gRPC本身也是不透明的-它让client提供调用server相关的信息，反之亦然。\nChannels gRPC的channel提供了在特定主机和端口与server的连接。创建client stub时使用channel, client可以指定channel的参数来修改gRPC的默认行为，例如:是否开启和关闭信息压缩。channel有状态属性，包括conencted和idle。\ngRPC如何处理channel的关闭事件是语言相关的。 有些语言甚至允许查询channel的状态。\n",
    "ref": "/blog/grpc/concepts/"
  },{
    "title": "ELK-搭建Kibana",
    "date": "",
    "description": "",
    "body": "kibana.yml version: '2'\rservices:\rkibana:\rimage: docker.elastic.co/kibana/kibana:7.2.0\renvironment:\rELASTICSEARCH_HOSTS: http://192.168.20.99:9200\rports:\r- 5601:5601\rrestart: always\r",
    "ref": "/blog/elk/kibana/"
  },{
    "title": "ELK-搭建Filebeat",
    "date": "",
    "description": "",
    "body": "安装 deb:\ncurl -L -O https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-7.3.0-amd64.deb\rsudo dpkg -i filebeat-7.3.0-amd64.deb\rrpm:\ncurl -L -O https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-7.3.0-x86_64.rpm\rsudo rpm -vi filebeat-7.3.0-x86_64.rpm\rdocker-compose version: '2'\rservices:\rfilebeat:\rimage: docker.elastic.co/beats/filebeat:7.2.0\rcontainer_name: filebeat\rrestart: always\rvolumes:\r- ./config/filebeat.yml:/usr/share/filebeat/filebeat.yml\r- /var/lib/docker/containers:/var/lib/docker/containers\ruser: root\r容器日志配置 {\r\u0026quot;log-driver\u0026quot;:\u0026quot;json-file\u0026quot;,\r\u0026quot;log-opts\u0026quot;:{ \u0026quot;max-size\u0026quot; :\u0026quot;5m\u0026quot;,\u0026quot;max-file\u0026quot;:\u0026quot;1\u0026quot;, \u0026quot;labels\u0026quot;:\u0026quot;{{.Name}}\u0026quot;}\r}\r",
    "ref": "/blog/elk/filebeat/"
  },{
    "title": "ELK-搭建Heartbeat",
    "date": "",
    "description": "",
    "body": "",
    "ref": "/blog/elk/heartbeat/"
  },{
    "title": "ELK-搭建Metricbeat",
    "date": "",
    "description": "",
    "body": "",
    "ref": "/blog/elk/metricbeat/"
  },{
    "title": "ELK-搭建PacketHeat",
    "date": "",
    "description": "",
    "body": "",
    "ref": "/blog/elk/packetheat/"
  },{
    "title": "ELK-搭建Elasticsearch",
    "date": "",
    "description": "",
    "body": "elasticsearch.yml version: '2'\rservices:\relasticsearch:\rimage: docker.elastic.co/elasticsearch/elasticsearch:7.2.0\rcontainer_name: elasticsearch\renvironment:\r- bootstrap.memory_lock=true\r- \u0026quot;ES_JAVA_OPTS=-Xms512m -Xmx512m\u0026quot;\r- \u0026quot;discovery.type=single-node\u0026quot;\rulimits:\rmemlock:\rsoft: -1\rhard: -1\rvolumes:\r- esdata:/usr/share/elasticsearch/data\rports:\r- 9200:9200\rnetworks:\r- esnet\rrestart: always\rvolumes:\resdata:\rdriver: local\rnetworks:\resnet:\r",
    "ref": "/blog/elk/elasticsearch/"
  },{
    "title": "ELK简介及日志收集、服务监控、性能监控",
    "date": "",
    "description": "",
    "body": "elk 描述 elk 架构是指：elastic 公司三个开源的产品： elasticsearch, logstash, kibana\nElasticsearch是个开源分布式搜索引擎，提供搜集、分析、存储数据三大功能。它的特点有：分布式，零配置，自动发现，索引自动分片，索引副本机制，restful风格接口，多数据源，自动搜索负载等。\nLogstash 主要是用来日志的搜集、分析、过滤日志的工具，支持大量的数据获取方式。一般工作方式为c/s架构，client端安装在需要收集日志的主机上，server端负责将收到的各节点日志进行过滤、修改等操作在一并发往elasticsearch上去。\nKibana 也是一个开源和免费的工具，Kibana可以为 Logstash 和 ElasticSearch 提供的日志分析友好的 Web 界面，可以帮助汇总、分析和搜索重要数据日志。\nweb地址 目前在内网服务器上搭建filebeat,metricbeat,heartbeat 等agent。 以及 elasticsearch, kibana 平台。\nkibana地址： 192.168.20.30:5601\n日志  查看： logs 过滤： log.file.path:xxx\n  搜索： discover 索引： filebeat-7.2.0-*\n 服务监控  查看：uptime\n  监控服务\n 硬件监控  查看：dashboard 索引： [Metricbeat System] Host overview ECS\n  监控硬件：\n cpu 内存 硬盘io 磁盘io 进程信息   集成 管理后台 完整日志架构： productor -\u0026gt; nsq -\u0026gt; nsqbeat -\u0026gt; elasticsearch -\u0026gt; kibana\n其它服务 无缓存 writefile -\u0026gt; filebeat -\u0026gt; elasticsearch -\u0026gt; kibana\n后续集成工作 目前由于学习成本，仅提供kibana入口， 后续：\n 后台深入集成elastic 错误日志告警  ",
    "ref": "/blog/elk/elk/"
  },{
    "title": "Docker部署和配置nsqbeat",
    "date": "",
    "description": "",
    "body": "\r############################# Nsqbeat ######################################\rnsqbeat:\r# A list of NSQ Lookup Daemons to connect to\rlookupdhttpaddrs: [\u0026quot;192.168.20.99:4161\u0026quot;]\r# a Topic to sucscribe to\rtopic: \u0026quot;logic.log\u0026quot;\r# The channel name to join\rchannel: \u0026quot;nsqbeat\u0026quot;\r# How many in Flights\rmaxinflight: 200\r# If data in the topic is Json then use the decoder, if not set to something else like plain\rcodec: \u0026quot;text\u0026quot;\r# use Golang time format layout to define if @timestamp exists and has a different format\rtimelayout: \u0026quot;2006-01-02T15:04:05.000Z\u0026quot;\r#================================ General =====================================\r# The name of the shipper that publishes the network data. It can be used to group\r# all the transactions sent by a single shipper in the web interface.\r#name:\r# The tags of the shipper are included in their own field with each\r# transaction published.\r#tags: [\u0026quot;service-X\u0026quot;, \u0026quot;web-tier\u0026quot;]\r# Optional fields that you can specify to add additional information to the\r# output.\r#fields:\r# env: staging\r#============================== Dashboards =====================================\r# These settings control loading the sample dashboards to the Kibana index. Loading\r# the dashboards is disabled by default and can be enabled either by setting the\r# options here, or by using the `-setup` CLI flag or the `setup` command.\r#setup.dashboards.enabled: false\r# The URL from where to download the dashboards archive. By default this URL\r# has a value which is computed based on the Beat name and version. For released\r# versions, this URL points to the dashboard archive on the artifacts.elastic.co\r# website.\r#setup.dashboards.url:\r#============================== Kibana =====================================\r# Starting with Beats version 6.0.0, the dashboards are loaded via the Kibana API.\r# This requires a Kibana endpoint configuration.\rsetup.kibana:\r# Kibana Host\r# Scheme and port can be left out and will be set to the default (http and 5601)\r# In case you specify and additional path, the scheme is required: http://localhost:5601/path\r# IPv6 addresses should always be defined as: https://[2001:db8::1]:5601\rhost: \u0026quot;192.168.20.99:5601\u0026quot;\r#============================= Elastic Cloud ==================================\r# These settings simplify using nsqbeat with the Elastic Cloud (https://cloud.elastic.co/).\r# The cloud.id setting overwrites the `output.elasticsearch.hosts` and\r# `setup.kibana.host` options.\r# You can find the `cloud.id` in the Elastic Cloud web UI.\r#cloud.id:\r# The cloud.auth setting overwrites the `output.elasticsearch.username` and\r# `output.elasticsearch.password` settings. The format is `\u0026lt;user\u0026gt;:\u0026lt;pass\u0026gt;`.\r#cloud.auth:\r#================================ Outputs =====================================\r# Configure what output to use when sending the data collected by the beat.\r#-------------------------- Elasticsearch output ------------------------------\routput.elasticsearch:\r# Array of hosts to connect to.\rhosts: [\u0026quot;192.168.20.99:9200\u0026quot;]\r# Optional protocol and basic auth credentials.\r#protocol: \u0026quot;https\u0026quot;\r#username: \u0026quot;elastic\u0026quot;\r#password: \u0026quot;changeme\u0026quot;\r#============================== Template =====================================\r# A template is used to set the mapping in Elasticsearch\r# By default template loading is enabled and the template is loaded.\r# These settings can be adjusted to load your own template or overwrite existing ones.\r# Set to false to disable template loading.\rsetup.template.enabled: false\r# Template name. By default the template name is \u0026quot;nsqbeat-%{[beat.version]}\u0026quot;\r# The template name and pattern has to be set in case the elasticsearch index pattern is modified.\r#setup.template.name: \u0026quot;nsqbeat-%{[beat.version]}\u0026quot;\r# Template pattern. By default the template pattern is \u0026quot;-%{[beat.version]}-*\u0026quot; to apply to the default index settings.\r# The first part is the version of the beat and then -* is used to match all daily indices.\r# The template name and pattern has to be set in case the elasticsearch index pattern is modified.\r#setup.template.pattern: \u0026quot;nsqbeat-%{[beat.version]}-*\u0026quot;\r# Path to fields.yml file to generate the template\r#setup.template.fields: \u0026quot;${path.config}/fields.yml\u0026quot;\r# Overwrite existing template\r#setup.template.overwrite: false\r# Elasticsearch template settings\rsetup.template.settings:\r# A dictionary of settings to place into the settings.index dictionary\r# of the Elasticsearch template. For more details, please check\r# https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping.html\r#index:\r#number_of_shards: 1\r#codec: best_compression\r#number_of_routing_shards: 30\r# A dictionary of settings for the _source field. For more details, please check\r# https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-source-field.html\r#_source:\r#enabled: false\r#----------------------------- Logstash output --------------------------------\r#output.logstash:\r# The Logstash hosts\r#hosts: [\u0026quot;localhost:5044\u0026quot;]\r# Optional SSL. By default is off.\r# List of root certificates for HTTPS server verifications\r#ssl.certificate_authorities: [\u0026quot;/etc/pki/root/ca.pem\u0026quot;]\r# Certificate for SSL client authentication\r#ssl.certificate: \u0026quot;/etc/pki/client/cert.pem\u0026quot;\r# Client Certificate Key\r#ssl.key: \u0026quot;/etc/pki/client/cert.key\u0026quot;\r#================================ Logging =====================================\r# Sets log level. The default log level is info.\r# Available log levels are: error, warning, info, debug\rlogging.level: debug\r# At debug level, you can selectively enable logging only for some components.\r# To enable all selectors use [\u0026quot;*\u0026quot;]. Examples of other selectors are \u0026quot;beat\u0026quot;,\r# \u0026quot;publish\u0026quot;, \u0026quot;service\u0026quot;.\r#logging.selectors: [\u0026quot;*\u0026quot;]\r#============================== Xpack Monitoring ===============================\r# nsqbeat can export internal metrics to a central Elasticsearch monitoring\r# cluster. This requires xpack monitoring to be enabled in Elasticsearch. The\r# reporting is disabled by default.\r# Set to true to enable the monitoring reporter.\r#xpack.monitoring.enabled: false\r# Uncomment to send the metrics to Elasticsearch. Most settings from the\r# Elasticsearch output are accepted here as well. Any setting that is not set is\r# automatically inherited from the Elasticsearch output configuration, so if you\r# have the Elasticsearch output configured, you can simply uncomment the\r# following line.\r#xpack.monitoring.elasticsearch:\r",
    "ref": "/blog/log-system/docker%E5%AE%89%E8%A3%85nsqbeat/"
  },{
    "title": "服务治理-限流",
    "date": "",
    "description": "",
    "body": "概念 当接口的访问频率或者并发请求数量超过系统的承受范围时， 需要考虑限流来保证接口的可用性；\n解决方案 通常策略是拒绝多余的访问或者让多余的访问排队等待；\n令牌桶 控制网络上数据的数目， 允许突发流量。系统会以一定的速度向桶里放入令牌， 如果有请求要被处理， 就去桶里面取一块令牌。 当桶里没有令牌可取时， 则拒绝请求。\nimport (\r\u0026quot;sync\u0026quot;\r\u0026quot;time\u0026quot;\r)\r// This implement the token bucket\rtype TokenBucket struct {\rrate int64 // the number of tokens are putted to bucket per second\rcapacity int64 // the capacity of bucket\rtokens int64 // current number of tokens in bucket\rlastTimestamp int64 // last timestamp of putted tokens to bucket.\rlock sync.Mutex\r}\rfunc (l *TokenBucket) Allow() bool {\rl.lock.Lock()\rdefer l.lock.Unlock()\r// first putting tokens to bucket\rnow := time.Now().Unix()\rl.tokens = l.tokens + (now-l.lastTimestamp)*l.rate\r// the number of tokens in bucket can not more than the capacity\rif l.tokens \u0026gt; l.capacity {\rl.tokens = l.capacity\r}\rl.lastTimestamp = now\r// 1. Get tokens when there are tokens left in the bucket.\r// 2. It can not get tokens when the bucket is empty.\rif l.tokens \u0026gt; 0 {\rl.tokens--\rreturn true\r} else {\rreturn false\r}\r}\rfunc (l *TokenBucket) Set(r, c int64) {\rl.rate = r\rl.capacity = c\rl.tokens = 0\rl.lastTimestamp = time.Now().Unix()\r}\rredis令牌桶 var tokenRateLimit = redis.NewScript(2, `\rlocal tokens_key = KEYS[1]\rlocal timestamp_key = KEYS[2]\r--redis.log(redis.LOG_WARNING, \u0026quot;tokens_key \u0026quot; .. tokens_key)\rlocal rate = tonumber(ARGV[1])\rlocal capacity = tonumber(ARGV[2])\rlocal now = tonumber(ARGV[3])\rlocal requested = tonumber(ARGV[4])\rlocal fill_time = capacity/rate\rlocal ttl = math.floor(fill_time*2)\r--redis.log(redis.LOG_WARNING, \u0026quot;rate \u0026quot; .. ARGV[1])\r--redis.log(redis.LOG_WARNING, \u0026quot;capacity \u0026quot; .. ARGV[2])\r--redis.log(redis.LOG_WARNING, \u0026quot;now \u0026quot; .. ARGV[3])\r--redis.log(redis.LOG_WARNING, \u0026quot;requested \u0026quot; .. ARGV[4])\r--redis.log(redis.LOG_WARNING, \u0026quot;filltime \u0026quot; .. fill_time)\r--redis.log(redis.LOG_WARNING, \u0026quot;ttl \u0026quot; .. ttl)\rlocal last_tokens = tonumber(redis.call(\u0026quot;get\u0026quot;, tokens_key))\rif last_tokens == nil then\rlast_tokens = capacity\rend\r--redis.log(redis.LOG_WARNING, \u0026quot;last_tokens \u0026quot; .. last_tokens)\rlocal last_refreshed = tonumber(redis.call(\u0026quot;get\u0026quot;, timestamp_key))\rif last_refreshed == nil then\rlast_refreshed = 0\rend\r--redis.log(redis.LOG_WARNING, \u0026quot;last_refreshed \u0026quot; .. last_refreshed)\rlocal delta = math.max(0, now-last_refreshed)\rlocal filled_tokens = math.min(capacity, last_tokens+(delta*rate))\rlocal allowed = filled_tokens \u0026gt;= requested\rlocal new_tokens = filled_tokens\rlocal allowed_num = 0\rif allowed then\rnew_tokens = filled_tokens - requested\rallowed_num = 1\rend\r--redis.log(redis.LOG_WARNING, \u0026quot;delta \u0026quot; .. delta)\r--redis.log(redis.LOG_WARNING, \u0026quot;filled_tokens \u0026quot; .. filled_tokens)\r--redis.log(redis.LOG_WARNING, \u0026quot;allowed_num \u0026quot; .. allowed_num)\r--redis.log(redis.LOG_WARNING, \u0026quot;new_tokens \u0026quot; .. new_tokens)\rif ttl \u0026gt; 0 then\rredis.call(\u0026quot;setex\u0026quot;, tokens_key, ttl, new_tokens)\rredis.call(\u0026quot;setex\u0026quot;, timestamp_key, ttl, now)\rend\r-- return { allowed_num, new_tokens, capacity, filled_tokens, requested, new_tokens }\rreturn { allowed_num, new_tokens }\r`)\r// params:\r// 1. the key name of token: used for get current number of tokens in bucket\r// 2. the key name of timestamp: used for get last timestamp of putted tokens\r// 3. the rate: // 4. the capacity:\r// 5. now timestamp:\r// 6. the number of request tokens:\rx, err := redis.Int64s(tokenRateLimit.Do(redisPool.Get(), \u0026quot;key:V\u0026quot;, \u0026quot;key:T\u0026quot;, 100, 100, time.Now().Unix(), 1))\r漏桶（leaky bucket） 控制数据注入到网络的速率， 平滑网络中的突发流量。按照一定的速率处理数据请求， 如果漏桶溢出，则超出的请求被舍弃。\n\rimport (\r\u0026quot;math\u0026quot;\r\u0026quot;sync\u0026quot;\r\u0026quot;time\u0026quot;\r)\rtype LeakyBucket struct {\rrate float64 // the speed of stream out from bucket\rcapacity float64 // the capacity of bucket\rwater float64 // the current volume of water in bucket\rlastTimestamp int64 // the last timestamp of stream out from bucket\rlock sync.Mutex\r}\rfunc (l *LeakyBucket) Allow() bool {\rl.lock.Lock()\rdefer l.lock.Unlock()\rnow := time.Now().UnixNano() / 1e6\r// first stream out from bucket\reclipse := float64((now - l.lastTimestamp)) * l.rate / 1000\rl.water = l.water - eclipse\r// the volume of water can be empty\rl.water = math.Max(0, l.water)\rl.lastTimestamp = now\r// 1. Stream in when the volume of water less than the capacity of bucket.\r// 2. It can not stream in when the bucket is full of water\rif (l.water + 1) \u0026lt; l.capacity {\rl.water++\rreturn true\r} else {\rreturn false\r}\r}\rfunc (l *LeakyBucket) Set(r, c float64) {\rl.rate = r\rl.capacity = c\rl.water = 0\rl.lastTimestamp = time.Now().UnixNano() / 1e6\r}\r",
    "ref": "/blog/distribution-system/%E9%99%90%E6%B5%81/"
  },{
    "title": "gRPC-Go快速入门",
    "date": "",
    "description": "",
    "body": "准备  Go 最新的三个主版本\n安装: https://golang.org/doc/install Protocol Buffer 编译器 protoc\n安装: https://www.grpc.io/docs/protoc-installation/ Protocol Buffer Go 插件  安装: $ export GO111MODULE=on # Enable module mode\r$ go get google.golang.org/protobuf/cmd/protoc-gen-go \\\rgoogle.golang.org/grpc/cmd/protoc-gen-go-grpc\r 更新环境变量 $ export PATH=\u0026quot;$PATH:$(go env GOPATH)/bin\u0026quot;\r    ",
    "ref": "/blog/golang/grpc/quick-start/"
  },{
    "title": "Protocol Buffer-Go FAQ",
    "date": "",
    "description": "",
    "body": "版本  Versions\n github.com/golang/protobuf和google.golang.org/protobuf有什么区别?\ngithub.com/golang/protobuf 模块是原始的Go protocol buffer API\ngoogle.golang.org/protobuf 模块是Go protocol buffer API的更新版本, 旨在更加简洁、易用和安全。 更新API的主要特性是支持反射， 以及将面向用户的API与底层实现分离。\n推荐在新代码中使用google.golang.org/protobuf。\ngithub.com/golang/protobuf的v1.4.0版本及更高版本封装了新的实现，并且允许程序逐步的采用新的API。 例如, github.com/golang/protobuf/ptypes中定义的知名类型在新模块中只是简单的别名。因此， google.golang.org/protobuf/types/known/emptypb和github.com/golang/protobuf/ptypes/empty是可以互换使用的。\nproto1,proto2,proto3有什么区别? 这些都是protocol buffer语言的修订版。 它不同于protobufs的Go 实现。\n proto3是当前版本。这是该语言最常用的版本。我们鼓励新代码使用proto3。 proto2是旧版本。尽管被proto3取代，但proto2仍然受到完全支持。 proto1是废弃版本。它从未以开源的形式发布。有关proto1的更多信息，请参阅FAQ。  有几种不同的Message类型。我应该用哪个？\n \u0026ldquo;google.golang.org/protobuf/proto\u0026rdquo;.Message是接口类型， 当前版本的protocol buffer编译器生成的所有message都要实现它。操作任意message的方法，如proto.Marshal或proto.Clone， 接收或返回该值。 \u0026ldquo;google.golang.org/protobuf/reflect/protoreflect\u0026rdquo;.Message 是一个描述message反射视图的接口类型。\n调用proto.Message的ProtoReflect方法，获取protoreflect.Message。 \u0026ldquo;google.golang.org/protobuf/reflect/protoreflect\u0026rdquo;.ProtoMessage 是\u0026quot;google.golang.org/protobuf/proto\u0026quot;.Message的别名。这两种类型是可以互换的。 \u0026ldquo;github.com/golang/protobuf/proto\u0026rdquo;.Message 是由遗留的Go Protocol Buffer API定义的接口类型。所有生成的message都需要实现该接口，但是该接口没有描述期望从这些message中得到的行为。 新代码应该避免使用这个类型。  常见问题  Common problems\n \u0026ldquo;go install\u0026rdquo;: working directory is not part of a module\n你已经设置环境变量GO111MODULE=on，并且在模块目录之外运行go install命令。\n设置GO111MODULE=auto，或者取消设置该环境变量。\nconstant -1 overflows protoimpl.EnforceVersion\n你正在使用生成的.pb.go文件，该文件需要更新版本的\u0026quot;google.golang.org/protobuf\u0026quot;模块。更新到一个更新的版本：\ngo get -u google.golang.org/protobuf/proto\rundefined: \u0026ldquo;github.com/golang/protobuf/proto\u0026rdquo;.ProtoPackageIsVersion4\n你正在使用生成的.pb.go文件，该文件需要更新版本的\u0026quot;github.com/golang/protobuf\u0026quot;模块。更新到一个更新的版本：\ngo get -u github.com/golang/protobuf/proto\r什么是Protocol Buffers命名冲突?\n所有链接到Go库的protocol buffers声明，都插入到全局的注册表中。\n每一个protobuf声明(e.g.,enums,enums值，或messages)都有一个绝对的名称，它是包名和.proto源文件中声明的相对名称的连接(e.g., my.proto.package.MyMessage.NestedMessage)。protobuf假设所有的声明都是唯一的。\n如果链接到Go库的两个protobuf声明有相同的名字，这样就导致命名空间冲突，注册表不可能通过名称正确的解析声明。这取决于使用的是Go protobuf的那个版本， 这会在初始时panic或者静默的删除冲突或者在运行时导致潜在bug。\n怎样解决Protocol Buffers 命名冲突?\n修复命名空间冲突的最好方法取决于冲突发生的原因。\n常见命名空间冲突发生的原因:\n  供应商.proto文件。当单个.proto文件生成两个或多个Go 包，并链接到同一个Go 库， 它会在生成Go包的每个protobuf声明上发生冲突。 通常发生在供应商提供.proto文件，并且从它生成了一个Go包，或者生成的Go包本身是供应商提供的情况下。用户应当避免供应商， 相反.proto文件应该依赖于一个集中的Go包。\n 如果.proto文件为外部所有，并且缺少go_package选项，那么你应该与.proto文件的所有者协调， 指定一个集中式的Go包，多个用户都可以依赖它。    缺少或默认proto包名。如果.proto文件没有指定包名，或者使用带下划线的包名(e.g.,\u0026ldquo;my_service\u0026rdquo;), 然后，该文件中的声明很可能与全局其他地方的声明发生冲突。我们建议每个.proto文件有一个包名， 这个包名被指定为全局唯一的(e.g. 例如加上公司名做前缀)。\n 警告: 追溯更改.proto文件上的包名，可能导致扩展字段或保存在google.protobuf.any中的message停止正常工作。    为什么protobuf message的reflect.DeepEqual行为异常？\n生成的protocol buffer message类型包含中间态，即使在相同的message之间也可能不同。\n此外reflect.DeepEqual函数不知道protocol buffer message的语义，并报告不存在的差异。例如，nil map 和 长度为0的non-nil map 语义上是相等的，但是reflect.DeepEqual报告为不相等。\n使用proto.Equal函数来比较message值。\n作为测试，你也可以使用\u0026ldquo;github.com/google/go-cmp/cmp\u0026rdquo;和 protocmp.Transform选项。cmp包可以比较任意的数据结构， cmp.Diff可以生成值之间差异的可读报告。\nif diff := cmp.Diff(a, b, protocmp.Transform()); diff != \u0026quot;\u0026quot; {\rt.Errorf(\u0026quot;unexpected difference:\\n%v\u0026quot;, diff)\r}\rHyrum定律  Hyrum\u0026rsquo;s Law\n 什么是Hyrum定律，为什么它会在这个FAQ中？ 一个API有大量的使用用户，其在协议中所作的承诺已经无关紧要：系统中所有可观察的行为将被其它人依赖。\n最新版本的Go protocol buffer API的设计目标是尽可能的避免提供未来我们无法保证稳定的可观察行为。 我们的哲学是， 我们不做出承诺的地方是不稳定的，这好过给人稳定的幻觉， 这种情况只有将来当可能基于错误假设的项目很久了才会改变。\n为什么错误文本一直在变化? 依赖于确切的错误文本的测试是脆弱的，并且当错误文本变化时经常中断。为了阻止测试时不安全的使用错误文本，这个模块产生的错误文本故意不稳定。 如果您需要确定一个错误是否由protobuf模块产生，我们保证所有的错误都与 proto.Error匹配，依据errors.Is。\n为什么protojson的输出一直在变化? 我们不承诺Go对Protocol Buffers的JSON格式实现的长期稳定性。 该规范只指定了什么是有效的JSON，而没有提供编组器应该如何准确地格式化给定消息的规范。 为了避免产生输出是稳定的错觉，我们故意引入了一些小的差异，这样字节对字节的比较可能会失败。\n为了获得一定程度的输出稳定性，我们建议通过JSON格式化器运行输出。\n为什么prototext的输出一直在变化? 我们对Go文本格式实现的长期稳定性不作任何承诺。protobuf文本格式没有规范规范，我们希望保留将来改进prototext包输出的能力。 因为我们不承诺包输出的稳定性，所以我们故意引入了不稳定性以阻止用户依赖它。\n为了获得一定的稳定性，我们建议通过txtpbfmt程序传递prototext的输出。 格式化程序可以在Go中使用parser.Format直接调用。\nMiscellaneous 怎样使用Protocol Buffer message作为Hash key? 您需要规范序列化，其中协议缓冲区消息的封送输出保证随时间稳定。 不幸的是，目前还不存在规范序列化的规范。你需要自己写，或者想办法避免使用。\n我能为Go Protocol Buffer 的实现添加新的特性吗？? 也许吧。我们总是喜欢建议，但我们对添加新东西非常谨慎。参见Protocol Buffers FAQ\nProtocol Buffers的Go实现努力与其他语言实现保持一致。因此，我们倾向于避开那些过于专业化的功能。 go特有的特性阻碍了Protocol Buffers成为语言无关的数据交换格式的目标。\n除非你的想法是针对Go实现的，否则你应该加入protobuf讨论组并在那里提出建议。\n如果你有一个Go实现的想法，请在我们的问题跟踪器上提交一个问题: https://github.com/golang/protobuf/issues\n我能定制protoc-gen-go生成的代码吗? 一般来说,没有。Protocol Buffers是一种语言无关的数据交换格式，自定义的特定实现与此意图背道而驰。\n",
    "ref": "/blog/golang/protocol-buffers/faq/"
  },{
    "title": "Protocol Buffer-Go代码生成",
    "date": "",
    "description": "",
    "body": "生成代码  Go Generated Code\n 本章详细描述protocol buffer编译器为协议定义的类型生成对应的Go代码。 proto2和proto3生成代码的任何差异都会突出显示————注意: 文档中描述的差异都在生成的代码中，而不是两个版本都相同的基础API中。 在读这篇文章之前，请先阅读protocol buffer guide\n编译器使用  Compiler Invocation\n 编译器需要安装插件来生成Go代码。 安装如下:\ngo install google.golang.org/protobuf/cmd/protoc-gen-go\r此命令在$GOBIN下安装protoc-gen-go命令。安装之前修改环境变量$GOBIN的值来改变protoc-gen-go安装目录。 为了编译器找到命令，安装目录必须添加到环境变量$PATH中。\n 当编译器被调用时设置参数--go_out,会创建输出目录,--go_out指定你想要编译器生成Go输出的目录。 编译器会为每个传入的.proto文件创建源文件,并替换文件的扩展名.proto为.pb.go  .proto文件需要包含go_package选项，用以指定包含生成代码的Go包的完整import路径。\n示例:\noption go_package = \u0026quot;example.com/foo/bar\u0026quot;;\r输出文件所在输出目录的子目录，取决于go_package选项和编译器参数:\n 默认情况，输出文件被放在以Go包导入路径命名的目录下。例如:\n设置上述go_pacakge选项的protos/foo.proto文件的输出文件名是example.com/foo/bar/foo.pb.go 如果命令行参数设置--go_opt=module=$PREFIX,指定目录前缀从输出文件名中删除。例如：\n设置上述go_pacakge选项和 --go_opt=module=example.com/foo的protos/foo.proto文件的输出文件名是bar/foo.pb.go 如果命令行参数设置--go_opt=paths=source_relative,输出文件被放在与输入文件相同的相对目录下。例如: 设置上述go_pacakge选项的protos/foo.proto文件的输出文件名是protos/foo.pb.go  当运行以下编译器命令时:\nprotoc --proto_path=src --go_out=build/gen --go_opt=paths=source_relative src/foo.proto src/bar/baz.proto\r编译器读取文件src/foo.proto和src/bar/baz.proto。生成两个输出文件: build/gen/foo.pb.go和build/gen/bar/baz.pb.go\n编译器会自动生成目录build/gen/bar,但是不会创建目录build或build/gen。这两层目录必须已经存在。\n包  Packages\n .proto源文件需要包含go_package选项，指定包含该文件的Go包的完整导入路径。 如果没有指定选项go_package,编译器会猜测一个。 将来的编译器版本，会设置go_package选项为必选的。\n生成Go包名为go_package选项定义路径的最后一个元素。 例如:\n// The Go package name is \u0026quot;timestamppb\u0026quot;.\roption go_package = \u0026quot;google.golang.org/protobuf/types/known/timestamppb\u0026quot;;\r导入路径用于确定，当一个.proto文件导入另一个.proto文件时，需要生成哪些import语句。例如: a.proto中导入b.proto, 生成的文件a.pb.go必须包含导入b.pb.go的语句(除非两个文件在同一个包中)。\ngo_package选项还可以包含一个显示的包名，用分号与导入路径分割。例如:\noption go_package = \u0026quot;example.com/foo;package_name\u0026quot;\r不鼓励这种方法，因为与导入路径对应的报名更清晰。作为go_package选项的替代， .proto文件生成Go包的导入路径可以在命令行指定:--go_opt=M=$FILENAME=$IMPORT_PATH\nMessages // github.com/golang/protobuf/proto\rtype Message = protoreflect.ProtoMessage\r// `Message` 是顶级interface，所有的`message`都需要实现该接口。它提供对`message`反射视图的访问。\r// 此接口的任何实现都可以用于protobuf模块中接受`message`的全部函数\r一个简单的message定义示例：\nmessage Foo {}\r编译生成名为Foo的结构体。 *Foo实现了proto.Message接口。接口定义了ProtoReflect方法，此方法返回protoreflect.Message。 protorefelct.Message提供message的基于反射的视图。\nproto包提供对message进行操作的函数，包括与二进制数据的转换。\n optimize_for 选项，不会影响Go代码生成器的输出。\n 嵌套类型  Nested Types\n message可以被定义在其它message中。 例如:\nmessage Foo {\rmessage Bar {\r}\r}\r这种情况，编译生成两种结构体: Foo和Foo_Bar。\n字段  Fields\n protocol buffer编译器为message中定义的每个字段生成指定的结构体字段。该字段的确切的特性取决于它的类型，可能是单数，复数，map活着oneof。\n生成的Go字段名使用驼峰法命名，即使.proto文件中字段名使用小写字母和下划线。大小写生成转换格式如下：\n 首字母大写表示可导出。 如果首字母是下划线_，它将被删除，并被替换成大写字母X。 如果下划线_后接小写字母，下划线被删除，后接字母大写。\n因此:\nfoo_bar_baz =\u0026gt; FooBarBaz\n_my_field_name_2 =\u0026gt; XMyFieldName_2  单数标量字段proto2  Singular Scalar Fields (proto2)\n optional int32 foo = 1;\rrequired int32 foo = 1;\r编译器生成的结构体包含名为Foo的*int32字段和访问器方法GetFoo()(该方法返回Foo中int32值，或者如果未设置的话，返回默认值)。 如果默认值没有显示的设置，则使用该类型的0值来替代(数字的零值为0，字符串的0值为空字符串)。\n其它的标量字段类型(包括bool,bytes,string),*int32依据标量类型表替换为相应的Go类型。\n单数标量字段proto3  Singular Scalar Fields (proto3)\n int32 foo = 1;\r编译器生成的结构体包含名为Foo的int32字段和访问器方法GetFoo()，该方法返回Foo中int32值， 或者如果未设置的话返回该字段的0值(数字的零值为0，字符串的0值为空字符串)\n其它的标量字段类型(包括bool,bytes,string),int32依据标量类型表替换为相应的Go类型。 proto中未设置的值表示为该类型的0值(数字的零值为0，字符串的0值为空字符串)\n单数message字段  Singular Message Fields\n message Bar {}\r// proto2\rmessage Baz {\roptional Bar foo = 1;\r// The generated code is the same result if required instead of optional.\r}\r// proto3\rmessage Baz {\rBar foo = 1;\r}\r编译器生成Go struct:\ntype Baz struct {\rFoo *Bar\r}\rmessage字段可以被设置为nil，这意味着该字段未设置。这不等同于将该字段设置为message struct的空实例。\n编译器同时生成辅助函数func (m *Baz) GetFoo() *Bar。如果m是nil或者foo未设置，此函数返回nil。 这使得不用nil检查，就可以链接get调用。\nrepeated字段  Repeated Fields\n  message Baz {\rrepeated Bar foo = 1;\r}\r每个repeated字段生成一个T类型的slice，T是字段的类型:\ntype Baz struct {\rFoo []*Bar\r}\r同样的，\nrepeated bytes foo = 1;编译器生成Foo [][]byte。\nrepeated MyEnum bar = 2;编译生成Bar []MyEnum。\n以下示例，展示怎么设置该字段:\nbaz := \u0026amp;Baz{\rFoo: []*Bar{\r{}, // First element.\r{}, // Second element.\r},\r}\r访问该字段，你可以做以下操作:\nfoo := baz.GetFoo() // foo type is []*Bar.\rb1 := foo[0] // b1 type is *Bar, the first element in foo.\rmap字段  Map Fields\n message Bar {}\rmessage Baz {\rmap\u0026lt;string, Bar\u0026gt; foo = 1;\r}\rmap字段生成map[TKey]TValue，TKey是字段的key类型，TValue是字段的value类型:\ntype Bar struct {}\rtype Baz struct {\rFoo map[string]*Bar\r}\roneof字段  Oneof Fields\n package account;\rmessage Profile {\roneof avatar {\rstring image_url = 1;\rbytes image_data = 2;\r}\r}\roneof字段生成isMessageName_FieldName的interface{}。同时为oneof中的每个字段生成一个struct。 这些struct都要实现isMessgeName_FieldName。\ntype Profile struct {\r// Types that are assignable to Avatar:\r//\t*Profile_ImageUrl\r//\t*Profile_ImageData\rAvatar isProfile_Avatar `protobuf_oneof:\u0026quot;avatar\u0026quot;`\r}\rtype isProfile_Avatar interface {\risProfile_Avatar()\r}\rtype Profile_ImageUrl struct {\rImageUrl string `protobuf:\u0026quot;bytes,1,opt,name=image_url,json=imageUrl,proto3,oneof\u0026quot;`\r}\rtype Profile_ImageData struct {\rImageData []byte `protobuf:\u0026quot;bytes,2,opt,name=image_data,json=imageData,proto3,oneof\u0026quot;`\r}\rfunc (*Profile_ImageUrl) isProfile_Avatar() {}\rfunc (*Profile_ImageData) isProfile_Avatar() {}\r*Profile_ImageUrl和*Profile_ImageData提供空的isProfile_Avatar方法实现接口isProfile_Avatar。\n以下示例，展示怎么设置oneof字段:\np1 := \u0026amp;account.Profile{\rAvatar: \u0026amp;account.Profile_ImageUrl{\u0026quot;http://example.com/image.png\u0026quot;},\r}\r// imageData is []byte\rimageData := getImageData()\rp2 := \u0026amp;account.Profile{\rAvatar: \u0026amp;account.Profile_ImageData{imageData},\r}\r访问oneof字段，可以使用type switch语法处理不同的message类型:\nswitch x := m.Avatar.(type) {\rcase *account.Profile_ImageUrl:\r// Load profile image based on URL\r// using x.ImageUrl\rcase *account.Profile_ImageData:\r// Load profile image based on bytes\r// using x.ImageData\rcase nil:\r// The field is not set.\rdefault:\rreturn fmt.Errorf(\u0026quot;Profile.Avatar has unexpected type %T\u0026quot;, x)\r}\r同时，编译器为每个oneof字段生成访问器(访问器返回字段的值，如果字段未设置，则返回字段对应的0值):\nfunc (x *Profile) GetImageUrl() string {\rif x, ok := x.GetAvatar().(*Profile_ImageUrl); ok {\rreturn x.ImageUrl\r}\rreturn \u0026quot;\u0026quot;\r}\rfunc (x *Profile) GetImageData() []byte {\rif x, ok := x.GetAvatar().(*Profile_ImageData); ok {\rreturn x.ImageData\r}\rreturn nil\r}\r枚举  Enumerations\n message SearchRequest {\renum Corpus {\rUNIVERSAL = 0;\rWEB = 1;\rIMAGES = 2;\rLOCAL = 3;\rNEWS = 4;\rPRODUCTS = 5;\rVIDEO = 6;\r}\rCorpus corpus = 1;\r...\r}\r编译器生成一个类型及一系列该类型的常量。\n对于message内的enum，则enum命名以message名开头：\ntype SearchRequest_Corpus int32\r包级的enum:\nenum Foo {\rDEFAULT_BAR = 0;\rBAR_BELLS = 1;\rBAR_B_CUE = 2;\r}\r不会修改proto中的名称:\ntype Foo int32\rString()方法，获取枚举值对应的名称。\nEnum()方法，用给定的值初始化新分配的内存，并返回对应的指针:\nfunc (Foo) Enum() *Foo\r编译器为enum中的每个值生成一个常量。对于message中的enum，其常量以message名称开头:\nconst (\rSearchRequest_UNIVERSAL SearchRequest_Corpus = 0\rSearchRequest_WEB SearchRequest_Corpus = 1\rSearchRequest_IMAGES SearchRequest_Corpus = 2\rSearchRequest_LOCAL SearchRequest_Corpus = 3\rSearchRequest_NEWS SearchRequest_Corpus = 4\rSearchRequest_PRODUCTS SearchRequest_Corpus = 5\rSearchRequest_VIDEO SearchRequest_Corpus = 6\r)\r包级的enum，以enum的名称开头:\nconst (\rFoo_DEFAULT_BAR Foo = 0\rFoo_BAR_BELLS Foo = 1\rFoo_BAR_B_CUE Foo = 2\r)\r编译器同时生成, 数值=名称和名称=数值的map:\nvar Foo_name = map[int32]string{\r0: \u0026quot;DEFAULT_BAR\u0026quot;,\r1: \u0026quot;BAR_BELLS\u0026quot;,\r2: \u0026quot;BAR_B_CUE\u0026quot;,\r}\rvar Foo_value = map[string]int32{\r\u0026quot;DEFAULT_BAR\u0026quot;: 0,\r\u0026quot;BAR_BELLS\u0026quot;: 1,\r\u0026quot;BAR_B_CUE\u0026quot;: 2,\r}\r注意，.proto允许多个enum名称拥有相同的数值，参考allow_alias。数值相同的名称是同义词。 反向映射包含一个单独的条目，将数值映射到.proto文件中最先出现的名称。\nExtensions(proto2) extend Foo {\roptional int32 bar = 123;\r}\r编译器将生成一个protoreflect。名称为E_Bar的ExtensionType值。该值可以与 proto.GetExtension,proto.SetExtension,proto.HasExtension和proto.ClearExtension一起使用。清除message中访问扩展的函数。 GetExtension函数和SetExtension函数分别接受和返回一个包含扩展值类型的interface {}值。\n对于单数标量扩展字段，扩展值类型是标量值类型表中对应的Go类型。\n对于单个内嵌message扩展字段，扩展值类型为*M，其中M为字段message类型。\n对于repeated扩展字段，扩展值类型是slice。\nextend Foo {\roptional int32 singular_int32 = 1;\rrepeated bytes repeated_string = 2;\roptional Bar repeated_message = 3;\r}\r扩展的值可以这样访问:\nm := \u0026amp;somepb.Foo{}\rproto.SetExtension(m, extpb.E_SingularInt32, int32(1))\rproto.SetExtension(m, extpb.E_RepeatedString, []string{\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;c\u0026quot;})\rproto.SetExtension(m, extpb.E_RepeatedMessage, \u0026amp;extpb.Bar{})\rv1 := proto.GetExtension(m, extpb.E_SingularInt32).(int32)\rv2 := proto.GetExtension(m, extpb.E_RepeatedString).([][]byte)\rv3 := proto.GetExtension(m, extpb.E_RepeatedMessage).(*extpb.Bar)\r扩展可以在另一种类型内嵌套定义。例如，一个常见的模式是这样做:\nmessage Baz {\rextend Foo {\roptional Baz foo_ext = 124;\r}\r}\r在本例中，ExtensionType值被命名为E_Baz_Foo。\n服务  Services\n 默认情况，Go生成器不产生service相关的代码输出。如果启用gRPC插件，生成的代码将支持gRPC。\n",
    "ref": "/blog/golang/protocol-buffers/generated/"
  },{
    "title": "Protocol Buffer-Go基础知识",
    "date": "",
    "description": "",
    "body": "这篇教程讲述了Go程序员使用protocol buffers的基本介绍，这里使用protocol buffers的proto3版本。 逐步的创建简单的示例程序，向你展示怎么去做。\n 在.proto文件中定义message格式 使用protocol buffers 编译器 使用Go protocol buffer API读写message  这不是一篇全面的教程，教你怎么在Go中使用protocol buffers。 想要更详细的参考信息， 参见Protocol Buffer Language Guide, the Go API Reference, Go Generated Code Guide, Encoding Reference\n为什么使用Protocol Buffers 我们将要演示的示例是一个非常简单的通讯录应用，这个应用可以在文件中读写人们的联系方式。通讯录中的每个人都有名字，ID，email,电话号码。\n怎样去序列化和反序列化这些信息？有以下几种方法:\n 使用gobs来序列化Go结构化对象。这在特定的Go语言环境中是好的解决方案，但是如果你需要 与其它平台编写的应用共享数据，这种方案就不太好用。 你可以发明专门的方法，将数据项编码到一个单独的字符串－比如将整数4 编码为\u0026quot;12:3:-23:67\u0026quot;。这是个简单而灵活的方法， 尽管它需要编写一次性编码和解析代码，而且解析的运行成本很小。这对于简单数据的编码最有效。 将数据序列化为XML。这个方法是非常有效的，因为XML是可读的，并且很多语言都有实现库。如果你想要和其它应用/项目共享数据， XML是一个很好的选择。但是，总所周知，XML是空间密集型的，并且XML的编解码会给应用带来很大的性能问题。此外操作XML的DOM树比操作 类中的简单字段要复杂的多。  Protocol Buffers 是灵活，高效，自动化的解决方案，刚好解决这个问题。使用Protocol buffer， 你需要编写一个想要存储的数据结构体的.proto描述。随后，protocol buffer 编译器创建一个类， 该类使用高效的二进制格式自动的编解码protocol buffer数据。该类为protocol buffer中的字段提供getter和setter， 并且负责将protocol buffer作为一个单元进行读写。重要的是，protocol buffer格式支持随时间推移扩展格式的思想， 这样代码仍然可以读取用旧格式编码的数据\n从哪里查找示例代码 我们的示例是一组命令行应用程序，用于管理使用protocol buffers编码的地址簿数据文件。 add_person_go命令向数据文件添加一个新条目。list_people_go命令解析数据文件并将数据打印到控制台。\n你可以在GitHub存储库的examples目录中找到完整的例子。\n定义你的协议格式 要创建您的地址簿应用程序，您需要从.proto文件开始。.proto文件中的定义很简单:为要序列化的每个数据结构添加一条消息， 然后为消息中的每个字段指定名称和类型。在我们的示例中，定义消息的.proto文件是addressbook.proto。\n.proto文件以包声明开始，这有助于防止不同项目之间的命名冲突\nsyntax = \u0026quot;proto3\u0026quot;;\rpackage tutorial;\rimport \u0026quot;google/protobuf/timestamp.proto\u0026quot;;\rgo_package选项定义了包的导入路径，该路径将包含为该文件生成的所有代码。 Go包名将是导入路径的最后一个路径组件。例如，我们的示例将使用名为“tutorialpb”的包名。\noption go_package = \u0026quot;github.com/protocolbuffers/protobuf/examples/go/tutorialpb\u0026quot;;\r然后，定义你的message。message只是包含一组类型化字段的集合。许多标准的简单数据类型都可以作为字段类型， 包括bool、int32、float、double和string。您还可以通过使用其他message类型作为字段类型向message添加进一步的结构。\nmessage Person {\rstring name = 1;\rint32 id = 2; // Unique ID number for this person.\rstring email = 3;\renum PhoneType {\rMOBILE = 0;\rHOME = 1;\rWORK = 2;\r}\rmessage PhoneNumber {\rstring number = 1;\rPhoneType type = 2;\r}\rrepeated PhoneNumber phones = 4;\rgoogle.protobuf.Timestamp last_updated = 5;\r}\r// Our address book file is just one of these.\rmessage AddressBook {\rrepeated Person people = 1;\r}\r在上面的示例中，Person包含PhoneNumber，而AddressBook包含Person。您甚至可以定义嵌套在其他message中的message类型—如您所见， PhoneNumber类型是在Person内部定义的。如果希望某个字段具有预定义的值列表之一， 还可以定义enum类型——这里希望指定一个电话号码可以是MOBILE、HOME或WORK中的一个。\n每个元素上的“= 1”、“= 2”标记标识字段在二进制编码中使用的唯一\u0026quot;标记\u0026quot;。编号1-15需要的编码字节比更大的数字少，因此作为一种优化， 您可以决定对常用的或重复的元素使用这些编号，而对不常用的可选元素使用编号16或更高。 重复字段中的每个元素都需要对编号进行重新编码，因此重复字段特别适合于这种优化。\n如果一个字段repeated，该字段可以重复任意次数(包括0)。重复值的顺序将保留在protocol buffers中。可以将重复字段看作动态大小的数组。 您可以在protocol buffers语言指南中找到编写.proto文件的完整指南——包括所有可能的字段类型。 但是，不要寻找类似于类继承的工具——protocol buffers不会这样做。\nProtocol Buffers 延申 在您发布使用protocol buffers的代码之后，您无疑会希望“改进”protocol buffers的定义。如果您希望您的新proto向后兼容， 而您的旧proto向后兼容——您几乎肯定希望这样——那么您需要遵循一些规则。在protocol buffers的新版本中:\n 一定不要修改现有字段的编号 可以删除字段 增加的新字段必须使用新的字段编号(在protocol buffer中从未使用过的编号以及删除的字段编号)  如果您遵循这些规则，旧代码将愉快地读取新消息，并简单地忽略任何新字段。对于旧的代码，被删除的单一字段将只保留它们的默认值， 而被删除的重复字段将为空。新代码也将透明地读取旧消息。\n但是，请记住，新字段不会出现在旧消息中，因此您需要对默认值做一些合理的操作。使用特定类型的默认值:对于字符串，默认值为空字符串。 对于布尔值，默认值是false。对于数字类型，默认值为零。\n",
    "ref": "/blog/golang/protocol-buffers/basics/"
  },{
    "title": "日志业务思考和规则",
    "date": "",
    "description": "",
    "body": "Logging\u0026amp;\u0026amp;Instrumentation思考 Logging 和 Instrumentation 在软件开发中是两个热门的话题， 尤其在微服务领域。\n当然具体，还有很多需要思考。\n关于Logging：要logging什么？logging到哪种详细的程度？流向哪里： syslog? file on disk? message queue?\n关于Instrumentation: 什么时候instrumenting代码？哪些信息需要instrumenting？ 使用哪些metrics系统？\n logging,instrumentation,tracing最终都只是实现系统的可观测性。\n Logging 服务应该只logging可操作信息，包括不限于:\n 需要人为处理的严重的、致命级别的错误\ne.g. 数据库不可用的消息信号   人为处理的log应该是稀少的，如果没有错误，理想中可以不logging任何信息\n 需要机器处理的结构化数据\ne.g. 媒体对象已经播放，logging下来以便批处理对版税进行日结算   机器处理的log应该是定义良好的格式化数据\n 因为log包的适用性有局限，所以选择功能简单的包。 避免多个log级别(info/warn/error)，尤其是不要在运行时进行level配置。 只输出需要查看的log。当然debug log是个例外，开发和诊断错误时有用。\nlog应当被视为事件流处理:\n 服务不应该关心输出流的转存 服务不应该尝试写入或管理log文件 服务应当将事件流无缓冲的写入stdout 由操作系统或基础设施转存进程或容器的stdout/stderr到目的地，e.g. 集中log系统ELK stack, 持久化消息代理Kafka, 滚动日志服务runit  logging的代价是昂贵的，因此不要logging任何不符合上述标准的信息。e.g. 禁止logging每一个HTTP请求，尤其是热点路由上的，这些更适合instrumenting\nInstrumentation Instrumentation 用于服务相关的所有剩余诊断信息。\n与Log相比，服务应该尽可能的instrumenting每一个可以捕获的有意义的数据。\nMetrics记录和报告的成本是低廉的， Instrumentation系统包含的数据越多越有意义。\n Instrumentation 表示一种“能够监测和度量某个系统的性能，分析系统错误，并能将追踪的数据进行记录”的监测工具\n instrumenting包含信息包括不限于:\n 排除在logging之外的信息 请求计数、请求延迟、请求错误计数  Brendan Gregg’s USE method 建议instrument所有系统资源的利用率，饱和度，错误计数。\n利用率(Utilization): 资源忙于服务工作的平均时间\n饱和度(Saturation): 资源有其他额外工作的程度\n几乎任何语言都有很多instrumentation库。所有的库都有以下三个主要原语:\nCounter: 用于记录发生的事件， e.g. 请求计数，错误请求数 Gauge: 用于记录随时间波动的事件， e.g. 线程池大小 Histogram: 用于记录观察值的标量， e.g. 请求时间\n老式的instrumentation库和系统，如Graphite，将原语和静态名称绑定。 这样可以创建一个名为http_request_duration的histogram， 并通过在每个HTTP请求结束的位置调用history.Observer, 来instrumenting HTTP请求时间。 这已经足够我们来开始instrumenting；\n最近精密的instrumentation系统，允许我们在每个metrics上指定更复杂的维度。 例如: 我们的http_request_duration metrics可能 会有URL路径(e.g. \u0026ldquo;/api/v1/foo\u0026rdquo;)、状态码(e.g. 200)。 这种维度的数据，使得数据探索，故障排除，故障关联得到强有力的支撑。\n推荐使用Prometheus作为instrumentation系统和监控基础设施。\n",
    "ref": "/blog/log-system/logging/"
  },{
    "title": "日志业务系统架构设计",
    "date": "",
    "description": "",
    "body": "日志业务 两种日志收集架构\n 应用产生日志-\u0026gt; 根据大小/时间 写入文件-\u0026gt; rotation 日志文件 -\u0026gt; 定期查看/定期删除 应用产生日志-\u0026gt; 传输 -\u0026gt; 过滤/转换 -\u0026gt; 存储-\u0026gt; 分析/查看  日志业务结构 采集-\u0026gt;缓存-\u0026gt;转换/过滤-\u0026gt;存储-\u0026gt;可视化\n日志技术架构 filebeat/logstash -\u0026gt; kafka -\u0026gt; fluentd -\u0026gt; es -\u0026gt; kibana\n日志平台优化  由于日志低频次， 将历史数据存入廉价存储， 普通用户需要时再导入es 日志存储的时间越长，意义越小。 根据实际情况制定留存数据策略 顺序写入磁盘，区别随机写入磁盘，我们采用顺序写数据模式  ",
    "ref": "/blog/log-system/%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/"
  },{
    "title": "Golang代码开发杂计",
    "date": "",
    "description": "",
    "body": " string bytes 互转，可以使用unitptr map 会按需扩张，需要内存拷贝和重新hash。 尽量预设定容量空间； defer 会多次函数调用参数复制，缓存等问题。所以除了异常捕获外， 资源释放等可以使用goto closure 闭包 隐式携带上下文环境； 接口调用这种动态绑定的方式性能不如对象赋值的直接调用；call(obj)\u0026amp;call(interface) reflect 性能问题； setFinalizer（延长生命周期，等待第二次gc） 避免内存清理时，对象互相依赖导致循环等待，内存释放不了；  优雅的打印  fmt打印  type Pretty struct {\rUgg string\rApp string\r}\rp1 := Pretty{\rUgg: \u0026quot;fly\u0026quot;,\rApp: \u0026quot;bird\u0026quot;,\r}\rfmt.Printf(\u0026quot;%+v\\n\u0026quot;, p1)\rfmt.Printf(\u0026quot;%#v\\n\u0026quot;, p1)\routput:\r{Ugg:fly App:bird}\rpkg.Pretty{Ugg:\u0026quot;fly\u0026quot;, App:\u0026quot;bird\u0026quot;}\r",
    "ref": "/blog/golang/misc/"
  },{
    "title": "chrome浏览器手机debug",
    "date": "",
    "description": "",
    "body": "环境准备  手机打开开发人员选项 用数据线将手机连接到主机  调试  chrome进入inspect:地址栏输入chrome://inspect\n 点击对应网址的inspect按钮进行调试\n  问题  DevTools页面空白或者404 Not Found  由于国内无法访问 https://chrome-devtools-frontend.appspot.com 这里的解决方法： 翻墙    ",
    "ref": "/blog/browser/chrome-debug/"
  },{
    "title": "Golang实现服务优雅的重启",
    "date": "",
    "description": "",
    "body": "https://grisha.org/blog/2014/06/03/graceful-restart-in-golang/\n",
    "ref": "/blog/golang/graceful/"
  },{
    "title": "Golang API实例",
    "date": "",
    "description": "",
    "body": "SetFinalizer   func SetFinalizer(obj interface{}, finalizer interface{})\n 参数obj必须是指针类型。 参数finalizer是一个函数，其参数类型是obj的类型，并且没有返回值。 如果不满足以上规则，SetFinalizer会中断程序。    SetFinalizer将obj和finalizer关联， 当gc检测到unreachable对象有关联的 finalizer时，会取消关联关系并在单独的goroutine中执行finalizer。假如没有再次调用 SetFinalizer, gc下次检测对象为unreachable时，将释放对象。\n  SetFinalizer(obj, nil) 取消和对象关联的所有finalizer.\n  finalizer运行依赖顺序如下: 如果A指向B，两者都关联了finalizer并且标识为unreachable， 则只有A的finalizer执行；一旦A被释放，B的finalizer才可以执行。\n  如果*obj大小为0字节，则不保证finalizer会执行。\n  不保证包级别init()的对象变量的finalizer会执行。 因为该对象可能是链接器分配的，而不是堆分配。\n  在对象被 GC 进程选中并从内存中移除以前，SetFinalizer 都不会执行，即使程序正常结束或者发生错误。 finalizer可以用于避免用户错误使用导致的内存泄露，e.g. os.NewFile,net.newFD() 等注册了对文件描述符的SetFinalizer，用以避免忘记Close()导致的fd泄露。 但是依赖finalizer 来flush内存中的缓冲区例如bufio.Writer是错误的，因为不能保证程序退出时缓冲区会被flush。\n  如果对象存在循环引用方法，需要给其添加wrapper， 并将实际类型作为wrapper的匿名字段： ``` type Cache struct{ \u0026hellip; stop chan bool }\n // wrapper定义\rtype CacheWrapper struct{\r*Cache\r}\rfunc New() *CacheWrapper {\rcc := \u0026amp;Cache{\r...\r}\rgo cc.clear()\r// 包一层\rcw := \u0026amp;CacheWrapper{cc}\r// 重点在此:设置被回收时操作\rruntime.SetFinalizer(cw, onGarbageCollect)\rreturn cw\r}\rfunc (m *Cache) clear() {\rfor {\rselect {\r// 关闭\rcase \u0026lt;-m.stop:\rreturn\r//定期清理...\r}\r}\r}\rfunc onGarbageCollect(m *Cache) {\rm.stop \u0026lt;- true\r}\r```    应用场景\n 一个对象object被GC时，如果需要执行一些特殊操作，比如，发信号，或者写日志等，可以通过调用SetFinalizer.    LockOSThread  定义  让goroutine 绑定并独立在一个系统线程M上执行   问题  子goroutine不能继承父goroutine的线程绑定；   应用场景  使用Go线程模型，对C代码，汇编代码或阻塞系统调用的调用与调用Go代码的线程相同  许多图形库（OS X Cocoa，OpenGL，SDL等）要求所有调用都必须在特定线程（某些情况下是主线程）上进行 某些外部库基于 线程本地存储（TLS）功能。它们将一些上下文存储附加到线程的数据结构中。或API的某些功能提供其内存生命周期附加到线程的结果   将某个goroutine锁定到某个系统线程，这个线程只调度这个goroutine，进而可以被优先调度    KeepAlive  定义 KeepAlive标记对象是reachable的。确保对象在调用KeepAlive之前不会被释放，并且不会触发对象注册的finalizer。 使用  func KeepAlive(x interface{}) 参数x必须是指针类型 官方示例: type File struct { d int }\rd, err := syscall.Open(\u0026quot;/file/path\u0026quot;, syscall.O_RDONLY, 0)\r// ... do something if err != nil ...\rp := \u0026amp;File{d}\rruntime.SetFinalizer(p, func(p *File) { syscall.Close(p.d) })\rvar buf [10]byte\rn, err := syscall.Read(p.d, buf[:])\r// Ensure p is not finalized until Read returns.\rruntime.KeepAlive(p)\r// No more uses of p after this point.\r 如果没有调用runtime.KeepAlive(),finalizer会在syscall.Read之前被调用， 导致文件描述符已经close.\n     rang  math/rand 生成伪随机数， 使用default resource， 产生有规则的随机数。 crypto/rand 生成真随机数，使用time.now() 作为种子。  ",
    "ref": "/blog/golang/%E9%83%A8%E5%88%86%E5%87%BD%E6%95%B0/"
  },{
    "title": "Grafana搭建部署环境和配置",
    "date": "",
    "description": "",
    "body": "概念 Grafana是一个开源可视化工具，可以在各种不同的数据存储上使用\n详情 从本质上讲，它是Graphite-web的一个功能丰富的替代品，可帮助用户轻松创建和编辑仪表板。它包含一个独特的Graphite目标解析器，可以轻松进行度量和功能编辑。用户可以使用智能轴格式（例如线条和点）创建全面的图表，这是Grafana快速的客户端渲染（即使在很长的时间范围内） - 使用Flot作为默认选项。\n",
    "ref": "/blog/elk/grafana/"
  },{
    "title": "Golang数据库-数据类型转换",
    "date": "",
    "description": "",
    "body": "#数据库\n问题 字段为空 row.scan 遇到字段为空时， 变量赋值异常：can not convert null=\u0026gt; *string 需要在sql语句中添加： ifnull/coalesce 指定默认空值\n添加 sql convert 函数 根据数据类型， 做转换\nconst (\rFormatTime = \u0026quot;15:04:05\u0026quot;\rFormatDate = \u0026quot;2006-01-02\u0026quot;\rFormatDateTime = \u0026quot;2006-01-02 15:04:05\u0026quot;\r)\rvar (\rErr_NilDests = errors.New(\u0026quot;destinations required\u0026quot;)\rErr_NilPointerDest = errors.New(\u0026quot;destination not support nil pointer\u0026quot;)\rErr_NotSupportDest = errors.New(\u0026quot;not support destination\u0026quot;)\r)\rconst Invalid_Id = 0\rfunc ConvertRow(row *sql.Row, dests ...interface{}) error {\rdestLen := len(dests)\rif destLen == 0 {\rreturn Err_NilDests\r}\rrefs := make([]interface{}, destLen)\rfor i := range refs {\rvar ref interface{}\rrefs[i] = \u0026amp;ref\r}\rerr := row.Scan(refs...)\rif err != nil {\rreturn err\r}\rfor i := 0; i \u0026lt; destLen; i++ {\rval := reflect.ValueOf(dests[i])\rind := reflect.Indirect(val)\rrefVal := reflect.ValueOf(refs[i])\rrefInd := reflect.Indirect(refVal)\rif err := convertValueFromDB(\u0026amp;ind, refInd.Interface()); err != nil {\rreturn err\r}\r}\rreturn nil\r}\rfunc convertValueFromDB(dest *reflect.Value, src interface{}) (err error) {\rvar (\rvalue interface{}\rkind = dest.Kind()\rstrSrc string\r)\rif src != nil {\rswitch v := src.(type) {\rcase []byte:\rstrSrc = string(v)\rdefault:\rstrSrc = fmt.Sprintf(\u0026quot;%v\u0026quot;, src)\r}\r}\rswitch kind {\rcase reflect.Bool:\rif src == nil {\rvalue = false\r} else {\rvalue, err = strconv.ParseBool(strSrc)\r}\rif err != nil {\rreturn\r}\rdest.Set(reflect.ValueOf(value).Convert(dest.Type()))\rcase reflect.Int8, reflect.Int16, reflect.Int, reflect.Int32, reflect.Int64:\rif src == nil {\rvalue = int64(0)\r} else {\rvalue, err = strconv.ParseInt(strSrc, 10, 64)\r}\rif err != nil {\rreturn\r}\rdest.Set(reflect.ValueOf(value).Convert(dest.Type()))\rcase reflect.Uint8, reflect.Uint16, reflect.Uint, reflect.Uint32, reflect.Uint64:\rif src == nil {\rvalue = uint64(0)\r} else {\rvalue, err = strconv.ParseUint(strSrc, 10, 64)\r}\rif err != nil {\rreturn\r}\rdest.Set(reflect.ValueOf(value).Convert(dest.Type()))\rcase reflect.Float32, reflect.Float64:\rif src == nil {\rvalue = float64(0)\r} else {\rvalue, err = strconv.ParseFloat(strSrc, 64)\r}\rif err != nil {\rreturn\r}\rdest.Set(reflect.ValueOf(value).Convert(dest.Type()))\rcase reflect.String:\rif src == nil {\rvalue = \u0026quot;\u0026quot;\r} else {\rvalue = strSrc\r}\rdest.Set(reflect.ValueOf(value).Convert(dest.Type()))\rdefault:\rif dest.Interface() == nil {\rpanic(Err_NilPointerDest)\r}\rswitch dest.Interface().(type) {\rcase time.Time:\rif src == nil {\rvalue = time.Time{}\r} else {\rswitch v := src.(type) {\rcase time.Time:\rvalue = v.In(time.Local)\rdefault:\rvar t time.Time\rif len(strSrc) \u0026gt;= 19 {\rt, err = time.ParseInLocation(FormatDateTime, strSrc[:19], time.Local)\r} else if len(strSrc) \u0026gt;= 10 {\rt, err = time.ParseInLocation(FormatDate, strSrc[:10], time.Local)\r} else if len(strSrc) \u0026gt;= 8 {\rt, err = time.ParseInLocation(FormatTime, strSrc[:8], time.Local)\r}\rif err != nil {\rreturn\r}\rvalue = t\r}\r}\rdest.Set(reflect.ValueOf(value).Convert(dest.Type()))\rdefault:\rpanic(Err_NotSupportDest)\r}\r}\rreturn\r}\r",
    "ref": "/blog/golang/%E6%95%B0%E6%8D%AE%E5%BA%93/"
  },{
    "title": "Golang-编译指令",
    "date": "",
    "description": "",
    "body": "Command compile go compile, 在命令行的调用为go tool compile。编译一个由命令行指定的多个文件组成的Go包。 执行后生成一个目标文件，文件名是第一个文件的基础名称，后缀是.o。后续该目标文件和其它 目标文件可以联合组成一个归档文件或者直接传递给连接器(go tool link). 如果使用-pack 调用，编译器直接组装成归档文件，绕过生成中间目标文件。\n编译生成的文件内容包含由包导出的符号的类型信息和该包导入的其它引用包的符号的类型信息。 因此在编译包P的client时，不需要读取P依赖的文件，只需要读取P的编译输出即可。\nCommand Line 使用方法:\ngo tool compile [flags] file...\n命令行指定的文件必须是go编码类型文件，且所有文件必须是同一个package的。 所有目标系统和体系结构都使用相同的编译器。环境变量GOOS和GOARCH用来设置期望的目标。\nflags\n-D path\r设置本地导入的相对路径,默认为$GOROOT\r-I dir1 -I dir2\r查询完$GOROOT/pkg/$GOOS_$GOARCH目录后\r再到dir1,dir2等目录下搜索导入的package\r-L\r在错误消息中显示完整的文件路径\r-N\r禁用编译优化\r-S\r将汇编程序表打印到标准输出(只包含代码)\r-S -S\r将汇编程序表打印到标准输出(包含代码和数据)\r-V\r打印编译器版本并退出\r-asmhdr file\r将汇编头写入文件\r-buildid id\r记录id作为导出元数据中的构建id\r-blockprofile file\r将编译的块分析写入文件\r-c int\r编译时并发执行。1表示不并发执行(默认1)\r-complete\r假设package中没有非go组件\r-cpuprofile file\r将编译的CPU分析写入文件\r-dynlink\r在共享库中允许引入Go符号(实验性)\r-e\r删除错误报告数量的限制(默认10)\r-goversion string\r指定runtime需要的`go tool`版本。\r当runtime版本和指定的版本不匹配时退出。\r-h\r当检测到第一个错误时，停止并进行堆栈trace。\r-importcfg file\r从指定文件读取import配置\r文件中需要指出importmap,packagefile\r-importmap old=new\r编译时将\u0026quot;old\u0026quot;导入解释为\u0026quot;new\u0026quot;导入\rimportmap参数可以重复，用以添加多个映射。\r-installsuffix suffix\r到$GOROOT/pkg/$GOOS_$GOARCH_suffix下检索packages， 而不是 $GOROOT/pkg/$GOOS_$GOARCH.\r-l\r禁止代码嵌入\r-lang version\r设置编译器语言版本，例如: -lang=go1.12.默认为当前版本\r-linkobj file\r将特定于连接器的对象写入文件，特定于编译器的对象写入通常的输出文件(此文件可以由-o指定)。\r不指定该标记，-o指定的输出是连接器和编译器两者输入的组合。\r-m\r打印优化决策\r-memprofile file\r指定编译时内存分析写入的文件\r-memprofilerate rate\r设置编译时runtime.MemProfileRate的值\r-msan\r插入c/c++ [Memory Sanitizer]的调用\r-mutexprofile file\r指定编译时mutex分析写入的文件\r-nolocalimports\r禁止本地(相对)导入\r-o file\r指定对象写入的文件(默认为xx.o，或者有-pack标记时为file.a)\r-p path\r为要编译的代码指定预期的包导入路径，并诊断可能会导致循环依赖的导入。\r-pack\r输出一个包(归档)文件而不是目标文件。\r-race\r开启竞争检测\r-s\r告警可以简化的符合字面值。\r-shared\r生成可以连接到共享库中的代码\r-spectre list\r开启spectre缓解方法(all,index,ret)\r-traceprofile file\r指定执行trace写入的文件。\r-trimpath prefix\r指定从记录资源文件中删除的前缀。\r调试信息相关的flags\n-dwarf\r生成dwarf符号\r-dwarflocationlists\r添加本地列表到[DWARF]\r-gendwarfinl int\r生成DWARF内联信息记录(default 2)\r编译器自身调试相关flags\n-E\r导出符号\r-K\r丢弃行号\r-d list\r打印list中每项调试信息。 使用-d help 查看更多信息。\r-live\r活性分析\r-v\r增加调试级别\r-%\r调试非静态初始化器\r-W\r在类型检查后调试解析树\r-f\r调试栈帧\r-i\r调试行号堆栈\r-j\r调试运行时初始化的变量。\r-r\r调试生成的包装器\r-w\r调试类型检查\r编译器指令 golang编译器接受注释形式的指令。为了和非指令的注释区分，指令行的注释符和指令之间不需要空格。 然而，由于指令也是注释，不能识别指令约定或特定指令的工具可以像其它任何注释一样跳过一条指令。\n行指令有以下几种格式:\n//line :line\r//line :line:col\r//line filename:line\r//line filename:line:col\r/*line :line*/\r/*line :line:col*/\r/*line filename:line*/\r/*line filename:line:col*/\r为了被识别为行指令，注释必须以//line或者/*line开头，后跟空格，且最少包含一个:。 行指令指定后面字符的源位置，来自指定的文件、行、列：对于//line这种格式，字符是下一行， 对于/*line这种格式，字符紧接结束符*/。如果没有指定文件名和列号，那么记录文件名为空。 否则文件名为最近记录的文件名(其实文件名为前一条行指令指定的文件名)。如果行指令没有指定列号， 那么在下一条指令前列都是未知的，并且编译器不会报告该区间的列号。行指令文本从后往前解释： 如果尾部的:ddd中ddd\u0026gt;0则将:ddd从指令文本中剥离，第二个:ddd进行相同的处理. 在此之前的任何内容都被认为是文件名。无效的行号和列号都被报告为错误。\n示例:\n//line foo.go:10 文件名是foo.go，行号是10\r//line C:foo.go:10 文件名允许有冒号,这里文件名是C:foo.go，行号是10\r//line a:100 :10 文件名允许有空格，这里文件名是\u0026quot; a:100 \u0026quot;(不含双引号)\r/*line :10:20*/x x的位置是当前文件的第10行20列\r/*line foo: 10 */ 这条注释被认为是无效的行指令(行号周围有额外的空格) 行指令一般出现在机器生成的代码中，以便编译器和调试器将原始输入的位置报告给生成器。\n行指令是一个特殊的历史情况:所有其它的指令都是//go:name格式，表明它们都是由Go工具链定义。 每条指令必须单独放置一行，注释前只允许前置空格或者制表符。每条指令都将应用于紧跟它的代码， 这些代码通常都是一个声明。\n//go:noescape 指令//go:noescepe必须紧跟一个没有函数体的函数声明(意味着该函数的实现不是用Go写的)。 它指定该函数不允许任何作为参数传递的指针逃逸到堆中或函数返回的值中。这个信息在编译器 对调用函数的Go代码做逃逸分析时使用。\n//go:unitptrescapes 指令//go:uintptrescapes必须紧跟一个函数声明。它指定该函数的uintptr类型的参数 可能是已经被转换为uintptr的指针值，并且必须被gc如此处理。从指针到uintptr的转换 必须出现在任何调用该函数的参数列表中。这个指令对于一些底层系统调用实现是必要的， 其它情况应该避免使用。\n//go:noinline 指令//go:noinline后面必须跟一个函数声明。它指定对这个函数的调用不能内联， 覆盖编译器通常的优化规则。这个指令通常只有在特殊的运行时函数或者调试编译器时需要。\n//go:norace 指令//go:norace后面必须跟一个函数声明。它指定函数的内存访问必须被被竞争检测器忽略。 当竞争检测器运行时不安全时， 底层代码经常用。\ngo:nosplit 指令//go:nosplit后面必须跟一个函数声明。它指定函数必须忽略堆栈溢出检查。 当调用goroutine抢占不合法时，底层运行时代码经常用。\ngo:linkname localname [importpath.name] 这个特殊的指令并不适用于后面跟着的Go代码。相反，//go:linkname指令指示编译器使用 importpath.name作为代码中声明为localname的变量或函数的对象文件符号名。如果 importpath.name参数被忽略，该指令使用默认的对象文件符号名，并且只起到让其它package 可以访问该符号的作用。因为该指令可以颠覆类型系统和package的模块化， 所以它只在导入了unsafe包的文件中启用。\ngo:generate 格式: // go:gererate command args...\n使用： go generate命令会自动执行go:generate 中注释的命令。\n问题 can't find imports package 这是编译器找不到package目录， 解决方案：\n 到导入的package目录下执行go install *.go 在当前package目录下执行go tool compile -S -I $GOROOT/pkg/$GOOS_$GOARCH *.go  ",
    "ref": "/blog/golang/%E7%BC%96%E8%AF%91%E6%8C%87%E4%BB%A4/"
  },{
    "title": "Golang跨平台之交叉编译",
    "date": "",
    "description": "",
    "body": "概述 交叉编译： 在一个平台生成另一个平台的可执行代码。\ngolang 交叉编译变量  GOOS:目标系统 GOARCH:目标架构 CGO_ENABLED: 开启cgo  支持的编译平台 查看命令：go tool dist list\n   GOOS(目标系统) GOARCH(目标架构)     aix ppc64   android 386   android amd64   android arm   android arm64   darwin 386   darwin amd64   darwin arm   darwin arm64   dragonfly amd64   freebsd 386   freebsd amd64   freebsd arm   illumos amd64   js wasm   linux 386   linux amd64   linux arm   linux arm64   linux mips   linux mips64   linux mips64le   linux mipsle   linux ppc64   linux ppc64le   linux s390x   nacl 386   nacl amd64p32   nacl arm   netbsd 386   netbsd amd64   netbsd arm   netbsd arm64   openbsd 386   openbsd amd64   openbsd arm   openbsd arm64   plan9 386   plan9 amd64   plan9 arm   solaris amd64   windows 386   windows amd64   windows arm    条件编译 golang 采用Tag标记和文件后缀方式实现条件编译；\n构建约束 规则：\n build tag必须在文件顶部，可以有多个， 之间是AND关系 ：  // +build linux darwin\r// +build arm 空格位或， 逗号为且， 叹号为非  // +build A,B !C,D\r// 翻译： (A\u0026amp;\u0026amp;B) || ((!C) \u0026amp;\u0026amp; D)\rbuild tag和package xxx 语句之间需要空行分隔：  // +build linux,arm\rpackage main\r使用: go build -tags ...\n文件后缀 规则：\n 以_$GOOS.go 为后缀的文件只能在指定平台编译，其他平台忽略该文件。\n syscall_linux_amd64.go：只在 Linux/amd64 下编译\rsyscall_windows_386.go：只在 Windows/i386 下编译\rsyscall_windows.go： 只在 Windows 下编译\rcgo 交叉编译 karalabe/xgo\n问题：\n 不支持 go mod 模式 不能 (完整支持) 编译本地代码 不支持最新的 golang 版本 项目维护热度不足  ",
    "ref": "/blog/golang/%E4%BA%A4%E5%8F%89%E7%BC%96%E8%AF%91/"
  },{
    "title": "Golang线程调度模型",
    "date": "",
    "description": "",
    "body": "CSP模型  communicating sequential process: 通讯顺序进程； 描述多个并发的实体通过共享channel进行通信的并发模型； channel是重要对象，不用关注发送消息的实体，只需要关心实体发送消息时使用的channel； 利用channel 实现两个实体之间的松耦合； go 使用goroutine和chan实现CSP模型  内核线程 内核调度实体（KSE，Kernel Scheduling Entity）即内核线程\n 内核线程为操作系统内核最小调度单元； 内核线程创建内存消耗较大，不适合创建太多内核线程； 内核线程调度： 线程挂起前会保存线程上下文到栈空间，再切换到其他可执行线程；线程上下文切换导致cpu开销变大； 内核线程都有固定的内存块（2MB）做栈，用来存储正在被调用或挂起的函数内部变量。  线程调度  线程池： 线程池实现线程复用，避免频繁创建新线程和线程切换，控制了线程数量和内存消耗；但是在资源共享时会发生竞争，降低了并发效率； 异步回调： 在线程阻塞时注册回调方法，不在阻塞当前线程，去处理新的请求。当处理完成后，把结果传给回调方法。回调方法不是在发起请求的线程里。异步回调会造成callback hell， 回调中嵌套回调； 协程： 在协程处理阻塞时， 协程让出cpu执行权，让其他协程执行。 等阻塞结束，在调度等待的协程继续执行；  线程模型  内核级线程模型：用户线程与内核线程KSE是一对一的映射模型；进程创建出来的用户线程与内核线程KSE一一静态绑定； 用户级线程模型： 用户线程与内核线程是多对一的映射模型； 一个进程创建的线程都只和同一个内核线程KSE在运行时动态绑定；线程的调度是在用户层面完成，相较于内核调度不需要让cpu在内核态和用户态切换；缺点： 假设某用户进程上的用户线程因为阻塞调用被cpu中断， 那么进程会被挂起。 混合型线程模型：用户线程与内核线程KSE是多对多的映射模型，一个进程与多个内核线程KSE关联，于是进程中的多个线程可以绑定不同的内核线程KSE。与内核级线程模型不同的是混合型线程模型与内核线程KSE是动态绑定的。当某个KSE绑定的线程阻塞被内核调度出cpu时， 其关联的进程中其余用户线程可以重新与其他KSE绑定运行。实现用户调度器实现用户线程到KSE的调度，内核调度器实现KSE到cpu的调度；  goroutine和Go Scheduler  golang中 goroutine是独立的执行单元。goroutine栈采用动态扩容，初始仅为2KB（最大1GB-64位机器，256M-32位机器）。 goroutine完全由golang自己的调度器 Go Scheduler调度。GC还会定期的将不使用的内存回收，收缩栈空间。  MPG  G: 表示Goroutine， 每个Goroutine对应一个G结构体。G存储goroutine的运行堆栈、状态及函数。G并非执行体，每个G绑定到P才能执行。 P：表示Processer，逻辑处理器。对于G来说P相当于CPU。G只有绑定到P上才会被调度。对M来说P提供了相关的执行环境（context）、内存分配（memcache)、任务队列（G）。 P的数量决定最大可并行G的数量。　P的数量由用户设置的GOMAXPROCS决定。最大位256. M:表示Machine，内核线程抽象，代表真正执行计算的资源。在绑定有效的P后，进入schedule循环。 schedule 循环机制大致从Global队列、P的local队列以及wait队列中获取G，切换到G的执行堆栈上并执行G，调用goexit做清理工作并回到M， 如此反复。M并不保留G状态，这是G可以跨M调度的基础。M数量不确定，由GO RunTime调整， 防止创建太多系统线程，最大为10000.  MPG调用流程 当goroutine 被关键字go创建时，优先加入到P的Local队列。为了运行goroutine，P需要绑定一个M，然后M启动一个内核线程，循环的从P的local队列中取goroutine去执行。 当M执行完当前P的local队列中所有的G后，P会优先将Global队列中的G加入到自己的Local队列来执行，如果Gloabl队列中的G也为空， P会随机挑选其他P的任务队列中的一半G加入到自己的local队列来执行。\n用户态阻塞/唤醒 当goroutine因为channel操作或I/O阻塞时，对应的G会被放置到某个wait队列，并且G的状态由_Gruning变为_Gowaitting，而M会跳过当前G，尝试获取并执行下一个G。 如果当前没有runable的G供M调用，则M将解绑P，并休眠。当阻塞的G被另一端G2唤醒后， G被标记为runable并加入到G2所在P的runnext队列中。\n系统调用阻塞 当G被阻塞到某个系统调用上时， 该G所在的P会与M解绑，P尝试与其他Idle的M进行绑定，继续执行其他G。 如果没有idle的M，且P的local队列中还有G， 则创建新的M。 当被阻塞的G系统调用完成后， G会重新获取一个idle的P，加入到他的local队列重新执行。 如果没有idle的P，则加入Global的队列。\ngolang gc gc也是运行到goroutine上的，当内存吃紧的时候，gc 的goroutine也会阻塞，导致P的local队列积压。内存溢出，程序crash。\nSTW stop the world GC会挂起用户程序直到垃圾回收完。\ngoroutine 池化 类似于多路复用，使用空闲routine处理任务队列；\n",
    "ref": "/blog/golang/%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%BC%8F/"
  },{
    "title": "《北京市小客车数量调控暂行规定》实施细则（2020年修订）",
    "date": "",
    "description": "",
    "body": "第一章 总 则 第一条 为实现小客车数量的合理、有序增长，有效缓解交通拥堵，降低能源消耗和减少环境污染，根据《北京市小客车数量调控暂行规定》制定本细则。\n第二条 本市对小客车实施数量调控和配额管理制度。\n小客车年度增长数量和配置比例由市交通行政主管部门会同市发展改革、公安机关交通管理、生态环境等相关行政主管部门，根据小客车需求状况和道路交通、停车泊位供给、环境承载能力合理确定，报市政府批准后向社会公布。政府各有关部门应当落实本市小客车年度调控目标。\n第三条 按照公开、公平、公正和促进公共资源均衡配置的原则，企业事业单位、社会团体及其他组织（以下统称单位），家庭和个人需要取得本市小客车配置指标的，应当通过摇号、积分排序、轮候等方式取得。普通小客车配置指标通过摇号方式配置，单位和个人新能源小客车配置指标通过轮候方式配置，家庭新能源小客车配置指标通过积分排序方式配置。\n本市机关、全额拨款事业单位不再新增公务用车指标。\n营运小客车指标单独配置，具体配置方式另行制定。\n第四条 市交通行政主管部门负责小客车数量调控的统筹协调工作，并组织实施小客车数量调控的政策、措施。\n公安、发展改革、科技、经信、民政、人力社保、生态环境、商务、税务、市场监管、人才工作等相关行政主管部门和区政府按照规定的职责分工，负责小客车指标申请单位、家庭和个人的资格审核、信访等管理工作。监察机关负责对各行政主管部门的履职行为监督检查。\n市小客车指标调控管理机构（以下简称指标管理机构）统筹负责通过小客车指标调控管理信息系统开展指标申请的归集、审核结果的公布、指标配置的组织和公示等工作。\n各区政府交通行政主管部门具体负责在本辖区政府对外办公大厅设置小客车指标对外办公窗口，为申请单位、家庭和个人提供指标申请、信息修改、公证书和其他相关材料上传、指标确认通知书打印及政策咨询等相关服务。\n第五条 指标配额按年度确定。每年5月26日配置新能源小客车指标，每年6月26日和12月26日配置普通小客车指标。指标配额不得跨年度配置。\n第二章 配置指标申请及审核 第六条 单位、家庭和个人申请配置指标按照以下程序进行：\n（一）提出申请，获取申请编码；\n（二）申请资格经审核通过后，参加指标配置；\n（三）获得配置指标的，可以取得配置指标确认通知书。\n第七条 单位申请配置指标的条件和数量按照以下规则之一确定：\n（一）注册地在本市的企业，具有统一社会信用代码的有效营业执照，上一年度在本市缴纳入库增值税额5万元（含）以上的，或新注册企业当年在本市缴纳入库增值税额5万元（含）以上的，当年可以申请1个指标，每增加50万元可以增加申请1个指标，但年度申请指标数量上限不得超过12个。在上限范围内，可以全部申请新能源小客车指标，普通小客车指标申请数量不得超过6个；\n（二）注册地在本市的制造业企业，信息传输、软件和信息技术服务业企业，具有统一社会信用代码的有效营业执照，上一年度在本市完成固定资产投资额1000万元（含）以上的，当年可以申请1个指标，每增加2000万元可以增加申请1个指标，但年度申请指标数量上限不得超过12个。在上限范围内，可以全部申请新能源小客车指标，普通小客车指标申请数量不得超过6个。\n（三）注册地在本市的非全额拨款事业单位、社会团体及其他组织，具有统一社会信用代码的有效登记证书，年度可以申请1个普通小客车指标和1个新能源小客车指标。\n第八条 符合以下规定情形的，可以以家庭为单位办理1个配置指标的申请登记：\n（一）家庭由家庭主申请人和其他家庭申请人构成，申请人总数不得少于2人；\n（二）家庭主申请人应当符合本细则第九条的规定；\n（三）其他家庭申请人限于家庭主申请人的配偶、子女、父母、公婆或者岳父母，且应当符合本细则第九条中“住所地在本市的个人”的规定；\n（四）所有家庭申请人及其配偶名下没有本市登记的小客车；\n（五）离婚时原配偶名下有本市登记的小客车的个人，离婚十年以内不得作为家庭申请人，2021年1月1日前已离婚的除外。\n家庭主申请人代表家庭参与指标配置并作为指标所有人。所有家庭申请人在家庭主申请人获得指标后的十年以内不得再次办理配置指标申请登记。以家庭为单位申请配置指标的过程中，家庭申请人不能同时再以其他形式申请配置指标。所有家庭申请人须声明申请信息及提供的材料真实有效，并承诺遵守前述规定。\n第九条 住所地在本市的个人，名下没有本市登记的小客车，具有有效的机动车驾驶证，可以办理1个配置指标的申请登记。住所地在本市的个人包括：\n（一）本市户籍人员；\n（二）驻京部队现役军人和现役武警；\n（三）持有效身份证件且近一年以上在京居住的港澳台人员和外国人；\n（四）持有效《北京市工作居住证》的非本市户籍人员；\n（五）持有效《北京市居住证》且近五年（含）连续在本市缴纳社会保险费和个人所得税的非本市户籍人员。\n近五年（含）连续在本市缴纳社会保险费是指：申请人从申请月的上一个月开始往前推算60个月连续向本市社保部门缴纳社会保险费，不能断月（如有断月，补缴后有效）。近五年（含）连续在本市缴纳个人所得税是指：申请人从申请年的上一年开始往前推算连续五年，每年在京缴纳个人所得税，且纳税额大于零，可以断月，不能断年，以税款入库日期为准（如有断年，补缴无效）。\n个体工商户申请指标的，按照个人的有关规定执行。\n第十条 申请指标的单位、家庭和个人，可以在指定网站填写申请表提出申请，也可以到各区政府设置的对外办公窗口提出申请。\n单位、家庭和个人申请信息在填报后发生变化的，应当于本细则第十二条规定的申请期内在指定网站或到各区政府设置的对外办公窗口进行变更。\n第十一条 指标管理机构负责归集申请信息，并会同各审核部门通过数据交换方式对申请信息进行核查。\n市公安机关人口管理部门负责审核个人（含家庭申请人）的身份信息和本市家庭申请人的亲属关系；市公安机关出入境管理部门负责审核港澳台人员、外国人的身份信息和在京居住信息；市公安机关交通管理部门负责审核个人（含家庭申请人及其配偶）的车辆信息以及个人（含家庭主申请人）的驾驶证件信息；经信部门负责审核企业的固定资产投资额信息；民政部门负责审核个人(含家庭申请人)的婚姻状况和配偶信息；人力社保部门负责审核非本市户籍人员的社会保险费缴纳信息；税务部门负责审核企业、非本市户籍人员的纳税信息；市场监管部门负责审核单位的统一社会信用代码信息；人才工作部门负责审核非本市户籍人员的《北京市工作居住证》信息。\n各相关审核部门负责与小客车指标调控管理信息系统进行审核、复核、指标等数据对接；做好本部门小客车指标相关系统运行维护工作，保障系统正常运行。\n第十二条 单位、家庭和个人可于每年1月1日至3月8日、8月1日至10月8日提交配置指标申请。\n1月1日至3月8日提交的申请，指标管理机构于3月9日归集发送至相关部门进行审核，相关部门应当于4月8日前反馈审核结果，申请单位、家庭和个人可在指定网站或各区政府设置的对外办公窗口查询审核结果。对审核结果有异议的，应当于4月23日前（15日内）提出复核申请，相应审核单位应当于5月24日前反馈复核结果。\n8月1日至10月8日提交的申请，指标管理机构于10月9日归集发送至相关部门进行审核，相关部门应当于11月8日前反馈审核结果，申请单位、家庭和个人可在指定网站或各区政府设置的对外办公窗口查询审核结果。对审核结果有异议的，应当于11月23日前（15日内）提出复核申请，相应审核单位应当于12月24日前反馈复核结果。\n申请家庭所填报的所有家庭申请人信息均审核通过的，视为该家庭通过家庭申请人个人资格审核。\n第十三条 申请单位、家庭和个人提出复核申请但复核不通过的，不可再次提出复核申请，如需继续申请指标，应当重新申请。\n申请单位、家庭和个人对审核部门做出的审核结果有异议但未在规定时间内提出复核申请的，视为放弃复核，如需继续申请指标，应当重新申请。\n第三章 配置指标取得和使用 第十四条 个人摇号根据参加摇号的累计次数计算阶梯数。截至2020年12月31日，已经累计的阶梯数不变，即：累计参加摇号6次（含）以内未中签的，阶梯数为1；每多参加摇号6次，增加1个阶梯数，以此类推。具有有效残疾人专用小型自动挡载客汽车准驾车型驾驶证（C5）的申请人，额外增加1个阶梯数。2021年1月1日起，在以前的阶梯数基础上，每多参加摇号2次，增加1个阶梯数，以此类推。\n第十五条 家庭摇号根据每个家庭申请人的积分计算家庭总积分。\n家庭申请人积分由基础积分和阶梯（轮候）积分组成。其中，家庭主申请人的基础积分为2分，其他家庭申请人的基础积分为每人1分。家庭申请人已参加普通小客车指标摇号的，按其累积的阶梯数每1阶梯加1分；正在轮候新能源小客车指标的，按其最近一次开始轮候的时间距离家庭摇号申请年上一年12月31日，每满一年加1分，以往参加摇号获得的阶梯数合并加分；以往没有参加摇号或轮候的，不加分。以家庭为单位申请每满一年，所有家庭申请人积分各增加1分。\n家庭申请人中包含家庭主申请人配偶的，家庭总积分按以下公式计算：总积分=[(主申请人积分+配偶积分)×2+其他成员积分之和]×家庭代际数。\n家庭申请人中不包含家庭主申请人配偶的，家庭总积分按以下公式计算：总积分=（主申请人积分+其他成员积分之和）×家庭代际数。\n家庭代际数是指家庭申请人中包含有几代人，最多为3代。\n第十六条 家庭申请人与个人申请人同池摇号。家庭总积分分数和个人阶梯数即为该家庭或个人的申请编码出现在摇号池中的次数，申请编码出现的次数越多，中签率越高，但只能中签一次。\n第十七条 扣除向单位配置的指标和营运小客车指标，2021年度新能源小客车配置指标数量的60%优先向家庭配置，2022年度该比例调整为70%，2023年度及以后该比例调整为80%，其余向个人配置。按上述比例向家庭配置后指标有剩余的，一并向申请轮候的个人配置。\n家庭申请新能源小客车配置指标的，按家庭总积分由高到低排序配置，总积分相同的家庭，以家庭申请人中最早在小客车指标调控管理信息系统注册时间的先后排序配置。单位、个人申请新能源配置指标的，按照申请时间先后顺序进行轮候。\n第十八条 指标管理机构组织指标配置时，公证机构依法现场予以公证，配置结果在指定网站公布。现场配置时间或者地点因故发生变化的，由指标管理机构提前向社会发布。\n第十九条 家庭摇号中签或者积分排序入围的，由本市公安人口管理部门和民政部门对家庭申请人的亲属关系进行核查。核查通过的，发放指标确认通知书。\n对部分家庭申请人亲属关系、婚姻状况不能通过数据交换进行核查的，指标管理机构应当通过指定网站通知家庭申请人。家庭主申请人可以自愿向本市公证机构申请办理亲属关系公证，对经公证机构依法审查仍不能查明亲属关系的，可自愿申请办理声明公证；但涉及家庭成员婚姻状况需要补充提交证明材料的，相关家庭申请人应当按照通知提示，首先到民政部门指定的办公窗口进行现场核查。\n公证书可自通知家庭主申请人之日起6个月内通过指定网站上传或到各区政府设置的对外办公窗口提交。指标管理机构核验公证书后，发放指标确认通知书。逾期未提交公证书的，视为自动放弃。\n第二十条 单位、家庭和个人可以在指定网站或者通过电话方式查询配置结果，小客车配置指标确认通知书可以自行下载打印或到各区政府设置的对外办公窗口领取，作为指标证明文件。\n单位未取得配置指标的有效编码，申请有效期保留到当年12月31日，在申请有效期内自动转入下一次指标配置，次年须再次提交配置指标申请。在次年3月8日前提交申请并通过审核的，单位申请新能源小客车指标的轮候时间不变；未在次年3月8日前提交申请或未通过审核的，轮候时间不予保留。\n家庭申请通过审核后，申请有效期保留到次年3月8日。未取得配置指标的，在申请有效期内自动转入下一次指标配置，申请有效期满后，将对家庭申请资格再次审核。申请有效期内，如因出生或死亡导致家庭申请人人数增减但家庭主申请人未发生变化的，应当变更申请；发生其他变化的应当重新申请。变更申请和重新申请均随下一次指标配置进行审核。通过审核后，家庭总积分重新计算。\n个人申请通过审核后，申请有效期保留到次年3月8日。未取得配置指标的，在申请有效期内自动转入下一次指标配置，申请有效期满后，将对个人申请资格再次审核。个人申请信息发生变化的应当重新申请，重新申请随下一次指标配置进行审核。在申请有效期内重新申请并通过审核的，个人申请新能源小客车指标的轮候时间不变；未在申请有效期内重新申请或重新申请未通过审核的，轮候时间不予保留。\n单位、家庭和个人主动取消配置指标申请的，其有效编码从指标配置数据中删除。家庭配置指标申请取消后，家庭申请人的原个人摇号的累计次数保留，原个人申请新能源小客车指标的轮候次序不予保留。\n第二十一条 单位和个人（含家庭主申请人）应当自取得指标确认通知书之日起12个月内办理完成车辆登记手续。逾期未办理完成的，视为自动放弃。\n指标所有人在办理车辆购置税申报、二手车销售发票验证、车辆赠与公证等相关手续时，应当出示真实有效的小客车指标确认通知书。\n税务部门受理车辆购置税申报时，应当先行查验小客车指标确认通知书。市场监管部门进行二手车发票验证、公证机构办理车辆赠与公证时，应当查验小客车指标确认通知书，经查验后在相应票证背面加盖“已取得指标”字样的印章。\n单位和个人（含家庭主申请人）申请办理小客车注册、转移登记和转入本市的变更登记时，由公安机关交通管理部门分别查验小客车指标确认通知书、车辆购置税完税凭证、二手车销售发票、车辆赠与公证书以及其他应当查验的材料和内容。\n第四章 更新指标管理 第二十二条 单位和个人（含家庭主申请人）出售、报废名下小客车后需要新购置小客车的，可以申请更新指标，以小客车更新指标确认通知书作为更新指标证明文件。但个人名下有两辆以上本市登记的小客车的，只能选择其中一辆取得更新指标。\n个人名下有两辆以上本市登记的小客车的，在保留一辆的基础上，其余车辆可以向其名下没有本市登记的小客车的配偶、子女、父母变更或转移登记，受让方无需指标证明文件。其中，配偶作为受让方的，按照本细则第三十五条第二款规定执行；子女、父母作为受让方的，须符合以下条件：\n（一）符合本细则第九条“住所地在本市的个人”的条件；\n（二）与车辆登记所有人之间的亲属关系存续满一年。\n符合前款规定的，可以由车辆登记所有人或受让方通过指定网站提出车辆变更或转移登记申请，车辆登记所有人和受让方均通过意愿确认后视为成功提交申请。相关部门参照本细则第十一条的职责分工核查双方的身份信息、亲属关系、婚姻状况、名下本市登记的小客车等信息。提交申请、相关部门审核的时间、流程和规则参照本细则第十二条规定执行。\n亲属关系、婚姻状况不能通过数据交换进行核查的，指标管理机构应当通过指定网站通知申请人。相关申请人可以自愿向本市公证机构申请办理亲属关系公证，对经公证机构依法审查仍不能查明亲属关系的，可自愿申请办理声明公证；但涉及婚姻状况需补充提交证明材料的，相关申请人应当按照通知提示，首先到民政部门指定的办公窗口进行现场核查。公证书可自通知相关申请人之日起6个月内通过指定网站上传或到各区政府设置的对外办公窗口提交。逾期未提交公证书的，视为放弃申请。\n通过审核的，车辆登记所有人和受让方持核查结果等材料，到公安机关交通管理部门办理车辆变更或转移登记。办理完成后，原车辆登记所有人不得申请更新指标。\n第二十三条 自2021年1月1日起，单位和个人（含家庭主申请人）需要申请小客车更新指标的，可以在车辆办理完成转移、注销登记之后根据需要随时提交更新指标申请，不再设置12个月的申请时限。2020年12月31日前，未在12个月时限内申请并获得更新指标的，视为自动放弃。指标管理机构根据公安机关交通管理部门提供的出售、报废小客车转移、注销登记信息，核对申请人申请信息，审核通过后在指定网站发布小客车更新指标确认通知书。\n第二十四条 按照《中华人民共和国道路交通安全法实施条例》和《机动车强制报废标准规定》的规定，因车辆达到国家规定的机动车强制报废标准逾期不办理注销登记，被本市公安机关交通管理部门在官方网站上公告机动车登记证书、号牌、行驶证作废后，办理注销登记的小客车，不予受理更新指标申请。\n第二十五条 车辆办理完成转移、注销登记后，原车辆登记所有人死亡或者单位注销的，更新指标申请资格作废，不得由他人代为申请更新指标。\n第二十六条 单位和个人（含家庭主申请人）获得更新指标后，应当自取得更新指标之日起12个月内办理完成车辆登记手续。逾期未办理完成的，视为自动放弃。\n第二十七条 单位和个人（含家庭申请人）在申请小客车配置指标或更新指标时，名下有应当报废但未办理注销登记的其他机动车，应当按照《北京市实施〈中华人民共和国道路交通安全法〉办法》的相关规定，先行办理报废机动车的注销登记手续。\n第二十八条 单位和个人（含家庭主申请人）名下处于正常登记状态的小客车若被盗抢，公安机关立案满12个月后仍未追回，并已在公安机关车辆管理系统登记被盗抢状态的，可在此后12个月内申请小客车指标。逾期未提出申请的，视为自动放弃。\n单位和个人（含家庭主申请人）在申请指标时须遵守下述规定并承诺：被盗抢小客车若被找回，已取得指标尚未使用的，可选择放弃小客车指标或者放弃已找回车辆；已使用指标购置车辆的，在使用指标购置的车辆或者已找回的车辆中，仅能保留一辆小客车。被放弃的小客车在出售或者报废后不产生更新指标。\n单位和个人（含家庭主申请人）持立案证明材料到本市公安机关交通管理部门打印小客车被盗抢状态信息凭证，持信息凭证和其他相关材料，到各区政府设置的对外办公窗口提出申请并签署承诺书。\n各区政府设置的对外办公窗口将前款相关信息录入到小客车指标调控管理信息系统。经审核，符合条件的申请人可获得小客车指标。\n第二十九条 持普通小客车指标购置的新能源小客车在出售、报废后，可以申请普通小客车更新指标。\n第五章 监督和失信责任 第三十条 承担审核申请信息和查验指标证明职责的相关部门，应当根据本细则的分工和工作实际，制订本部门审核标准、工作流程和操作办法并切实履行职责。工作人员未按本细则要求履行查验职责办理相关手续的，依法追究其责任。\n第三十一条 任何单位或者个人均有权对申请人采取不正当手段取得和使用指标的行为、政府部门及工作人员玩忽职守、徇私舞弊的行为进行监督和举报。指标管理机构、各审核部门和监察机关应当向社会公布举报电话，及时受理举报并认真履行监督职责。\n第三十二条 单位、家庭和个人应当确保所填报申请信息真实、准确，对所填报信息的真实性负责。对于单位、家庭和个人错误填报申请信息导致的审核不通过等后果，由其自行承担。对于提供虚假信息和材料申请小客车指标或办理指标相关公证的、冒用他人名义骗取小客车指标、虚构车辆报废事实骗取小客车更新指标的，由指标管理机构取消该申请人的申请资格、公布其非法取得的指标作废，三年内不予受理该单位、家庭申请人中有过错的申请人、个人提出的指标申请，已使用指标完成车辆登记的，由公安机关交通管理部门依法撤销机动车登记。对于严重违反向行政机关承诺的，由市经信局负责纳入本市公共信用信息服务平台。对于伪造、涂改小客车指标确认通知书等涉嫌伪造证件，构成犯罪的，移交司法机关依法处理。\n第三十三条 小客车指标确认通知书仅限指标所有人使用。对于经公安、司法机关等调查确认有买卖、变相买卖、出租或者承租、出借或者借用小客车指标确认通知书行为的，由指标管理机构公布指标作废；已使用指标完成车辆登记的，由公安机关交通管理部门依法撤销机动车登记，由指标管理机构公布指标作废。同时，三年内不予受理该申请人提出的指标申请。\n第六章 附 则 第三十四条 本细则下列用语含义：\n（一）小客车包括小型、微型载客汽车及市人民政府公布的其他需要实施调控的车型；\n（二）新能源小客车是指纯电驱动小客车；\n（三）营运小客车是指《机动车行驶证》登记的使用性质为“出租客运”、“租赁客运”、“教练”等的小客车；\n（四）有效机动车驾驶证是指公安机关交通管理部门核发的、具有驾驶小客车资格的驾驶证。\n第三十五条 已登记的机动车所有人为个人的，因继承发生财产转移的已注册登记的小客车不适用本细则。有关机关依法办理转移登记。\n夫妻间办理车辆变更登记、离婚析产办理车辆转移登记时，婚姻关系存续期满一年且受让方名下没有本市登记的小客车的，受让方无需指标证明文件。申请变更或转移登记时，参照本细则第二十二条第三款、第四款、第五款规定执行。\n因法院判决、裁定、调解发生小客车所有权转移，申请在本市办理小客车转移登记、由外省（区、市）转入本市或其他涉及车辆所有权转移的情形，现机动车所有人需提交已取得的北京市小客车指标证明文件。其中涉及因继承发生小客车转移登记的，适用本条第一款。涉及因婚姻发生小客车转移登记的，适用本条第二款。\n取得个人小客车指标确认通知书后个人死亡的，或者取得单位小客车指标确认通知书后单位注销的，其尚未使用的指标确认通知书无效。取得家庭小客车配置指标确认通知书后家庭主申请人死亡的，其尚未使用的配置指标确认通知书（不含更新指标确认通知书）可由其他家庭申请人共同指定一名家庭申请人使用。\n因本市法院司法拍卖本市号牌小客车发生所有权转移的，竞买人须符合小客车配置指标申请条件，竞拍成功后买受人持市高级人民法院和指标管理机构共同出具的相关证明文件，到公安机关交通管理部门办理转移登记手续。原车辆所有人不能因此获得更新指标。\n二手车流通过程中涉及小客车指标的管理办法另行制定。\n第三十六条 《\u0026lt;北京市小客车数量调控暂行规定实施细则\u0026gt;（2020年修订）》自2021年1月1日起施行。《\u0026lt;北京市小客车数量调控暂行规定\u0026gt;;实施细则（2017年修订）》（京交发〔2017〕332号）同时废止。\n",
    "ref": "/blog/stories/bjcar/family/"
  },{
    "title": "北京市小客车摇号-《告知承诺书》",
    "date": "",
    "description": "",
    "body": "告知承诺书 尊敬的申请人：\n1、您须完整、仔细阅读并遵守《北京市小客车数量调控暂行规定》（北京市人民政府令第296号）、《\u0026lt;北京市小客车数量调控暂行规定\u0026gt;实施细则（2020年修订）》的相关规定。\n2、您须确认本人为完全民事行为能力人，具有相应的民事权利能力和民事行为能力，能够理解并完成申请过程中的相关操作。若您是某位家庭申请人的合法监护人，则该家庭申请人的相关操作须由您代为完成。\n3、注册北京市小客车指标调控管理信息系统（以下简称“本系统”）账户后，您须对个人账户名下发生的所有登录、操作等活动承担责任。您应妥善保管个人账户的账户名和登录密码，通过个人账户进行的操作视同本人真实意愿的表示。\n4、提交小客车配置指标申请后，若摇号中签或积分排序入围，需要对家庭申请人填报的部分信息进行公示。尊重用户个人隐私是本系统的基本原则。除上述正常公示外，本系统不会公开、透露用户的个人信息，但发生以下事由的除外：\n（1）相关政府主管部门或者司法机构要求本系统提供的；\n（2）因不可抗力所导致的用户信息资料的公开；\n（3）因用户自身过错而导致的用户信息资料的公开；\n（4）超出本系统使用的硬件和软件的技术能力范围所导致的用户信息资料的公开；\n（5）为维护本系统相关权利的而进行的公开；\n（6）因行政机关认定不公开可能对公共利益造成重大影响而进行的公开。\n5、您须知悉并自愿承诺遵守《北京市小客车数量调控暂行规定》（北京市人民政府令第296号）、《\u0026lt;北京市小客车数量调控暂行规定\u0026gt;实施细则（2020年修订）》及以下规定：\n（1）家庭主申请人组织填报申请信息、代表家庭参与指标配置，其他家庭申请人需配合本次家庭申请完成个人信息核验等申请事项。获得指标后，家庭主申请人作为指标所有人，使用该指标购买的车辆登记在该家庭主申请人名下。\n（2）您须核实并确认申请信息的真实、准确、完整，保证相关证件持续合法有效，因遗漏填报、错误填报申请信息及证件过期失效等情形导致审核不通过或无法取得配置指标的后果，由所有家庭申请人共同承担。\n（3）不得同时参与其他家庭或者以个人身份办理配置指标申请登记，以家庭为单位办理配置指标申请登记完成后，所有家庭申请人的原个人配置指标申请将自动取消。\n（4）以家庭为单位申请配置指标的过程中，取消申请的，其有效编码从指标配置数据中删除。家庭配置指标申请取消后，家庭申请人的原个人摇号的累计次数保留，原个人申请新能源小客车指标的轮候次序不予保留。\n（5）以家庭为单位申请配置指标的过程中，所有家庭申请人均不得再以任何形式申请配置指标。\n（6）以家庭为单位办理配置指标申请登记，获得指标后，所有家庭申请人十年内不得再以任何形式申请配置指标，所有家庭申请人的原个人配置指标申请中的普通指标摇号次数、新能源指标轮候次序均不予保留。\n6、您有义务在以下时间节点前登录本系统进行相关操作：\n每年1月1日至3月8日期间填报或修改申请并完成提交的，当年的4月9日起查看审核状态；对审核结果有异议时，于当年的4月9日至4月23日期间按审核单位要求，向审核单位提交复核申请；当年的5月25日起查看复核结果；家庭摇号中签或者积分排序入围的，根据核查需要，必要时按审核单位要求补充提交相关材料，必要时须按照信息系统提示在规定时间内办理并提交亲属关系公证，具体以各审核单位要求为准。\n每年8月1日至10月8日期间填报或修改申请并完成提交的，当年的11月9日起查看审核情况；对审核结果有异议时，于当年的11月9日至11月23日期间按审核单位要求，向审核单位提交复核申请；当年的12月25日起查看复核结果；家庭摇号中签后，根据核查需要，必要时按审核单位要求补充提交相关材料，必要时须按照信息系统提示在规定时间内办理并提交亲属关系公证，具体以各审核单位要求为准。\n7、以家庭为单位办理配置指标申请登记后，所有家庭申请人的身份类型、个人信息、证件状态、婚姻状况、人员自然增减情况及拥车状况等申请信息发生变化的，您须在每年的1月1日至3月8日、8月1日至10月8日两个期间内，及时、主动申报并更正相关申请信息，其他时间不得修改申请信息；申请信息发生上述变化，但您未在每年的1月1日至3月8日、8月1日至10月8日两个期间内，及时、主动申报并更正相关信息，导致审核不通过或无法取得配置指标的后果，由所有家庭申请人共同承担。\n8、对于提供虚假信息和材料办理配置指标申请登记或办理指标相关公证、违反本告知承诺书的，将取消该家庭申请资格、公布指标作废，三年内不予受理该家庭中有过错的申请人提出的指标申请，相关信息纳入本市公共信用信息服务平台。涉嫌违法犯罪的，移交司法机关依法追究责任。\n",
    "ref": "/blog/stories/bjcar/commitment/"
  },{
    "title": "Golang源码阅读-内存管理",
    "date": "",
    "description": "",
    "body": "内存管理 内存模型 保证共享内存的可见性、有序性、原子性，内存模型定义了共享内存系统中多线程读写操作的规范。\nhappens before  go中也定义了happens before以及各种发生happens before关系的操作。 在单个goroutine中，读取和写入必须按照程序指定的顺序执行 在单goroutine的程序中，Happens-Before的顺序就是程序中表达的顺序 当多个goroutine同时访问变量v时，我们必须使用同步事件(synchronization events)来满足Happends-Before条件以确保读操作(r)观察到期望的写操作(w)的值。  init 函数 程序初始化在单个goroutine中运行，但是goroutine可能会创建其他同时运行的goroutine； 如： 在package p中import package q， 那么q的init函数happens-before p的init函数执行。起始的main.main函数在所有包的init函数之后执行；\ngoroutine  creation： go 关键字声明一个goroutine的动作happens-before goroutine 执行； destruction： goroutine退出时，并不能保证其happens-before其他任何事件；  channel  buffered channel  1. 一个容量为C的channel的第k个接收操作happens-before第（k+C）个发送操作；\r2. 发送操作会使channel复制发送的元素。如果channel缓冲已满而无法复制，则阻塞发送操作。复制的目的地址有两种：\r当channel为空且有接收方等待时，它会是最早等待的接收方的地址，否则会是通道持有的缓冲中的地址；\r3. 在channel完全复制一个元素值之前，任何goroutine都不可能从channel接收到元素值的副本；\runbuffered channel  1. 对一个channel的发送操作happens-before相应的channel的接受操作；\r2. 对一个channel的接受操作happens-before相应的channel的发送操作完成\rsync lock 任何sync.Mutex或sync.RWMutex 变量（l），定义 n \u0026lt; m， 第n次 l.Unlock() happens-before 第m次l.lock()调用返回。\nsync once once.Do(f)中的f() happens-before 任何多个once.Do(f)调用的返回，且f()有且只有一次调用。\nautomic  内存分配 概述  Go内置运行时(runtime), 不同于传统的内存分配， Go 启动时，先从操作系统申请一大块内存(虚拟内存)，进行自主管理，减少系统调用 Go运行时内存分配算法使用Google为C语言开发的TCMalloc算法(全称： Thread-Caching Malloc)， 细分内存，多级管理，降低锁粒度 Go对象回收时，并没有将其真正释放，只是放回预先分配的大块内存中，以便复用。只有当自主内存闲置太多时，才会尝试归还部分内存给操作系统，降低开销  内存分配算法 Go运行时内存分配算法使用Google为C语言开发的TCMalloc算法(全称： Thread-Caching Malloc).\n 核心思想  将内存分为多级管理，从而降低锁的粒度 将堆内存采用二级分配的方式进行管理  每个线程会自行维护一个独立的内存池 进行内存分配时优先从该内存池中分陪 当内存池不足时才会向全局进行申请，以避免多线程对全局内存池的频繁竞争      基本概念  Go 启动时，先从操作系统申请一块内存(虚拟内存) 将内存切分成三个区域进行管理  arena区域  是通常说的堆区 arena区域大小为512G Go动态分配的内存都在这个区域 arena区域被分割成大小8KB的页  从管理分配出发，arena由多个连续页组成。这些页是堆内存管理的最小单元 从使用角度出发，arena由多个对象组成     bitmap区域  bitmap区域大小为16G 标识arena区域中的对象，分别使用1bit标志位标识地址中是否包含对象以及对象是否被GC标记过 bitmap中的一个字节大小内存对应arena区域中4个指针指向对象，所以bitmap区域大小为 512GB/(4*8B)=16G bitmap地址由高地址向低地址增长   spans区域  用于管理分配arena的内存页 存放mspan的指针， 标识arena中的某一页属于mspan 每个指针对应一页，所以spans区域大小为512GB/8KB*8B=512MB。除以8KB计算arena总页数，乘以8B计算spans区域存放指针的大小   mspan 内存管理单元  Go中内存管理的基本单元 Go将内存分为大小不同的67种，在把67种大块内存，逐个分为小块称之为span， 在go中就是mspan Go分配对象时，根据对象的大小选择相近的span， 这样避免太多内存碎片问题 Go当出现大于32k的对象时，直接从head分配特殊的span，这个特殊的span类型为0， 只包含这个大对象      内存管理组件  mspan  内存管理基础单元，直接存储数据的地方 结构： type mspan struct {\r// 双向链表结构\rnext *mspan // next span in list, or nil if none\rprev *mspan // previous span in list, or nil if none\r// 首地址\rstartAddr uintptr // address of first byte of span aka s.base()\r// 有多少内存页\rnpages uintptr // number of pages in span\rmanualFreeList gclinkptr // list of free objects in mSpanManual spans\rfreeindex uintptr\r// 允许分配多少对象\rnelems uintptr // number of object in the span.\r// 是否分配对象标志位\rallocBits *gcBits\r// 对象是否被gc标记标志位\rgcmarkBits *gcBits\r// 已经分配了多少对象\rallocCount uint16 // number of allocated objects\r// mspan是哪一种size class\rspanclass spanClass // size class and noscan (uint8)\r// 每个对象大小\relemsize uintptr // computed from sizeclass or from npages\r}\r   mcache  mcache绑定P，用以分配goroutine运行中所需的内存 mcache初始化时，没有任何mspan资源， 使用过程中会动态从mcentral申请，并缓存 数据结构 type mcache struct {\rnext_sample uintptr // trigger heap sample after allocating this many bytes\rlocal_scan uintptr // bytes of scannable heap allocated\r// Tiny allocator： 微内存分配器， 用于给小于16B的对象分配内存，此对象不可被GC扫描\rtiny uintptr\rtinyoffset uintptr\rlocal_tinyallocs uintptr // number of tiny allocs not counted in other stats\r// 已经缓存的mspan 列表， 分为两类：1. 可以被GC扫描的指针对象；2. 不可以被GC扫描的非指针对象\ralloc [numSpanClasses]*mspan // spans to allocate from, indexed by spanClass\r}\r   mcentral  为所有mcache提供切分好的mspan资源 每个mcentral保存一种有相同size class的全局mspan列表，包含已分配和未分配的mspan列表 再P分配对象时，如果P的mcache中没有合适的mspan，则会从mcentral中获取 mcentral被所有P共享，所以存在多Goroutine竞争的情况， 会消耗锁资源 数据结构 type mcentral struct {\r// 多协程内存申请竞争锁\rlock mutex\r// mcentral的mspan列表 size class 类型\rspanclass spanClass\r// 有空闲object的mspan链表 nonempty mSpanList // list of spans with a free object, ie a nonempty free list\r// 没有空闲object的mspan链表\rempty mSpanList // list of spans with no free objects (or cached in an mcache)\r// 已经累计分配对象个数\rnmalloc uint64\r}\r P从mcentral申请mspan流程  加锁 从nonempty获取可用mspan，将其从链表中删除 将取出的mspan，放入empty中 将mspan 返回给P 解锁 P将mspan缓存进mcache   P归还mspan流程  加锁 将mspan从empty中删除 将mspan加入到nonempty中 解锁     mheap  代表Go程序持有的所有堆空间，Go程序使用一个全局的mheap对象来管理堆内存 主要用于大对象的内存分配，以及切割内存为合适的mspan，分配给mcentral 当mcentral中没有空闲的mspan时，会向mheap申请 当mheap中没有资源时，会向操作系统申请 数据结构 type mheap struct {\r// 用于内存页申请分配竞争锁\rlock mutex\r// 空闲spans\rfree mTreap // free spans\r// 已经创建的所有mspan\rallspans []*mspan // all spans out there\r// span bitmap arena 映射关系\rarenas [1 \u0026lt;\u0026lt; arenaL1Bits]*[1 \u0026lt;\u0026lt; arenaL2Bits]*heapArena\r}\r    内存分配逻辑  如果object size\u0026gt;32KB, 则直接使用mheap来分配空间； 如果object size\u0026lt;16Byte, 则通过mcache的tiny分配器来分配(tiny可看作是一个指针offset)； 如果object size在上面两者之间，首先尝试通过sizeclass对应的分配器分配; 如果mcache没有空闲的span， 则向mcentral申请空闲块； 如果mcentral也没空闲块，则向mheap申请并进行切分； 如果mheap也没合适的span，则向系统申请新的内存空间。  内存回收逻辑  如果object size\u0026gt;32KB, 直接将span返还给mheap； 如果object size\u0026lt;32KB, 查找object对应sizeclass， 归还到mcache； 如果mcache空闲列表过长或内存过大，将部分mspan归还到mcentral； 如果某个范围的mspan都已经归还到mcentral，则将这部分mspan归还到mheap； 而mheap不会定时将内存归还到系统，但会归还虚拟地址到物理内存的映射关系，当系统需要的时候可以回收这部分内存，否则暂时先留着给Go使用。  ",
    "ref": "/blog/golang/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/"
  },{
    "title": "Golang源码阅读-Context",
    "date": "",
    "description": "",
    "body": "context 数据结构 type Context interface {\r// Done return a channel that is closed when this context is canceld or timeout\rDone() \u0026lt;- chan struct{}\r// Err indicates why this context is canceled, after the done channel is closed\rErr() error // Deadline returns the time when this context will be canceld, if any\rDeadline() (deadline time.Time, ok bool)\r// Value returns the value associated with key or nil if none.\rValue(key interface{}) interface{}\r}\r Done会返回一个channel，当该context被取消的时候，该channel会被关闭，同时对应的使用该context的routine也应该结束并返回。 Context中的方法是协程安全的，这也就代表了在父routine中创建的context，可以传递给任意数量的routine并让他们同时访问。 Deadline会返回一个超时时间，routine获得了超时时间后，可以对某些io操作设定超时时间。 Value可以让routine共享一些数据，当然获得数据是协程安全的。  context中的上下文数据并不是全局的，它只查询本节点及父节点们的数据，不能查询兄弟节点的数据。\n   Context 使用原则 和 技巧  不要把Context放在结构体中，要以参数的方式传递，parent Context一般为Background 应该要把Context作为第一个参数传递给入口请求和出口请求链路上的每一个函数，放在第一位，变量名建议都统一，如ctx。 给一个函数方法传递Context的时候，不要传递nil，否则在tarce追踪的时候，就会断了连接 Context的Value相关方法应该传递必须的数据，不要什么数据都使用这个传递 Context是线程安全的，可以放心的在多个goroutine中传递 可以把一个 Context 对象传递给任意个数的 gorotuine，对它执行 取消 操作时，所有 goroutine 都会接收到取消信号。 父operation启动goroutine用于子operation，这些子operation不能够取消父operation； value 查询从子节点， 倒查询到根节点；  ",
    "ref": "/blog/golang/context/"
  },{
    "title": "Golang源码阅读-sync.map",
    "date": "",
    "description": "",
    "body": "sync.map  runtime中go的基本类型 map 不支持并发的读写， 会报错：fatal error: concurrent map writes 为了支持并发， 我们直接对整个map加读写锁，相当低效， 因此官方实现了sync.map  高效的原理和思路  用空间换时间，降低锁的区域 用两个map来存储数据  虽然两个map存储有冗余，但是底层数据类型都是指针，所以冗余的空间还是有限的。    总结  如果对map的读操作大于写操作， 则sync.map能大大提升性能； 写操作需要加锁， 且操作两个map 写操作也会触发， 两个map之间的切换。  源码解析 基础结构  Map type Map struct {\rmu Mutex // 互斥锁，用于锁定dirty map， 写锁\rread atomic.Value // 优先读， 支持原子操作。相当于dirty的缓存\rdirty map[interface{}]*entry // dirty保存最新写入数据， 允许读写\rmisses int // 记录在read中读取不到数据，去dirty中查询的次数\r}\r readonly type readOnly struct {\rm map[interface{}]*entry\ramended bool // 当key不在read中而在dirty中时， 为true\r}\r entry type entry struct {\r//可见value是个指针类型，虽然read和dirty存在冗余情况（amended=false），但是由于是指针类型，存储的空间应该不是问题\rp unsafe.Pointer // *interface{}\r}\r  删除  语法 mm := sync.map{}\rmm.Delete(1)  源码分析 func (m *Map) Delete(key interface{}) {\rread, _ := m.read.Load().(readOnly)\re, ok := read.m[key]\r// read中不存在key，且read和dirty不同步\rif !ok \u0026amp;\u0026amp; read.amended {\rm.mu.Lock()\rread, _ = m.read.Load().(readOnly)\re, ok = read.m[key]\rif !ok \u0026amp;\u0026amp; read.amended {\r// 删除dirty中key\rdelete(m.dirty, key)\r}\rm.mu.Unlock()\r}\r// 如果read中查询到，则将此key值标记为删除\rif ok {\re.delete()\r}\r}\rfunc (e *entry) delete() (hadValue bool) {\rfor {\rp := atomic.LoadPointer(\u0026amp;e.p)\rif p == nil || p == expunged {\rreturn false\r}\rif atomic.CompareAndSwapPointer(\u0026amp;e.p, p, nil) {\rreturn true\r}\r}\r}\r  插入和更新 -语法 \rmm := sync.map{}\rmm.Store(1,1)\r\n 源码分析 func (m *Map) Store(key, value interface{}) {\r// 如果read中存在key，且没有被标记删除，则更新，更新是原子操作\rread, _ := m.read.Load().(readOnly)\rif e, ok := read.m[key]; ok \u0026amp;\u0026amp; e.tryStore(\u0026amp;value) {\rreturn\r}\rm.mu.Lock()\r// 加锁二次读取read， 避免上面读取和加锁之间，read 有改动\rread, _ = m.read.Load().(readOnly)\rif e, ok := read.m[key]; ok { // read中存在key\r// read中存在key， 但是被标记删除， 则dirty中key已被删除， 需要添加\rif e.unexpungeLocked() {\rm.dirty[key] = e\r}\r// 更新read和dirty 中key映射的value值\re.storeLocked(\u0026amp;value)\r} else if e, ok := m.dirty[key]; ok { // dirty中存在key，则更新\re.storeLocked(\u0026amp;value)\r} else { // read 和 dirty 中都没有\rif !read.amended { // 第一次添加key\rm.dirtyLocked() // 将read中数据添加到dirty\rm.read.Store(readOnly{m: read.m, amended: true}) // 后面dirty会添加新的key/value， 因此amended设置为true\r}\r// 添加新key/value\rm.dirty[key] = newEntry(value)\r}\r//解锁\rm.mu.Unlock()\r}\r// 尝试对entry进行更新\rfunc (e *entry) tryStore(i *interface{}) bool {\rfor {\r// 加载entry 数据\rp := atomic.LoadPointer(\u0026amp;e.p)\r// 如果被标记为删除， 则直接返回false\rif p == expunged {\rreturn false\r}\r// cas 更新entry值\rif atomic.CompareAndSwapPointer(\u0026amp;e.p, p, unsafe.Pointer(i)) {\rreturn true\r}\r}\r}\r// 取消entry的删除标记\rfunc (e *entry) unexpungeLocked() (wasExpunged bool) {\rreturn atomic.CompareAndSwapPointer(\u0026amp;e.p, expunged, nil)\r}\r// 更新entry的值\rfunc (e *entry) storeLocked(i *interface{}) {\ratomic.StorePointer(\u0026amp;e.p, unsafe.Pointer(i))\r}\r// 将read中未删除的数据加入到dirty中\rfunc (m *Map) dirtyLocked() {\rif m.dirty != nil {\rreturn\r}\rread, _ := m.read.Load().(readOnly)\rm.dirty = make(map[interface{}]*entry, len(read.m))\r// 遍历read。\rfor k, e := range read.m {\r// 通过此次操作，dirty中的元素都是未被删除的，可见标记为expunged的元素不在dirty中！！！\rif !e.tryExpungeLocked() {\rm.dirty[k] = e\r}\r}\r}\r// 判断entry是否被标记删除，并且将标记为nil的entry更新标记为expunge\rfunc (e *entry) tryExpungeLocked() (isExpunged bool) {\rp := atomic.LoadPointer(\u0026amp;e.p)\rfor p == nil {\r// 将已经删除标记为nil的数据标记为expunged\rif atomic.CompareAndSwapPointer(\u0026amp;e.p, nil, expunged) {\rreturn true\r}\rp = atomic.LoadPointer(\u0026amp;e.p)\r}\rreturn p == expunged\r}\r  查询  语法 mm := sync.map{}\rm.Load(1)\r 源码分析 func (m *Map) Load(key interface{}) (value interface{}, ok bool) {\r// 查询只读read， 线程安全，优先读取\rread, _ := m.read.Load().(readOnly)\re, ok := read.m[key]\r// 如果read中不存在key， 且dirty和read 不同步，则读取dirty\rif !ok \u0026amp;\u0026amp; read.amended {\rm.mu.Lock()\rread, _ = m.read.Load().(readOnly)\re, ok = read.m[key]\rif !ok \u0026amp;\u0026amp; read.amended {\r// 查询dirty中key\re, ok = m.dirty[key]\r// 记录查询失败次数\rm.missLocked()\r}\r// 解锁\rm.mu.Unlock()\r}\r// 没有查询到，返回nil和false\rif !ok {\rreturn nil, false\r}\r// 查询到， 则返回值\rreturn e.load()\r}\r// 记录查询read 失败次数\rfunc (m *Map) missLocked() {\r// 失败记录++\rm.misses++\rif m.misses \u0026lt; len(m.dirty) {\rreturn\r}\r// 查询穿透到dirty过多， 则将dirty复制到read, 且 amended 为false\rm.read.Store(readOnly{m: m.dirty})\r// 将dirty清空\rm.dirty = nil\r// 查询read失败记录清零\rm.misses = 0\r}\r  ",
    "ref": "/blog/golang/sync.map/"
  },{
    "title": "Golang源码阅读-sync.Mutex",
    "date": "",
    "description": "",
    "body": "概述 Go的互斥锁有两种模式: 正常模式和饥饿模式。\n  正常模式 正常模式，等待队列按FIFO顺序排序，但是等待队列中被唤醒的G并不拥有互斥锁， 而是与新来的G竞争所有权。新来的G有一个优势-它已经再CPU上运行并且可能有很多， 因此等待队列中被唤醒的G可能会输掉竞争。这种情况下先来的G排在等待队列的前面。 如果等待队列中的G获取互斥锁失败超过1ms，它会将互斥锁切换为饥饿模式。\n  饥饿模式\n 饥饿模式下，互斥锁的所有权直接从解锁的G传递给等待队列队首的G。 新来的G不要试图获取互斥锁，即使它看起来是要解锁，并且不要试图自旋。 将新来的G放到等待队列的队尾。 如果等待队列中的G获取互斥锁的所有权并且有以下情况: 1)G是等待队列中的最后一个， 2) G的等待市场小于1ms， 它将互斥锁切换为正常模式。    正常模式有很好的性能表现，因为G可以连续多次的获取互斥锁，即使存在阻塞的等待者。\n饥饿模式可以有效的预防尾延迟的情况。\nMutex // Mutex是互斥锁\r// Mutex的0值是一个未锁定的mutex。\r//\r// Mutex 不允许复制\rtype Mutex struct {\rstate int32\rsema uint32\r}\r// Locker表示可以被锁定和解锁的对象\r// Mutex 实现该接口\rtype Locker interface {\rLock()\rUnlock()\r}\r// Mutex 状态标志常量\rconst (\rmutexLocked = 1 \u0026lt;\u0026lt; iota // mutex is locked\rmutexWoken\rmutexStarving\rmutexWaiterShift = iota\rstarvationThresholdNs = 1e6\r)\rLock // Lock 锁定m\r// 如果m已经锁定，调用Lock的goroutine会阻塞，直到m被解锁。\rfunc (m *Mutex) Lock() {\r// 快通道: 抢占未锁定的mutex\r// 将mutex.state 标记为 mutexLocked。\rif atomic.CompareAndSwapInt32(\u0026amp;m.state, 0, mutexLocked) {\rif race.Enabled {\rrace.Acquire(unsafe.Pointer(m))\r}\rreturn\r}\r// 慢通道\rm.lockSlow()\r}\rfunc (m *Mutex) lockSlow() {\rvar waitStartTime int64\rstarving := false\rawoke := false\riter := 0\rold := m.state\rfor {\r// 饥饿模式下不要自旋，互斥锁的所有权直接转移给等待队列\r// 因此不允许新到的G获取互斥锁的所有权。\r// 如果不是饥饿模式，且满足自旋条件，开始自旋\rif old\u0026amp;(mutexLocked|mutexStarving) == mutexLocked \u0026amp;\u0026amp; runtime_canSpin(iter) {\r// Active spinning makes sense.\r// Try to set mutexWoken flag to inform Unlock\r// to not wake other blocked goroutines.\rif !awoke \u0026amp;\u0026amp; old\u0026amp;mutexWoken == 0 \u0026amp;\u0026amp; old\u0026gt;\u0026gt;mutexWaiterShift != 0 \u0026amp;\u0026amp;\ratomic.CompareAndSwapInt32(\u0026amp;m.state, old, old|mutexWoken) {\rawoke = true\r}\rruntime_doSpin()\riter++\rold = m.state\rcontinue\r}\rnew := old\r// Don't try to acquire starving mutex, new arriving goroutines must queue.\rif old\u0026amp;mutexStarving == 0 {\rnew |= mutexLocked\r}\rif old\u0026amp;(mutexLocked|mutexStarving) != 0 {\rnew += 1 \u0026lt;\u0026lt; mutexWaiterShift\r}\r// The current goroutine switches mutex to starvation mode.\r// But if the mutex is currently unlocked, don't do the switch.\r// Unlock expects that starving mutex has waiters, which will not\r// be true in this case.\rif starving \u0026amp;\u0026amp; old\u0026amp;mutexLocked != 0 {\rnew |= mutexStarving\r}\rif awoke {\r// The goroutine has been woken from sleep,\r// so we need to reset the flag in either case.\rif new\u0026amp;mutexWoken == 0 {\rthrow(\u0026quot;sync: inconsistent mutex state\u0026quot;)\r}\rnew \u0026amp;^= mutexWoken\r}\rif atomic.CompareAndSwapInt32(\u0026amp;m.state, old, new) {\rif old\u0026amp;(mutexLocked|mutexStarving) == 0 {\rbreak // locked the mutex with CAS\r}\r// If we were already waiting before, queue at the front of the queue.\rqueueLifo := waitStartTime != 0\rif waitStartTime == 0 {\rwaitStartTime = runtime_nanotime()\r}\rruntime_SemacquireMutex(\u0026amp;m.sema, queueLifo, 1)\rstarving = starving || runtime_nanotime()-waitStartTime \u0026gt; starvationThresholdNs\rold = m.state\rif old\u0026amp;mutexStarving != 0 {\r// If this goroutine was woken and mutex is in starvation mode,\r// ownership was handed off to us but mutex is in somewhat\r// inconsistent state: mutexLocked is not set and we are still\r// accounted as waiter. Fix that.\rif old\u0026amp;(mutexLocked|mutexWoken) != 0 || old\u0026gt;\u0026gt;mutexWaiterShift == 0 {\rthrow(\u0026quot;sync: inconsistent mutex state\u0026quot;)\r}\rdelta := int32(mutexLocked - 1\u0026lt;\u0026lt;mutexWaiterShift)\rif !starving || old\u0026gt;\u0026gt;mutexWaiterShift == 1 {\r// Exit starvation mode.\r// Critical to do it here and consider wait time.\r// Starvation mode is so inefficient, that two goroutines\r// can go lock-step infinitely once they switch mutex\r// to starvation mode.\rdelta -= mutexStarving\r}\ratomic.AddInt32(\u0026amp;m.state, delta)\rbreak\r}\rawoke = true\riter = 0\r} else {\rold = m.state\r}\r}\rif race.Enabled {\rrace.Acquire(unsafe.Pointer(m))\r}\r}\rcanSpin // Active spinning for sync.Mutex.\r//go:linkname sync_runtime_canSpin sync.runtime_canSpin\r//go:nosplit\rfunc sync_runtime_canSpin(i int) bool {\r// sync.Mutex是协作式的，因此对待自旋是保守的\r// 自旋的条件:\r// 自旋次数小于等于active_spin(4)次\r// 运行机器为多核心\r// GOMAXPROCS \u0026gt; 1\r// P的可运行队列不为空\r// 与runtime.mutex相反，我们不在这里做被动自旋，因为sync.Mutex可能在全局运行队列或其它P工作。\rif i \u0026gt;= active_spin || ncpu \u0026lt;= 1 || gomaxprocs \u0026lt;= int32(sched.npidle+sched.nmspinning)+1 {\rreturn false\r}\rif p := getg().m.p.ptr(); !runqempty(p) {\rreturn false\r}\rreturn true\r}\rrunqempty // runqempty reports whether _p_ has no Gs on its local run queue.\r// It never returns true spuriously.\r// runqempty 报告P的local运行队列中是否已经没有G\r// 它永远不会返回虚假的true\rfunc runqempty(_p_ *p) bool {\r// Defend against a race where 1) _p_ has G1 in runqnext but runqhead == runqtail,\r// 2) runqput on _p_ kicks G1 to the runq, 3) runqget on _p_ empties runqnext.\r// Simply observing that runqhead == runqtail and then observing that runqnext == nil\r// does not mean the queue is empty.\rfor {\rhead := atomic.Load(\u0026amp;_p_.runqhead)\rtail := atomic.Load(\u0026amp;_p_.runqtail)\rrunnext := atomic.Loaduintptr((*uintptr)(unsafe.Pointer(\u0026amp;_p_.runnext)))\rif tail == atomic.Load(\u0026amp;_p_.runqtail) {\rreturn head == tail \u0026amp;\u0026amp; runnext == 0\r}\r}\r}\r",
    "ref": "/blog/golang/sync.mutex/"
  },{
    "title": "Golang源码阅读-sync.pool",
    "date": "",
    "description": "",
    "body": "基本概述 Pool定义在package sync中.\nPool是一组临时对象的集合， 可以用于保存和检索临时对象。\n存储在Pool中的任何对象，都可以在任何时间被自动删除，而不需要通知。如果当前Pool持有对象的唯一引用， 那么该对象可能会被释放。\nPool是多协程并发使用安全的。\nPool在第一次使用后，不能再被拷贝赋值。\nPool作用 Pool设计用来缓存已分配内存但未使用的对象，用于后续的复用。用来减轻gc的压力。 换言之，Pool使得构建高效、线程安全的缓存变得简单。但是，它并不适用所有的缓存情况。 Pool只是提供了一种在多客户机之间分摊分配开销的方法。\n使用场景 Pool在标准库中的使用示例是在package fmt中， 维护一个临时输出缓冲区的动态大小存储区。 当goroutine打印活跃时扩容缓冲区，打印沉寂时收缩缓冲区。\n另一方面，缓存列表维护一组短命的临时对象的场景不适合使用Pool，因为这种情况不能很好的 分摊分配开销。让这些对象实现他们自己的缓存列表会更有效。\n数据结构 type Pool struct {\rnoCopy noCopy // 第一次使用后不允许被复制\rlocal unsafe.Pointer // 固定大小的per-P pool, 实际类型是[P]poolLocal\rlocalSize uintptr // local的大小\rvictim unsafe.Pointer // 上一个gc周期local的备份\rvictimSize uintptr // victim的大小\r// `New` 是可选项，指定函数用以在`Get`返回`nil`时生成一个值。 // 它不能与`Get`调用同时更改\rNew func() interface{}\r}\r local大小为什么是GOMAXPROCS？\n优化G对local的竞争。G绑定到P上只能操作对应的local[PID],这样设计避免了多个G操作Pool时需要加锁。  type poolLocal struct {\rpoolLocalInternal\r// Prevents false sharing on widespread platforms with\r// 128 mod (cache line size) = 0 .\rpad [128 - unsafe.Sizeof(poolLocalInternal{})%128]byte\r}\r// Local per-P Pool appendix.\r// local per-P Pool 附录。\rtype poolLocalInternal struct {\rprivate interface{} // 只能P自身使用\rshared poolChain // P对链表可以进行pushHead/popHead; 其它P可以进行popTail.\r}\r// poolChain is a dynamically-sized version of poolDequeue.\r//\r// This is implemented as a doubly-linked list queue of poolDequeues\r// where each dequeue is double the size of the previous one. Once a\r// dequeue fills up, this allocates a new one and only ever pushes to\r// the latest dequeue. Pops happen from the other end of the list and\r// once a dequeue is exhausted, it gets removed from the list.\rtype poolChain struct {\r// head is the poolDequeue to push to. This is only accessed\r// by the producer, so doesn't need to be synchronized.\rhead *poolChainElt\r// tail is the poolDequeue to popTail from. This is accessed\r// by consumers, so reads and writes must be atomic.\rtail *poolChainElt\r}\rtype poolChainElt struct {\rpoolDequeue\r// next and prev link to the adjacent poolChainElts in this\r// poolChain.\r//\r// next is written atomically by the producer and read\r// atomically by the consumer. It only transitions from nil to\r// non-nil.\r//\r// prev is written atomically by the consumer and read\r// atomically by the producer. It only transitions from\r// non-nil to nil.\rnext, prev *poolChainElt\r}\r// poolDequeue is a lock-free fixed-size single-producer,\r// multi-consumer queue. The single producer can both push and pop\r// from the head, and consumers can pop from the tail.\r//\r// It has the added feature that it nils out unused slots to avoid\r// unnecessary retention of objects. This is important for sync.Pool,\r// but not typically a property considered in the literature.\rtype poolDequeue struct {\r// headTail packs together a 32-bit head index and a 32-bit\r// tail index. Both are indexes into vals modulo len(vals)-1.\r//\r// tail = index of oldest data in queue\r// head = index of next slot to fill\r//\r// Slots in the range [tail, head) are owned by consumers.\r// A consumer continues to own a slot outside this range until\r// it nils the slot, at which point ownership passes to the\r// producer.\r//\r// The head index is stored in the most-significant bits so\r// that we can atomically add to it and the overflow is\r// harmless.\rheadTail uint64\r// vals is a ring buffer of interface{} values stored in this\r// dequeue. The size of this must be a power of 2.\r//\r// vals[i].typ is nil if the slot is empty and non-nil\r// otherwise. A slot is still in use until *both* the tail\r// index has moved beyond it and typ has been set to nil. This\r// is set to nil atomically by the consumer and read\r// atomically by the producer.\rvals []eface\r}\rtype eface struct {\rtyp, val unsafe.Pointer\r}\r源码 poolCleanup var (\rallPoolsMu Mutex\r// allPools 是具有非空主缓存Pool的集合 // allPools的原子操作保护有两种： allPoolsMu琐和STW。\rallPools []*Pool\r// oldPools是具有非空受害者缓存Pool的集合\r// oldPools的原子操作由STW保护。\roldPools []*Pool\r)\rfunc init() {\r// 在runtime中注册poolCleanup\rruntime_registerPoolCleanup(poolCleanup)\r}\r// poolCleanup 在STW时调用，在gc开始时。 func poolCleanup() {\r// This function is called with the world stopped, at the beginning of a garbage collection.\r// It must not allocate and probably should not call any runtime functions.\r// Because the world is stopped, no pool user can be in a pinned section (in effect, this has all Ps pinned).\r// Drop victim caches from all pools.\r// 清空所有P中的victim缓存\rfor _, p := range oldPools {\rp.victim = nil\rp.victimSize = 0\r}\r// Move primary cache to victim cache.\r// 将主缓存的转移给victim缓存，并清空主缓存\rfor _, p := range allPools {\rp.victim = p.local\rp.victimSize = p.localSize\rp.local = nil\rp.localSize = 0\r}\r// The pools with non-empty primary caches now have non-empty\r// victim caches and no pools have primary caches.\r// oldPools, allPools = allPools, nil\r}\r  为什么poolCleanup没有加锁？ 答: 因为poolCleanup是在STW时被调用，所有的P都被抢占，因此不会发生竞争。\n  runtime_procPin怎么阻止GC发生，即怎么阻止poolCleanup发生的？\n  Get // + go1.3\r// Get从Pool中选择任意项，将其从Pool中删除，并返回给调用者。\r// Get可能选择性忽略pool并视其为空。调用者不应假设传递给Put的值和Get返回的值之间有任何联系\r//\r// 如果Get返回nil且Pool.New不为nil，Get返回调用New生成的结果。\rfunc (p *Pool) Get() interface{} {\r...\r// 将G和P进行绑定，禁止抢占，并返回P的poolLocal和P的id\rl, pid := p.pin()\r// x := l.private\rl.private = nil\rif x == nil {\r// Try to pop the head of the local shard. We prefer\r// the head over the tail for temporal locality of\r// reuse.\rx, _ = l.shared.popHead()\rif x == nil {\rx = p.getSlow(pid)\r}\r}\rruntime_procUnpin()\rif race.Enabled {\rrace.Enable()\rif x != nil {\rrace.Acquire(poolRaceAddr(x))\r}\r}\rif x == nil \u0026amp;\u0026amp; p.New != nil {\rx = p.New()\r}\rreturn x\r}\rpin // pin 绑定当前G到P，禁止抢占并且返回当前P的poolLocal和id。\rfunc (p *Pool) pin() (*poolLocal, int) {\r// runtime_procPin runtime\r// 抢占P并返回pid用于Pool.local的索引\rpid := runtime_procPin()\r// In pinSlow we store to local and then to localSize, here we load in opposite order.\r// Since we've disabled preemption, GC cannot happen in between.\r// Thus here we must observe local at least as large localSize.\r// We can observe a newer/larger local, it is fine (we must observe its zero-initialized-ness).\r// s := atomic.LoadUintptr(\u0026amp;p.localSize) // load-acquire\rl := p.local // load-consume\r// 判断local是否有效(已经初始化，且未经过GC)\rif uintptr(pid) \u0026lt; s {\r// 返回当前P对应索引的poolLocal\rreturn indexLocal(l, pid), pid\r}\r// 如果local无效\rreturn p.pinSlow()\r}\r runtime_procPin怎么绑定G实现抢占的？  首先看一下runtime中procPin的实现： //go:nosplit\rfunc procPin() int {\r// 获取当前goroutine兑现\r_g_ := getg()\r// 获取执行G的M\rmp := _g_.m\r// 这里实现P的抢占\rmp.locks++\r// 返回PID\rreturn int(mp.p.ptr().id)\r}\r    pinSlow func (p *Pool) pinSlow() (*poolLocal, int) {\r// Retry under the mutex.\r// Can not lock the mutex while pinned.\rruntime_procUnpin()\rallPoolsMu.Lock()\rdefer allPoolsMu.Unlock()\rpid := runtime_procPin()\r// poolCleanup won't be called while we are pinned.\rs := p.localSize\rl := p.local\rif uintptr(pid) \u0026lt; s {\rreturn indexLocal(l, pid), pid\r}\rif p.local == nil {\rallPools = append(allPools, p)\r}\r// If GOMAXPROCS changes between GCs, we re-allocate the array and lose the old one.\rsize := runtime.GOMAXPROCS(0)\rlocal := make([]poolLocal, size)\ratomic.StorePointer(\u0026amp;p.local, unsafe.Pointer(\u0026amp;local[0])) // store-release\ratomic.StoreUintptr(\u0026amp;p.localSize, uintptr(size)) // store-release\rreturn \u0026amp;local[pid], pid\r}\r 为什么要先调用runtime_procUnpin，再lock?  看一下mutext.lock()的实现    Put // + go 1.3 // Put 将x添加到poll中\rfunc (p *Pool) Put(x interface{})\r",
    "ref": "/blog/golang/sync.pool/"
  },{
    "title": "Golang doc使用细则",
    "date": "",
    "description": "",
    "body": "简介 go doc和godoc 在golang 1.13版本被移除，可手动安装go get golang.org/x/tools/cmd/godoc\ngo doc GO 命令行工具， 打印和显示文档 打印内容：\npackage pkgxxx // import \u0026quot;project/pkgxxx\u0026quot;\rFUNCTIONS\rfunc FuncXxx(n int) string\rTYPES\rtype TXxx struct {\rVal int\r}\rgo doc Flags -all: 显示package的所有文档\n-c: 区分大小写，默认不区分\n-cmd: 打印文档包含package main,默认是不包含的\n-u: 打印文档包含不能导出(首字母小写)的FUNCTIONS和TYPES文档,默认是不包含的\n-src: 显示源代码\n-short: 单行显示\ngo doc参数  go doc: 输出当前目录下package的文档说明 go doc \u0026lt;pkg\u0026gt;: 输出指定package的文档说明  示例： go doc http   go doc \u0026lt;sym\u0026gt;[.\u0026lt;methodOrField\u0026gt;]: 输出指定package的指定FUNCTIONS或TYPES的文档说明  示例: go doc http.Request   go doc [\u0026lt;pkg\u0026gt;.]\u0026lt;sym\u0026gt;[.\u0026lt;methodOrField\u0026gt;]: 输出package中TYPES的FUNCTIONS的文档说明  示例: go doc http.Request.Write   go doc \u0026lt;pkg\u0026gt; \u0026lt;sym\u0026gt;[.\u0026lt;methodOrField\u0026gt;]: 输出package中TYPES的FUNCTIONS的文档说明， 此处pkg需要全路径  示例： go doc net/http Request    godoc Go自带文档发布工具\ngodoc 文档结构 Overview // 包的描述\rIndex // 包内Const, Var, Functions,Types的目录索引\rExamples // 包内Examples\rPackage files // 包内文件列表\r... // Index 中包含的条目\rSubdirectories // 包目录下的子目录列表\rBugs // BUG(whos) 声明的bug列表\rgodoc 启动 godoc -http=:6060 -index -timestamps\ngodoc 参数 -http : 指定文档服务地址 -index: 开启查询索引 -maxresults: 设置查询结果最大显示数量，默认10000 -play: 显示play模块，在线编辑运行代码 -timestamps: 显示文档最新更新时间\nExample 表示在测试源文件中的示例函数\nExamples function 命名规则  package xxx 的命名为： func Example() func Fxx() 的命名为： func ExampleFxx() type Txx 的命名为： func ExampleTxx() func (*Txx) Fxx() 的命名为： func ExampleTxx_Fxx()  Examples function 示例 引用: go/src/encoding/json/example_test.go\nfunc ExampleMarshal() {\rtype ColorGroup struct {\rID int\rName string\rColors []string\r}\rgroup := ColorGroup{\rID: 1,\rName: \u0026quot;Reds\u0026quot;,\rColors: []string{\u0026quot;Crimson\u0026quot;, \u0026quot;Red\u0026quot;, \u0026quot;Ruby\u0026quot;, \u0026quot;Maroon\u0026quot;},\r}\rb, err := json.Marshal(group)\rif err != nil {\rfmt.Println(\u0026quot;error:\u0026quot;, err)\r}\ros.Stdout.Write(b)\r// Output:\r// {\u0026quot;ID\u0026quot;:1,\u0026quot;Name\u0026quot;:\u0026quot;Reds\u0026quot;,\u0026quot;Colors\u0026quot;:[\u0026quot;Crimson\u0026quot;,\u0026quot;Red\u0026quot;,\u0026quot;Ruby\u0026quot;,\u0026quot;Maroon\u0026quot;]}\r}\rdoc编写规范 大型package，可以新建doc.go来专门记录package注释\n注释规则  直接将常见注释//添加到声明前，且两者之间不能有空行 如果注释需要段落，则段落间添加空行注释  // Sentence 1.\r//\r// Sentence 2.\rtype StructXxx struct {\r}\r 如果注释需要代码块，则代码块使用缩进 // Xxx\r// code ....\rtype StructXxx struct {\r}   注释模块   package注释\n 版权注释和package正文注释之间需要添加空行 eg: // Copyright 2019 zylhorse@126.com Author. All rights reserved.\r// Use of this source code is governed by a BSD-style\r// license that can be found in the LICENSE file.\r// Package docc implements demo with godoc format\rpackage docc\r    Const, Var, Functions,Types注释 引用： go/src/bytes/buffer.go\n eg: // smallBufferSize is an initial allocation minimal capacity.\rconst smallBufferSize = 64\r// A Buffer is a variable-sized buffer of bytes with Read and Write methods.\r// The zero value for Buffer is an empty buffer ready to use.\rtype Buffer struct {\rbuf []byte // contents are the bytes buf[off : len(buf)]\r...\r}\r// The readOp constants describe the last action performed on\r// the buffer, so that UnreadRune and UnreadByte can check for\r// invalid usage. opReadRuneX constants are chosen such that\r// converted to int they correspond to the rune size that was read.\rtype readOp int8\r// Don't use iota for these, as the values need to correspond with the\r// names and comments, which is easier to see when being explicit.\rconst (\ropRead readOp = -1 // Any other read operation.\ropInvalid readOp = 0 // Non-read operation.\ropReadRune1 readOp = 1 // Read rune of size 1.\ropReadRune2 readOp = 2 // Read rune of size 2.\ropReadRune3 readOp = 3 // Read rune of size 3.\ropReadRune4 readOp = 4 // Read rune of size 4.\r)\r// ErrTooLarge is passed to panic if memory cannot be allocated to store data in a buffer.\rvar ErrTooLarge = errors.New(\u0026quot;bytes.Buffer: too large\u0026quot;)\r// String returns the contents of the unread portion of the buffer\r// as a string. If the Buffer is a nil pointer, it returns \u0026quot;\u0026lt;nil\u0026gt;\u0026quot;.\r//\r// To build strings more efficiently, see the strings.Builder type.\rfunc (b *Buffer) String() string {\rif b == nil {\r// Special case, useful in debugging.\rreturn \u0026quot;\u0026lt;nil\u0026gt;\u0026quot;\r}\rreturn string(b.buf[b.off:])\r}\r  BUG注释\n 规则 // BUG(whos): whos可以是更详细的人名信息 该注释会显示到godoc文档底部的BUGS目录  eg: // Title returns a copy of the string s with all Unicode letters that begin words\r// mapped to their Unicode title case.\r//\r// BUG(rsc): The rule Title uses for word boundaries does not handle Unicode punctuation properly.\rfunc Title(s string) string{\r...\r}\r  Deprecated接口\n 表示接口被弃用 GoLand等IDE在使用时会做出提示 // Deprecated: the function will deprecate after v1.0.1\r    ",
    "ref": "/blog/golang/godoc/"
  },{
    "title": "Golang swagger应用",
    "date": "",
    "description": "",
    "body": "简介 goswagger包含了Swagger 2.0的golang实现。\nswag方式 参考: README\nswagger 采用源码安装方式：\ngit clone https://github.com/go-swagger/go-swagger\rgo install ./go-swagger/cmd/swagger\r参考: SPEC\n",
    "ref": "/blog/golang/goswagger/"
  },{
    "title": "服务治理-服务注册和发现",
    "date": "",
    "description": "",
    "body": "概述 ",
    "ref": "/blog/distribution-system/%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/"
  },{
    "title": "服务治理-服务的熔断和降级",
    "date": "",
    "description": "",
    "body": "Hystrix 和 Sentinel\n",
    "ref": "/blog/distribution-system/%E7%86%94%E6%96%AD%E5%92%8C%E9%99%8D%E7%BA%A7/"
  },{
    "title": "服务治理-负载均衡",
    "date": "",
    "description": "",
    "body": " 随机 加权随机 哈希 最小压力  ",
    "ref": "/blog/distribution-system/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"
  },{
    "title": "Golang代码诊断工具-Tracing",
    "date": "",
    "description": "",
    "body": "Tracing  Tracing通过检测代码来分析一个调用链在整个生命周期中的开销。 Go提供了一个执行追踪器来追踪一个时间间隔内的运行时事件  Tracing作用  测量和分析Go P中程序的开销 精确测量某个调用在调用链中的开销 通过追踪数据来找出利用率和性能瓶颈  分布式Tracing  在单进程模式，收集诊断数据相对容易。所有的模块都在一个进程，并且通过共享公共资源来报告日志、错误和其他诊断信息 当系统扩展成分布式后，追踪一个完整的调用(从前端web服务器及其后端所有调用，直到响应返回给用户)将会非常困难 当分布式系统需要分析用户请求和RPC的性能时，就需要用到分布式Tracing Go为需要追踪的系统和后台无关的系统提供了大量的分布式Tracing库  分布式Tracing作用   测量和分析在大型系统中程序的开销\n  追踪用户请求周期中的所有RPC调用，并且发现线上服务的集成问题\n  通过追踪数据来找出系统的利用率和性能瓶颈\n  Go 没有提供自动拦截函数调用并创建追踪范围的方法，需要手动的注入代码来创建/结束/注释追踪 可以使用context.Context传递追踪标识和标签 Go可以Tracing部分内部库或运行时的底层事件，eg: httptrace.ClientTrace     httptrace net/http/httptrace包提供追踪单个HTTP请求过程中事件的机制， 事件包含：\n Connection creation Connection reuse DNS lookups Writing the request to the wire Reading the response  使用实例：\nreq, _ := http.NewRequest(\u0026quot;GET\u0026quot;, \u0026quot;http://example.com\u0026quot;, nil)\rtrace := \u0026amp;httptrace.ClientTrace{\rDNSDone: func(dnsInfo httptrace.DNSDoneInfo) {\rfmt.Printf(\u0026quot;DNS Info: %+v\\n\u0026quot;, dnsInfo)\r},\rGotConn: func(connInfo httptrace.GotConnInfo) {\rfmt.Printf(\u0026quot;Got Conn: %+v\\n\u0026quot;, connInfo)\r},\r}\rreq = req.WithContext(httptrace.WithClientTrace(req.Context(), trace))\rif _, err := http.DefaultTransport.RoundTrip(req); err != nil {\rlog.Fatal(err)\r}\r收集数据文件 Test数据生成 生成命令： $ go test -trace=trace.out pkg // pkg为可选项，当前目录或指定目录\n可视化命令：\n$ go tool trace trace.out\r\nProfile数据转换 生成命令(转换trace.out为pprof格式)：\n$ wget -O trace.out http://localhost:6060/debug/pprof/trace?seconds=5 // seconds指定采集时间段\r$ go tool trace -pprof=TYPE trace.out \u0026gt; TYPE.pprof // TYPE  支持的TYPE:\n net: network blocking profile sync: synchronization blocking profile syscall: syscall blocking profile sched: scheduler latency profile   可视化命令:\n$ go tool pprof TYPE.pprof\n可视化界面 View trace：查看跟踪\nGoroutine analysis：Goroutine 分析\nNetwork blocking profile：网络阻塞概况\nSynchronization blocking profile：同步阻塞概况\nSyscall blocking profile：系统调用阻塞概况\nScheduler latency profile：调度延迟概况\nUser defined tasks：用户自定义任务\nUser defined regions：用户自定义区域\nMinimum mutator utilization：最低 Mutator 利用率\nView trace  时间线，显示程序执行的时长 STATS   Goroutines 程序执行期间Goroutines的状态(GCWaiting/Runnable/Running) Heap 程序执行期间内存分配和释放情况(NextGC/Allocated) Threads 程序执行期间OS线程的数量及状态(InSyscall/Running)  PROCS 虚拟处理器   GC 程序执行期间GC状况 Network 程序执行期间网络请求状况 Syscalls  Procs 进程中所有虚拟处理器详情    Goroutine 协程详细信息 点击后可以看到以下详细信息 Title： Goroutine概要\nStart：开始时间\nWall Duration：持续时间\nSelf Time：执行时间\nStart Stack Trace：开始时的堆栈信息\nEnd Stack Trace：结束时的堆栈信息\nIncoming flow：输入流\nOutgoing flow：输出流\nPreceding events：之前的事件\nFollowing events：之后的事件\nAll connected：所有连接的事件 // 点击Flow Events勾选，可显示关联事件追踪。如下图：   Goroutine analysis  统计整个运行过程中，每个函数创建Goroutine个数  统计函数中每个Goroutine各个阶段的开销，来确定哪个阶段开销大      名称 含义     Goroutine Goroutine 序号   Total 总时间开销   Execution Time 执行时间   Network Wait Time 网络等待时间   Sync Block Time 同步阻塞时间   Blocking Syscall Time 调用阻塞时间   Scheduler Wait Time 调度等待时间   GC Sweeping GC 清扫   GC Pause GC 暂停    Network blocking profile 网络阻塞概要分析\nSynchronization blocking profile 同步阻塞概要分析\nSyscall blocking profile 系统调用阻塞概要分析\nScheduler latency profile 调度延时概要分析\nGC Tracing set GOGCTRACE=1\rset GODEBUG=gctrace=1\rgc 1 @0.005s 0%: 0+11+0.99 ms clock, 0+0/15/0+7.9 ms cpu, 25-\u0026gt;25-\u0026gt;24 MB, 26 MB goal, 8 P\rgc 1：说明gc过程，1 表示第几次执行gc操作\r@0.005s：表示程序执行的总时间\r0%:表示gc时时间和程序运行总时间的百分比\r0+11+0.99 ms clock：GC的时间，分为：STW时间+并发标记和扫描时间+STW标记时间\r0+0/15/0+7.9 ms cpu：垃圾回收占用CPU时间 25-\u0026gt;25-\u0026gt;24 MB：gc开始时的堆大小；GC结束时的堆大小；存活的堆大小\r26 MB goal：整体堆的大小\r8 P：使用的处理器的数量\r说明 scvg4: inuse: 143, idle: 70, sys: 213, released: 0, consumed: 213 (MB)\rinuse: 143：使用多少M内存\ridle: 70： 剩下要清除的内存\rsys: 213： 系统映射的内存\rreleased: 0： 释放的系统内存\rconsumed: 213： 申请的系统内存\r问题:\n web 白屏bug#34374 暂时解决方案: chrome.exe --enable-blink-features=ShadowDOMV0,CustomElementsV0,HTMLImports  ",
    "ref": "/blog/golang/tracing/"
  },{
    "title": "Golang代码诊断工具-Diagnostics",
    "date": "",
    "description": "",
    "body": "Diagnostics Go生态系统提供了大量的接口套件和工具来诊断Go程序的业务和性能问题\n 这些工具之间会互相干扰，因此需要单独使用工具来获取精确数据\n   Profiling: 分析Go程序的复杂性和成本，例如内存占用和函数调用，来确定Go程序的开销。\n详情参考: Golang代码诊断工具-Profiling\n  Tracing\n Tracing检测代码用于分析一个调用或用户请求在整个生命周期中的执行时间; Tracing提供每个组件影响整个系统执行时间的概览； Tracing可以跨越多个Go进程\n详情参考: Golang代码诊断工具-Tracing    Debugging Debugging允许暂停一个Go程序并检测它的执行，验证程序的状态和流程\n工具:\n Delve GDB    Runtime statistics and events\n 收集和分析运行时状态和事件提供Go程序运行状况的高级概览； 指标的变化帮助我们识别吞吐量、利用率和性能的变化。    ",
    "ref": "/blog/golang/diagnostics/"
  },{
    "title": "Golang代码诊断工具-Profiling",
    "date": "",
    "description": "",
    "body": "概述 Profiling对于识别昂贵的和经常调用的代码段非常有用。\nGo 运行时以pprof工具可以识别的格式提供概要数据，这些概要数据可以通过go test测试或引入net/http/pprof时被收集。\n概要数据内容 runtime/pprof包，以pprof visualization tool可以识别的格式生成概要数据\n数据包含以下内容：\n cpu: 报告程序在消耗CPU周期时将时间花费在何处(与睡眠和等待I/O相反) heap: 报告内存分配; 用来监视当前和历史内存使用情况，并且检查内存泄漏 threadcreate: 报告程序中哪些部分导致创建新的系统线程(OS threads) goroutine: 报告所有goroutine的堆栈跟踪 block: 报告哪些goroutine阻塞等待(包括定时器)。默认关闭该项，使用runtime.SetBlockProfileRate来启用。 mutex: 报告琐竞争。当你认为由于锁竞争导致CPU没有充分利用时，开启该项。 默认关闭该项，使用runtime.SetMutexProfileFraction来启用。  收集概要数据 Benchmarks数据 go test 内置了对Benchmarks进行Profiling的支持。\n以下示例：go test -cpuprofile cpu.prof -memprofile mem.prof -bench .\n 执行当前目录下的benchmarks并将CPU和memory概要数据写入到文件中：\n 应用程序数据   生成概要文件\n var cpuprofile = flag.String(\u0026quot;cpuprofile\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;write cpu profile to `file`\u0026quot;)\rvar memprofile = flag.String(\u0026quot;memprofile\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;write memory profile to `file`\u0026quot;)\rfunc main() {\rflag.Parse()\rif *cpuprofile != \u0026quot;\u0026quot; {\rf, err := os.Create(*cpuprofile)\rif err != nil {\rlog.Fatal(\u0026quot;could not create CPU profile: \u0026quot;, err)\r}\rdefer f.Close() // error handling omitted for example\rif err := pprof.StartCPUProfile(f); err != nil {\rlog.Fatal(\u0026quot;could not start CPU profile: \u0026quot;, err)\r}\rdefer pprof.StopCPUProfile()\r}\r// ... rest of the program ...\rif *memprofile != \u0026quot;\u0026quot; {\rf, err := os.Create(*memprofile)\rif err != nil {\rlog.Fatal(\u0026quot;could not create memory profile: \u0026quot;, err)\r}\rdefer f.Close() // error handling omitted for example\rruntime.GC() // get up-to-date statistics\rif err := pprof.WriteHeapProfile(f); err != nil {\rlog.Fatal(\u0026quot;could not write memory profile: \u0026quot;, err)\r}\r}\r}\r  启动web服务\n  net/http/pprof包通过启动HTTP server提供Profiling服务支持;\n  导入该包通常会引起HTTP handlers的副作用， pprof的路由地址以/debug/pprof/开始\n  代码注入：\nimport _ \u0026quot;net/http/pprof\u0026quot;\r// 如果应用程序没有启动http server，就需要在func main 中启动一个\rgo func() {\rlog.Println(http.ListenAndServe(\u0026quot;localhost:6060\u0026quot;, nil))\r}()\r    概要数据可视化 pprof工具 Go pprof 是Google\u0026rsquo;s pprof C++ profiler 的变体\n交互式控制台 命令格式：\ngo tool pprof \u0026lt;可执行文件\u0026gt; \u0026lt;概要数据文件\u0026gt;\n(pprof) 参数：\n top5 top10 top5 -cum // 根据cum排序 web // web可视化 web funxx // 只显示包含特定函数的示例 list funxx // 输出匹配regexp函数的源代码及性能参数  字段说明： Flat: 表示函数自身CPU消耗时长 Flat%: 表示函数自身CPU消耗占总CPU百分比 Sum%: 表示当前函数及其上级调用函数消耗占总CPU百分比 Cum: 表示函数自身及其内部函数调用CPU消耗时长 Cum%: 表示函数自身及其内部函数调用CPU消耗占总CPU百分比\nweb可视化 命令格式：\n ALL: 浏览器打开地址：http://localhost:6060/debug/pprof/ cpu: $ go tool pprof -http=localhost:5999 http://localhost:6060/debug/pprof/profile?seconds=30 // seconds指定采集时间段 heap: $ go tool pprof -http=localhost:5999 http://localhost:6060/debug/pprof/heap block: $ go tool pprof -http=localhost:5999 http://localhost:6060/debug/pprof/block mutex: $ go tool pprof -http=localhost:5999 http://localhost:6060/debug/pprof/mutex trace: 参考Profile数据转换  其他工具:  linux\nperf tools是一个基于Linux2.6+系统的分析工具，提供一个简单的命令行接口 macOS\nInstruments是一个强大和灵活的性能分析和测试工具， 是Xcode工具集的一部分  线上服务 线上Profiling是安全的， 但是会增加额外的开销(e.g. CPU)，应该能看到服务性能降级。\n 性能损耗可以在服务上线前测量完进行评估。\n 如果需要对线上服务周期性的进行Profiling，可以对线上服务每Y秒进行X秒的Profiling，将结果保存以供可视化分析。\n 多项概要数据文件的收集会产生干扰，建议一次只进行一项收集\n 内存概要分析 Alloc uint64 //golang语言框架堆空间分配的字节数\rTotalAlloc uint64 //从服务开始运行至今分配器为分配的堆空间总 和，只有增加，释放的时候不减少\rSys uint64 //服务现在系统使用的内存\rLookups uint64 //被runtime监视的指针数\rMallocs uint64 //服务malloc heap objects的次数\rFrees uint64 //服务回收的heap objects的次数\rHeapAlloc uint64 //服务分配的堆内存字节数\rHeapSys uint64 //系统分配的作为运行栈的内存\rHeapIdle uint64 //申请但是未分配的堆内存或者回收了的堆内存（空闲）字节数\rHeapInuse uint64 //正在使用的堆内存字节数\rHeapReleased uint64 //返回给OS的堆内存，类似C/C++中的free。\rHeapObjects uint64 //堆内存块申请的量\rStackInuse uint64 //正在使用的栈字节数\rStackSys uint64 //系统分配的作为运行栈的内存\rMSpanInuse uint64 //用于测试用的结构体使用的字节数\rMSpanSys uint64 //系统为测试用的结构体分配的字节数\rMCacheInuse uint64 //mcache结构体申请的字节数(不会被视为垃圾回收)\rMCacheSys uint64 //操作系统申请的堆空间用于mcache的字节数\rBuckHashSys uint64 //用于剖析桶散列表的堆空间\rGCSys uint64 //垃圾回收标记元信息使用的内存\rOtherSys uint64 //golang系统架构占用的额外空间\rNextGC uint64 //垃圾回收器检视的内存大小\rLastGC uint64 // 垃圾回收器最后一次执行时间。\rPauseTotalNs uint64 // 垃圾回收或者其他信息收集导致服务暂停的次数。\rPauseNs [256]uint64 //一个循环队列，记录最近垃圾回收系统中断的时间\rPauseEnd [256]uint64 //一个循环队列，记录最近垃圾回收系统中断的时间开始点。\rNumForcedGC uint32 //服务调用runtime.GC()强制使用垃圾回收的次数。\rGCCPUFraction float64 //垃圾回收占用服务CPU工作的时间总和。如果有100个goroutine，垃圾回收的时间为1S,那么就占用了100S。\rBySize //内存分配器使用情况\r",
    "ref": "/blog/golang/profiling/"
  },{
    "title": "分布式事务",
    "date": "",
    "description": "",
    "body": "概述  分布式事务： 分布式事务涉及到多组操作， 将一个事务的概念扩大到多个分布式操作上 分布式事务的参与者，资源服务器，事务管理器分别位于分布式系统的不同节点上  分布式事务产生原因  service 产生多个节点 resource 产生多个节点  ",
    "ref": "/blog/distribution-system/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/"
  },{
    "title": "分布式锁",
    "date": "",
    "description": "",
    "body": "分布式锁 应用场景  多节点并发的对数据进行操作； 多节点并发的执行同一个任务， 请求同一接口；  分布式锁条件  在分布式系统环境下， 一个资源同时只能被一个线程执行； 高可用的获取锁和释放锁 高性能的获取锁和释放锁 具备可重入性， 同一线程可以并发使用； 具备锁失效机制，不会死锁 非阻塞特性， 即获取锁失败需要返回失败；  分布式锁实现  redis分布式锁 mutext.go:  package redsync\r// lock\rfunc (m *Mutex) Lock() error {\r// generate mutex identifier, used for unlock and extend\rvalue, err := m.genValueFunc()\rif err != nil {\rreturn err\r}\r// acquire the lock and try some times when failed.\rfor i := 0; i \u0026lt; m.tries; i++ {\rif i != 0 {\r// next try will wait randnom duration.\rtime.Sleep(m.delayFunc(i))\r}\rstart := time.Now()\r// acquire lock on multi redis nodes.\rn, err := m.actOnPoolsAsync(func(pool Pool) (bool, error) {\rreturn m.acquire(pool, value)\r})\rif n == 0 \u0026amp;\u0026amp; err != nil {\rreturn err\r}\r// acquire the lock when the number of success nodes \u0026gt; quonum.\rnow := time.Now()\runtil := now.Add(m.expiry - now.Sub(start) - time.Duration(int64(float64(m.expiry)*m.factor)))\rif n \u0026gt;= m.quorum \u0026amp;\u0026amp; now.Before(until) {\rm.value = value\rm.until = until\rreturn nil\r}\r// release the lock when failed.\rm.actOnPoolsAsync(func(pool Pool) (bool, error) {\rreturn m.release(pool, value)\r})\r}\rreturn ErrFailed\r}\r// acquire\rfunc (m *Mutex) acquire(pool Pool, value string) (bool, error) {\rconn := pool.Get()\rdefer conn.Close()\r// set mutex with value and expire to redis.\rreply, err := redis.String(conn.Do(\u0026quot;SET\u0026quot;, m.name, value, \u0026quot;NX\u0026quot;, \u0026quot;PX\u0026quot;, int(m.expiry/time.Millisecond)))\rif err != nil {\rif err == redis.ErrNil {\rreturn false, nil\r}\rreturn false, err\r}\rreturn reply == \u0026quot;OK\u0026quot;, nil\r}\r// unlock\rfunc (m *Mutex) Unlock() (bool, error) {\rn, err := m.actOnPoolsAsync(func(pool Pool) (bool, error) {\rreturn m.release(pool, m.value)\r})\rif n \u0026lt; m.quorum {\rreturn false, err\r}\rreturn true, nil\r}\r// delete the mutex with the specify value.\rvar deleteScript = redis.NewScript(1, `\rif redis.call(\u0026quot;GET\u0026quot;, KEYS[1]) == ARGV[1] then\rreturn redis.call(\u0026quot;DEL\u0026quot;, KEYS[1])\relse\rreturn 0\rend\r`)\rfunc (m *Mutex) release(pool Pool, value string) (bool, error) {\rconn := pool.Get()\rdefer conn.Close()\rstatus, err := redis.Int64(deleteScript.Do(conn, m.name, value))\rreturn err == nil \u0026amp;\u0026amp; status != 0, err\r}\r// extend\rfunc (m *Mutex) Extend() (bool, error) {\rn, err := m.actOnPoolsAsync(func(pool Pool) (bool, error) {\rreturn m.touch(pool, m.value, int(m.expiry/time.Millisecond))\r})\rif n \u0026lt; m.quorum {\rreturn false, err\r}\rreturn true, nil\r}\r// reset the expire of mutex\rvar touchScript = redis.NewScript(1, `\rif redis.call(\u0026quot;GET\u0026quot;, KEYS[1]) == ARGV[1] then\rreturn redis.call(\u0026quot;pexpire\u0026quot;, KEYS[1], ARGV[2])\relse\rreturn 0\rend\r`)\rfunc (m *Mutex) touch(pool Pool, value string, expiry int) (bool, error) {\rconn := pool.Get()\rdefer conn.Close()\rstatus, err := redis.Int64(touchScript.Do(conn, m.name, value, expiry))\rreturn err == nil \u0026amp;\u0026amp; status != 0, err\r}\r etcd分布式锁  import (\r\u0026quot;context\u0026quot;\rclientv3 \u0026quot;go.etcd.io/etcd/client/v3\u0026quot;\r\u0026quot;go.etcd.io/etcd/client/v3/concurrency\u0026quot;\r\u0026quot;sync\u0026quot;\r\u0026quot;time\u0026quot;\r)\r// new etcd client\rfunc Client() *clientv3.Client {\rcliV3, err := clientv3.New(clientv3.Config{\rEndpoints: []string{\u0026quot;192.168.20.92:2379\u0026quot;},\rDialTimeout: time.Second * 5,\rUsername: \u0026quot;root\u0026quot;,\rPassword: \u0026quot;zylhorse@126.com\u0026quot;,\r})\rif err != nil {\rpanic(err)\r}\rreturn cliV3\r}\r// new client session\rfunc Sessoin(cliV3 *clientv3.Client) *concurrency.Session {\rlease, err := cliV3.Grant(context.Background(), 10)\rif err != nil {\rpanic(err)\r}\rsess, err := concurrency.NewSession(cliV3, concurrency.WithLease(lease.ID))\rif err != nil {\rpanic(err)\r}\rreturn sess\r}\r// new etcd locker\rfunc Locker(sess *concurrency.Session, prefix string) sync.Locker {\rreturn concurrency.NewLocker(sess, prefix)\r}\r// close etcd client and destroy the session and locker.\rfunc Close(cli *clientv3.Client) {\rif cli == nil {\rreturn\r}\rcli.Close()\r}\r",
    "ref": "/blog/distribution-system/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/"
  },{
    "title": "Golang进程管理工具",
    "date": "",
    "description": "",
    "body": "简介 Go 生态系统提供了一套API和工具来检测程序的逻辑和性能问题。本章总结了可用的工具，并帮助用户在遇到问题时，选择正确的工具。\ngops gops: Golang进程管理工具，支持远程调用\n 安装：go get -u github.com/google/gops 项目启动代理： package main\rimport (\r\u0026quot;log\u0026quot;\r\u0026quot;time\u0026quot;\r\u0026quot;github.com/google/gops/agent\u0026quot;\r)\rfunc main() {\rif err := agent.Listen(agent.Options{}); err != nil {\rlog.Fatal(err)\r}\rtime.Sleep(time.Hour)\r}\r agent.Options{} type Options struct {\r// gops agent 监听地址\r// 格式： host:port\rAddr string\r// 配置文件保存目录\r// 保存内容： gops pid，filename， port，content\rConfigDir string\r// 设置是否自动清理资源\r// true: 进程接收到终端信号后，会自动清理\r// false：进程关闭前用户需要调用 Close\rShutdownCleanup bool\r}\r   命令行使用：  打印所有Go进程： $ gops\rpid ppid 进程名 go 版本 关联进程的位置\r983 980 docc * go1.11 ~/code/godev/docc\r52697 52695 gops go1.10 /Users/jbd/bin/gops\r 如果进程运行了agent则进程名后会标记*\n  打印进程更多信息 $ gops \u0026lt;pid\u0026gt;\rparent PID:\t5985\rthreads:\t27\rmemory usage:\t0.199%\rcpu usage:\t0.139%\rusername:\tjbd\rcmd+args:\t/Applications/Splice.app/Contents/Resources/Splice Helper.app/Contents/MacOS/Splice Helper -pid 5985\rlocal/remote:\t127.0.0.1:56765 \u0026lt;-\u0026gt; :0 (LISTEN)\rlocal/remote:\t127.0.0.1:56765 \u0026lt;-\u0026gt; 127.0.0.1:50955 (ESTABLISHED)\rlocal/remote:\t100.76.175.164:52353 \u0026lt;-\u0026gt; 54.241.191.232:443 (ESTABLISHED)\r 获取进程树 $ gops tree\r...\r├── 1\r│ └── 13962 [gocode] {go1.9}\r├── 557\r│ └── 635 [com.docker.supervisor] {go1.9.2}\r│ └── 638 [com.docker.driver.amd64-linux] {go1.9.2}\r└── 13744\r└── 67243 [gops] {go1.10}\r 获取进程堆栈 $ gops stack (\u0026lt;pid\u0026gt;|\u0026lt;addr\u0026gt;)\rgops stack 85709\rgoroutine 8 [running]:\rruntime/pprof.writeGoroutineStacks(0x13c7bc0, 0xc42000e008, 0xc420ec8520, 0xc420ec8520)\r/Users/jbd/go/src/runtime/pprof/pprof.go:603 +0x79\rruntime/pprof.writeGoroutine(0x13c7bc0, 0xc42000e008, 0x2, 0xc428f1c048, 0xc420ec8608)\r/Users/jbd/go/src/runtime/pprof/pprof.go:592 +0x44\rruntime/pprof.(*Profile).WriteTo(0x13eeda0, 0x13c7bc0, 0xc42000e008, 0x2, 0xc42000e008, 0x0)\r/Users/jbd/go/src/runtime/pprof/pprof.go:302 +0x3b5\rgithub.com/google/gops/agent.handle(0x13cd560, 0xc42000e008, 0xc420206000, 0x1, 0x1, 0x0, 0x0)\r/Users/jbd/src/github.com/google/gops/agent/agent.go:150 +0x1b3\rgithub.com/google/gops/agent.listen()\r/Users/jbd/src/github.com/google/gops/agent/agent.go:113 +0x2b2\rcreated by github.com/google/gops/agent.Listen\r/Users/jbd/src/github.com/google/gops/agent/agent.go:94 +0x480\r# ...\r 获取进程当前内存\n$ gops memstats \u0026lt;pid\u0026gt; | \u0026lt;addr\u0026gt; GC 当前进程\n$ gops gc (\u0026lt;pid\u0026gt;|\u0026lt;addr\u0026gt;) 设置当前进程gc百分比\n$ gops setgc (\u0026lt;pid\u0026gt;|\u0026lt;addr\u0026gt;) 10 打印构建目标程序的go版本\n$ gops version (\u0026lt;pid\u0026gt;|\u0026lt;addr\u0026gt;) 打印运行时统计信息\n$ gops stats (\u0026lt;pid\u0026gt;|\u0026lt;addr\u0026gt;)    gops pprof  gops pprof-cpu (\u0026lt;pid\u0026gt;|\u0026lt;addr\u0026gt;) gops pprof-heap (\u0026lt;pid\u0026gt;|\u0026lt;addr\u0026gt;)  gops trace gops trace (\u0026lt;pid\u0026gt;|\u0026lt;addr\u0026gt;)\n",
    "ref": "/blog/golang/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"
  },{
    "title": "分布式一致性",
    "date": "",
    "description": "",
    "body": "一致性算法 算法目的是让整个集群的结点对某个值的变更达成一致\n Paxos 算法目的是让整个集群的结点对某个值的变更达成一致。Paxos 算法(强一致性算法)属于多数派——大多数的决定会成个整个集群的统一决定。任何一个点都可以提出要修改某个数据的提案，是否通过这个提案取决于这个集群中是否有超过半数的结点同意（所以 Paxos 算法需要集群中的结点是单数）；  这个算法有两个大阶段，四个小阶段（Paxos 有 Proposer 和 Acceptor 两个角色）\rPrepare proposer 提出一个提案，编号为 N ，此 N 大于这个 proposer 之前提出提案编号。请求 acceptors 的 quorum 接受。\rPromise 如果 N 大于此 acceptor 之前接受的任何提案编号则接受，否则拒绝\rAccept 如果达到了多数派， Proposer 会发出 accept 请求，此请求包含提案编号 N，以及提案内容\rAccepted 如果此 acceptor 在此期间没有收到任何编号大于 N 的提案，则接受此提案内容，否则忽略\rRaft 是简化版的 Paxos。Raft 划分成三个子问题：一是Leader Election；二是 Log Replication；三是 Safety。Raft 定义了三种角色 Leader、Follower、Candidate，最开始大家都是 Follower，当 Follower 监听不到 Leader，就可以自己成为 Candidate，发起投票。  ",
    "ref": "/blog/distribution-system/%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7/"
  },{
    "title": "Golang单元测试",
    "date": "",
    "description": "",
    "body": "简介  Package testing为Go packages提供自动化测试支持。 使用 go test 命令来启动测试 编写新的测试套件，需要创建以_test.go结尾的新文件  admin.go的测试文件，需要在当前目录新建测试文件admin_test.go   测试方法func TestXxx(*testing.T)  测试方法需要以Test开头 Xxx方法必须以大写字母开头 方法参数必须是：t *testing.T    关键词 tests: 常规测试\nbeanchmarks: 基准测试\nexamples : 样例测试\nsub: 子模式\nBenchmarks(基准测试) func BenchmarkXxx(b *testing.B)\n benchmarks方法需要以Benchmark开头 benchmarks方法，在go test命令添加-bench时才执行 benchmarks中，需要目标代码被执行b.N次 func BenchmarkXxx(b *testing.B) {\rfor i := 0; i \u0026lt; b.N; i++ {\rXxx()\r}\r}\r benchmarks在执行过程中会调整b.N，直到benchmarks函数持续足够长的时间，可以可靠的计时为止 执行结果： BenchmarkXxx 68453040\t17.8 ns/op  单次执行目标代码耗时17.8ns,目标代码执行68453040次   benchmarks目标代码执行前，如果有比较耗时的准备操作，benchmarks的时间可以重置 func BenchmarkXxx(b *testing.B) {\rPrepareLongTime()\rb.ResetTimer()\rfor i := 0; i \u0026lt; b.N; i++ {\rXxx()\r}\r}\r  Parallel(并行测试) 如果benchmarks需要并行的测试性能，可以使用RunParallel。\n一般需要给go test指定参数-cpu 1,2,4\nfunc BenchmarkXxxParallel(b *testing.B) {\rb.RunParallel(func(pb *testing.PB) {\rfor pb.Next() {\rXxx()\r}\r})\r}\rExamples(样例测试) examples运行测试时，会比较测试代码输出的结果和Output:模块声明的结果\n Output: 比较时会忽略头尾空格 Unordered output: 比较时忽略结果顺序 当没有 Output: 模块时，go test 不会执行examples  Skipping 跳过测试代码不去执行\neg:\rfunc TestTimeConsuming(t *testing.T) {\rif testing.Short() {\rt.Skip(\u0026quot;skipping test in short mode.\u0026quot;)\r}\r...\r}\rSubtests and Sub-benchmarks go test 支持子模式，避免创建多个TestFuncXxx\neg: func TestFoo(t *testing.T) {\r// \u0026lt;setup code\u0026gt;\rt.Run(\u0026quot;A=1\u0026quot;, func(t *testing.T) { ... })\rt.Run(\u0026quot;A=2\u0026quot;, func(t *testing.T) { ... })\rt.Run(\u0026quot;B=1\u0026quot;, func(t *testing.T) { ... })\r// \u0026lt;tear-down code\u0026gt;\r}\rgo test -run '' # Run all tests.\rgo test -run Foo # Run top-level tests matching \u0026quot;Foo\u0026quot;, such as \u0026quot;TestFooBar\u0026quot;.\rgo test -run Foo/A= # For top-level tests matching \u0026quot;Foo\u0026quot;, run subtests matching \u0026quot;A=\u0026quot;.\rgo test -run /A=1 # For all top-level tests, run subtests matching \u0026quot;A=1\u0026quot;.\r Parallel(并行测试)也支持子模式\n Main 有些时候需要在测试执行前做一些准备工作,测试完成做一些资源回收工作，这时就用到函数：\nfunc TestMain(m *testing.M) {\r// call flag.Parse() here if TestMain uses flags\rflag.Parse()\r// prepare for testing\rsetup()\r// finish testing operation\rdefer teardown()\ros.Exit(m.Run())\r}\r TestMain在main goroutine中执行 m.Run() 会执行所有的tests等，并返回exit code flag.Parse()在TestMain后执行，如果需要命令行参数，在TestMain中需要显示的调用flag.Parse()  go test 参数详解  -bench regexp 执行符合正则表达式的benchmarks  -bench . 执行所有的benchmarks -bench reg1/reg2/reg3 正则表达式由/分割   -benchmem 打印benchmarks内存分配统计信息 -benchtime t 设置benchmarks运行足够的次数  -benchtime 2s 默认为1s -benchtime 1000x 指定执行benchmarks次数   -count n 指定tests和benchmarks执行次数  如果指定-cpu, 则每个GOMAXPROCS都要执行n次 examples 总是执行1次   -cpu 1,2,4 指定tests和benchmarks在哪些GOMAXPROCS上并行执行  默认时当前GOMAXPROCS   -list regexp 列出所有符合正则表达式的 tests,benchmarks,examples  只列出符合条件的，不执行   -run regexp 执行符合正则表达式的tests  -run . 执行所有的tests -run reg1/reg2/reg3 正则表达式由/分割   -v 打印所有测试日志 -c 生成可执行二进制测试文件，但不运行测试 -i 安装测试依赖的package,但不运行测试 -short 设置是否缩短运行时长的tests  使用testing.Short()接收该参数   -cpuprofile 生成CPU profile文件  -cpuprofile=cpu.out 同时生成二进制测试文件   -memprofile 生成MEM profile文件  -memprofile=mem.out 同时生成二进制测试文件   -blockprofile 生成 BLOCK profile文件  -blockprofile=block.out 同时生成二进制测试文件   -mutexprofile 生成MUTEX profile文件  -mutexprofile=mutex.out 同时生成二进制测试文件   -trace 生成执行trace文件   测试生成的二进制文件和profile文件，使用命令go tool pprof app.test cpu.prof 分析\n go 辅助函数  T.Helper(): 标记当前函数为helper函数，当打印文件和行信息时跳过当前函数。  T.Helper()是协程安全的， 可以在多个goroutine中调用\n  T.SkipNow(): 标记跳过当前测试函数，并调用runtime.Goexit终止当前测试函数 T.CleanUp(f func()): 注册回调清理函数，该函数将在测试流程结束时执行。 T.ResetTimer(): 将运行基准时间和内存计数器置零。  testing.ResetTimer() 不影响定时器的运行。\n   问题  缓存: golang 单元测试，有缓存机制，导致前后测试结果一致, 需要手动清理；  go clean -testcache\r  Reference golang.org/pkg/testing\n",
    "ref": "/blog/golang/testing/"
  },{
    "title": "分布式系统",
    "date": "",
    "description": "分布式系统的概念、特性",
    "body": "概念  建立在网络上的软件系统 若干独立系统的集合  特性  分布性： 分布式系统由多个节点组成， 地域上分散； 自治性： 分布式系统的每个节点都包含自己的处理器和内存， 具备独立处理数据能力； 并行性： 一个完整的任务可以划分成若干子任务， 运行在分布式系统的多个节点上； 全局性： 分布式系统中的节点可以互相通信及系统间的相互调用；  CAP   一致性（consistency）： 分布式系统中的所有数据备份，在同一时刻是否是同样的值（分为弱、强、最终一致性）\n  可用性（availability）： 在集群中某一个节点故障后， 集群整体是否还能响应客户端的读写请求（数据高可用性）\n  分区容忍性（partition tolerance）： 提供如果在时限内不能达成数据一致性， 必须就当前操作在一致性和可用性之间做出选择；\n  任何一个分布式系统都无法同时满足一致性（consistency)、可用性（availability）和分区容忍性（partition tolerance）；\n  大多数场景都需要牺牲强一致性来换取系统的高可用性， 往往只需要保证最终一致性；\n  BASE策略  Basically Available（基本可用）：在分布式系统出现不可预知的故障时， 允许损失部分可用性； Soft state（软状态）： 允许系统中数据存在中间状态，并认为该中间状态存在不会影响系统的整体可用性；指的是数据不一致； Eventually consistent（最终一致性）： 系统中所有的数据副本，在一定的时限内，最终能够达到一个一致的状态；  ",
    "ref": "/blog/distribution-system/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"
  },{
    "title": "Golang源码阅读-defer",
    "date": "",
    "description": "",
    "body": "defer 逻辑  defer代码块会在函数调用链表中增加一个函数调用，该函数调用是在return之后； defer的执行顺序是先进后出； defer表达式中变量的值在defer表达式被定义时就已经明确； defer可以获取有名返回值； goroutine 控制结构中，有张表记录所有defer；  defer 作用 defer表达式通常用来清理和释放资源\ndefer 性能  defer 性能在1.13版本之前不高 defer 会涉及到内存、缓存、多次调用，所以有一定性能问题； 使用注意： 除了需要异常捕获，必须使用defer；其他资源回收，可以在判断失败后，使用goto跳转到资源回收的代码； 对于竞争资源，在使用完成后立刻进行释放，这样才可以最优的使用竞争资源。 1.14后性能优化增加开放编码（Open-coded）defer类型,是普通函数调用的log10； 减少defer链表长度(测试: 不要超出8个， 超出8个后性能骤降)。这种场景可以拆分增加函数调用来解决。  defer原理 每一个defer在编译的时候就会转换成deferproc，编译器会在函数return之前插入deferreturn。\n 调用deferproc，这里会进行参数拷贝； 执行deferreturn，这里会提取信息；  defer goroutine defer 会被添加到G _defer链表的首部，所以defer是一个后进先出的链表； G 退出时会遍历G上的defer 链表。\ndefer 源码 type _defer struct {\rsiz int32 //参数大小\rstarted bool // defer是否被调用过的标识\rsp uintptr // sp at time of defer\rpc uintptr\rfn *funcval // defer 后面跟的function\r_panic *_panic // panic that is running defer\rlink *_defer // 链表结构\r}\r",
    "ref": "/blog/golang/defer/"
  },{
    "title": "Windows Subsystem for Linux",
    "date": "",
    "description": "",
    "body": "概述 WSL： Windows Subsystem for Linux\n目的  terminal 界面定制 支持ubuntu terminal  WSL安装 reference\n 启用Linux的windows子系统 功能  仅安装WSL1 dism.exe /online /enable-feature /featurename:Microsoft-Windows-Subsystem-Linux /all /norestart\r 重启电脑 windows store 下载安装 linux 发行版   windows terminal 安装  windows store 下载安装 windows terminal    ",
    "ref": "/blog/windows/wsl/"
  },{
    "title": "Golang源码阅读-select",
    "date": "",
    "description": "",
    "body": "描述 select就是用来监听和channel有关的IO操作，当 IO 操作发生时，触发相应的动作。\n执行步骤  构建select对象：  type hselect struct {\rtcase unit16 // total count of scase[]\rncase unit16 // currently field scase[]\rpollorder *unit16 // case poll order\rlockorder *uint16 // channel lock order\rscase [1]scase //one per scase }\r注册case  所有channel表达式都会被求值、所有被发送的表达式都会被求值。求值顺序：自上而下、从左到右.\r1. 注册写chan case\r2. 注册读chan case\r3. 注册default case\r执行select  1. 对case洗牌，排序 获取locking order\r2. 对lockorder里的元素进行枷锁\r3. 顺序遍历case，等待某个case 被解锁唤醒\r4. 将未唤醒的case 踢出队列\r5. 对lockorder里的元素进行解锁\r释放select  \r问题  select default 谨慎操作； default 阻塞导致select 不退出； 当chan被触发时，select随机挑选执行；  ",
    "ref": "/blog/golang/select/"
  },{
    "title": "Jenkins部署配置",
    "date": "",
    "description": "",
    "body": "docker安装  docker-compose.yml  version: '2'\rservices:\rjenkins:\rimage: jenkins/jenkins:lts\rports:\r- 8080:8080\r- 50000:50000\rvolumes:\r- /opt/jenkins:/var/jenkins_home\rrestart: always\rsudo docker-compose up -d  ",
    "ref": "/blog/jenkins/jenkins%E5%AE%89%E8%A3%85/"
  },{
    "title": "Golang源码阅读-chan",
    "date": "",
    "description": "",
    "body": "描述 channel 是golang实现CSP理念的重点。channel实现一个进程内不同协程之间的通信方式。\n结构体 channel 实际上是一个环形队列，实际的队列空间就是在这个channel结构体之后申请的空间。\ntype hchan struct {\rqcount uint // 缓冲队列中的元素计数器\rdataqsiz uint // 缓冲队列，=make(chan T, x)中的x\rbuf unsafe.Pointer // 缓冲队列，数组类型\relemsize uint16 // 元素大小，单位为字节\rclosed uint32 // chan关闭标记\relemtype *_type // 元素类型\rsendx uint // 待发送元素在缓冲器中的索引\rrecvx uint // 待接收元素在缓冲器中的索引\rrecvq waitq // 阻塞等待读channel的G队列\rsendq waitq // 阻塞等待写channel的G队列\rlock mutex // 互斥锁\r}\r elem 大小不能超过65536个字节，超过会抛异常  特性  当chan缓冲中还有数据时，关闭chan后，接受者不会立刻接收到chan的关闭信号， 而是等缓冲中所有的数据被全部读取后接受者才会收到chan的关闭信号； 没有被初始化的chan在调用发送或者接收的时候会被阻塞 当chan被close之后不能被写入，但是可以被读取； chan不能被重复close，chan可以不被close；可以被系统自动回收；  make chan  新建channel时调用func makechan(t *chantype, size int) *hchan函数\n 函数接收两个参数， 一个是channel里面保存元素的类型， 一个是缓冲的容量（为0则表示非缓冲buffer），创建流程如下：\n 根据传递传冲大小size是否为0， 分别创建不带buffer的channel或者带size大小buffer的channel  对于不带缓冲channel， 申请hchan数据结构大小的内存 对于带缓冲channel， new 一个hchan对象， 并初始化size大小的buffer   初始化dataqsiz: 缓冲区大小 初始化elemsize: 元素值大小；不能超过65536； 初始化elemtype: 元素类型  \u0026lt;- chan  接收channel时调用chanrecv(c *hchan, ep unsafe.Pointer, block bool) (selected, received bool)函数；\n 该函数表示从channel中接收数据，并将接收到的数据写入到ep指向的对象中。接收流程如下：\n case1  前置channel为nil的场景  如果block 为非阻塞(false)，直接return 如果block 为阻塞(true)， 调用gopark()阻塞当前goroutine，并抛出异常     case2  block为非阻塞且(channel为非缓冲队列且sendq等待队列为空 或 channel为缓冲队列但是没有数据)且channel未关闭 直接return   lock(\u0026amp;c.lock) 锁住channel case3  channel 被关闭且channel缓冲中没有数据， 直接return   case4  sendq(sender 等待队列)非空，调用func recv(c *hchan, sg *sudog, ep unsafe.Pointer, unlockf func(), skip int)函数：  如果是非缓冲channel，直接调用recvDirect函数直接从sendq中recv数据到ep中， 这样只复制一次； 如果是有缓冲channel：  将缓冲队列读指针(recvx)指向的数据复制到ep中 将缓冲队列读指针(recvx)后移一位(循环后移，大于缓冲队列大小则从0开始) 将缓冲队列写指针(sendx)指向当前缓冲队列被读元素位置(recvx), 用于sendq将队头元素数据复制到channel的缓冲队列，这样缓冲队列就不用移动数据了   释放channel锁 调用goready()函数将发送消息的goroutine设置为就绪状态，等待调度   直接return   case5  sendq为空且缓冲队列不为空  将缓冲队列读指针(recvx)指向的数据复制到ep中 将缓冲队列读指针(recvx)后移一位(循环后移，大于缓冲队列大小则从0开始) 将缓冲队列的元素计数器减一(qcount\u0026ndash;) 释放channel锁 直接return     case6  sendq为空且缓冲队列为空且不阻塞协程 释放channel锁 直接return   case7  sendq为空且缓冲队列为空  将goroutine 加入recvq，并阻塞，      chan \u0026lt;-  发送channel时调用func chansend(c *hchan, ep unsafe.Pointer, block bool, callerpc uintptr) bool函数\n 该函数表示将ep中的数据写入到channel， 主要流程如下：\n case1  前置channel为nil情景  如果block为非阻塞(false), 直接return 如果block为阻塞(true),调用gopark()函数阻塞当前goroutine，并抛出异常     case2  blcok非阻塞且channel未close且(非缓冲channel且recvq等待队列为空 或 缓冲channel且缓冲队列已满)， 则直接return   lock(\u0026amp;c.lock) 锁住channel case3  channel 已经close  释放channel锁 抛异常(\u0026ldquo;send on closed channel\u0026rdquo;)     case4  recvq(receiver 等待队列)非空，调用func send(c *hchan, sg *sudog, ep unsafe.Pointer, unlockf func(), skip int)函数：  直接调用sendDirect函数将ep中数据复制到recvq上， 这样只复制一次 释放channel锁 调用goready()函数将接收消息的goroutine设置为就绪状态，等待调度   直接return   case5  如果缓冲队列未满  将ep中的数据拷贝到缓冲队列写指针(sendx)指向的位置 将缓冲队列写指针(sendx)后移一位(循环后移，大于缓冲队列大小则从0开始) 将缓冲队列的元素计数器加一(qcount++) 释放channel锁 直接return     case6  缓冲队列已满且recvq为空且不阻塞协程 释放channel锁 直接return   case7  缓冲队列已满且recvq为空  将goroutine 加入sendq，并阻塞，      close(chan)  关闭channel时调用func closechan(c *hchan)函数\n 该函数表示关闭channel， 主要流程如下：\n 如果channel为nil，则抛出异常(\u0026ldquo;close of nil channel\u0026rdquo;) lock(\u0026amp;c.lock) 锁住channel 如果channel已经关闭， 则抛出异常(\u0026ldquo;close of nil channel\u0026rdquo;) c.closed = 1 设置channel已关闭 获取所有读goroutine， 并push到释放链表 获取所有写goroutine， 并push到释放链表 unlock(\u0026amp;c.lock) 释放channel 锁 调用goready()函数，将释放链表中的所有goroutine设置为就绪状态， 等待调度  ",
    "ref": "/blog/golang/chan/"
  },{
    "title": "Oracle数据库安装配置",
    "date": "",
    "description": "",
    "body": "docker安装 sudo docker pull deepdiver/docker-oracle-xe-11g\rsudo docker run -d -p 1522:22 -p 1521:1521 --name oracle deepdiver/docker-oracle-xe-11g\rclient https://www.oracle.com/database/technologies/instant-client/linux-x86-64-downloads.html\n basic sdk sqlplus  链接动态库 #!/bin/bash\rln /opt/instantclient_11_2/libclntsh.so.11.1 /usr/lib/libclntsh.so\rln /optinstantclient_11_2/libnnz11.so /usr/lib/libnnz11.so\rln /opt/instantclient_11_2/libocci.so.11.1 /usr/lib/libocci.so\rln /opt/instantclient_11_2/libociei.so /usr/lib/libociei.so\rln /opt/instantclient_11_2/libocijdbc11.so /usr/lib/libocijdbc11.so\rln /opt/instantclient_11_2/libsqlplusic.so /usr/lib/libsqlplusic.so\rln /opt/instantclient_11_2/libsqlplus.so /usr/lib/libsqlplus.so\r添加动态库到系统 echo /opt/instantclient_11_2 \u0026gt;\u0026gt; /etc/ld.so.conf\rldconfig\r安装 oracle client 下载地址： https://www.oracle.com/database/technologies/112010-win64soft.html\n错误提示  不满足安装条件, oracle 没有配置当前系统的支持   修改stage/cvu/cvu_prereq.xml添加\n  \u0026lt;OPERATING_SYSTEM RELEASE=\u0026quot;6.2\u0026quot;\u0026gt;\r\u0026lt;VERSION VALUE=\u0026quot;3\u0026quot;/\u0026gt;\r\u0026lt;ARCHITECTURE VALUE=\u0026quot;64-bit\u0026quot;/\u0026gt;\r\u0026lt;NAME VALUE=\u0026quot;Windows 10\u0026quot;/\u0026gt;\r\u0026lt;ENV_VAR_LIST\u0026gt;\r\u0026lt;ENV_VAR NAME=\u0026quot;PATH\u0026quot; MAX_LENGTH=\u0026quot;1023\u0026quot; /\u0026gt;\r\u0026lt;/ENV_VAR_LIST\u0026gt;\r\u0026lt;/OPERATING_SYSTEM\u0026gt;\r安装plsql developer 软件 下载地址： https://www.allroundautomations.com/registered/plsqldev.html\n",
    "ref": "/blog/database/oracle/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"
  },{
    "title": "Golang源码阅读-slice",
    "date": "",
    "description": "",
    "body": "数组(array) golang 中 array 在函数传参中是值传递， 修改不影响原数组；\n切片(slice)  切片数据结构很简单， 对底层数组进行了抽象，并提供相关操作方法； 切片数据结构包含三个字段： 数组指针， 切片长度， 切片容量 切片只能访问切片长度内的元素， 容量只是为了切片后续扩容使用  声明 var ss []int\r初始化  make 不允许创建len小于cap的切片  指定len和cap ss := make([]int, 5, 10) 指定len ss := make([]int, 5)   字面量  全量创建并初始化切片： ss := []int{1, 2, 3, 3} 使用索引创建并初始化： ss := []int{9: 1}   创建数组的引用 arr := [5]int{}\rss := arr[:]\r 通过切片创建新的切片  默认容量 s := []int{1,2,3,4,5}\r// ss := s[i:j] // ss = []int{i, ..., j-1}, 长度为j-i, 容量为cap(s)-i\rss := s[1:3] // ss = []int{2,3}, 长度为2， 容量为4\r 指定容量(容量不能超出原有切片容量)  s := []int{1,2,3,4,5}\r// ss := s[i:j:k] // ss = []int{i, ..., j-1}, 长度为j-i, 容量为k-i ( j \u0026lt;= k \u0026lt;= cap(s))\rss := s[1:3:2] // ss = []int{2,3}, 长度为2， 容量为2     empty slice 和 nil slice   empty slice\nss := make([]int, 0)\rss1 := []int{}\r  nil slice\nvar ss []int\r  总结\n 两者都不能查询 s[0] = 1 报错： 数组越界 nil slice == nil 而 empty slice != nil json 序列化nil slice后为 \u0026ldquo;NULL\u0026rdquo;, 序列化 empty slice后为\u0026quot;[]\u0026quot;    切片扩容  func append(slice []Type, elems ...Type) []Type  append 会增加slice的长度 容量增加，根据添加的elems长度是否超出slice的容量  如果未超出slice容量，则将elems合并到slice尾部 如果超出slice容量  创建全新的底层数组 当slice容量小于1000时，新建切片容量会成倍增加 当slice容量超出1000时，新建切片容量会增加25%        限制切片容量  创建切片时，第三个参数用来限制切片的容量。 内置func append(slice []Type, elems ...Type) []Type函数会优先使用slice现有容量。 一旦超出slice现有容量，会重新分配底层数组。 一旦这个过程中对进行修改，会导致其他引用切片数据错乱  切片拷贝  func copy(dst, src []Type) int  它表示把切片 src 中的元素拷贝到切片 dst 中，返回值为拷贝成功的元素个数。如果 src 比 dst 长，就截断；如果 src 比 dst 短，则只拷贝 src 那部分    内存浪费问题  当slice底层数组很大，而数据仅仅少量被引用 golang的垃圾回收并不会回收数组中没有被引用的空间，这就造成内存空间浪费 因此，这种情况需要重新构建新的slice，避免引用数据量大的slice；  ",
    "ref": "/blog/golang/slice/"
  },{
    "title": "Golang源码阅读-map",
    "date": "",
    "description": "",
    "body": "map 声明 var m map[string]string\rmap声明默认值是nil， 此时取值，返回的是value对应类型的零值\n初始化 // 声明之后必须初始化，才能使用\rm = make(map[string]int)\rm = map[string]int{}\r// 声明并初始化\rm = make(map[string]int, 10)\rm = map[string]int{\u0026quot;x\u0026quot;:1}\r向未初始化的map赋值引起： panic: assignment to entry in nil map\nkey/value 限制  key 一定是可以比较的类型（支持==操作），如果是非法的key会报invalid map key type value可以是任意类型  遍历  map 本身是无序的 在iterate 整个map时， 使用delete 是安全的。这里和C++ 不一样， C++ 不能再迭代的时候删除元素，会导致map的红黑树结构发生变化  函数传参 golang中没有引用传递， 均为值传递。意味参数是一种数据拷贝。\nmap 本身是引用类型，作为形参或返回值时，传递的是地址的拷贝。\n扩容时也不会改变这个地址。\nmap 基础数据结构 map实现的底层结构是hmap\n// A header for a Go map.\rtype hmap struct {\r// Note: the format of the hmap is also encoded in cmd/compile/internal/gc/reflect.go.\r// Make sure this stays in sync with the compiler's definition.\r// 记录 map 当前元素个数\rcount int // # live cells == size of map. Must be first (used by len() builtin)\r// 记录 map当前状态： 读、写、扩容等标记\rflags uint8\r// 用于计算桶大小， 2^B\rB uint8 // log_2 of # of buckets (can hold up to loadFactor * 2^B items)\r// 溢出的bucket 个数, 是个近似值\rnoverflow uint16 // approximate number of overflow buckets; see incrnoverflow for details\r// 计算key哈希值的种子， 保证一个key在不同的map中，存放的位置是随机的\rhash0 uint32 // hash seed\r// 当前哈希桶的首地址\rbuckets unsafe.Pointer // array of 2^B Buckets. may be nil if count==0.\r// 旧哈希桶地址\roldbuckets unsafe.Pointer // previous bucket array of half the size, non-nil only when growing\r// 已迁移桶个数\rnevacuate uintptr // progress counter for evacuation (buckets less than this have been evacuated)\r// 扩展字段\rextra *mapextra // optional fields\r}\rbucket实现的底层结构是bmap， 下面的机构体中只包含了一个tophash用于桶内快速查询。 从下面Followed定义可以看出， hmap结构只给出了部分字段的描述，下面还有 K/V 以及 指向溢出桶的指针。 由于K/V 大小会实时变化，所以而这两个字段的数据只能通过指针偏移的方式获取\n// A bucket for a Go map.\rtype bmap struct {\r// tophash generally contains the top byte of the hash value\r// for each key in this bucket. If tophash[0] \u0026lt; minTopHash,\r// tophash[0] is a bucket evacuation state instead.\r// 长度为8的数组， 用于存放桶中每个key hash值的高8位，用于后续快速查找桶内元素\rtophash [bucketCnt]uint8\r// Followed by bucketCnt keys and then bucketCnt elems.\r// NOTE: packing all the keys together and then all the elems together makes the\r// code a bit more complicated than alternating key/elem/key/elem/... but it allows\r// us to eliminate padding which would be needed for, e.g., map[int64]int8.\r// Followed by an overflow pointer.\r}\r名称解释  哈希桶 是hmap结构中的buckets数组， 数组内的每个元素为一个桶 桶链 是桶以及该桶下挂着的所有溢出桶 桶 (bucket) 是bmap结构， 是哈希桶的一个元素 溢出桶(overflow bucket) 是bmap结构， 挂在桶下 负载因子(loadfactor) 表示平均每个桶中元素的个数, 主要用于判断当前map是否需要扩容。如果当前map有20个元素，哈希桶长为4， 则负载因子为5。 新旧哈希桶 是hmap结构中的buckets和oldbuckets数组， 此概念仅存在于map扩容阶段。在哈希桶扩容时，会申请一个新的哈希桶，原来的哈希桶成为旧哈希桶。然后会分步将旧哈希桶上的元素迁移到新哈希桶桶，当旧哈希桶被迁移完成，就会被释放掉。  文件组成 map源码都在src/runtime下， 主要有四个文件组成：\nmap.go // 源代码实现主体\rmap_fast32.go // 针对key类型为int32/uint32做了优化\rmap_fast64.go // 针对key类型为int64/uint64做了优化\rmap_faststr.go // 针对key类型为string做了优化\r优化功能  查询上的优化  当只有一个桶时，不做hash，直接遍历桶 当多个桶时  fast 32/64 省略tophash的比较， 直接比较key值 string 省略tophash比较，多了字符串长度比较和首尾4个字符的比较，且在实际key比较时直接使用内置memequal。     内存管理优化  源码解析 map 创建 语法  不带参数 make(map[keyType]valueType) 带参数 make(map[keyType]valueType,size)  源码 分析  创建map func makemap(t *maptype, hint int, h *hmap) *hmap {\r// 校验hint大小是否操作内存限制， 32系统限制1\u0026lt;\u0026lt;32， 64系统限制1\u0026lt;\u0026lt;48\rmem, overflow := math.MulUintptr(uintptr(hint), t.bucket.size)\rif overflow || mem \u0026gt; maxAlloc {\rhint = 0\r}\r// initialize Hmap\rif h == nil {\rh = new(hmap)\r}\r// 获取随机种子， 保证同一个key再不同的map中hash值不一样（安全） h.hash0 = fastrand()\r// Find the size parameter B which will hold the requested # of elements.\r// For hint \u0026lt; 0 overLoadFactor returns false since hint \u0026lt; bucketCnt.\r// 计算哈希桶大小\rB := uint8(0)\rfor overLoadFactor(hint, B) {\rB++\r}\rh.B = B\r// allocate initial hash table\r// if B == 0, the buckets field is allocated lazily later (in mapassign)\r// If hint is large zeroing this memory could take a while.\r// 如果哈希桶大小不为0， 则创建哈希桶，有必要还要创建溢出桶结构 if h.B != 0 {\rvar nextOverflow *bmap\rh.buckets, nextOverflow = makeBucketArray(t, h.B, nil)\rif nextOverflow != nil {\rh.extra = new(mapextra)\rh.extra.nextOverflow = nextOverflow\r}\r}\rreturn h\r}\r 计算哈希桶大小 // 1. 哈希桶大小为2的整次幂\r// 2. 哈希桶大小为size/6.5 func overLoadFactor(count int, B uint8) bool {\rreturn count \u0026gt; bucketCnt \u0026amp;\u0026amp; uintptr(count) \u0026gt; loadFactorNum*(bucketShift(B)/loadFactorDen)\r}\r  map查找 语法 m := make(map[string]int)\n v := m[key] 只返回value， 如果key不存在则返回对应的 空对象(对应源码： mapaccess1) v, ok := m[key] 返回value 以及key是否存在标志(对应源码： mapaccess2) for k, v := range m 返回key和value 仅用于range迭代场景(对应源码： mapaccessK)  源码 分析  查找map func mapaccess2(t *maptype, h *hmap, key unsafe.Pointer) (unsafe.Pointer, bool) {\rif raceenabled \u0026amp;\u0026amp; h != nil {\rcallerpc := getcallerpc()\rpc := funcPC(mapaccess2)\rracereadpc(unsafe.Pointer(h), callerpc, pc)\rraceReadObjectPC(t.key, key, callerpc, pc)\r}\rif msanenabled \u0026amp;\u0026amp; h != nil {\rmsanread(key, t.key.size)\r}\r// 如果是nil 或者 空map， 直接返回 空对象和key不存在\rif h == nil || h.count == 0 {\rif t.hashMightPanic() {\rt.key.alg.hash(key, 0) // see issue 23734\r}\rreturn unsafe.Pointer(\u0026amp;zeroVal[0]), false\r}\r// 如果map正在写入，则直接报错\rif h.flags\u0026amp;hashWriting != 0 {\rthrow(\u0026quot;concurrent map read and map write\u0026quot;)\r}\r// 计算key的hash\ralg := t.key.alg\rhash := alg.hash(key, uintptr(h.hash0))\r// 获取哈希桶中key 所在的桶链首地址\rm := bucketMask(h.B)\rb := (*bmap)(unsafe.Pointer(uintptr(h.buckets) + (hash\u0026amp;m)*uintptr(t.bucketsize)))\r// 如果哈希桶正在扩容，则去旧哈希桶中获取key 所在的桶链首地址\rif c := h.oldbuckets; c != nil {\r// 如果不是等量扩容， 则重新计算旧哈希桶为当前的一半\rif !h.sameSizeGrow() {\r// There used to be half as many buckets; mask down one more power of two.\rm \u0026gt;\u0026gt;= 1\r}\roldb := (*bmap)(unsafe.Pointer(uintptr(c) + (hash\u0026amp;m)*uintptr(t.bucketsize)))\rif !evacuated(oldb) {\rb = oldb\r}\r}\r// 计算key的tophash\rtop := tophash(hash)\r// 遍历桶链中所有桶和溢出桶\rbucketloop:\rfor ; b != nil; b = b.overflow(t) {\r// 遍历桶里所有元素\rfor i := uintptr(0); i \u0026lt; bucketCnt; i++ {\r// 匹配key的tophash\rif b.tophash[i] != top {\rif b.tophash[i] == emptyRest {\rbreak bucketloop\r}\rcontinue\r}\r// 取得桶里当前位置对应key值\rk := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize))\rif t.indirectkey() {\rk = *((*unsafe.Pointer)(k))\r}\r// 如果key匹配，说明找到了，直接返回 value 和 true\rif alg.equal(key, k) {\re := add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.elemsize))\rif t.indirectelem() {\re = *((*unsafe.Pointer)(e))\r}\rreturn e, true\r}\r}\r}\r// 一直没找到，返回默认空对象和false\rreturn unsafe.Pointer(\u0026amp;zeroVal[0]), false\r}\r  map 插入和更新 语法 m := make(map[string]int, 10)\n m[\u0026quot;key\u0026quot;] = value map 的插入和更新都通过这一个表达式  源码分析  插入和更新 func mapassign(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer {\r// 不允许向未初始化的map插入key\rif h == nil {\rpanic(plainError(\u0026quot;assignment to entry in nil map\u0026quot;))\r}\rif raceenabled {\rcallerpc := getcallerpc()\rpc := funcPC(mapassign)\rracewritepc(unsafe.Pointer(h), callerpc, pc)\rraceReadObjectPC(t.key, key, callerpc, pc)\r}\rif msanenabled {\rmsanread(key, t.key.size)\r}\r// 如果map 正在写入，则抛错： concurrent map writes\rif h.flags\u0026amp;hashWriting != 0 {\rthrow(\u0026quot;concurrent map writes\u0026quot;)\r}\r// 计算key 哈希值\ralg := t.key.alg\rhash := alg.hash(key, uintptr(h.hash0))\r// Set hashWriting after calling alg.hash, since alg.hash may panic,\r// in which case we have not actually done a write.\r// 设置map fags 为正在写入\rh.flags ^= hashWriting\r// 如果哈希桶为空， 则创建哈希桶，大小为1\rif h.buckets == nil {\rh.buckets = newobject(t.bucket) // newarray(t.bucket, 1)\r}\ragain:\r// 计算key分布到的桶链位置\rbucket := hash \u0026amp; bucketMask(h.B)\r// 如果哈希桶在扩容则进行扩容处理\rif h.growing() {\rgrowWork(t, h, bucket)\r}\r// 计算key分布到的桶\rb := (*bmap)(unsafe.Pointer(uintptr(h.buckets) + bucket*uintptr(t.bucketsize)))\r// 计算key的tophash\rtop := tophash(hash)\r// 记录存放key的tophash和桶中位置\rvar inserti *uint8\rvar insertk unsafe.Pointer\rvar elem unsafe.Pointer\rbucketloop:\r// 遍历桶链的每个桶和溢出桶\rfor {\rfor i := uintptr(0); i \u0026lt; bucketCnt; i++ {\r// 如果元素key的tophash 和 key的不一致则继续\rif b.tophash[i] != top {\r// 记录元素为空的位置\rif isEmpty(b.tophash[i]) \u0026amp;\u0026amp; inserti == nil {\rinserti = \u0026amp;b.tophash[i]\rinsertk = add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize))\relem = add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.elemsize))\r}\r// 如果桶中元素及后续元素都标记为空，则退出循环\rif b.tophash[i] == emptyRest {\rbreak bucketloop\r}\rcontinue\r}\r// 获取元素对应的key值\rk := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize))\rif t.indirectkey() {\rk = *((*unsafe.Pointer)(k))\r}\r// 元素对应key值和key不一致则继续\rif !alg.equal(key, k) {\rcontinue\r}\r// already have a mapping for key. Update it.\r// 如果元素对应key值和key一致，则更新value\rif t.needkeyupdate() {\rtypedmemmove(t.key, k, key)\r}\relem = add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.elemsize))\rgoto done\r}\r// 继续遍历溢出桶\rovf := b.overflow(t)\rif ovf == nil {\rbreak\r}\rb = ovf\r}\r// Did not find mapping for key. Allocate new cell \u0026amp; add entry.\r// If we hit the max load factor or we have too many overflow buckets,\r// and we're not already in the middle of growing, start growing.\r// 如果所有桶的平均负载因子超出6.5 或者 溢出桶个数超过 1\u0026lt;\u0026lt; 15\rif !h.growing() \u0026amp;\u0026amp; (overLoadFactor(h.count+1, h.B) || tooManyOverflowBuckets(h.noverflow, h.B)) {\rhashGrow(t, h)\rgoto again // Growing the table invalidates everything, so try again\r}\r// 如果当前桶链中没有空位置， 则创建新的溢出桶\rif inserti == nil {\r// all current buckets are full, allocate a new one.\rnewb := h.newoverflow(t, b)\rinserti = \u0026amp;newb.tophash[0]\rinsertk = add(unsafe.Pointer(newb), dataOffset)\relem = add(insertk, bucketCnt*uintptr(t.keysize))\r}\r// store new key/elem at insert position\r// 保存key和value到指定位置\rif t.indirectkey() {\rkmem := newobject(t.key)\r*(*unsafe.Pointer)(insertk) = kmem\rinsertk = kmem\r}\rif t.indirectelem() {\rvmem := newobject(t.elem)\r*(*unsafe.Pointer)(elem) = vmem\r}\rtypedmemmove(t.key, insertk, key)\r*inserti = top\r// map总元素个数加一\rh.count++\rdone:\rif h.flags\u0026amp;hashWriting == 0 {\rthrow(\u0026quot;concurrent map writes\u0026quot;)\r}\r// 清空写入标记\rh.flags \u0026amp;^= hashWriting\rif t.indirectelem() {\relem = *((*unsafe.Pointer)(elem))\r}\rreturn elem\r}\r 扩容  扩容条件  为了保证访问效率， 当新元素添加到map时，都会检查是否需要扩容， 扩容实际上以空间换时间 条件：  哈希桶的平均负载因子\u0026gt; 6.5时， 即平均每个桶存储的键值对大于6.5 溢出桶的数量大于 2^15时     增量扩容  当负载因子过大时，新建哈希桶， 新哈希桶是旧哈希桶长度的两倍 考虑如果map存储键值对太多，一次性搬迁延时较大，采用逐步搬迁策略 每次访问map时都会触发搬迁，每次搬迁两个键值对   等量扩容  在极端条件下， 不断地增删key，而这些操作集中到一个桶上，就会导致溢出桶很多，而负载因子不高，导致无法增量搬迁 这种情况下做一次等量扩容，哈希桶的长度不变， 把松散的键值重新排列，让桶的利用率增高。      map删除 语法  delete(m, key) 删除map中某个键  源码分析  删除map func mapdelete(t *maptype, h *hmap, key unsafe.Pointer) {\rif raceenabled \u0026amp;\u0026amp; h != nil {\rcallerpc := getcallerpc()\rpc := funcPC(mapdelete)\rracewritepc(unsafe.Pointer(h), callerpc, pc)\rraceReadObjectPC(t.key, key, callerpc, pc)\r}\rif msanenabled \u0026amp;\u0026amp; h != nil {\rmsanread(key, t.key.size)\r}\r// 如果是nil map或者空map，则直接 返回 if h == nil || h.count == 0 {\rif t.hashMightPanic() {\rt.key.alg.hash(key, 0) // see issue 23734\r}\rreturn\r}\r// 如果map正在写入，则抛错\rif h.flags\u0026amp;hashWriting != 0 {\rthrow(\u0026quot;concurrent map writes\u0026quot;)\r}\r// 计算key的hash值\ralg := t.key.alg\rhash := alg.hash(key, uintptr(h.hash0))\r// Set hashWriting after calling alg.hash, since alg.hash may panic,\r// in which case we have not actually done a write (delete).\r// 设置map的状态标志为正在写入\rh.flags ^= hashWriting\r// 计算key 分布的桶链\rbucket := hash \u0026amp; bucketMask(h.B)\rif h.growing() {\rgrowWork(t, h, bucket)\r}\r// 计算key 分布所在的桶\rb := (*bmap)(add(h.buckets, bucket*uintptr(t.bucketsize)))\rbOrig := b\r// 计算key 的tophash值\rtop := tophash(hash)\rsearch:\r// 遍历桶链中所有的桶和溢出桶\rfor ; b != nil; b = b.overflow(t) {\r// 遍历桶里面所有元素\rfor i := uintptr(0); i \u0026lt; bucketCnt; i++ {\r// 如果tophash不相等，继续遍历桶中元素\rif b.tophash[i] != top {\r// 如果\rif b.tophash[i] == emptyRest {\rbreak search\r}\rcontinue\r}\r// 元素tophash和key的一致，获取当前元素key值\rk := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize))\rk2 := k\r// 如果元素的key值是指针类型，则取其值\rif t.indirectkey() {\rk2 = *((*unsafe.Pointer)(k2))\r}\r// 如果当前元素key值和key不一致，则继续\rif !alg.equal(key, k2) {\rcontinue\r}\r// Only clear key if there are pointers in it.\r// 如果当前元素key值是指针类型，则赋nil，否则清空该段内存\rif t.indirectkey() {\r*(*unsafe.Pointer)(k) = nil\r} else if t.key.ptrdata != 0 {\rmemclrHasPointers(k, t.key.size)\r}\re := add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.elemsize))\rif t.indirectelem() {\r*(*unsafe.Pointer)(e) = nil\r} else if t.elem.ptrdata != 0 {\rmemclrHasPointers(e, t.elem.size)\r} else {\rmemclrNoHeapPointers(e, t.elem.size)\r}\r// 将元素对应的tophash位标记为空\rb.tophash[i] = emptyOne\r// If the bucket now ends in a bunch of emptyOne states,\r// change those to emptyRest states.\r// It would be nice to make this a separate function, but\r// for loops are not currently inlineable.\rif i == bucketCnt-1 {\rif b.overflow(t) != nil \u0026amp;\u0026amp; b.overflow(t).tophash[0] != emptyRest {\rgoto notLast\r}\r} else {\rif b.tophash[i+1] != emptyRest {\rgoto notLast\r}\r}\r// 如果后续元素无赋值key， 则将元素及后续元素对应的tophash 置为空\rfor {\rb.tophash[i] = emptyRest\rif i == 0 {\rif b == bOrig {\rbreak // beginning of initial bucket, we're done.\r}\r// Find previous bucket, continue at its last entry.\rc := b\rfor b = bOrig; b.overflow(t) != c; b = b.overflow(t) {\r}\ri = bucketCnt - 1\r} else {\ri--\r}\rif b.tophash[i] != emptyOne {\rbreak\r}\r}\rnotLast:\r// map 总元素个数减一\rh.count--\rbreak search\r}\r}\rif h.flags\u0026amp;hashWriting == 0 {\rthrow(\u0026quot;concurrent map writes\u0026quot;)\r}\r// 清空写标记\rh.flags \u0026amp;^= hashWriting\r}\r  清空map 语法 for k, v := range m {\rdelete(m, k)\r}\r源码分析  mapclear func mapclear(t *maptype, h *hmap) {\rif raceenabled \u0026amp;\u0026amp; h != nil {\rcallerpc := getcallerpc()\rpc := funcPC(mapclear)\rracewritepc(unsafe.Pointer(h), callerpc, pc)\r}\r// 如果nil map 或 空map 则直接返回\rif h == nil || h.count == 0 {\rreturn\r}\r// 如果 map正在写入，则抛出错误\rif h.flags\u0026amp;hashWriting != 0 {\rthrow(\u0026quot;concurrent map writes\u0026quot;)\r}\r// 标记map为正在写入\rh.flags ^= hashWriting\r// 清空hmap 中成员\rh.flags \u0026amp;^= sameSizeGrow\rh.oldbuckets = nil\rh.nevacuate = 0\rh.noverflow = 0\rh.count = 0\r// Keep the mapextra allocation but clear any extra information.\rif h.extra != nil {\r*h.extra = mapextra{}\r}\r// makeBucketArray clears the memory pointed to by h.buckets\r// and recovers any overflow buckets by generating them\r// as if h.buckets was newly alloced.\r// 清空溢出桶\r_, nextOverflow := makeBucketArray(t, h.B, h.buckets)\rif nextOverflow != nil {\r// If overflow buckets are created then h.extra\r// will have been allocated during initial bucket creation.\rh.extra.nextOverflow = nextOverflow\r}\r// 清空写入标记\rif h.flags\u0026amp;hashWriting == 0 {\rthrow(\u0026quot;concurrent map writes\u0026quot;)\r}\rh.flags \u0026amp;^= hashWriting\r}\r  ",
    "ref": "/blog/golang/map/"
  },{
    "title": "Golang 代码规范",
    "date": "",
    "description": "代码编写，命名等规范",
    "body": "gofmt工具 gofmt 格式化Go程序。使用tabs进行缩进，blanks进行对齐。\ngofmt 参数 gofmt [flags] [path...]\n -cpuprofile: 指定打印cpu profile文件路径 -d: 打印gofmt前后文件差异，并不格式化重写源文件 -e: 打印gofmt出现的错误,并不格式化重写源文件 -l: 打印不符合gofmt的文件列表,并不格式化重写源文件 -r: 设置gofmt重写规则 -s: 简化代码  源: tt := []int{1, 2, 3, 4, 5, 6}\rtt = tt[3:len(tt)]\r 目标: tt := []int{1, 2, 3, 4, 5, 6}\rtt = tt[3:]\r   -w: 将gofmt结果写入源文件，而不是stdout  命名 Go中命名具有语义性， 命名在包外的可见性取决于首字母的大小写；\n  目录\n 目录名小写 允许中划线-,但是不要出现在头尾    文件\n 文件名小写 允许下划线_,但是不要出现在头尾 可以结合系统平台、CPU架构、版本号等 eg: defs_linux_amd64.go\rdefs_linux_386.go\r    package\n package名要小写 不允许特殊字符 简短，能表示实现内容 避免和系统package重复 package名与目录名一致 统一单数形式 eg: // 文件名\rdocc.go\r// Package docc\rpackage docc  包内导出变量、函数、类型等的命名，不要在添加包的说明 eg: bytes.Buffer strings.Reader 替代：\rbytes.ByteBuffer strings.StringReader\r    变量名\n 不允许特殊字符 lowerCamelCase命名 根据是否导出首字母大写 局部变量尽量简短 eg: i =\u0026gt; index 保持某些特殊名词格式 eg: HTTP/HTTPS ...\r// PType protocol type\rtype PType int\r// Protocol type 枚举\rconst (\rHTTP PType = iota HTTPS PType = 1\r)\r    结构体名\n 不允许特殊字符 lowerCamelCase命名 根据是否导出首字母大写 应该是名词短语,避免使用动词 eg:\rtype Buffer struct {\r...\r}     函数名\n 不允许特殊字符 lowerCamelCase命名 根据是否导出首字母大写 尽量体现接口功能和必要参数 如果是结构体方法，则Receiver尽量简写，使用一两个字符表示 eg: func (b *Reader) Read(p []byte) (n int, err error)\r 应该是动词短语 eg:\rfunc (b *Reader) ReadByte() (byte, error)\r 返回值尽量能表示其含义，代替其文档说明  func (b *Reader) Discard(n int) (discarded int, err error)\r Go不提供对getter和setter的自动支持,对于字段的操作可以自定义 owner := obj.Owner()\rif owner != user {\robj.SetOwner(user)\r}\r 如果对象obj有一个字段owner(包外不可见), owner的getter方法应该是Owner(), 而不是GetOwner()\n     接口名\n  不允许特殊字符\n  UpperCamelCase命名\n  接口名以er结尾\neg:\r// Reader reader interface\rtype Reader interface {\rRead(p []byte) (n int, err error)\r}\r// WriteFlusher write/flush interface\rtype WriteFlusher interface {\rWrite([]byte) (int, error)\rFlush() error\r}\r```\r    代码  每行代码长度不超过80个字符  注释 参考 doc 编写规范\nREADME  每个目录下应该有README文件 描述目录结构 描述主要的方法和代码逻辑 代码地址 引用文档 API地址  ",
    "ref": "/blog/golang/%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83/"
  },{
    "title": "LDAP协议简介",
    "date": "",
    "description": "",
    "body": "概述 LDAP: light diretory access protocol, 轻量级目录访问协议； LDAP 目录服务，由目录数据库和访问协议组成；\n目录树  目录树： 在目录服务系统中， 整个目录信息集， 都可以表示为一个目录信息树。树中的每个节点是一个条目； 条目： 每个条目是一条记录， 每个条目有自己唯一的名称（DN） 对象类： 与某个实体类型对应的一组属性，可以继承。这样父类的属性也会被继承下来。 属性： 描述条目的某方面信息。 一个属性由一个属性类型和一个或多个属性值组成， 属性由必须属性和非必须属性。  关键字    关键字 英文全称 含义     dc domain Component 域名的部分，其格式是将完整的域名分成几部分，如域名为example.com变成dc=example,dc=com（一条记录的所属位置）   uid User Id 用户ID songtao.xu（一条记录的ID）   ou Organization Unit 组织单位，组织单位可以包含其他各种对象（包括其他组织单元），如“oa组”（一条记录的所属组织）   cn Common Name 公共名称，如“Thomas Johansson”（一条记录的名称）   sn Surname 姓，如“许”   dn Distinguished Name “uid=songtao.xu,ou=oa组,dc=example,dc=com”，一条记录的位置（唯一）   rdn Relative dn 相对辨别名，类似于文件系统中的相对路径，它是与目录树结构无关的部分，如“uid=tom”或“cn= Thomas Johansson”    DN 格式： dn: cn=zyl,ou=aishijie,ou=developer,ou=manager,ou=zhijinxinganxian, dc=beijing, dc=com\n应用错误 Golang https请求发生错误 x509: certificate signed by unknown authority ### 重点： 引入\u0026quot;crypto/tls\u0026quot;\n",
    "ref": "/blog/web/ldap/"
  },{
    "title": "CDN内容分发网络工作过程和分类",
    "date": "",
    "description": "",
    "body": "CDN  全称 Content Delivery Network，即内容分发网络 概念始于1996，美国麻省理工学院的研究小组，并于1999年创建CDN服务公司 CDN构建在现有网络基础上，依靠部署在各地的边缘服务器，通过中心平台的负载均衡、内容分发、调度等模块，是用户就近获取内容，降低网络拥塞，挺高用户访问的响应速度和命中率。 CDN的关键技术是内容存储和分发  一些前端开源CDN服务  基于github的cdn BootCDN  CDN基本工作过程 使用CDN可以简化网站的系统维护工作\n 运维只需要将网站内容注入到CDN系统，就可以同通过CDN系统部署在各个物理位置的服务器进行全网分发，实现跨运营商、跨地域的用户覆盖 由于CDN将内容推送到网络边缘，大量用户访问被分散到网络边缘  不在构成网站出口、互联互通点的资源挤占 也不需要跨越长距离的IP路由    实现原理 关键字：\n CNAME：即：别名记录。这种记录允许您将多个名字映射到同一台计算机。 GSLB： Global Server Load Balance, 全局负载均衡。 实现在广域网上不同地域服务器间的流量调配，保证使用最佳的服务器服务离自己最近的客户。  今天我们看到的网站系统基本上基于B/S架构，具体流程如下：\n 未使用CDN，用户访问网站过程：    用户在自己的浏览器中输入要访问的网站域名 浏览器向本地的DNS服务器请求对该域名解析  本地DNS服务器中如果有缓存该域名的解析结果，则直接响应用户的解析请求 本地DNS服务器中如果没有缓存该域名的解析结果， 则以递归的方式向整个DNS系统请求解析，获得应答后将结果反馈给浏览器   浏览器得到域名的解析结果，就是该域名对应的服务器设备IP 浏览器向服务器请求内容 服务器将用户请求内容传输给浏览器     使用CDN，用户访问网站过程    当用户加载网站上的内容和资源URL时 经过本地DNS系统解析，DNS系统会将域名的解析权交给CNAME指向的CDN专用DNS服务器 CDN的专属DNS服务器将CDN的全局负载均衡设备IP返回给用户 用户向CDN的全局负载均衡设备发起内容URL的访问请求 CDN全局负载均衡设备根据用户IP和用户请求内容URL，选择一台用户所在区域的区域负载均衡设备， 告诉用户向这台设备发起请求 区域负载均衡设备会为用户选择一台合适的缓存服务器提供服务。选择依据：  判断哪台服务器距离用户最近 根据请求URL携带内容，判断哪一台服务器上有用户所需内容 查询当前服务器负载情况，判断哪一台有服务能力。 基于以上条件的综合分析后， 区域负载均衡设备会向全局负载均衡设备返回一台缓存服务器IP   全局负载均衡设备把缓存服务器的IP返回给用户 用户向缓存服务器发起请求，缓存服务器响应用户需求，返回用户请求内容  如果这台缓存服务器没有请求内容，而区域负载均衡设备依然将其分配给用户 这台缓存服务器会向它的上级缓存服务器请求内容，直到追溯到网站的源服务器将内容缓存到自身        CDN基于内容分类 关键字：\n POP点： 网络服务提供点（或称局端），通常POP点越近则线路信号损耗越小，可为连接用户提供的带宽保障越高  CDN的承载内容类型分为： 静态网页、动态网页、流媒体、下载类型和应用协议\n因此将CDN分为： 网页加速、流媒体加速、文件传输加速和应用协议加速\n 网页加速  将网页的静态资源： 文字、图片、动画等静态内容缓存在各个CDN节点上 并将用户请求调度到最有节点上来获取所需内容，从而加速页面响应速度 主要面向： 每户网站、新闻发布类网站、访问量较大的行业网站、政府机构网站和企业门户网站等   流媒体加速  将流媒体内容推送到离用户最近的POP点，使得用户能够从网络边缘获取内容。 缩短访问时间，节省骨干网络流量，避免单一中心服务器瓶颈问题 流媒体加速分为两类：  流媒体直播加速 流媒体点播加速  将流媒体以内容类别、版本等为索引按片段存放再服务器上       文件传输加速  通过CDN的分布式POP点提供下载服务，将大量文件下载的性能压力和带宽压力交割CDN分担， 提高下载速度 目前CDN支持HTTP下载、FTP下载和P2P下载方式 主要用于软件厂商的补丁发布、杀毒软件厂商的病毒库更新、网络游戏运营商的游戏客户端下载等   应用协议加速  应用协议加速不针对特定内容类型进行加速，而是通过对TCP/IP等传输协议优化，改善用户在广域网上内容传输速度 主要应用协议加速服务有以下集中： 广域网应用加速  目的： 让广域网像局域网一样 针对在局域网上正常运行， 但一到广域网就收到极大影响的应用和协议如： CIFS、NFS 将分布式IT基础设施文件服务器、邮件服务器、网络附加存储(NAS)和远程办公备份等集中起来，整合到统一的数据中心。使得世界各地的文件共享边得简单高效 还支持通过长距离广域网链路进行文件备份和复制，在不升级带宽的前提下，在现有广域网上提供更丰富的服务   SSl应用加速  CDN使用专用的SSL加速硬件进行网络请求的加解密运算工作 用户源站只需信任有限的CDN cache， 无需面海量用户，从而减轻网站繁重的运算和认证压力   网页压缩  CDN利用网页压缩技术，对网页数据进行压缩传输，加快内容传输速度      CDN基于内容生成机制的分类和分层加速 从内容生成机制来看，互联网内容主要有两类：\n 静态内容：内容完全由HTML文件组成，任何时间浏览静态内容看到的都是一样的东西 动态内容：不同访问者或在不同时间访问同一个web页面，可能得到不同页面内容   web网站都能在逻辑上划分为三层，即： 表现层、业务逻辑层、数据访问层。 CDN实现网络加速主要依赖于内容边缘缓存和功能复制。本质是将web源站各个层次上的功能移植到CDN边缘Cache 上完成。 根据不同层面的web功能转移，将CDN分为表示层复制和全站复制两大类   表示层复制  静态内容加速可以通过CDN边缘Cache复制web系统的表示层来完成 CDN的Cache设备以反向代理的角色接受用户发来的请求，在本地查找满足用户需求的数据  在Cache上命中的内容，则无需向源站web系统请求。   这种情况Cache上缓存的内容通常是完整的web内容实体，如： 脚本、样式、图片、多媒体文件   全站复制  动态内容的加速需要在CDN上复制和缓存业务逻辑层和后台数据访问层 业务逻辑层在CDN Cache上的复制使之能够承担用户的请求处理、应用数据计算、动态内容生成等，此类方法称之为\u0026quot;边缘计算\u0026quot;  将web应用层序或组件直接安装到CDN Cache中，目的是在最接近用户的位置完成应用处理   数据访问层在CDN Cache上的复制，可以加速动态内容的生成  问题： 系统中多个副本间数据的一致性问题      ",
    "ref": "/blog/distribution-system/cdn/"
  },{
    "title": "golang-tags及扩展使用",
    "date": "",
    "description": "记录golang学习和使用的常用地址",
    "body": "",
    "ref": "/blog/golang/gotag/"
  },{
    "title": "golang常用网址",
    "date": "",
    "description": "记录golang学习和使用的常用地址",
    "body": "官网  golang官方地址: https://golang.org/ golang在线运行的互动小程序: https://tour.golang.org golang CMD: https://golang.org/cmd golang Release: https://golang.org/doc/devel/release.html golang Issue: https://github.com/golang/go/issues golang wiki: https://github.com/golang/go/wiki/ golang 论坛: https://groups.google.com/g/golang-announce golang asesome-go: https://github.com/avelino/awesome-go golang trending: https://github.com/trending/go?since=daily  学习地址  The Go Programming Language 英文原版地址: http://www.gopl.io/ The Go Programming Language中文github地址: https://github.com/golang-china/gopl-zh  ",
    "ref": "/blog/golang/%E5%B8%B8%E7%94%A8%E7%BD%91%E5%9D%80/"
  },{
    "title": "Node开发常见问题及解决方案",
    "date": "",
    "description": "",
    "body": "证书设置 添加证书路径到环境变量：\nexport NODE_EXTRA_CA_CERTS=\u0026quot;/etc/nginx/ssl/ca.crt\u0026quot;\rinstall慢  全局配置  查看全局配置文件位置npm config -g ls -l :  globalconfig = \u0026quot;$prefix/etc/npmrc\u0026quot;\r 编辑该文件，写入内容: \rregistry=https://registry.npm.taobao.org\rdisturl = https://npm.taobao.org/mirrors/node\rmetrics-registry = https://registry.npm.taobao.org     EACCESS npm install 执行时出现以下错误：Error: EACCES: permission denied, mkdtemp...\n解决方案：\nnpm install --unsafe-perm=true --allow-root=true\r",
    "ref": "/blog/nodejs/problem/"
  },{
    "title": "Golang源码阅读-interface",
    "date": "",
    "description": "",
    "body": "",
    "ref": "/blog/golang/interface/"
  },{
    "title": "Linux系统下服务监控和报警解决方案",
    "date": "",
    "description": "",
    "body": "zabbix prometheus ",
    "ref": "/blog/linux/%E6%9C%8D%E5%8A%A1%E7%9B%91%E6%8E%A7%E5%8F%8A%E5%91%8A%E8%AD%A6/"
  },{
    "title": "Golang-Effective Go",
    "date": "",
    "description": "",
    "body": "",
    "ref": "/blog/golang/effective_go/"
  },{
    "title": "Golang-package-unsafe",
    "date": "",
    "description": "",
    "body": "本文主要分析unsafe.Pointer和uintptr的主要工作和区别，以及我们在项目中的使用场景\nunsafe.Pointer\nunsafe包 unsafe包主要包含绕过Go程序类型安全的操作。\n包中引入unsafe可能是不可移植的，并且不受Go 1兼容性指南的保护。\nfunc Alignof\nfunc Alignof(x ArbitraryType) uintptr\nAlignof接受任意类型的表达式x，并且返回变量v(假设的)需要的内存对齐字节数。它的值m是v的地址对m取余为0的最大值。 它与reflect.TypeOf(x).Align()返回值相同。\n特定情况下，如果变量s是struct类型，并且f是struct中的field，那么Alignof(s.f)返回f需要的内存对齐字节数。 这种情况下它与reflect.TypeOf(s.f).FieldAlign()返回值相同。\nAlignof的返回值是Go常量。\nfunc Offsetof\nfunc Offsetof(x ArbitraryType) uintptr\nOffsetof返回x表示的field在struct中的偏移量,x必须是structValue.field类型。换言之,它返回struct开始和field开始之间的字节数。\nOffset的返回值是Go常量。\nfunc Sizeof\nfunc Sizeof(x ArbitraryType) uintptr\n接受任意类型的表达式x，并且返回变量v(假设的)的内存大小,单位是字节。它的值不包含任何可能被x引用的内存。\n举个例子,如果x是一个slice，sizeof返回slice的内存大小，不包含slice中引用的内存大小。\nSizeof的返回值是Go常量。\ntype ArbitraryType type ArbitraryType int\nArbitraryType这里仅用于文档说明，它不属于unsafe包。它表示任意类型的Go表达式\ntype Pointer\ntype Pointer *ArbitraryType\rPointer表示指向任意类型的指针。type Pointer有四种指定的操作可用，其它不可用：\n 任意类型的指针可以转换为Pointer Pointer可以转换为任意类型的指针 uintptr可以转换为Pointer Pointer可以转换为uintptr Pointer允许程序使类型检测失效，可以读写任意的内存。因此使用时要小心。  以下使用Pointer的模式是有效的。未使用以下模式的代码可能是无效的，可能将来也是无效的。\n即使是有效的模式也有重要的注意事项。\n执行go vet可以帮助检测不符合使用Pointer模式的地方，但是go vet的沉默不能保证代码是有效的。\n(1) 将*T1转换为指向*T2的指针 前提是T2不大于T1，并且两者共享相同的内存布局，这种转换允许讲一种类型的数据转换为另一种类型的数据。\n一项示例是math.Float64bits的实现:\nfunc Float64bits(f float64) uint64 {\rreturn *(*uint64)(unsafe.Pointer(\u0026amp;f))\r(2) 将Pointer转换为uintptr(但是不能再转换为Pointer)\n将Pointer转换为uintptr，会生成这个值指向的内存地址，是整数形式。 uintptr的通常使用方式是打印它。\n将uintptr转换回Pointer通常是无效的。\nuintptr是整数值，不是引用。将Pointer转换为uintptr,会创建一个不是指针语义的整数值。即使uintptr保存了某个对象的地址， 垃圾清理器在对象移动时不会更新uintpr的值，同时这个uintptr也不会阻止对象被回收。\n以下模式枚举了uintptr转换为Pointer的唯一有效方式。 (3) 将Pointer转换为uintptr和反转，使用算术计算 如果p指向一个已经分配的对象，它可以通过转换为uintptr并增加一个偏移量，然后转换为Pointer来访问该对象。\np = unsaafe.Pointer(uintptr(p) + offset) 通常使用这种模式来访问struct中的field或者数组中的元素:\n// 等同于: f := unsafe.Pointer(\u0026amp;s.f)\rf := unsafe.Pointer(uintptr(unsafe.Pointer(\u0026amp;s)) + unsafe.Offsetof(s.f))\r// 等同于: e := unsafe.Pointer(\u0026amp;x[i])\re := unsafe.Pinter(uintptr(unsafe.Pointer(\u0026amp;x[0]) + i*unsafe.Sizeof(x[0]))\r在指针上加减偏移量的方式是有效的。使用\u0026amp;^来操作指针同样有效，一般用于对齐。在所有场景中，结果必须继续指向原始分配的对象。\n与C不同的是，移动指针超出原始分配对象的末尾是无效的：\n// 无效: 终点超出已分配的空间\rvar s thing\rend = unsafe.Pointer(uintptr(unsafe.Pointer(\u0026amp;s)) + unsafe.Sizeof(s))\r// 无效: 终点超出已分配的空间\rb := make([]byte, n)\rend = unsafe.Pointer(uintptr(unsafe.Pointer(\u0026amp;b[0])) + uintptr(n))\r注意，两种转换必须放在同一表达式中，它们中间只能有算术表达式:\n// 无效: 在转换为Pointer之前，uinptr不能保存在变量中\ru := uintptr(p)\rp = unsafe.Pointer(u + offset)\r注意，指针必须指向已分配对象，因此指针不能为nil:\n// 无效: 转换空指针\ru := unsafe.Pointer(nil)\rp := unsafe.Pointer(uintptr(u) + offset)\r(4) 在调用syscall.Syscall时转换Pointer为uintptr.\n函数Syscall将uintptr参数直接传递给操作系统，然后根据调用的详情，将其中的一些参数直接转换为指针类型。 也就是说，系统调用时隐式的将一些参数从uintptr转回指针。\n如果一个指针类型的参数必须转换为uintptr类型，才能使用，那么转换语句必须在调用表达式中：\nsyscall.Syscall(SYS_READ,uintptr(fd), uintptr(unsafe.Pointer(p)), uintptr(n))\r编译器处理参数列表中的Pointer转换为uintptr时，引用的分配对象需要保留，直到调用完成才能移动。 即使从类型来看，在调用期间似乎也不再需要该对象。\n要让编译器识别这种模式，转换语句必须在参数列表中:\n// 无效: 在系统调用隐式转换回指针前，uintptr不能保存在中间变量中，\ru := uintptr(unsafe.Pointer(p))\rsyscall.Syscall(SYS_READ, uintptr(fd), u, uintptr(n))\r(5) 将reflect.Value.Pointer或reflect.Value.UnsafeAddr从unitptr转换成Pointer. reflect包中Value的Pointer()和UnsafeAddr方法，返回值类型是uintptr而不是unsafe.Pointer, 是为了避免调用者将结果转换为任意类型(不使用unsafe.Pointer)。但是这意味着它们的返回值是脆弱的，因此在reflect.Value.Pointer()和 reflect.Value.UnsafeAddr()调用后需要在同一表达式中立刻转换成unsafe.Pointer:\np := (*int)(unsafe.Pointer(reflect.ValueOf(new(int)).Pointer()))\r如上所述，在转换前将结果保存在中间变量中是无效的:\n// 无效: 在转换前将uintptr保存在中间变量中是无效的\ru := reflect.ValueOf(new(int)).Pointer()\rp := (*int)(unsafe.Pointer(u))\r(6) 转换reflect.SliceHeader或reflect.StringHeader为unsafe.Pointer。 如上所述，SliceHeader和StringHeader结构中声明的field类型为uintptr，用来防止调用者将结果转换为任意类型(不使用unsafe.Pointer). 这意味着，SliceHeader和StringHeader只在诠释slice或string时是有效的。\nvar s string\rhdr := (*refelct.StringHeader)(unsafe.Pointer(\u0026amp;s)) // case (1)\rhdr.Data = uintptr(unsafe.Pointer(p)) // case (6)\rhdr.Len = n\r在上述使用中，hdr.Data是字符串header中引用底层指针的另一种方法，而不是uintptr变量本身。\n通常reflect.SliceHeader和reflect.StringHeader的使用方法只能是使用*reflect.SliceHeader和*reflect.StringHeader 指向slice或string，而不是其它struct。 程序不应该使用这两种类型声明和分配变量。\n// 无效：直接声明的header， 不会将数据作为引用保存。\rvar hdr reflect.StringHeader\rhdr.Data = uintptr(unsafe.Pointer(p))\rhdr.Len = n\rs := *(*string)(unsafe.Pointer(\u0026amp;hdr)) // p possibly already lost\r",
    "ref": "/blog/golang/pointer/"
  },{
    "title": "申请免费SSL证书",
    "date": "",
    "description": "",
    "body": "证书申请 ssl证书申请的3个主要步骤\n  制作CSR文件\n所谓CSR就是由申请人制作的Certificate Secure Request证书请求文件。制作过程中，系统会产生2个密钥，一个是公钥就是这个CSR文件，另外一个是私钥，存放在服务器上。要制作CSR文件，申请人可以参考WEB SERVER的文档，一般APACHE等，使用OPENssl命令行来生成KEY+CSR2个文件，Tomcat，JBoss，Resin等使用KEYTOOL来生成JKS和CSR文件，IIS通过向导建立一个挂起的请求和一个CSR文件。\n  CA认证\n将CSR提交给CA，CA一般有2种认证方式：\n   域名认证：一般通过对管理员邮箱认证的方式，这种方式认证速度快，但是签发的证书中没有企业的名称; 企业文档认证：需要提供企业的营业执照。 也有需要同时认证以上2种方式的证书，叫EV ssl证书，这种证书可以使IE7以上的浏览器地址栏变成绿色，所以认证也最严格。  证书安装\n在收到CA的证书后，可以将证书部署上服务器，一般APACHE文件直接将KEY+CER复制到文件上，然后修改httpD.CONF文件;TOMCAT等，需要将CA签发的证书CER文件导入JKS文件后，复制上服务器，然后修改SERVER.XML;IIS需要处理挂起的请求，将CER文件导入。   Letsencrypt证书申请   环境配置 $ sudo apt-get install letsencrypt\n  生成证书, 需要用到80端口，先停止相关进程：\n$ sudo letsencrypt certonly --email xxx@xxx.com -d www.example.com\rxxx@xxx.com 为邮箱,用于后续证书状态(过期)通知；\nwww.example.com 为生成服务器证书域名；\n  多域名证书(收费)\n*.zylhorse.com 通配符证书匹配所有三级域名，eg：\rys.zylhorse.com\rys1.zylhorse.com\rpin.zylhorse.com\r  ",
    "ref": "/blog/security/%E7%94%B3%E8%AF%B7%E5%85%8D%E8%B4%B9%E8%AF%81%E4%B9%A6/"
  },{
    "title": "一致性哈希特性和使用场景",
    "date": "",
    "description": "一致性哈希算法的原理、特性、应用场景",
    "body": "概念  一种hash算法 简单说： 移除和添加一台服务器是， 此算法能够尽可能小的改变已存在的服务请求和处理请求服务器之间的映射关系；  特性 考虑到分布式系统每个节点都可能失效， 且新的节点有可能加入进来。 一致性哈希需要保证以下特性\n平衡性 hash的结果尽可能的分配到所有的节点去，是的所有节点都能得到利用\n分散性  分散性： 客户端请求可能不知道所有的节点存在， 部分客户端将部分节点作为一个完整的hash环；导致同一请求不能映射到同一个节点； 一致性哈希 应降低分散性；  单调性  增加或删除节点，原有的请求应该被映射到原有的节点或新的节点中去； 增加或删除节点 不应造成大量的哈希重定向  工作原理  一致性哈希算法， 将整个hash空间映射成一个虚拟的圆环，取值范围为0-uint32max； 整个空间按顺时针方向组织； 将请求对应的hash映射到圆环上， 沿圆环做顺时针查找， 分配到最近的节点上； 增加节点只会影响新的节点和逆时针节点之间得请求；  ",
    "ref": "/blog/distribution-system/%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C/"
  },{
    "title": "Golang代码版本管理工具-go mod",
    "date": "",
    "description": "",
    "body": "概述 golang 模块管理工具，在Go 1.11版本中添加\n配置环境变量 # Enable the go modules feature\rexport GO111MODULE=on\r# Set the GOPROXY environment variable\rexport GOPROXY=https://goproxy.io\r",
    "ref": "/blog/golang/gomodule/"
  },{
    "title": "Golang和c语言互相调用的机制-cgo",
    "date": "",
    "description": "",
    "body": "参考: https://github.com/golang/go/wiki/cgo\n概述 CGO模块提供了golang和c语言互相调用的机制。某些第三方库只有c/c++实现且自己实现成本较高。\nwindow 额外配置  安装mingw-get， 配置环境变量 安装gcc： mingw-get install gcc  golang与c基本类型转换 golang 调用c函数，需要将golang数据类型通过cgo进行转换\n   C语言类型 CGO类型 Go语言类型     char C.char byte   singed char C.schar int8   unsigned char C.uchar uint8   short C.short int16   unsigned short C.ushort uint16   int C.int int32   unsigned int C.uint uint32   long C.long int32   unsigned long C.ulong uint32   long long int C.longlong int64   unsigned long long int C.ulonglong uint64   float C.float float32   double C.double float64   size_t C.size_t uint    cgo 注意  C.CString() 返回的 C 字符串是在堆上新创建的并且不受 GC 的管理，使用完后需要自行调用 C.free() 释放，否则会造成内存泄露，而且这种内存泄露用前文中介绍的 pprof 也定位不出来 由于底层内存模型的差异，不能直接将 golang 切片的指针传给 C 函数调用，而是需要将存储切片数据的内部缓冲区的首地址及切片长度取出传传递 引用的C头文件需要在注释中声明，紧接着注释需要有import \u0026ldquo;C\u0026rdquo;，且这一行和注释之间不能有空格  cgo 例子 clibrary.c\n#include \u0026lt;stdio.h\u0026gt;\r#include \u0026lt;stdlib.h\u0026gt;\r#include \u0026lt;string.h\u0026gt;\r#include \u0026lt;unistd.h\u0026gt;\r#include \u0026quot;clibrary.h\u0026quot;\rvoid C_InitStruct(void **st){\rC_Struct *stt = (C_Struct*)malloc(sizeof(C_Struct));\rchar *str = \u0026quot;constructor c struct\u0026quot;;\rstt-\u0026gt;len = strlen(str);\rstt-\u0026gt;buf = str;\r*st = stt;\rprintf(\u0026quot;c struct info: %p\\n\u0026quot;, stt);\r}\rvoid C_FreeStruct(void *stt) {\rprintf(\u0026quot;free c struct info: %p\\n\u0026quot;, stt);\rC_Struct *cst = (C_Struct*)stt;\rfree(cst);\r}\rvoid C_WithGOCallback(callback cb) {\rchar *str = \u0026quot;operate result\u0026quot;;\rprintf(\u0026quot;start operate\\n\u0026quot;);\rcb(str);\rprintf(\u0026quot;end operate\\n\u0026quot;);\r}\rvoid C_PrintString(char *s) {\rprintf(\u0026quot;%s\\n\u0026quot;, s);\r}\rvoid C_InitArray(char *buf, int len) {\rfor(int i = 0; i \u0026lt; len; i++) {\rbuf[i] = 111;\r}\r}\rclibrary.h\n#ifndef CLIBRARY_H\r#define CLIBRARY_H\rtypedef struct {\rint len;\rchar * buf;\r}C_Struct;\r// transfer go and c struct\rvoid C_InitStruct(void **);\rvoid C_FreeStruct(void *);\r// callback go func pointer\rtypedef void (*callback)(char *);\rvoid C_WithGOCallback(callback);\r// transfer go string\rvoid C_PrintString(char *s);\r// transfer go slice\rvoid C_InitArray(char *buf, int len);\r#endif //CLIBRARY_H\rccallback.go\npackage main\r/*\r#include \u0026lt;stdio.h\u0026gt;\r#include \u0026lt;stdlib.h\u0026gt;\rvoid GO_Callback(char *result);\rvoid C_MiddleCallback(char * result) {\rprintf(\u0026quot;start middle function\\n\u0026quot;);\rGO_Callback(result);\rprintf(\u0026quot;end middle function\\n\u0026quot;);\r}\r*/\rimport \u0026quot;C\u0026quot;\rmain.go\npackage main\r/*\r#cgo CFLAGS: -I .\r#cgo LDFLAGS: -L . -lclibrary\r#include \u0026lt;stdio.h\u0026gt;\r#include \u0026lt;stdlib.h\u0026gt;\r#include \u0026lt;string.h\u0026gt;\r#include \u0026quot;clibrary.h\u0026quot;\rvoid C_MiddleCallback(char * result);\r*/\rimport \u0026quot;C\u0026quot;\rimport (\r\u0026quot;fmt\u0026quot;\r\u0026quot;time\u0026quot;\r\u0026quot;unsafe\u0026quot;\r)\rtype GO_Struct struct {\rlen int\rbuf string\r}\r//export GO_Callback\rfunc GO_Callback(result *C.char) {\rfmt.Println(C.GoString(result))\r}\rfunc main() {\r// cgo transfer struct\rvar gstt unsafe.Pointer\rC.C_InitStruct(\u0026amp;gstt)\rfmt.Println(\u0026quot;transform c struct to go struct:\u0026quot;, gstt)\rC.C_FreeStruct(gstt)\r// cgo transfer go string\rcgostr := C.CString(\u0026quot;Hello World\u0026quot;)\rC.C_PrintString(cgostr)\rC.free(unsafe.Pointer(cgostr))\r// cgo transfer go slice\rgslice := make([]byte, 5)\rC.C_InitArray((*C.char)(unsafe.Pointer(\u0026amp;gslice[0])), C.int(len(gslice)))\rfmt.Println(gslice)\r// cgo callback with go *function\rC.C_WithGOCallback((C.callback)(unsafe.Pointer(C.C_MiddleCallback)))\rselect {\rcase \u0026lt;- time.After(time.Minute):\r}\r}\r执行过程：\ngcc -c clibrary.c ar -rcu libclibrary.a clibrary.o\rgo build ./main\r",
    "ref": "/blog/golang/cgo/"
  },{
    "title": "高防IP服务工作原理和配置",
    "date": "",
    "description": "",
    "body": "概念 高防IP是针对互联网服务器遭受大流量的DDos攻击后， 导致服务不可用的情况下。 用户通过配置高防IP， 将攻击流量引流到高防IP， 并配置一定的转发规则， 将合法的请求转发到源站；\n高防IP包含  SYN Flood UDP Flood ICMP Flood IGMP Flood ACK Flood Ping Sweep  ",
    "ref": "/blog/security/%E9%AB%98%E9%98%B2ip/"
  },{
    "title": "消息队列简介和消息队列中间件",
    "date": "",
    "description": "",
    "body": "消息队列 消息队列是消息的一个链表。 拥有写权限的可以向队列中写入特定格式消息， 拥有读权限可以从队列中读取特定格式消息。\n消息队列中间件 ActiveMQ，RabbitMQ，ZeroMQ，Kafka，MetaMQ，RocketMQ，NSQ，NATS,NATS-Streaming\n意义  解耦： 生产者根据自己逻辑发布消息； 消费者根据需要去订阅；对于多服务依赖有解耦的意义； 异步： 多服务调用，减少同步等待时间； 削峰： 业务系统根据自己的处理能力去消息队列中拿，防止大量信息导致系统崩溃；  问题  高可用：mq 肯定事集群部署，防止单机挂掉，业务停掉； 数据丢失： mq 需要数据本地磁盘持久化；  ",
    "ref": "/blog/message-queue/%E4%B8%AD%E9%97%B4%E4%BB%B6/"
  },{
    "title": "ZooKeeper工作原理",
    "date": "",
    "description": "",
    "body": "ZooKeeper ZooKeeper是一个开源的分布式协调服务， 由雅虎创建， 是Google Chubby的开源实现， 现在被拆分为Hadoop的独立子项目。\n ZookKeeper是一个分布式小文件系统，且被设计为高可用。通过选举算法和集群复制来避免单点故障。 因为是基于文件系统设计， 即使所有ZooKeeper节点全部挂掉， 数据也会持久化， 重启服务器后， 可恢复数据。 ZooKeeper通过mvvc（多版本控制）实现乐观锁，节点更新是原子的，所以不是成功就是失败。  功能简介 分布式系统基于ZooKeeper可以实现诸如： 数据发布/订阅、负载均衡、命名服务、分布式协调/通知、集群管理、Master选举、配置维护、名字服务、分布式同步、分布式锁、分布式队列\n基本概念 集群角色 一个ZooKeeper集群同一时刻只能有一个Leader， 其他都是Follower或Observer\n Leader Follower Observer  ",
    "ref": "/blog/distribution-system/zookeeper/"
  },{
    "title": "Docker部署和配置nsq集群",
    "date": "",
    "description": "",
    "body": "nsq.yml version: '3'\rservices:\rnsqlookupd:\rimage: nsqio/nsq\rcommand: /nsqlookupd\rports:\r- 4160:4160\r- 4161:4161\rnsqd:\rimage: nsqio/nsq\rcommand: /nsqd --lookupd-tcp-address=192.168.20.99:4160 --broadcast-address=192.168.20.99\rdepends_on:\r- nsqlookupd\rports:\r- 4150:4150\r- 4151:4151\rnsqadmin:\rimage: nsqio/nsq\rcommand: /nsqadmin --lookupd-http-address=192.168.20.99:4161\rdepends_on:\r- nsqlookupd\rports:\r- 4171:4171\r",
    "ref": "/blog/message-queue/nsq/docker-%E5%AE%89%E8%A3%85nsq/"
  },{
    "title": "NSQ简介",
    "date": "",
    "description": "",
    "body": "描述 是一个守护进程，负责接收，排队，投递消息给客户端\n参数 -lookupd-tcp-address=: nslookup tcp 监听地址 -broadcast-address=\u0026quot;\u0026quot;: 注册到nslookup地址， 需要显示指定\n",
    "ref": "/blog/message-queue/nsq/nsqd/"
  },{
    "title": "Kafka简介",
    "date": "",
    "description": "",
    "body": "简介 ",
    "ref": "/blog/message-queue/kafka/kafka/"
  },{
    "title": "Docker问题集锦",
    "date": "",
    "description": "",
    "body": " docker 解决 x509: certificate signed by unknown authority # vim /etc/docker/daemon.json\r{ \u0026quot;insecure-registries\u0026quot;: [\u0026quot;registry.svc.xxx.cn\u0026quot;]\r}\r Macos Docker Network 模式\nMacos不支持host模式，因此需要使用端口映射模式  ",
    "ref": "/blog/docker/%E9%97%AE%E9%A2%98/"
  },{
    "title": "Docker在linux上部署和配置",
    "date": "",
    "description": "",
    "body": "Docker Ubuntu安装 下载地址\n查看容器 $ sudo docker ps -a\n查看镜像 $ sudo docker images\n设置容器重启策略 $ docker run xxx --restart\n no: 默认策略，在容器退出时不重启容器 on-failure: 在容器非正常退出时（退出状态非0），才会重启容器 on-failure:3，在容器非正常退出时重启容器，最多重启3次 always: 在容器退出时总是重启容器 unless-stopped: 在容器退出时总是重启容器，但是不考虑在Docker守护进程启动时就已经停止了的容器   如果创建时未指定 启动策略， 可以通过update命令: docker update \u0026ndash;restart=always xxx\n 运行容器 $ docker exec -it xxx /bin/bash\n xxx 容器ID\n 拷贝本地文件到容器 $ docker cp [option] local container:/dir\n -L 保持源文件链接\n 提交镜像 $ docker commit -m=message -a=author containerid imagesname\n保存镜像 $ docker save imageid \u0026gt; image.tar\n加载镜像 $ docker load \u0026lt; image.tar\n使用 Dockerfile 构建镜像 $ docker build -t aishijie/asjview:base Dockerfile-path\nubuntu docker 语言设置   Dockfile 中添加：\nRUN locale-gen en_US.UTF-8\rENV LANG en_US.UTF-8 ENV LANGUAGE en_US:en ENV LC_ALL en_US.UTF-8   /etc/default/locale中添加：\nLANG=en_US.UTF-8\rLANGUAGE=en_US:en\rLC_CTYPE=\u0026quot;en_US.UTF-8\u0026quot;\rLC_NUMERIC=\u0026quot;en_US.UTF-8\u0026quot;\rLC_TIME=\u0026quot;en_US.UTF-8\u0026quot;\rLC_COLLATE=\u0026quot;en_US.UTF-8\u0026quot;\rLC_MONETARY=\u0026quot;en_US.UTF-8\u0026quot;\rLC_MESSAGES=\u0026quot;en_US.UTF-8\u0026quot;\rLC_PAPER=\u0026quot;en_US.UTF-8\u0026quot;\rLC_NAME=\u0026quot;en_US.UTF-8\u0026quot;\rLC_ADDRESS=\u0026quot;en_US.UTF-8\u0026quot;\rLC_TELEPHONE=\u0026quot;en_US.UTF-8\u0026quot;\rLC_MEASUREMENT=\u0026quot;en_US.UTF-8\u0026quot;\rLC_IDENTIFICATION=\u0026quot;en_US.UTF-8\u0026quot;\rLC_ALL=en_US.UTF-8\r  $ locale-gen en_US.UTF-8\n 如果提示没有安装 en_US $ apt-get --reinstall install language-pack-en $ update-locale LC_ALL=en_US.UTF-8 LANG=en_US.UTF-8     安装mysql  $ sudo rm /var/lib/mysql/ -R $sudo rm /etc/mysql/ -R $ sudo apt-get autoremove mysql* --purge $ sudo apt-get remove apparmor // 输入Y回车 $ sudo apt-get install mysql-server mysql-common //重新安装  mysql启动问题 chown -R mysql:mysql /var/lib/mysql\n修改镜像名 docker tag IMAGEID(镜像id) REPOSITORY:TAG（仓库：标签）\n网络模式  host模式\n使用-–net=host指定。 container模式\n使用-–net=container:NAME_or_ID指定。 none模式\n使用-–net=none指定。 bridge模式\n使用-–net=bridge指定，默认设置。  修改docker 映射port 如何对运行中的Docker容器添加端口映射？\n iptables -t nat -A DOCKER -p tcp --dport ${YOURPORT} -j DNAT --to-destination ${CONTAINERIP}:${YOURPORT} iptables -t nat -A POSTROUTING -j MASQUERADE -p tcp --source ${CONTAINERIP} --destination ${CONTAINERIP} --dport ${YOURPORT} iptables -A DOCKER -j ACCEPT -p tcp --destination ${CONTAINERIP} --dport ${YOURPORT}  总共有3条命令，把他们运行在安装了docker的宿主机上。其中就修改两个参数：\n ${CONTAINERIP} 就是对应容器的ip地址，比如我的容器ip地址是 172.17.0.2 ，  容器的IP可以通过如下方式查看  在容器中：ip addr; 在宿主机中: docker inspect 容器名 |grep IPAddress   所以我就把上述的参数换成我的IP地址   ${YOURPORT} 就是要映射出来的端口，我配置的是一个hadoop平台，其端口是50070  所以最终我的几条命令更改如下：\n sudo iptables -t nat -A DOCKER -p tcp --dport 50070 -j DNAT --to-destination 172.17.0.2:50070 sudo iptables -t nat -A POSTROUTING -j MASQUERADE -p tcp --source 172.17.0.2 --destination 172.17.0.2 --dport 50070 sudo iptables -A DOCKER -j ACCEPT -p tcp --destination 172.17.0.2 --dport 50070  supervisorctl 无状态 正常情况下配置正常是能让supervisorctl加载当前supervisor管理的进程信息的，但是有时候换一个docker打包就不一定行。\n这个时候修改 supervisorctl 的链接方式从 serverurl=unix:///tmp/supervisor.sock，切换到serverurl=http://127.0.0.1:9001\n挂载本地磁盘 docker run -v /localDir:/dockerDir\n本地修改docker容器中文件 cd /var/lib/docker/overlay2\rfind ./ -name you_err_conf_file\rdocker 映射地址段 $ docker run xxx -p 44000-65000:44000-65000\n",
    "ref": "/blog/docker/docker/"
  },{
    "title": "方法论和世界观",
    "date": "",
    "description": "",
    "body": "方法论 是人们认识世界改变世界的的根本方法。\r 世界观 通俗讲就是”观世界“， 是人们对世界的总体看法和根本观点。\r 关系  世界观主要解决世界”是什么“的问题，方法论主要解决”怎么办“的问题。\n方法论是一种以解决问题为目标的体系，通常涉及对问题阶段、人物、工具、方法技巧的论述。方法论会对一系列具体的方法进行分析研究、系统总结并最终提出解决问题的较为一般性的规则。\n世界观原则在认识和实践的过程中的运用表现为方法。方法论是这些方法的理论，没有和世界观相分离、相分裂的孤立的方法论；也没有不具备方法论意义的纯粹的世界观。\n一般来说有什么样的世界观就有什么样的方法论。\n ",
    "ref": "/blog/stories/%E6%96%B9%E6%B3%95%E8%AE%BA%E5%92%8C%E4%B8%96%E7%95%8C%E8%A7%82/"
  },{
    "title": "MongoDB数据库安装配置",
    "date": "",
    "description": "",
    "body": "远程访问 修改 /etc/mongod.conf: bindIpAll:true\n",
    "ref": "/blog/database/mongo/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"
  },{
    "title": "MongoDB数据库常用sql语句",
    "date": "",
    "description": "",
    "body": "备份数据库 mongodump -h dbhost -d dbname -o dumpdir\n备份数据库表 mongoexport -d dbname -c collectionname -o file --type json/csv -f field\r参数说明：\r-d ：数据库名\r-c ：collection名\r-o ：输出的文件名\r--type ： 输出的格式，默认为json\r-f ：输出的字段，如果-type为csv，则需要加上-f \u0026quot;字段名\u0026quot;\r还原数据库 mongorestore -h dbhost -d dbname dumppath\n还原数据库表 mongoimport -d dbname -c collectionname --file filename --headerline --type json/csv -f field\r参数说明：\r-d ：数据库名\r-c ：collection名\r--type ：导入的格式默认json\r-f ：导入的字段名\r--headerline ：如果导入的格式是csv，则可以使用第一行的标题作为导入的字段\r--file ：要导入的文件\r还原数据库表json mongoimport \u0026ndash;db meteor \u0026ndash;collection meetings \u0026ndash;type json \u0026ndash;file /asj/meteor-batch/meetings.json \u0026ndash;jsonArray -h 127.0.1.1\n",
    "ref": "/blog/database/mongo/sql%E8%AF%AD%E5%8F%A5/"
  },{
    "title": "Golang validator应用",
    "date": "",
    "description": "",
    "body": "",
    "ref": "/blog/golang/validator/"
  },{
    "title": "从GW和IM实战描述websocket协议",
    "date": "",
    "description": "",
    "body": "描述 用于在单个tcp连接上进行全双工通信的协议；RFC6455标准；\n",
    "ref": "/blog/network/websocket/"
  },{
    "title": "流媒体学习-Flv视频封装格式",
    "date": "",
    "description": "",
    "body": "简介 FLV(Flash Video) 是Adobe公司开发的一种流媒体格式，由其封装的视频文件体积小、封装简单。FLV可以使用Flash Player播放。FLV封装的视频文件后缀通常为.flv。\n FLV包含两部分，文件头(file header)和文件体(file body)。文件体由一系列Tag组成。\n FLV Header    字段名 字段大小 字段描述     Signature 3Byte 文件标识(FLV)   Version 1Byte 版本号（0x01)   Flags 1Byte 前5位保留为0，第6位表示是否有音频Tag，第7位保留为0，第8位表示是否有视频Tag。   HeaderSize 4Byte 表示从file header开始到file body开始的字节数，版本1总为9。    FLV Body  间隔包含Previous Tag Size字段，标识前一个Tag大小。\n    Previous Tag Size Tag1 \u0026hellip; Previous Tag Size Tagn    Tag    Tag Header Tag Data    Tag Header    字段 字段大小 字段描述     Type 1Byte 标识Tag类型，音频(0x08)、视频(0x09)、script data(0x12),其他值保留   Datasize 3Byte 标识Tag Data数据大小   Timestamp 3Byte 标识Tag时间戳   Timestamp_ex 1Byte 时间戳扩展字节，24字节数值不够时，该字节最高位将时间戳扩展为32位数。   StreamID 3Byte stream id 总是0    Tag Data 不同类型Tag的data部分结构不同；\nAudio Tag Data 音频Tag Data开始的第一个字节包含了音频数据的参数信息，第二个字节开始为音频流数据。\n   音频编码类型 采样率 精度 类型 数据\u0026hellip;     4bit 2bit 1bit 1bit \u0026hellip;    音频编码类型 Audio Tag Data的前4bit标识音频编码类型。\n   值 含义     0 Linear PCM，platform endian   1 ADPCM   2 MP3   3 Linear PCM，little endian   4 Nellymoser 16-kHz mono   5 Nellymoser 8-kHz mono   6 Nellymoser   7 G.711 A-law logarithmic PCM   8 G.711 mu-law logarithmic PCM   9 reserved   10 AAC   14 MP3 8-Khz   15 Device-specific sound    采样率    值 含义     0 5.5kHz   1 11KHz   2 22 kHz   3 44 kHz    音频采样精度    值 含义     0 8bits   1 16bits    音频类型    值 含义     0 sndMono   1 sndStereo    Video Tag Data 视频Tag Data开始的第一个字节包含了视频数据的参数信息，第二个字节开始为视频流数据。\n   帧类型 视频编码类型 数据\u0026hellip;     4bit 4bit \u0026hellip;    帧类型    值 含义     1 keyframe （for AVC，a seekable frame）   2 inter frame （for AVC，a nonseekable frame）   3 disposable inter frame （H.263 only）   4 generated keyframe （reserved for server use）   5 video info/command frame    视频编码类型 ",
    "ref": "/blog/mediastream/flv%E5%B0%81%E8%A3%85%E6%A0%BC%E5%BC%8F%E8%A7%A3%E6%9E%90/"
  },{
    "title": "流媒体学习-H264视频编解码",
    "date": "",
    "description": "",
    "body": "H.264 H.264原始码流（“裸流”）的基本单元是NALU。\n NALU之间通过startcode（起始码）分隔。\n起始码分为0x000001(3Byte)或0x00000001(4Byte)。\nH.264码流的解析步骤就是首先从码流中搜索起始码，分离出NALU，然后在分析NALU的各个字段。\n ",
    "ref": "/blog/mediastream/h264%E8%A7%86%E9%A2%91%E7%A0%81%E6%B5%81%E8%A7%A3%E6%9E%90/"
  },{
    "title": "流媒体学习-音频码流格式",
    "date": "",
    "description": "",
    "body": "AAC AAC原始码流（“裸流”）的基本单元是ADTS frame。\n 其中每个ADTS frame之间通过syncword（同步字）分隔。\n同步字为0xfff。\nAAC码流解析的步骤就是从码流中搜索syncword,分离出ADTS frame，然后再解析ADTS frame 字段。\n ",
    "ref": "/blog/mediastream/aac%E9%9F%B3%E9%A2%91%E7%A0%81%E6%B5%81%E8%A7%A3%E6%9E%90/"
  },{
    "title": "Linux TCP/IP内核参数调优",
    "date": "",
    "description": "",
    "body": "Sysctl命令 用来配置与查看在/proc/sys目录中的内核参数。如果想使参数长期保存，可以通过编辑/etc/sysctl.conf文件来实现。\n命令格式：\n sysctl [-n] [-e] -w variable=value\rsysctl [-n] [-e] -p (default /etc/sysctl.conf)\rsysctl [-n] [-e] –a\r常用参数的意义：\n -w 临时改变某个指定参数的值，如: $ sysctl -w net.ipv4.ip_forward=1 -a 显示所有的系统参数 -p 从指定的文件加载系统参数,默认从/etc/sysctl.conf 文件中加载，如： echo 1 \u0026gt; /proc/sys/net/ipv4/ip_forward sysctl -w net.ipv4.ip_forward=1   以上两种方法都可能立即开启路由功能，但如果系统重启，或执行了$ service network restart命令，所设置的值即会丢失。\n如果想永久保留配置，可以修改/etc/sysctl.conf文件，将 net.ipv4.ip_forward=0改为net.ipv4.ip_forward=1\n内核参数调整 内核参数调整有两种方式\n  修改/proc下内核参数文件内容，不能使用编辑器来修改内核参数文件，理由是由于内核随时可能更改这些文件中的任意一个， 另外，这些内核参数文件都是虚拟文件，实际中不存在，因此不能使用编辑器进行编辑，而是使用echo命令，然后从命令行将输出重定向至 /proc 下所选定的文件中。 如：将 timeout_timewait 参数设置为30秒：$ echo 30 \u0026gt; /proc/sys/net/ipv4/tcp_fin_timeout。\n参数修改后立即生效，但是重启系统后，该参数又恢复成默认值。因此，想永久更改内核参数，需要修改/etc/sysctl.conf文件。\n  修改/etc/sysctl.conf文件。检查sysctl.conf文件，如果已经包含需要修改的参数，则修改该参数的值,如果没有需要修改的参数， 在sysctl.conf文件中添加该参数。如：net.ipv4.tcp_fin_timeout=30。保存退出后，可以重启机器使参数生效，如果想使参数马上生效， 也可以执行如下命令：$ sysctl -p。\n  sysctl.conf说明    名称 区间 默认值 建议值 描述     - - - - 目录/proc/sys/net/ipv4/   tcp_syn_retries  5 1 对于一个新建连接，内核要发送多少个 SYN 连接请求才决定放弃。不应该大于255，默认值是5，对应于180秒左右时间。。(对于大负载而物理通信良好的网络而言,这个值偏高,可修改为2.这个值仅仅是针对对外的连接,对进来的连接,是由tcp_retries1决定的)   tcp_synack_retries  5 1 对于远端的连接请求SYN，内核会发送SYN ＋ ACK数据报，以确认收到上一个 SYN连接请求包。这是所谓的三次握手( threeway handshake)机制的第二个步骤。这里决定内核在放弃连接之前所送出的 SYN+ACK 数目。不应该大于255，默认值是5，对应于180秒左右时间。   tcp_keepalive_time  7200 600 TCP发送keepalive探测消息的间隔时间（秒），用于确认TCP连接是否有效。防止两边建立连接但不发送数据的攻击。   tcp_keepalive_probes  9 3 TCP发送keepalive探测消息的间隔时间（秒），用于确认TCP连接是否有效。   tcp_keepalive_intvl  75 15 探测消息未获得响应时，重发该消息的间隔时间（秒）。默认值为75秒。 (对于普通应用来说,这个值有一些偏大,可以根据需要改小.特别是web类服务器需要改小该值,15是个比较合适的值)   tcp_retries1  3 3 放弃回应一个TCP连接请求前﹐需要进行多少次重试。RFC 规定最低的数值是3   tcp_retries2  15 5 在丢弃激活(已建立通讯状况)的TCP连接之前﹐需要进行多少次重试。默认值为15，根据RTO的值来决定，相当于13-30分钟(RFC1122规定，必须大于100秒).(这个值根据目前的网络设置,可以适当地改小)   tcp_orphan_retries  7 3 在近端丢弃TCP连接之前﹐要进行多少次重试。默认值是7个﹐相当于 50秒 - 16分钟﹐视 RTO 而定。如果您的系统是负载很大的web服务器﹐那么也许需要降低该值﹐这类 sockets 可能会耗费大量的资源。另外参的考tcp_max_orphans。(事实上做NAT的时候,降低该值也是好处显著的,我本人的网络环境中降低该值为3)   tcp_fin_timeout  60 2 对于本端断开的socket连接，TCP保持在FIN-WAIT-2状态的时间。对方可能会断开连接或一直不结束连接或不可预料的进程死亡。默认值为 60 秒。   tcp_max_tw_buckets  180000 36000 系统在同时所处理的最大 timewait sockets 数目。如果超过此数的话﹐time-wait socket 会被立即砍除并且显示警告信息。之所以要设定这个限制﹐纯粹为了抵御那些简单的 DoS 攻击﹐不过﹐如果网络条件需要比默认值更多﹐则可以提高它(或许还要增加内存)。(事实上做NAT的时候最好可以适当地增加该值)   tcp_tw_recycle  0 1 打开快速 TIME-WAIT sockets 回收。除非得到技术专家的建议或要求﹐请不要随意修改这个值。(做NAT的时候，建议打开它)   tcp_tw_reuse  0 1 表示是否允许重新应用处于TIME-WAIT状态的socket用于新的TCP连接(这个对快速重启动某些服务,而启动后提示端口已经被使用的情形非常有帮助)   tcp_max_orphans  8192 32768 系统所能处理不属于任何进程的TCP sockets最大数量。假如超过这个数量﹐那么不属于任何进程的连接会被立即reset，并同时显示警告信息。之所以要设定这个限制﹐纯粹为了抵御那些简单的 DoS 攻击﹐千万不要依赖这个或是人为的降低这个限制。如果内存大更应该增加这个值。(这个值Redhat AS版本中设置为32768,但是很多防火墙修改的时候,建议该值修改为2000)   tcp_abort_on_overflow  0 0 当守护进程太忙而不能接受新的连接，就象对方发送reset消息，默认值是false。这意味着当溢出的原因是因为一个偶然的猝发，那么连接将恢复状态。只有在你确信守护进程真的不能完成连接请求时才打开该选项，该选项会影响客户的使用。(对待已经满载的sendmail,apache这类服务的时候,这个可以很快让客户端终止连接,可以给予服务程序处理已有连接的缓冲机会,所以很多防火墙上推荐打开它)   tcp_syncookies  0 1 只有在内核编译时选择了CONFIG_SYNCOOKIES时才会发生作用。当出现syn等候队列出现溢出时象对方发送syncookies。目的是为了防止syn flood攻击。   tcp_stdurg  0 0 使用 TCP urg pointer 字段中的主机请求解释功能。大部份的主机都使用老旧的 BSD解释，因此如果您在 Linux 打开它﹐或会导致不能和它们正确沟通。   tcp_max_syn_backlog  1024 16384 对于那些依然还未获得客户端确认的连接请求﹐需要保存在队列中最大数目。对于超过 128Mb 内存的系统﹐默认值是 1024 ﹐低于 128Mb 的则为 128。如果服务器经常出现过载﹐可以尝试增加这个数字。警告﹗假如您将此值设为大于 1024﹐最好修改include/net/tcp.h里面的TCP_SYNQ_HSIZE﹐以保持TCP_SYNQ_HSIZE16(SYN Flood攻击利用TCP协议散布握手的缺陷，伪造虚假源IP地址发送大量TCP-SYN半打开连接到目标系统，最终导致目标系统Socket队列资源耗尽而无法接受新的连接。为了应付这种攻击，现代Unix系统中普遍采用多连接队列处理的方式来缓冲(而不是解决)这种攻击，是用一个基本队列处理正常的完全连接应用(Connect()和Accept() )，是用另一个队列单独存放半打开连接。这种双队列处理方式和其他一些系统内核措施(例如Syn-Cookies/Caches)联合应用时，能够比较有效的缓解小规模的SYN Flood攻击(事实证明)   tcp_window_scaling  1 1 该文件表示设置tcp/ip会话的滑动窗口大小是否可变。参数值为布尔值，为1时表示可变，为0时表示不可变。tcp/ip通常使用的窗口最大可达到 65535 字节，对于高速网络，该值可能太小，这时候如果启用了该功能，可以使tcp/ip滑动窗口大小增大数个数量级，从而提高数据传输的能力(RFC 1323)。（对普通地百M网络而言，关闭会降低开销，所以如果不是高速网络，可以考虑设置为0）   tcp_timestamps  1 1 Timestamps 用在其它一些东西中﹐可以防范那些伪造的 sequence 号码。一条1G的宽带线路或许会重遇到带 out-of-line数值的旧sequence 号码(假如它是由于上次产生的)。Timestamp 会让它知道这是个 \u0026lsquo;旧封包\u0026rsquo;。(该文件表示是否启用以一种比超时重发更精确的方法（RFC 1323）来启用对 RTT 的计算；为了实现更好的性能应该启用这个选项。)   tcp_sack  1 1 使用 Selective ACK﹐它可以用来查找特定的遗失的数据报\u0026mdash; 因此有助于快速恢复状态。该文件表示是否启用有选择的应答（Selective Acknowledgment），这可以通过有选择地应答乱序接收到的报文来提高性能（这样可以让发送者只发送丢失的报文段）。(对于广域网通信来说这个选项应该启用，但是这会增加对 CPU 的占用。)   tcp_fack  1 1 打开FACK拥塞避免和快速重传功能。(注意，当tcp_sack设置为0的时候，这个值即使设置为1也无效)[这个是TCP连接靠谱的核心功能]   tcp_dsack  1 1 允许TCP发送\u0026quot;两个完全相同\u0026quot;的SACK。   tcp_ecn  0 0 TCP的直接拥塞通告功能。   tcp_reordering  3 6 TCP流中重排序的数据报最大数量。 (一般有看到推荐把这个数值略微调整大一些,比如5)   tcp_retrans_collapse  1 0 对于某些有bug的打印机提供针对其bug的兼容性。(一般不需要这个支持,可以关闭它)   tcp_wmem    发送缓存设置   tcp_wmem min 4096 8192 min：为TCP socket预留用于发送缓冲的内存最小值。每个tcp socket都可以在建议以后都可以使用它。默认值为4096(4K)。   tcp_wmem default 16384 131072 default：为TCP socket预留用于发送缓冲的内存数量，默认情况下该值会影响其它协议使用的net.core.wmem_default 值，一般要低于net.core.wmem_default的值。默认值为16384(16K)。   tcp_wmem max 131072 16777216 max:用于TCP socket发送缓冲的内存最大值。该值不会影响net.core.wmem_max，\u0026ldquo;静态\u0026quot;选择参数SO_SNDBUF则不受该值影响。默认值为131072(128K)。（对于服务器而言，增加这个参数的值对于发送数据很有帮助）   tcp_rmem min 4096 32768 接收缓存设置。同tcp_wmem   tcp_rmem default 87380 131072    tcp_rmem max 174760 16777216    tcp_mem    一般情况下这些值是在系统启动时根据系统内存数量计算得到的。   tcp_mem min 根据内存计算 786432 low：当TCP使用了低于该值的内存页面数时，TCP不会考虑释放内存。即低于此值没有内存压力。(理想情况下，这个值应与指定给 tcp_wmem 的第 2 个值相匹配 - 这第 2 个值表明，最大页面大小乘以最大并发请求数除以页大小 (131072 300 / 4096)。 )   tcp_mem default 根据内存计算 1048576 pressure：当TCP使用了超过该值的内存页面数量时，TCP试图稳定其内存使用，进入pressure模式，当内存消耗低于low值时则退出pressure状态。(理想情况下这个值应该是 TCP 可以使用的总缓冲区大小的最大值 (204800 300 / 4096)。 )   tcp_mem max 根据内存计算 1572864 high：允许所有tcp sockets用于排队缓冲数据报的页面量。(如果超过这个值，TCP 连接将被拒绝，这就是为什么不要令其过于保守 (512000 300 / 4096) 的原因了。 在这种情况下，提供的价值很大，它能处理很多连接，是所预期的 2.5 倍；或者使现有连接能够传输 2.5 倍的数据。)   tcp_app_win  31 31 保留max(window/2^tcp_app_win, mss)数量的窗口由于应用缓冲。当为0时表示不需要缓冲。   tcp_adv_win_scale  2 2 计算缓冲开销bytes/2^tcp_adv_win_scale(如果tcp_adv_win_scale \u0026gt; 0)或者bytes-bytes/2^(-tcp_adv_win_scale)(如果tcp_adv_win_scale BOOLEAN\u0026gt;0)   tcp_low_latency  0 0 允许 TCP/IP 栈适应在高吞吐量情况下低延时的情况；这个选项一般情形是的禁用。(但在构建Beowulf 集群的时候,打开它很有帮助)   tcp_westwood  0 0 启用发送者端的拥塞控制算法，它可以维护对吞吐量的评估，并试图对带宽的整体利用情况进行优化；对于 WAN 通信来说应该启用这个选项。   tcp_bic  0 0 为快速长距离网络启用 Binary Increase Congestion；这样可以更好地利用以 GB 速度进行操作的链接；对于 WAN 通信应该启用这个选项。   ip_forward  0 － NAT必须开启IP转发支持，把该值写1   ip_local_port_range min 32768 1024 表示用于向外连接的端口范围，默认比较小，这个范围同样会间接用于NAT表规模。   ip_local_port_range max 61000 65000    ip_conntrack_max  65535 65535 系统支持的最大ipv4连接数，默认65536（事实上这也是理论最大值），同时这个值和你的内存大小有关，如果内存128M，这个值最大8192，1G以上内存这个值都是默认65536   - - - - 目录/proc/sys/net/ipv4/netfilter, 只有打开防火墙，文件才会存在   ip_conntrack_max  65536 65536 系统支持的最大ipv4连接数，默认65536（事实上这也是理论最大值），同时这个值和你的内存大小有关，如果内存128M，这个值最大8192，1G以上内存这个值都是默认65536,这个值受/proc/sys/net/ipv4/ip_conntrack_max限制   ip_conntrack_tcp_timeout_established  432000 180 已建立的tcp连接的超时时间，默认432000，也就是5天。影响：这个值过大将导致一些可能已经不用的连接常驻于内存中，占用大量链接资源，从而可能导致NAT ip_conntrack: table full的问题。建议：对于NAT负载相对本机的NAT表大小很紧张的时候，可能需要考虑缩小这个值，以尽早清除连接，保证有可用的连接资源；如果不紧张，不必修改   ip_conntrack_tcp_timeout_time_wait  120 120 time_wait状态超时时间，超过该时间就清除该连接   ip_conntrack_tcp_timeout_close_wait  60 60 close_wait状态超时时间，超过该时间就清除该连接   ip_conntrack_tcp_timeout_fin_wait  120 120 fin_wait状态超时时间，超过该时间就清除该连接   - - - - 目录/proc/sys/net/core   netdev_max_backlog  1024 16384 每个网络接口接收数据包的速率比内核处理这些包的速率快时，允许送到队列的数据包的最大数目，对重负载服务器而言，该值需要调高一点。   somaxconn  128 16384 用来限制监听(LISTEN)队列最大数据包的数量，超过这个数量就会导致链接超时或者触发重传机制。web应用中listen函数的backlog默认会给我们内核参数的net.core.somaxconn限制到128，而nginx定义的NGX_LISTEN_BACKLOG默认为511，所以有必要调整这个值。对繁忙的服务器,增加该值有助于网络性能   wmem_default  129024 129024 默认的发送窗口大小（以字节为单位）   rmem_default  129024 129024 默认的接收窗口大小（以字节为单位）   rmem_max  129024 873200 最大的TCP数据接收缓冲   wmem_max  129024 873200 最大的TCP数据发送缓冲    ",
    "ref": "/blog/linux/core-tcp-ip/"
  },{
    "title": "Ubuntu Hotspot配置",
    "date": "",
    "description": "开启ubuntu下wifi 热点",
    "body": "背景 配置瘦客户机，进行自组网，摒弃复杂的网络环境\n环境配置   网卡Master模式\n 安装 $ apt install iw 检查 iw list  Supported interface modes:\r* IBSS\r* managed //作为客户端接入AP\r* AP // 作为无线接入点使用\r* AP/VLAN\r* monitor\r* P2P-client\r* P2P-GO\r* P2P-device\r 如果显示以上内容，则该网卡支持作为无线AP使用\n   Wlan Interface\n 查看: ifconfig -a enp2s0: flags=4163\u0026lt;UP,BROADCAST,RUNNING,MULTICAST\u0026gt; mtu 1500\rinet 172.16.3.173 netmask 255.255.255.0 broadcast 172.16.3.255\rinet6 fe80::6600:6aff:fe02:755a prefixlen 64 scopeid 0x20\u0026lt;link\u0026gt;\rether 64:00:6a:02:75:5a txqueuelen 1000 (Ethernet)\rRX packets 63949 bytes 79546938 (79.5 MB)\rRX errors 0 dropped 2 overruns 0 frame 0\rTX packets 45238 bytes 4261910 (4.2 MB)\rTX errors 0 dropped 0 overruns 0 carrier 0 collisions 0\rlo: flags=73\u0026lt;UP,LOOPBACK,RUNNING\u0026gt; mtu 65536\rinet 127.0.0.1 netmask 255.0.0.0\rinet6 ::1 prefixlen 128 scopeid 0x10\u0026lt;host\u0026gt;\rloop txqueuelen 1000 (Local Loopback)\rRX packets 47213 bytes 6617452 (6.6 MB)\rRX errors 0 dropped 0 overruns 0 frame 0\rTX packets 47213 bytes 6617452 (6.6 MB)\rTX errors 0 dropped 0 overruns 0 carrier 0 collisions 0\rwlp3s0: flags=4098\u0026lt;BROADCAST,MULTICAST\u0026gt; mtu 1500\rether 60:57:18:54:4b:a6 txqueuelen 1000 (Ethernet)\rRX packets 33 bytes 5886 (5.8 KB)\rRX errors 0 dropped 0 overruns 0 frame 0\rTX packets 44 bytes 7692 (7.6 KB)\rTX errors 0 dropped 0 overruns 0 carrier 0 collisions 0\r wlp3s0 无线网卡\n     Hostapd\n 安装 $ apt install hostapd 配置/etc/hostapd/hostapd.conf： #sets the wifi interface to use, is wlan0 in most cases\rinterface=wlp3s0\r#driver to use, nl80211 works in most cases\rdriver=nl80211\r#sets the ssid of the virtual wifi access point\rssid=wonderfull\r#sets the mode of wifi, depends upon the devices you will be using. It can be a,b,g,n. Setting to g ensures backward compatiblity.\rhw_mode=g\r#sets the channel for your wifi\rchannel=6\r#macaddr_acl sets options for mac address filtering. 0 means “accept unless in deny list”\rmacaddr_acl=0\r#setting ignore_broadcast_ssid to 1 will disable the broadcasting of ssid\rignore_broadcast_ssid=0\r#Sets authentication algorithm\r#1 - only open system authentication\r#2 - both open system authentication and shared key authentication\rauth_algs=1\r#####Sets WPA and WPA2 authentication#####\r#wpa option sets which wpa implementation to use\r#1 - wpa only\r#2 - wpa2 only\r#3 - both\rwpa=3\r#sets wpa passphrase required by the clients to authenticate themselves on the network\rwpa_passphrase=wonderfull\r#sets wpa key management\rwpa_key_mgmt=WPA-PSK\r#sets encryption used by WPA\rwpa_pairwise=TKIP\r#sets encryption used by WPA2\rrsn_pairwise=CCMP\r 配置/etc/default/hostapd.conf # Defaults for hostapd initscript\r# # See /usr/share/doc/hostapd/README.Debian for information about alternative\r# methods of managing hostapd.\r#\r# Uncomment and set DAEMON_CONF to the absolute path of a hostapd configuration\r# file and hostapd will be started during system boot. An example configuration\r# file can be found at /usr/share/doc/hostapd/examples/hostapd.conf.gz\r#\rDAEMON_CONF=\u0026quot;/etc/hostapd/hostapd.conf\u0026quot;\r    DHCP\n 安装DHCP服务器: $ sudo apt install isc-dhcp-server 配置/etc/dhcp/dhcpd.conf: ddns-update-style none;\rignore client-updates;\rauthoritative;\roption local-wpad code 252 = text;\roption domain-name-servers 10.10.10.100, 8.8.8.8, 8.8.4.4;\rsubnet 10.10.10.0 netmask 255.255.255.0 {\r# --- default gateway\roption routers 10.10.10.100;\r# --- Netmask\roption subnet-mask 255.255.255.0;\r# --- Broadcast Address\roption broadcast-address 10.10.10.255;\r# --- Domain name servers, tells the clients which DNS servers to use.\roption time-offset 0;\rrange 10.10.10.110 10.10.10.170;\rdefault-lease-time 1209600;\rmax-lease-time 1814400;\r}\r 配置/etc/default/isc-dhcp-server # On what interfaces should the DHCP server (dhcpd) serve DHCP requests?\r# Separate multiple interfaces with spaces, e.g. \u0026quot;eth0 eth1\u0026quot;.\rINTERFACESv4=\u0026quot;wlp3s0\u0026quot;\rINTERFACESv6=\u0026quot;\u0026quot;\r 应用dhcp到wlp3s0网口\n     启动热点\n 脚本hotspot.sh #!/bin/bash\r#Initial wifi interface configuration\rifconfig $1 up 10.10.10.100 netmask 255.255.255.0\rsleep 2\r###########Start DHCP, comment out / add relevant section##########\r#Doesn’t try to run dhcpd when already running\rservice isc-dhcp-server restart\r###########\r#Enable NAT\riptables --flush\riptables --table nat --flush\riptables --delete-chain\riptables --table nat --delete-chain\riptables --table nat --append POSTROUTING --out-interface $2 -j MASQUERADE\riptables --append FORWARD --in-interface $1 -j ACCEPT\r#Uncomment the line below if facing problems while sharing PPPoE, see lorenzo’s comment for more details\r#iptables -I FORWARD -p tcp --tcp-flags SYN,RST SYN -j TCPMSS --clamp-mss-to-pmtu\rsysctl -w net.ipv4.ip_forward=1\r#start hostapd\rservice hostapd restart  执行 sudo ./hotspot.sh wlp3s0 enp2s0    ",
    "ref": "/blog/linux/ubuntu-hotspot/"
  },{
    "title": "流媒体学习-开源网站",
    "date": "",
    "description": "记录流媒体学习、应用网站",
    "body": "golang webrtc https://github.com/pion\n",
    "ref": "/blog/mediastream/%E5%BC%80%E6%BA%90%E7%BD%91%E7%AB%99/"
  },{
    "title": "流媒体学习-视频像素格式",
    "date": "",
    "description": "",
    "body": "视频像素数据 格式 数据格式为\n Planar(YUV):分量分块存储； Packed(RGB):分量连续村粗。   注：像素的采样位数根据图像不同获取。本文默认采样位数为8bit，所以一个像素采样值为1Byte。\n YUV 分离Y、U、V分量 一帧YUV像素数据得宽和高为w 和 h，那么一帧YUV像素数据大小为:w*h*3/2 Byte;\n Y分量：前w*h Byte\nU分量：中间w*h/4 Byte\nV分量：后面w*h/4 Byte\n Y、U、V分量功能 更改图像灰度 只需将U、V分量设置为128（无色）\n U、V是图像的色度分量。由于色度分量会进行偏置处理（-128）所以这里的无色为128；\n 更改图像亮度 只需将Y分量每个像素点除以2；\n Y是图像的亮度分量。\n PSNR PSNR是最基本的视频质量评价方法。\nRGB 分离R、G、B分量 一帧RGB像素数据的宽和高为w和h,那么一帧RGB像素数据大小为w*h*3Byte；\n R、G、B分量连续存储， 存储格式为：R1,G1,B1,\u0026hellip;,Rn,Gn,Bn。\n RGB转换成BMP BMP采用小端存储方式（B、G、R），因此将RGB像素数据中的R和B分量顺序进行交换。\nRGB和YUV转换 Y= 0.299*R+0.587*G+0.114*B\rU=-0.147*R-0.289*G+0.463*B\rV= 0.615*R-0.515*G-0.100*B\r",
    "ref": "/blog/mediastream/%E8%A7%86%E9%A2%91%E5%83%8F%E7%B4%A0%E6%95%B0%E6%8D%AE/"
  },{
    "title": "流媒体学习-音频采样格式",
    "date": "",
    "description": "",
    "body": "音频采样数据 保存格式：pcm文件\n格式  左声道数据 右声道数据   注：左声道和右声道数据间隔存储，声道的每个样值大小根据采样格式决定。\n 增、降音量值 将声道的每个样值做加、减法。\n提高速度 根据速度间隔获取样值。\n截取音频 从指定采样点截取指定长度的音频\n采样数据格式转换 将PCM16LE双声道音频采样数据转换为WAVE格式音频数据  wave格式音频实在pcm文件的前面添加一个文件头，从而封装成wave格式音频。\n ",
    "ref": "/blog/mediastream/%E9%9F%B3%E9%A2%91%E9%87%87%E6%A0%B7%E6%95%B0%E6%8D%AE/"
  },{
    "title": "流媒体学习-流媒体名词解释",
    "date": "",
    "description": "了解流媒体技术常用名称",
    "body": "入门 封装格式 将音频、视频打包成一个文件的规范，主要是把视频码流和音频码流按一定格式存储在一个文件中。\n mp4,flv,mkv,avi,rmvb,mkv\n不同封装格式差距不大，支持的音视频编码标准也不一样。如：mkv封装格式支持的音视频编码标准十分广泛；\nrmvb封装格式制车的音视频编码标准比较少。\n 查看音视频文件信息工具： mediainfo（https://github.com/MediaArea/MediaInfo）。\n常见封装格式    名称 推出机构 流媒体 支持的视频编码 支持的音频编码 应用领域     AVI Microsoft Inc. 不支持 几乎所有格式 几乎所有格式 BT下载影视   MP4 MPEG 支持 MPEG-2,MPEG-4,H.264,H.263等 AAC,MPEG-1 Layers I,II,III,AC-3等 互联网视频网站   TS MPEG 支持 MPEG-1,MPEG-2,MPEG-4,H.264 AAC,MPEG-1 Layers I,II,III IPTV,数字电视   FLV Adobe Inc. 支持 Sorenson,VP6,H.264 MP3,ADPCM,Linear PCM,AAC等 互联网视频网站   MKV CoreCodec Inc. 支持 几乎所有格式 几乎所有格式 互联网视频网站   RMVB Real Networks Inc. 支持 RealVideo 8,9,10 AAC,Cook Codec, RealAudio Lossless BT下载影视    视频编码 将视频像素数据（RGB,YUV）按算法压缩成视频码流，降低视频的数据量。\n 视频数据不经过压缩会非常巨大，一部电影可能就要上百G。视频码流占了音视频数据的绝大部分。\n 常见视频编码    名称 推出机构 时间     H.265 MPEG/ITU-T 2013   H.264 MPEG/ITU-T 2003   MPEG4 MPEG 2001   MPEG2 MPEG 1994   VP9 Google 2013   VP8 Google 2008   VC-1 Microsoft Inc. 2006    编码标准 H.264 等仅仅是编码标准，而不是具体编码器，只是给编码器的实现提供具体参考。\n 国产视频编码标准：AVS。\n 音频编码 将音频采样数据（PCM）压缩成音频码流，降低音频数据量。\n 一般情况音频的数据量要远小于视频的数据量。\n 常见音频编码    名称 推出机构 时间     AAC MPEG 1997   AC-3 Dolby Inc. 1992   MP3 Mpeg 1993   WMA Microsoft Inc. 1999    流媒体协议 流媒体协议是服务器和客户端在音视频数据传输过程中应遵循的规定。\n常见流媒体协议    名称 推出机构 传输成协议 客户端 使用领域     RTSP+RTP IETF TCP+UDP VLC,WMP IPTV   RTMP Adobe Inc. Tcp Flash 互联网直播   RTMFP Adobe Inc. UDP Flash 互联网直播   MMS Microsoft Inc. TCP/UDP WMP 互联网直播,点播   HTTP WWW+IETF TCP Flash 互联网点播     RTSP+RTP 采用UDP传输音视频，支持组播，效率高，用于IPTV领域。但是网络不好情况容易丢包。 RTMP/HTTP/MMS 采用TCP协议，不会发生丢包，可以保证视频质量，多用于互联网音视频服务中。但是传输效率相对较低。 RTMFP是一种比较新的流媒体协议，特点是支持P2P。   流媒体协议在传输音视频数据的同时，也传输信令数据以及网络状态。信令数据包包含对播放的控制（播放、暂停、停止）。\n 现有网络音视频平台对比 现有网络视频服务主要有：点播和直播。\n点播：根据用户需要播放响应视频节目；\n直播：互联网音视频平台将内容直接实时发送给用户。\n直播平台参数 直播平台普遍采用RTMP作为流媒体协议，FLV作为封装格式，H.264作为视频编码格式，AAC作为音频编码格式。\n RTMP 协议被Flash支持，由此可以实现流媒体直播平台的“无插件播放”。\nFLV 是RTMP的封装格式。\n 点播平台参数 点播平台普遍采用HTTP作为流媒体协议，H.264作为视频编码格式，AAC作为音频编码格式。\n HTTP点播，不会出现丢包现象而且HTTP被大多数web服务器支持。\n 视频播放器原理 视频播放器播放一个互联网上的视频文件，需要经过以下步骤：\n 解协议:将流媒体协议的数据，解析为标准的封装格式数据。解析过程会去除信令数据只保留音视频数据。 解封装：将封装格式的数据分离成音频流和视频流压缩编码数据。 解码音视频：将音视频压缩编码数据解码成非压缩的音视频原始数据。 音视频同步：根据解封装模块获取的参数信息，同步解码出来的音视频数据，并将音视频数据传输到显卡和声卡播放。  ",
    "ref": "/blog/mediastream/%E5%85%A5%E9%97%A8/"
  },{
    "title": "数据结构-RingBuffer",
    "date": "",
    "description": "",
    "body": "",
    "ref": "/blog/data-structure/ringbuffer/"
  },{
    "title": "数据结构-RBTree",
    "date": "",
    "description": "",
    "body": "",
    "ref": "/blog/data-structure/rbtree/"
  },{
    "title": "数据结构-BTree",
    "date": "",
    "description": "",
    "body": "",
    "ref": "/blog/data-structure/btree/"
  },{
    "title": "数据结构-Huffman",
    "date": "",
    "description": "",
    "body": "",
    "ref": "/blog/data-structure/huffman/"
  },{
    "title": "HPACK工作原理",
    "date": "",
    "description": "",
    "body": "原理  HAPCK使用两个索引表（静态索引表和动态索引表）把http的请求头映射到索引值 如果请求头在静态索引表中不存在， 则对其进行哈夫曼（huffman）编码， 并缓存到动态索引表中， 从而达到压缩headers的效果  ",
    "ref": "/blog/network/hpack/"
  },{
    "title": "http2协议解析及解决哪些问题",
    "date": "",
    "description": "",
    "body": "http超文本传输协议  http是简单的请求-响应协议，指定客户端发送数据格式以及服务器响应的数据格式 http是一次性连接，每次连接处理一个请求 http是无状态连接，服务器不保留客户信息  http 报文格式  请求报文：  请求行\\r\\n\r通用信息头\\r\\n\r请求头\\r\\n\r实体头\\r\\n\r报文主体\r响应报文：  状态行\\r\\n\r通用信息头\\r\\n\r响应头\\r\\n\r实体头\\r\\n\r报文主体\rhttp1.1 缺陷 高延迟 网络延迟问题主要由队头阻塞（head-of-line blocking）导致带宽无法被充分利用；\n 队头阻塞指当顺序请求序列中的一个请求因为某种原因被阻塞时，后面排队的请求也一并阻塞，导致客户端迟迟收不到数据。\n 解决办法：\n 合并多张小图为一张大图（雪碧图），前端利用算法进行切割使用 内联： 防止发送很多小图请求， 将图片原始数据嵌入在css的URL中 拼接： 将体量小的js文件使用webpack打包成一个js文件 将同一页面资源分散到不同域名，提升连接上限： 浏览器限制同一域名最多建立6个tcp连接。  无状态 由于http是无状态连接，为了服务器识别同一用户请求，报文header中一般会携带 User Agent、Cookie、Accept、Server等许多固定头字段。header携带内容过大，一定层度上增加传输成本。\n不支持服务器推送消息 明文传输的不安全性 HTTP/2 二进制传输  将原来的header+body消息，打散为数个小片的二进制帧（Frame），用HEADERS帧存放头数据，用DATA帧存放主体数据 同域名下所有通信都在单个连接下完成， 该连接可以承载任意数量的双向数据流 每个数据流都是以消息的形式发送，而消息由一个或多个帧组成 多个帧可以乱序发送，根据帧首部的流标识进行重新组装  Header 压缩  建立HPACK索引表， 由客户端和服务器共同渐进更新； 相同的报文头不用每次请求都发送 采用哈夫曼编码来压缩报文头  多路复用  对于同一域名下的多个请求连接，复用一个tcp连接， 消除了tcp建立连接带来的延迟和内存消耗 单个连接可以承载任意数量的双向数据流， 并行交错发送和响应请求， 请求之间互不影响； 每个请求可以携带一个31bit的优先值， 数值越大优先级越低。 客户端和服务器根据优先级采用不同的策略处理流；  server push 服务器可以新建流，主动向客户端发送消息。\n",
    "ref": "/blog/network/http2/"
  },{
    "title": "Reactor模式深入浅出",
    "date": "",
    "description": "",
    "body": "Reactor设计模式是一种事件处理模式，用于Service Handler处理由一个或多个输入发送的并发请求。 Service Handler将传入的请求进行Demultiplex，并将它们同步的分发到关联的Event Handler。\n模块 Handle\n任何可以提供输入或者消费系统输出的资源,它可以是打开的文件，一个网络连接(socket)等。\nSynchronous Event Demultiplexer 使用一个event loop来阻塞所有的Handle. 当可以在一个Handle上非阻塞的开始 同步操作时，Demultiplexer将该Handle发送到Dispatcher上。\n e.g.: 如果Handle没有数据可读时,read()同步调用会阻塞。demultiplexer在Handle上使用select()， 它会阻塞,直到Handle有数据可以读。这种情况下，对read()的同步调用不会阻塞， 并且Demultiplexer可以将Handle发送给Dispatcher。\n Dispatcher\n管理对Event Handler的注册和移除。分发从Demultiplexer来的Handle到关联的Event Handler。\nEvent Handler\n事件处理器，以供Dispatcher回调使用。\nConcrete Event Handler 具体的Event Handler实现。\n下面使用一张图来表现以上各个模块之间的关系:\n",
    "ref": "/blog/network/reactor/"
  },{
    "title": "Redis发布订阅模式和事件通知",
    "date": "",
    "description": "",
    "body": "发布订阅 redis发布订阅是一种消息通讯模式， 接收者subscribe channel 消息， 发送者publish channel 消息\n语法：\rsubscribe channel1 channel2\rpublish channel message\runsubscribe channel1 channel2\rpubsub subcommand // eg: pubsub channels 查看订阅channel\rpsubscribe pattern // 订阅给定模式频道\rpunsubscribe pattern // 退订给定模式频道\r事件通知（keyspace notification）  keyspace 通知是的客户端可以通过订阅频道或模式，来接收那些以某种方式改动redis数据集的事件； 事件通过redis的订阅发布功能来进行分发； redis的订阅和发布功能采取的是发送即忘（fire and forget）策略， 会导致离线的redis-cli，丢失这部分事件。  事件类型 对每个数据的修改， 键空间都会发送两种不同类型的事件：\n 键空间（key-space）通知 键事件（key-event）通知  例如： 当del key命令执行时：\r1. 键空间频道的订阅者将接收到被执行的事件的名字，在这个例子中，就是 del\r2. 键事件频道的订阅者将接收到被执行事件的键的名字，在这个例子中，就是 mykey\r配置 修改 redis.conf 中的notify-keyspace-events， 参数配置如下：\n字符\t发送的通知\rK\t键空间通知，所有通知以__keyspace@\u0026lt;db\u0026gt;__为前缀，针对Key\rE\t键事件通知，所有通知以__keyevent@\u0026lt;db\u0026gt;__为前缀，针对event\rg\tDEL、EXPIRE、RENAME等类型无关的通用命令的通知\r$\t字符串命令的通知\rl\t列表命令的通知\rs\t集合命令的通知\rh\t哈希命令的通知\rz\t有序集合命令的通知\rx\t过期事件：每当有过期键被删除时发送\re\t驱逐(evict)事件：每当有键因为maxmemory政策而被删除时发送\rA\t参数g$lshzxe的别名，相当于是All\r输入的参数中至少要有一个K或E， 否则不管其余的参数是什么， 都不会有任何通知被分发。\nredis cluster keyspace notification keyspace notification 指定node 自身， 不像常规pub/sub广播到所有node， 因此需要连接集群中所有节点去获取keyspace notification；\n应用场景  delayqueue： 下单未支付，库存锁定。超时后检查订单状态是否为未支付，未支付则还原库存；   ",
    "ref": "/blog/cache/redis/%E5%8F%91%E5%B8%83%E8%AE%A2%E9%98%85/"
  },{
    "title": "代码统计工具",
    "date": "",
    "description": "",
    "body": "Cloc 安装\n npm install -g cloc # https://www.npmjs.com/package/cloc\rsudo apt-get install cloc # Debian, Ubuntu\rsudo yum install cloc # Red Hat, Fedora\rsudo pacman -S cloc # Arch\rsudo pkg install cloc # FreeBSD\rsudo port install cloc # Mac OS X with MacPorts\r基本使用\n\u0026gt; cloc ./dir\r4076 text files.\r3883 unique files. 1521 files ignored.\rhttp://cloc.sourceforge.net v 1.50 T=12.0 s (209.2 files/s, 70472.1 lines/s)\r-------------------------------------------------------------------------------\rLanguage files blank comment code\r-------------------------------------------------------------------------------\rPerl 2052 110356 130018 292281\rC 135 18718 22862 140483\rC/C++ Header 147 7650 12093 44042\rBourne Shell 116 3402 5789 36882\rLisp 1 684 2242 7515\rmake 7 498 473 2044\rC++ 10 312 277 2000\rXML 26 231 0 1972\ryacc 2 128 97 1549\rYAML 2 2 0 489\rDOS Batch 11 85 50 322\rHTML 1 19 2 98\r-------------------------------------------------------------------------------\rSUM: 2510 142085 173903 529677\r-------------------------------------------------------------------------------\rGitStats 待续\n",
    "ref": "/blog/tools/cloc/"
  },{
    "title": "缓存穿透、缓存雪崩、缓存击穿的区别和解决方案",
    "date": "",
    "description": "",
    "body": "缓存穿透 描述： 请求不存在的数据， 使得大量请求发送到DB， 增加DB压力；\r解决方案：　1. 对落在数据库上的请求进行限流， 降低DB压力\r2. 接口层过滤非法参数；\r3. 缓存空查询结果。\r4. 使用布隆过滤器， 将所有可能数据hash到一个足够大的bitmap中， 一个一定不存在的数据会被bitmap拦截掉\r缓存击穿 描述： 高频访问热点数据，在缓存失效的瞬时，大量请求发送到DB， 来更新缓存， 增加DB压力；\r解决方案： 1. 设置热点数据永不过期；\r2. 加分布式全局锁，只允许单线程访问该数据；锁竞争较大。\r缓存雪崩 描述： 给大量缓存设置同样过期时间， 在某一刻，大量缓存数据过期，导致大量请求发送到DB，增加DB压力；\r解决方案： 1. 给数据过期时间添加随机数，避免同时过期；\r2. 将热点数据分不到不同的缓存数据库中\r3. 设置热点数据永不过期；\r5. hystrix 限制每秒请求数量， 超出请求引导到降级页面 6. 提高缓存中间件的高可用性\r",
    "ref": "/blog/cache/%E7%BC%93%E5%AD%98/"
  },{
    "title": "缓存数据不一致和解决方案",
    "date": "",
    "description": "",
    "body": "缓存数据不一致  使用缓存来存储热点数据是高并发的常用手段， 通过缓存大大减轻了数据库的压力， 同时减少了响应请求实际时间； 但是引入缓存后，就会导致缓存和db中数据不一致。这个时候就要更新缓存或淘汰缓存；  问题： 如果引入了db读写分离， 还需要考虑到db主从同步时的延迟。 可以监听binlog来异步更新缓存；（阿里canel）\n方案一： 先读db后写缓存  请求来了，先读缓存， 为空则访问数据库， 并将数据放入缓存 更新的时候，先删除缓存，在更新数据库  问题：\n 更新时， 先删除缓存，导致db还没有写入成功，另一个请求到来会将旧的db数据 更新到缓存中； 造成只有下次更新数据库时，才会更新缓存；造成缓存和数据库数据不一致；  方案二  请求来了，先读缓存， 为空则访问数据库， 并将数据放入缓存 更新的时候，先更新数据库，在删除缓存  问题：\n 更新数据库成功， 而删除缓存失败， 造成脏数据； 引入消息队列和binlog监听， 尝试重复删除；  ",
    "ref": "/blog/cache/%E7%BC%93%E5%AD%98%E4%B8%8D%E4%B8%80%E8%87%B4/"
  },{
    "title": "Redis源码解读-dict",
    "date": "",
    "description": "",
    "body": "定义 dict实现通过key查找value的键值对的数据结构，底层通过hash表实现\n数据结构 \r",
    "ref": "/blog/cache/redis/dict/"
  },{
    "title": "心念旧是",
    "date": "",
    "description": "",
    "body": "唯\n",
    "ref": "/blog/stories/%E5%BF%83%E5%BF%B5%E6%97%A7%E6%98%AF/"
  },{
    "title": "数据结构-Bitmap",
    "date": "",
    "description": "",
    "body": "",
    "ref": "/blog/data-structure/bitmap/"
  },{
    "title": "不同类型代码执行引擎",
    "date": "",
    "description": "",
    "body": "概述 代码在物理机器上执行过程：\n 代码被编译成二进制文件 二进制文件运行， 加载程序到内存中 CPU通过总线将内存中指令取出并放入指令流水线， 对指令进行 译码、执行、缓冲、回写（参考arm7 三级流水 和 arm9 五级流水）  类似于程序在物理机器上运行， 虚拟机上代码执行过程：\n 代码被编译成相关字节码，然后在虚拟机上运行 虚拟机对字节码进行取指令、译码、执行、结果回写  虚拟机实现概念  将源码编译成VM所能执行的字节码 包含指令和操作数的数据结构 一个包含所有函数操作的调用栈 一个指令指针，用于指向下一条要被执行的指令 一个虚拟的CPU（指令派发者）： 取指， 译码，执行  虚拟机分类 主要区别是操作数和结果的存储和检索机制不一样。\n栈虚拟机（stack vm）  基于栈的虚拟机有操作数栈的概念，首先从符号表中取出数据然后压入操作数栈 进行真正的运算时都是直接与操作数栈进行交互 运算时指令无需指定操作数， 因为默认操作数存放在操作数栈上， 直接从栈上pop出数据使用即可 运算后的将结果存入操作数栈顶  栈虚拟机优缺点 优点：\n 不管任何操作都通过操作数栈进行， 可以无视具体的物理结构 指令紧凑，一两个字节即可存储 编译器实现简单 寄存器由硬件直接提供，不用进行寄存器分配 可移植性强  缺点：\n 因为无论什么操作都要通过操作数栈， 所以速度慢  寄存器虚拟机 （register vm）  基于寄存器的虚拟机会分配虚拟寄存器，存放数据 进行运算时， 需要指定操作数的寄存器 虚拟机对寄存器进行解析，找出操作数的位置，然后取出操作数进行运算  寄存器虚拟机优缺点 优点：\n 没有栈虚拟机在拷贝数据时进行大量的出入栈操作     栈式 VS 寄存器式 对比     指令条数 栈式 \u0026gt; 寄存器式   代码尺寸 栈式 \u0026lt; 寄存器式   移植性 栈式优于寄存器式   指令优化 栈式更不易优化   解释器执行速度 栈式解释器速度稍慢   代码生成难度 栈式简单   简易实现中的数据移动次数 栈式移动次数多    ",
    "ref": "/blog/software-programming/%E8%99%9A%E6%8B%9F%E6%9C%BA/"
  },{
    "title": "暖与凉",
    "date": "",
    "description": "",
    "body": "谢谢陌生人的关心\n",
    "ref": "/blog/stories/%E6%9A%96%E4%B8%8E%E5%87%89/"
  },{
    "title": "冬风",
    "date": "",
    "description": "",
    "body": "当风再来，冬已悄至。\n",
    "ref": "/blog/stories/%E5%86%AC%E9%A3%8E/"
  },{
    "title": "讲诉互联网的概念，区分广义互联网和侠义互联网",
    "date": "",
    "description": "",
    "body": "广义互联网 大家所说的互联网一般指广义互联网，由两层组成\n 核心层： TCP/IP网络传输层(侠义互联网) 上层： 万维网WWW为代表的应用层  这一层包含多种类型的流量和应用：邮件、软件、在线影视、游戏、电子商务、移动应用 所有的SP(service provider, 服务提供商)提供的都是用户看的见的应用    互联网拥堵问题 关键字：\n ISDN： 综合业务数字网（Integrated Services Digital Network，ISDN）是一个数字电话网络国际标准 ADSL：非对称数字用户线路（ADSL，Asymmetric Digital Subscriber Line）是数字用户线路（xDSL，Digital Subscriber Line）服务中最流行的一种 IDC：互联网数据中心（Internet Data Center，简称IDC）是指一种拥有完善的设备（包括高速互联网接入带宽、高性能局域网络、安全可靠的机房环境等）、专业化的管理、完善的应用的服务平台 收敛比： 就是N对应到M的一个过程,当N\u0026gt;M时被称作收敛.鉴于排队论的原理,当有N个顾客按其概率到达要求服务时,如果在一定的服务质量(收敛条件)被约定,则本系统仅需要有M(M\u0026lt;N)个服务员就够了. 相当于输入的比输出的多   \u0026ldquo;第一公里\u0026rdquo;  万维网流量向用户传送的第一个出口，即网站服务器接入互联网的链路所能提供的带宽。 这个带宽决定了网站能为用户提供的访问速度和并发访问量 一个网站，其服务的用户越多，对其出口带宽要求越大   \u0026ldquo;最后一公里\u0026rdquo;  万维网流量向用户传输的最后一段接入链路，即用户接入带宽 用户的平均接入带宽，是影响互联网上层应用发展的决定性因素之一 互联网初期  主要上网方式为拨号上网和ISDN()等，网络接入速度低。 主要内容是占用带宽非常小的文字为主，主流应用是Telnet、BBS等   万维网出现  多媒体内容开始在互联网上传播 用户接入带宽成为制约用户使用互联网的主要瓶颈 2001年开始，各大电信运营商发展ADSL等带宽服务，随着带宽提升和接入手段丰富(光纤入户、wifi，4G等)，\u0026ldquo;最后一公里\u0026quot;问题得以解决     对等互联关口  不同基础运营商之间的互联互通 一般运营商之间只有两三个互联互通点， 可以想象这两三个点上会产生多大流量 如：  当某个网站部署在运营商A的IDC机房中 运营商B的用户要访问该网站，就必须经过A，B之间的互联互通点进行跨网访问。   不同网络间的互联互通带宽，对于任何一个运营商网络流量来水，占比都比较小，收敛比高，因此这里通常是互联网传输中的拥堵点   长途骨干传输  长距离传输时延问题 从网站服务器到用户之间要经过网站所在的IDC、骨干网、用户所在的城域网、用户所在的接入网等 距离非常遥远，因此不可避免的带来较长的传输时延 由于互联网上的绝大部分流量需要经过骨干网进行传输，所以需要骨干网络的承载能力必须与互联网的应用同步发展  实际两者并不同步，当骨干网络升级和扩容滞后于互联网上应用的发展，就会阶段性的使得大型骨干网的承载能力成为影响互联网性能的瓶颈      8秒定律  当用户访问一个网站时， 如果网页打开等待时间超过8秒，就会由30%用户放弃等待 一个网站10秒后网页打不开，会有40% 的用户跳出该页面。 大部分手机用户愿意等待时间为6-10秒 一秒延迟会导致转化率下降7%  ",
    "ref": "/blog/network/%E4%BA%92%E8%81%94%E7%BD%91/"
  },{
    "title": "一次",
    "date": "",
    "description": "",
    "body": "往事讲一遍，是最初的感受。\n有些事情一次就好。\n",
    "ref": "/blog/stories/%E4%B8%80%E6%AC%A1/"
  },{
    "title": "Redis的主从同步方式",
    "date": "",
    "description": "",
    "body": "概述 为了分担redis读写压力， 支持主从复制； 分为全量同步和增量同步\n全量同步 全量同步一般发生在slave 初始化阶段， 这时slave需要将master上的所有数据复制一份，具体步骤：\n slave连接master， 发送SYNC命令 master接收到SYNC命令，开始执行BGSAVE命令生成RDB文件并在缓冲区记录此后执行的所有命令； master执行完BGSAVE命令后， 向所有slave发送快照，并在发送期间继续记录被执行的命令； slave收到快照文件后，丢弃所有数据，并载入新的快照； master快照发送完成后，开始向slave分发缓冲中记录的命令 slave载入快照完成后，开始接收master上缓冲的写命令；  增量同步 增量同步主要发生在slave初始化后，开始正常工作后， 将master上后续发生的写操作同步到slave上。具体过程：\n master每执行一个写命令， 就会向slave发送同样的写命令。  主从同步特点  异步同步，不阻塞master服务器 master要开启持久化，否则master重启很危险 repl-diskless-sync no 默认不使用diskless同步方式  ",
    "ref": "/blog/cache/redis/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"
  },{
    "title": "Redis高可用方案-集群模式",
    "date": "",
    "description": "",
    "body": "概述  redis cluster 时redis的分布式解决方案， 在3.0 推出； 当遇到单机内存，并发流量等瓶颈时，可以采用cluster架构达到负载均衡的目的； cluster 将整个数据集，按照分区规则映射到多个节点上，每个节点负责整个数据集的一个子集； 节点之间会相互通信， meet操作时节点之间相互通信的基础， meet 操作有一定的频率和规则； 推荐节点小于1000， 因为节点之间meet操作会占用大量带宽；  原理  redis cluster采用哈希分区中的虚拟槽分区。 虚拟槽分区巧妙的使用哈希空间， 使用分散度良好的哈希函数把所有的数据映射到一个固定范围的整数集合（槽）； 槽的范围时0~16383， 槽是集群内数据管理和迁移的基本单位； 把16384槽按照节点数量进行平均分配，由节点进行管理 对每个key按照CRC16规则进行hash运算 把hash结果对16383进行取余 把余数发送给Redis节点 节点接收到数据，验证是否在自己管理的槽编号的范围 如果在自己管理的槽编号范围内，则把数据保存到数据槽中，然后返回执行结果 如果在自己管理的槽编号范围外，则会把数据发送给正确的节点进行moved重定向，由正确的节点来把数据保存在对应的槽中  增加主节点  redis-trib.rb add-node new-node-addr cluster-node-addr redis-trib.rb reshared cluster-node-addr  增加从节点  redis-trib.rb add-node new-node-addr cluster-node-addr cluster replicate new-node-Id  删除从节点  redis-trib.rb del-node cluster-node-addr del-node-id redis-trib.rb reshared cluster-node-addr redis-trib.rb del-node cluster-node-addr del-node-id  部署  至少需要6台机器， 3个master，3个slave； 每个master至少搭配一个slave；  hashtag  hashtag 解决让相关的key 划分到同一个节点上； 原理： 给相关key 使用{}添加同样的标记；  fail 状态必要条件  某个主节点和所有从节点全部挂掉，我们集群就进入faill状态。 如果集群超过半数以上master挂掉，无论是否有slave，集群进入fail状态. 如果集群任意master挂掉,且当前master没有slave.集群进入fail状态  ",
    "ref": "/blog/cache/redis/%E9%9B%86%E7%BE%A4%E6%A8%A1%E5%BC%8F/"
  },{
    "title": "MySQL索引详解",
    "date": "",
    "description": "",
    "body": "是什么 为什么 索引可以大大的提高MySQL的检索速度。\nExplain key_len 索引长度限制\nINNODB引擎的每个索引列长度限制为767字节（bytes），所有组成索引列的长度和不能大于3072字节\nMYISM引擎的每个索引列长度限制为1000字节，所有组成索引列的长度和不能大于1000字节\n在MySQL5.5版本，引入了innodb_large_prefix，用来禁用大型前缀索引，以便与不支持大索引键前缀的早期版本的InnoDB兼容。 开启innodb_large_prefix可以使单索引的长度限制达到3072字节（但是联合索引总长度限制还是3072字节），禁用时单索引的长度限制为767字节\n在MySQL5.5版本与MySQL5.6版本，innodb_large_prefix是默认关闭的。\n在MySQL5.7及以上版本，innodb_large_prefix是默认开启的。\n在MySQL8.0版本中，innodb_large_prefix已被移除\nkey_len的长度计算公式：\nTINYINT 允许NULL = 1 + 1(NULL)\rTINYINT 不允许NULL = 1\rSMALLINT 允许为NULL = 2+1(NULL)\rSMALLINT 不允许为NULL = 2\rINT 允许为NULL = 4+1(NULL)\rINT 不允许为NULL = 4\rDATETIME 允许为NULL = 8 + 1(NULL)\rDATETIME 不允许为NULL = 8\rTIMESTAMP 允许为NULL = 4 + 1(NULL)\rTIMESTAMP 不允许为NULL = 4\rVARCHAR(N) 变长字段且允许NULL = N * ( character set：utf8=3,gbk=2,latin1=1)+1(NULL)+2(变长字段)\rVARCHAR(N) 变长字段且不允许NULL = N * ( character set：utf8=3,gbk=2,latin1=1)+2(变长字段)\rCHAR(N) 固定字段且允许NULL = N * ( character set：utf8=3,gbk=2,latin1=1)+1(NULL)\rCHAR(N) 固定字段且不允许NULL = N * ( character set：utf8=3,gbk=2,latin1=1)\r",
    "ref": "/blog/database/mysql/"
  },{
    "title": "Redis高可用方案-哨兵模式",
    "date": "",
    "description": "",
    "body": "哨兵模式 哨兵是一个独立的进程， 通过和redis各个节点的通信，监听各节点的状态；并互相监控； 备注： sentinel节点需要2n+1(n\u0026gt;=1)个\nsentinel监听  每10秒 sentinel 对 master和slave 进行info； 发现slave节点，确认主从关系 每2秒 sentinel 通过master（pub/sub） 交换信息， 所有的sentinel都订阅master的一个channel， 并每隔2秒向该channel发送信息； 感知新的sentinel， 协商master是否通信失败； 每1秒 sentinel 向其他sentinel/master/slave节点 ping； 用于心跳监测；  主观下线 单个sentinel对redis 节点通信失败的‘偏见’；如果一个redis节点在down-after-millseconds 时间内， 没有回复sentinel心跳包，则该redis节点被sentinel认定为主观下线\n客观下线  当redis节点被sentinel标记为主观下线后， 并不意味该redis节点故障了。 该sentinel会询问其他sentinel， 如果sentinel cluster中超过quorum数量的sentinel 认定该节点主观下线， 则该redis 客观下线； 如果该节点为sentinel和slave节点， 则操作到此为止； 如果客观下线的redis节点为master， 则开始故障转移；  故障转移流程 sentinel cluster 选举leader  当一个sentinel 确定master 主观下线后， 会请求其他sentinel将自己选举为leader， 被请求的sentinel 如果没有同意其他sentinel的选举请求， 则同意该请求， 否则为不同意； 如果一个sentinel 获得的选票数达到了leader最低票数（quorum和sentinel节点数/2+1）则该sentinel当选为leader， 否则重新选举；  sentinel leader 决定新的master  过滤故障节点 选择slave-priority配置的优先级别 最高的slave节点， 如不存在继续下一步； 选择复制偏移量最大（复制的最完整）的slave节点， 如不存在继续下一步； 选择run_id 最小的slave节点；  ",
    "ref": "/blog/cache/redis/%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F/"
  },{
    "title": "Redis高可用解决方案",
    "date": "",
    "description": "",
    "body": "高可用扩容  垂直扩容： 提升机器内存配置， 不需要应用程序支持； 水平扩容： 增加节点，需要应用程序支持；  哨兵模式（sentinel） 故障转移后redis客户端将无法感知redis节点的变化；导致无法正常使用；\n哨兵模式高可用客户端流程  客户端获取 sentinel 集合； 客户端获取master 信息； 客户端验证获取的master 为真正的master， 防止故障转移期间主节点的变化； 客户端订阅sentinel节点 相关频道， 时刻获取节点去读写；  问题  不能解决读写分离；  集群模式（cluster）  数据异步复制，不能保证强一致性。复制结构只支持一层，从节点只能复制主节点； key 批量操作限制，目前只支持相同槽的key 批量查询， 不允许跨槽查询； key 事务操作优先，当key在多个槽上分布时， 不支持事务功能；  ",
    "ref": "/blog/cache/redis/%E9%AB%98%E5%8F%AF%E7%94%A8ha-high-available/"
  },{
    "title": "Redis的hotkey和bigkey监控和处理",
    "date": "",
    "description": "",
    "body": "bigkey  单个key 存储value很大 hash set list zset 等存储元素过多  如何发现  redis-cli \u0026ndash;bigkeys rdbtools 分析rdb 文件 redis-rdb-cli 第三方工具  怎么解决  减少list hash set zset 成员， 对成员过多的数据进行取模分片 string类型的big value 不建议存入 redis， 可以用文档型数据库mongodb或cdn等方式优化。  hotkey  并发访问量很大的热点key  如何发现 收集所有redis请求，统计分析\n redis-cli \u0026ndash;hotkeys 在proxy 层，对每一个redis请求进行收集上报，统计分析 对redis端口的tcp数据包进行抓包统计； 基于lfu（最近最少使用） 根据使用频率进行统计  怎么解决 产生随机值（0-2N, N 为集群节点数），作为key的后缀， 将key分布到集群的多个实例中。并设置随机过期时间；\nconst M = N * 2\r//生成随机数\rrandom = GenRandom(0, M)\r//构造备份新key\rbakHotKey = hotKey + “_” + random\rdata = redis.GET(bakHotKey)\rif data == NULL {\rdata = redis.GET(hostKey)\rif data == NULL {\rdata = GetFromDB()\rredis.SET(bakHotKey, expireTime + GenRandom(0,5)) }\r}\r自动处理hostkey  监控hotkey 通知程序处理  ",
    "ref": "/blog/cache/redis/hotkeybigkey/"
  },{
    "title": "什么人都有",
    "date": "",
    "description": "",
    "body": "什么人都有\n可以这样的歇斯底里\r",
    "ref": "/blog/stories/%E4%BB%80%E4%B9%88%E4%BA%BA%E9%83%BD%E6%9C%89/"
  },{
    "title": "快乐是一种方式",
    "date": "",
    "description": "",
    "body": "快乐是一种方式\n有心快乐，自然快乐",
    "ref": "/blog/stories/%E5%BF%AB%E4%B9%90%E6%98%AF%E4%B8%80%E7%A7%8D%E6%96%B9%E5%BC%8F/"
  },{
    "title": "Redis源码阅读-ziplist",
    "date": "",
    "description": "",
    "body": "定义 ziplist由一系列特殊编码的连续内存块组成的顺序存储结构，类似数组， 但是ziplist每个元素占用内存大小不同。\n数据结构 type ziplist struct {\rzlbytes: ziplist的长度（单位: 字节)，是一个32位无符号整数\rzltail: ziplist最后一个节点的偏移量，反向遍历ziplist或者pop尾部节点的时候有用。\rzllen: ziplist的节点（entry）个数\rentry: 节点\rzlend: 值为0xFF，用于标记ziplist的结尾 }\rtype entry struct {\rprevlengh: 记录上一个节点的长度，为了方便反向遍历ziplist\rencoding: 当前节点的编码规则，下文会详细说\rdata: 当前节点的值，可以是数字或字符串\r}\r当data小于63字节时(2^6)，节点存为上图的第一种类型，高2位为00，低6位表示data的长度。\r当data小于16383字节时(2^14)，节点存为上图的第二种类型，高2位为01，后续14位表示data的长度。\r当data小于4294967296字节时(2^32)，节点存为上图的第二种类型，高2位为10，下一字节起连续32位表示data的长度。\r应用 ziplist 是list键、hash键、zset键的底层实现之一\n",
    "ref": "/blog/cache/redis/ziplist/"
  },{
    "title": "Redis源码阅读-skiplist",
    "date": "",
    "description": "",
    "body": "",
    "ref": "/blog/cache/redis/skiplist/"
  },{
    "title": "Redis自带性能测试命令",
    "date": "",
    "description": "",
    "body": "性能测试 redis-benchmark options options value\n序号\t选项\t描述\t默认值\r1\t-h\t指定服务器主机名\t127.0.0.1\r2\t-p\t指定服务器端口\t6379\r3\t-s\t指定服务器 socket\t4\t-c\t指定并发连接数\t50\r5\t-n\t指定请求数\t10000\r6\t-d\t以字节的形式指定 SET/GET 值的数据大小\t2\r7\t-k\t1=keep alive 0=reconnect\t1\r8\t-r\tSET/GET/INCR 使用随机 key, SADD 使用随机值\t9\t-P\t通过管道传输 \u0026lt;numreq\u0026gt; 请求\t1\r10\t-q\t强制退出 redis。仅显示 query/sec 值\t11\t--csv\t以 CSV 格式输出\t12\t-l\t生成循环，永久执行测试\t13\t-t\t仅运行以逗号分隔的测试命令列表。\t14\t-I\tIdle 模式。仅打开 N 个 idle 连接并等待。\r性能和网络阻塞  大文本数据需要压缩存储，如果不压缩占用内存大，而且访问时占用流量带宽 线上禁止keys使用正则匹配， keys匹配时效率低， 可以使用scan替代 线上禁止monitor， 存在内存暴增，影响性能  ",
    "ref": "/blog/cache/redis/%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/"
  },{
    "title": "Windows系统删除U盘EFI分区",
    "date": "",
    "description": "",
    "body": " 管理员权限启动CMD 输入磁盘分区命令： diskpart C:\\Users\\Administrator\u0026gt;diskpart DISKPART\u0026gt;\r 查看所有磁盘： list disk DISKPART\u0026gt; list disk\r磁盘 ### 状态 大小 可用 Dyn Gpt\r-------- ------------- ------- ------- --- ---\r磁盘 0 联机 111 GB 0 B\r磁盘 1 联机 465 GB 0 B\r磁盘 2 联机 111 GB 0 B\r磁盘 3 联机 7648 MB 809 MB\r 选择要进行操作的磁盘： select disk 3 DISKPART\u0026gt; select disk 3\r磁盘 3 现在是所选磁盘。\r 清理磁盘： clean  DISKPART\u0026gt; clean\rDiskPart 成功地清除了磁盘。\r 重新挂载U盘： 进入计算机管理 -\u0026gt; 磁盘管理 -\u0026gt; 找到相应U盘，右键新加卷  ",
    "ref": "/blog/windows/u-efi/"
  },{
    "title": "LRU(Least Recently Used)算法原理和代码实现",
    "date": "",
    "description": "",
    "body": "概述 least recently used ： 淘汰最近最少使用页面\n技术实现 hashmap + linked list\n",
    "ref": "/blog/algorithm/lru%E7%AE%97%E6%B3%95/"
  },{
    "title": "Redis有哪些内存淘汰策略",
    "date": "",
    "description": "",
    "body": "淘汰策略  volatile-lru： 从设置过期事件的数据集合中，对最近最少使用的数据进行淘汰 volitile-ttl： 从设置过期事件的数据集合中，对将要过期数据进行淘汰 allkeys-lru： 在内存不足容纳新的数据时，对最近最少使用的数据进行淘汰； allkeys-random: 从数据集中淘汰任意数据   redis 4.0版本新增\n volatile-lfu: 从设置过期事件的数据集合中，对使用次数最少的数据进行淘汰 allkeys-lru： 在内存不足容纳新的数据时，对使用次数最少的数据进行淘汰  ",
    "ref": "/blog/cache/redis/%E5%86%85%E5%AD%98%E6%B7%98%E6%B1%B0%E7%AD%96%E7%95%A5/"
  },{
    "title": "Redis源码阅读-SDS动态字符串",
    "date": "",
    "description": "",
    "body": "概述  redis 没有直接使用C语言的字符串，而是定义了自己的字符串结构： SDS(simple dynamic string)作为默认字符串； 我们使用的所有键值基本都是SDS类  定义 ",
    "ref": "/blog/cache/redis/sds%E5%8A%A8%E6%80%81%E5%AD%97%E7%AC%A6%E4%B8%B2/"
  },{
    "title": "Redis中key过期删除",
    "date": "",
    "description": "",
    "body": "定期删除  redis 默认每个100ms 就会随机抽取一些设置过期时间的key， 检查其是否过期， 如果过期就删除。 随机抽取是为了防止完整遍历增加cpu负载  惰性删除  key在被使用时， 去检查过期时间， 如果过期就删除  ",
    "ref": "/blog/cache/redis/key%E8%BF%87%E6%9C%9F%E5%88%A0%E9%99%A4/"
  },{
    "title": "Redis中key的命名规范",
    "date": "",
    "description": "",
    "body": " 建议全部大写 key不能太长，太长占用资源，可读性差 key根据命名空间使用： 分开； 命名空间示例： 项目名：表名：字段名：字段id  ",
    "ref": "/blog/cache/redis/key%E5%91%BD%E5%90%8D%E8%A7%84%E8%8C%83/"
  },{
    "title": "Redis持久化有哪些方式",
    "date": "",
    "description": "",
    "body": "持久化   RDB:\n redis 会fork一个子进程，将内存数据写磁盘；写完临时文件后， 将旧的rdb文件替换； 实现copy-on-write； 以快照的形式将内存中数据备份到dump.rdb文件中；定时保存； 缺点：  在服务故障时会丢失部分数据； 数据量大会导致服务停止几百毫秒；      AOF：\n 将redis 命令都存到一个文件中；redis 每执行一行命令都会将其写入到aof文件中； 配置： appendonly yes appendfsync always # 每次数据修改都会写入AOF文件， 影响redis性能\rappendfsync everysec # 每秒同步一次， 将更多写命令同步到磁盘\rappendsync no # 让系统决定何时同步\r 缺点： 文件会会大一些， 还原速度慢 ；    查看目录 语法： save\rconfig get dir\rredis 4.0 新增  RDB和AOF混合持久， 配置： aof-use-rdb-preamble  如果混合持久打开， AOF重写时会直接吧RDB的内容写到AOF文件开头。 优点： 结合RDB和AOF优点，快速加载同时避免丢失过多数据。 缺点： AOF中的RDB部分时二进制格式， 可读性差；    ",
    "ref": "/blog/cache/redis/%E6%8C%81%E4%B9%85%E5%8C%96/"
  },{
    "title": "Redis的基本常识和memcache对比",
    "date": "",
    "description": "",
    "body": "redis  redis 使用c语言编写的高性能键值对内存数据库； 读速度： 110000/s; 写速度： 81000/s 单进程单线程， 是线程安全的； 采用多路复用机制处理请求； 有5种数据结构strnig、hash、list、set、sort set 使用管道技术，解决客户端发送阻塞； 服务端对多个请求批量处理，一次返回；  redis性能  redis 所有数据都存储在内存中， 读写都非常迅速； redis 采用单线程， 避免了线程调度的上下文切换和资源竞争 redis 多路复用，非阻塞I/O  memecache 区别  memcache 数据全部存储到内存中， 断电会挂掉； memcache 数据不能超出内存大小； redis 部分数据存储到磁盘上，可以保证数据持久性； memcache 仅支持key-value， redis 支持5中数据类型；  ",
    "ref": "/blog/cache/redis/redis/"
  },{
    "title": "Nginx Http upstream",
    "date": "",
    "description": "",
    "body": "配置目的  负载均衡 多机热备  ",
    "ref": "/blog/nginx/balance/"
  },{
    "title": "Erlang分布式编程",
    "date": "",
    "description": "",
    "body": "分布式编程 分布式编程需求  性能   通过安排程序的不同部分在不同的机器上并行运行，让程序跑的更快。\n 可靠性   通过让系统运行到数台机器上来实现容错系统，如果一台机器故障，可以在另一台机器上继续。\n 可扩展性   随着应用程序越做越大，即使机器的处理能力再强大也会被耗尽。这时我们需要添加更多的机器来提升处理能力。添加新机器应当是一次简单的操作，不需对程序架构做大的修改。\n 天生分布式的程序   许多应用程序天生分布式。如编写一个聊天系统，就会有来自世界各地的分散用户。如果我们在某个地理位置拥有大量用户，就希望把计算资源放在接近这些用户的地方。\n 两种分布式模型 我们构建程序的基本单位是进程，编写分布式 Erlang程序是很容易的，要做的就是在正确的机器上分裂出进程，然后一切就能像之前那样运行。\n 分布式Erlang   在分布式Erlang里，我们编写的程序会在Erlang的节点(node)上运行。节点是一个独立的Erlang系统，包含一个自带地址空间和进程组的完整虚拟机。\n  可以在任意节点上分裂进程，所有消息传递和错误处理基本函数也都能像在单节点上那样工作。\n  分布式Erlang应用程序，运行在一个可信环境中。因为任何节点都可以在其他Erlang节点上执行任意操作，所以这涉及高度的信任。虽然分布式Erlang应用程序可以运行在开放式网络上，但他们通常是运行在属于同一个局域网的集群上，并受防火墙保护。\n 基于套接字的分布式模型   可以用Tcp/Ip套接字来编写运行在不可信环境中的分布式应用程序。这个编程模型不如分布式Erlang那样强大，但是更安全。\n 编写一个分布式程序 步骤  在一个常规的非分布式Erlang系统上编写和测试程序。 在同一台机器的两个节点上测试程序。 在同一个局域网内分属两台不同机器的节点上测试程序。 在分属不同国家和域的两台机器上测试程序。  最后两步可能会带来问题。如果所运行的机器属于相同的管理域，就很少有问题。但当相关节点属于不同域上的机器时，就可能遇到连接问题，而且必须确保系统防火墙和安全设置都已经正确配置。\n创建名称服务器 同一局域网的不同机器上 erl -name NodeName -setcookie Cookie\n 用-name参数启动Erlang。我们在同一台机器上运行两个节点时使用了\u0026quot;短\u0026quot;（short）名称（通过-sname标识体现）。但如果它们属于不同的网络，我们就要使用-name。   当两台机器位于同一个子网时我们也可以使用-sname，如果没有DNS服务，-sname是唯一的可行方式。\n 确保两个节点拥有相同的cookie。这正是启动两个节点时都使用命令行参数-setcookie abc的原因。 确保相关节点的完全限定主机名可以被DNS解析。 确保两个系统相同版本的代码和相同版本的Erlang。  测试节点互联 net_adm:ping(Node).\n跨互联网不同机器上的客户端和服务器  确保4369端口对TCP和UDP流量都开放。这个端口会被一个名为epmd的程序使用（它是Erlang Port Mapper Daemon的缩写，即Erlang端口映射守护进程）。 选择一个或一段连续的端口给分布式Erlang使用，并确保这些端口都是开放的。如果这些端口位于Min和Max之间，就用以下的命令启动Erlang： erl -name \u0026hellip; -setcookie \u0026hellip; -kernel inet_dist_listen_min Min inet_dist_listen_max Max  分布式编程的库和内置函数 标准分发套装里的两个模块能够满足大多数的需求：\n rpc提供许多远程调用服务。 global里的函数可以用来在分布式系统里注册名称和加锁，以及维护一个全连接网络。  rpc模块里面最重要的函数：\n call(Name, Mod, Fun, [Args]) -\u0026gt; Result | {badrpc, Reason}. 它会在Node上执行apply(Mod, Function, Args), 然后返回Result，如果调用失败则返回{badrpc, Reason}。\n 分布式基本函数  -spec spawn(Node, Fun) -spec spawn(Node, Mod, Fun, ArgList)   这种形式的spawn比spawn(Node, Fun)更健壮。如果运行在多个分布式节点上的特定模块不是完全相同的版本，spawn(Node,Fun)就可能出错。\n -spec spawn_link(Node, Fun) -\u0026gt; Pid -spec spawn_link(Node,Mod,Fun,Arglist) -spec disconnect_node(Node) -\u0026gt;bool()|ignore   强制断开与某个节点的连接\n -spec monitor_node(Node, Flag)-\u0026gt;true   如果Flag是true就会开启监视，Flag是false就会关闭监视。如果有Node加入或离开Erlang的互联节点组时，执行这个内置函数的进程就会收到{nodeup,Node}或{nodedown, Node}\n -spec node() -\u0026gt; Node | nonode@nohost   返回本地节点的名称.如果本地节点不是分布式的则返回nonode@nohost\n -spec node(Arg) -\u0026gt;Node | nonode@nohost   返回Arg所在的节点。Arg可以是Pid,引用，或者端口。如果本地节点不是分布式的则返回nonode@nohost\n -spec nodes() -\u0026gt;[Node]   返回一个节点列表，内含网络里所有与我们相连的节点。\n -spec is_alive() -\u0026gt; bool()   如果本地节点是活动的，并可以成为分布式系统的一部分，就返回true，否则返回false。\n  另外，send可以用来向一组分布式的erlang节点上的某个注册进程发送消息。语法如下：  {RegName, Node} ! Msg\rcookie保护系统  cookie系统让访问单个或一组节点变得更安全。每个节点都有一个cookie，如果它想与其他任何节点通信，他的cookie就必须和对方节点的cookie相同。 为了确保cookie相同，分布式erlang系统的所有节点必须以相同的cookie启动，或者通过erlang: set_cookie把他们的cookie修改成相同值。 Erlang集群的定义就是一组带有相同cookie的互连节点。  可以使用三种方法设置cookie：\n 在文件$HOME/.erlang.cookie中存放相同的cookie。此文件包含一个随机字符串，是erlang在机器上第一次在启动时生成的。 当erlang启动时，可以使用命令行参数-setcookie C设置cookie为C。 内置函数erlang: set_cookie(node(), C)能把本地节点的cookie设置为C。   cookie不会再网络中明文传输，只用来对某次回话进行初始认证。分布式erlang会话是不加密的，但可以被设置成在加密通道中运行。\n 基于套接字的分布式模型  如你所见分布式Erlang系统，适合编写那些可信任其他参与者的集群应用程序。但在并非人人都可信的开放式环境里，他就不那么适合了。 分布式erlang的主要问题在于客户端可自行决定在服务器上分裂出各种进程。因此要摧毁你的系统只需要执行以下命令：  rpc:multicall(nodes, os, cmd, [\u0026quot;cd /;rm -rf *\u0026quot;])\r 分布式Erlang适用情形是你拥有全部机器，并想在单独机器上控制他们。但如果这些机器不为同一个人拥有，并且他们想要精确的控制自己的机器可以执行哪些软件，这种计算模型就不合适了。 这种情况下，我们使用一种受限形式的spawn,让机器所有者能够显示控制自己的机器。  用lib_chan控制进程  lib_chan模块让用户能够显示的控制自己的机器能够分裂哪些进程。\n  -spec start_server() -\u0026gt; true   它会在本地主机启动一个服务器。这个服务器的行为由文件$HOME/.erlang_config/lib_chan.conf设定\n  -spec start_server(Conf) -\u0026gt; true   它会在本地主机上启动一个服务器。这个服务器的行为由文件Conf决定，它包含一个由下列元组组成的列表：\n {port, NNNN}\r它会开始监听端口号NNNN\r{service, S, password, P, mfa, SomeMod, SomeFunc, SomeArgs}\r它会定义一个被密码P保护的服务S。如果这个服务启动了，就会通过分裂SomeMod:SomeFunc(MM,ArgsC,SomeArgs)创建进程，负责处理来自客户端的消息。这里的MM是一个代理进程的Pid, 可以用来向客户端发送消息.参数ArgsC 来自于客户端的连接调用。\r -spec connect(Host, Port, S, P, ArgsC) -\u0026gt; {ok,Pid}|{error,Why}   尝试开启主机Host上的端口Port，然后尝试激活被密码P保护的服务S。如果密码正确返回{OK,Pid}。Pid是一个代理进程的标示符，可以用来向服务器发送消息。\n  当客户端调用connect/5建立连接后，就会分裂出两个代理进程，一个在客户端，一个在服务器。这些代理进程负责把erlang消息转换成TCP数据包，捕捉来自控制进程的退出信号，以及套接字关闭。\n  -spec lib_chan:cast(Pid, Msg) -spec lib_chan:rpc(Pid, Msg)   向pid发送信息。\n ",
    "ref": "/blog/erlang/%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%96%E7%A8%8B/"
  },{
    "title": "Erlang接口技术",
    "date": "",
    "description": "",
    "body": "接口技术 可以多种方式建立外部语言程序与Erlang之间的接口。\n 让程序以外部操作系统进程的方式在erlang虚拟机以外运行。这是一种安全的方式，即使外部程序代码有问题，也不会让erlang程序崩溃。   Erlang 通过一种名为端口(port)的对象来控制外部进程，与外部进程的通信则是通过一个面向字节的通信信道。Erlang通过端口，控制外部进程的启动和结束。并监视外部进程，崩溃后启动。\n 在Erlang内部运行操作系统命令并捕获结果。 在Erlang虚拟机的内部运行外部语言代码。这涉及链接外部代码和Erlang虚拟机代码。   外部语言代码的错误可能导致Erlang系统崩溃。虽然它不安全，但是这么做比使用外部进程更高效。\n  把代码连接到Erlang内核，只适用于C这样能生成目标代码的语言，不适用于Java这种自带虚拟机的语言。\n Erlang如何与外部程序通信  对于程序员而言端口的行为就像一个进程。你可以向它发消息，可以注册它，诸如此类。如果外部程序崩溃，就会有一个退出信号发送给相连进程。如果相连进程挂了，外部程序就会被关闭。 使用端口与外部程序通信和使用套接字有区别。如果使用端口，它会表现的像Erlang进程，可以连接它，从某个远程的分布式Erlang节点上向它发送信息等。如果使用套接字就不会表现出类似进程的行为。 创建端口的进程被称为该端口的相连进程。相连进程有其特殊的重要性，所有发往端口的消息都必须包含相连进程的PID，所有来自外部程序的消息都会发往相连进程。  端口创建和使用 创建端口-spec open_port(PortName, [Opt]) -\u0026gt; Port\n PortName选项如下： {spawn, Command}   启动一个外部程序。Command是这个外部程序的名称。除非能找到一个名为Command的内链驱动，否则Command会在Erlang工作空间之外运行。\n  {fd, In, Out}   允许一个Erlang进程访问Erlang使用的任何当前打开文件描述符。文件描述符In可以用作标准输入，文件描述符Out可以用作标准输出。\n  Opt选项如下： {packet, N}   数据包(packet)前面有N(1、2、4)个字节的长度计数。\n  stream   发送消息时不带数据包长度信息。应用程序必须知道如何处理这些数据包。\n  {line, Max}   发送消息时使用一次一行的形式。如果有一行超过了Max字节，就会在Max字节处被拆分。\n  {cd, Dir}   只适用于{spawn,Command}选项。外部程序在Dir目录启动。\n  {env, Env}   只适用于{spawn,Command}选项。外部程序的环境通过Env列表中的环境变量进行扩展。Env列表由若干个{VarName, Value}对组成，其中VarName,Value是字符串。\n 这里不是open_port接口的完整参数清单。下面消息可以被发往端口。这些消息里的PidC都是相连进程的PID。\n Port ! {PidC, {command, Data}}   向端口发送Data(一个I/o列表)。\n  Port ! {PidC, {connect, Pid1}}   把相连进程的PID从PidC改为Pid1。\n  Port ! {PidC, close}   关闭端口\n 相连进程可以使用以下方式从外部程序接受消息：\nreceive\r{Port, {data, Data}} -\u0026gt;\r...\r在Erlang里调用shell脚本 使用库函数os:cmd(Str)\n 它会运行字符串Str里的命令并捕捉结果。\n 高级接口技术  内链驱动和之前讨论的端口驱动遵循相同的协议。要构建一个内链驱动，必须添加少量代码来初始化它，驱动本身必须被编译和链接到Erlang虚拟机上。  git://github.com/erlang/linked_in_drives.git 里有最新的内链驱动范例。\r NIF 指原生实现函数。这些函数用C编写，并被链接到Erlang虚拟机中。NIF直接将参数传递到Erlang进程的栈上，还能直接访问所有的Erlang内部数据结构。  git://github.com/erlang/nifs.git 提供了NIF的范例和最新消息\r C-node 用C实现节点，遵循Erlang分布式协议。一个真正的Erlang分布式节点不仅能够与C-node通信，还会bata把它当做一个Erlang节点  http://www.erlang.rog/doc/tutorial/introduction.html 里的互操作性教程对C-node做了介绍。\r",
    "ref": "/blog/erlang/%E6%8E%A5%E5%8F%A3%E6%8A%80%E6%9C%AF/"
  },{
    "title": "防止并发请求重复提交",
    "date": "",
    "description": "",
    "body": "方案  客户端为每个订单生成deduplicate key，并在前端缓存商品信息及dedupkey 列表 提交订单时，传递dedup key 和订单信息， 客户端则一直等待该订单处理结果； 服务端接收到订单提交， 缓存该信息并设置过期时间； 服务器校验新的订单提交， 去缓存中校验dedupkey， 存在则直接返回。  token  client去server请求token， token 为server端生成的全局唯一标识（业务编码或订单号） client数据请求绑定token server校验：  1. 缓存中token和client请求绑定的token不一致，则拒绝处理\r2. client请求未绑定token，则拒绝处理\r3. 缓存中没有token， 则拒绝处理\rredis atomic  client 每次请求，server端生成一个 userId + request（请求数据） 的唯一标识，放到缓存中； server校验client请求是否已经存在，存在则拒绝处理；  ",
    "ref": "/blog/web/%E9%98%B2%E6%AD%A2%E9%87%8D%E5%A4%8D%E6%8F%90%E4%BA%A4/"
  },{
    "title": "Redis使用遇到的问题",
    "date": "",
    "description": "",
    "body": "",
    "ref": "/blog/cache/redis/%E9%97%AE%E9%A2%98/"
  },{
    "title": "记录web开发遇到的问题和详细解决方案",
    "date": "",
    "description": "",
    "body": "中文名下载乱码 对文件名进行UTF-8编码\nhttp文件下载 添加报文头: \u0026quot;content-disposition\u0026quot;, \u0026quot;attachment;filename=$fileName\u0026quot;\n",
    "ref": "/blog/web/%E9%97%AE%E9%A2%98/"
  },{
    "title": "Erlang二进制语法",
    "date": "",
    "description": "",
    "body": "二进制型（binary）  用一种节省空间的方式来保存大批量的无结构原始数据。 多数情况二进制型的位数都是8的整数倍，因此对应一个字节串。如果位数不是8的整数倍，我们叫这段数据为位串（bitstring）。 将二进制型、位串、位级模式匹配引入Erlang 是为了简化网络编程。  格式  \u0026laquo;5,9,10\u0026raquo; : 二进制型的编写和打印形式。 在二进制型里面使用整数时，整数范围0~255.  操作二进制型  list_to_binary(L) -\u0026gt; Bin: 将io列表（iolist）L中的所有元素转换成二进制型。 split_binary(Bin, Pos) -\u0026gt; {Bin1, Bin2}: 将二进制型Bin一分为二。 term_to_binary(Term) -\u0026gt; Bin :将任意Erlang数据类型转换成二进制型。此方法使用了所谓的外部数据格式（external term format）。 binary_to_term(Bin) -\u0026gt; Term : 这是term_to_binary的逆向函数。 byte_size(Bin) -\u0026gt; Size: 返回二进制型里面的字节数。  位语法 位语法是一种表示法，用于从二进制数据里提取或加入单独的位或者位串。开发位语法是为了进行协议编程，以及生成操作二进制数据的高效代码。\n位语法表达式 \u0026lt;\u0026lt; E1,E2,...,E3\u0026gt;\u0026gt;\r每个Ei元素都标示出二进制型或位串里的一个片段。单个Ei元素可以有四种形式：\rEi = Value |\rValue:Size |\rValue/TypeSpecifierList |\rValue:Size/TypeSpecifierList\r 如果表达式的总位数是８的倍数则会构建一个二进制型，否则构建一个位串。　 当构建二进制型时，Value必须是已绑定变量、字符串，或是能够得出整数、浮点数或二进制型的表达式。　当它被用来模式匹配时，Value可以是绑定或未绑定的。 Size必须是一个能得出整数的表达式。在模式匹配里，Size必须是一个整数，或是值为整数的已绑定变量。 Size的值指明了片段的位数大小。它的默认值取决于不同的数据类型：  整数：8\r浮点数：64\rbinary: 1\r 在模式匹配里面，默认值只对最后的元素有效，如果未指定大小，就采用默认值。 TypeSpecifierList(类型指定列表)是一个用连字符分割的列表，形式是End-Sign-Type-Unit。 End可以是 big | little | native : 机器的字节顺序，默认big。这一项只和从二进制型里面打包和解包整数和浮点数有关。term_to_binary 和 binary_to_term可以解决打包和解包整数的问题。 Sign可以是signed | unsigned, 这个参数只用于模式匹配，默认值是unsigned。 Type可以是integer | float | binary | bytes | bitstring | bits | utf8 | utf16 | utf32,默认值是integer。　 Unit的写法是unit:1|2|\u0026hellip;256 : integer、float和bitstring的Unit默认值是１，binary则是８。utf8、utf16、utf32类型无需提供值。 一个片段的总长度是Size * Unit字节。  ",
    "ref": "/blog/erlang/%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%92%8C%E4%BD%8D%E8%AF%AD%E6%B3%95/"
  },{
    "title": "TCP/UDP端口扫描工具",
    "date": "",
    "description": "",
    "body": "译注 该Nmap参考指南中文版由Fei Yang fyang1024@gmail.com和Lei Lililei_721@6611.org 从英文版本翻译而来。 我们希望这将使全世界使用中文的人们更了解Nmap，但我们不能保证该译本和官方的 英文版本一样完整，也不能保证同步更新。 它可以在Creative Commons Attribution License下被修改并重新发布。\n选项概要 当Nmap不带选项运行时，该选项概要会被输出，最新的版本在这里 http://www.insecure.org/nmap/data/nmap.usage.txt。\n它帮助人们记住最常用的选项，但不能替代本手册其余深入的文档，一些晦涩的选项甚至不在这里。\nUsage: nmap [Scan Type(s)] [Options] {target specification} TARGET SPECIFICATION:\nCan pass hostnames, IP addresses, networks, etc.\nEx: scanme.nmap.org, microsoft.com/24, 192.168.0.1; 10.0-255.0-255.1-254\n-iL : Input from list of hosts/networks\n-iR : Choose random targets\n\u0026ndash;exclude \u0026lt;host1[,host2][,host3],\u0026hellip;\u0026gt;: Exclude hosts/networks\n\u0026ndash;excludefile \u0026lt;exclude_file\u0026gt;: Exclude list from file\nHOST DISCOVERY:\n-sL: List Scan - simply list targets to scan\n-sP: Ping Scan - go no further than determining if host is online\n-P0: Treat all hosts as online \u0026ndash; skip host discovery\n-PS/PA/PU [portlist]: TCP SYN/ACK or UDP discovery probes to given ports\n-PE/PP/PM: ICMP echo, timestamp, and netmask request discovery probes\n-n/-R: Never do DNS resolution/Always resolve [default: sometimes resolve]\nSCAN TECHNIQUES:\n-sS/sT/sA/sW/sM: TCP SYN/Connect()/ACK/Window/Maimon scans\n-sN/sF/sX: TCP Null, FIN, and Xmas scans\n\u0026ndash;scanflags : Customize TCP scan flags\n-sI \u0026lt;zombie host[:probeport]\u0026gt;: Idlescan\n-sO: IP protocol scan\n-b : FTP bounce scan\nPORT SPECIFICATION AND SCAN ORDER:\n-p : Only scan specified ports\nEx: -p22; -p1-65535; -p U:53,111,137,T:21-25,80,139,8080\n-F: Fast - Scan only the ports listed in the nmap-services file)\n-r: Scan ports consecutively - don\u0026rsquo;t randomize\nSERVICE/VERSION DETECTION:\n-sV: Probe open ports to determine service/version info\n\u0026ndash;version-light: Limit to most likely probes for faster identification\n\u0026ndash;version-all: Try every single probe for version detection\n\u0026ndash;version-trace: Show detailed version scan activity (for debugging)\nOS DETECTION:\n-O: Enable OS detection\n\u0026ndash;osscan-limit: Limit OS detection to promising targets\n\u0026ndash;osscan-guess: Guess OS more aggressively\nTIMING AND PERFORMANCE:\n-T[0-6]: Set timing template (higher is faster)\n\u0026ndash;min-hostgroup/max-hostgroup : Parallel host scan group sizes\n\u0026ndash;min-parallelism/max-parallelism : Probe parallelization\n\u0026ndash;min-rtt-timeout/max-rtt-timeout/initial-rtt-timeout : Specifies\nprobe round trip time.\n\u0026ndash;host-timeout : Give up on target after this long\n\u0026ndash;scan-delay/\u0026ndash;max-scan-delay : Adjust delay between probes\nFIREWALL/IDS EVASION AND SPOOFING:\n-f; \u0026ndash;mtu : fragment packets (optionally w/given MTU)\n-D \u0026lt;decoy1,decoy2[,ME],\u0026hellip;\u0026gt;: Cloak a scan with decoys\n-S \u0026lt;IP_Address\u0026gt;: Spoof source address\n-e : Use specified interface\n-g/\u0026ndash;source-port : Use given port number\n\u0026ndash;data-length : Append random data to sent packets\n\u0026ndash;ttl : Set IP time-to-live field\n\u0026ndash;spoof-mac \u0026lt;mac address, prefix, or vendor name\u0026gt;: Spoof your MAC address\nOUTPUT:\n-oN/-oX/-oS/-oG : Output scan results in normal, XML, s|\u0026lt;rIpt kIddi3,\nand Grepable format, respectively, to the given filename.\n-oA : Output in the three major formats at once\n-v: Increase verbosity level (use twice for more effect)\n-d[level]: Set or increase debugging level (Up to 9 is meaningful)\n\u0026ndash;packet-trace: Show all packets sent and received\n\u0026ndash;iflist: Print host interfaces and routes (for debugging)\n\u0026ndash;append-output: Append to rather than clobber specified output files\n\u0026ndash;resume : Resume an aborted scan\n\u0026ndash;stylesheet \u0026lt;path/URL\u0026gt;: XSL stylesheet to transform XML output to HTML\n\u0026ndash;no-stylesheet: Prevent Nmap from associating XSL stylesheet w/XML output\nMISC:\n-6: Enable IPv6 scanning\n-A: Enables OS detection and Version detection\n\u0026ndash;datadir : Specify custom Nmap data file location\n\u0026ndash;send-eth/\u0026ndash;send-ip: Send packets using raw ethernet frames or IP packets\n\u0026ndash;privileged: Assume that the user is fully privileged\n-V: Print version number\n-h: Print this help summary page.\nEXAMPLES:\nnmap -v -A scanme.nmap.org\nnmap -v -sP 192.168.0.0/16 10.0.0.0/8\nnmap -v -iR 10000 -P0 -p 80\n目标说明 除了选项，所有出现在Nmap命令行上的都被视为对目标主机的说明。 最简单的情况是指定一个目标IP地址或主机名。\n有时候您希望扫描整个网络的相邻主机。为此，Nmap支持CIDR风格的地址。您可以附加 一个/在一个IP地址或主机名后面， Nmap将会扫描所有和该参考IP地址具有 相同比特的所有IP地址或主机。 例如，192.168.10.0/24将会扫描192.168.10.0 (二进制格式: 11000000 10101000 00001010 00000000)和192.168.10.255 (二进制格式: 11000000 10101000 00001010 11111111)之间的256台主机。 192.168.10.40/24 将会做同样的事情。假设主机 scanme.nmap.org的IP地址是205.217.153.62， scanme.nmap.org/16 将扫描205.217.0.0和205.217.255.255之间的65,536 个IP地址。 所允许的最小值是/1， 这将会扫描半个互联网。最大值是/32，这将会扫描该主机或IP地址， 因为所有的比特都固定了。\nCIDR标志位很简洁但有时候不够灵活。例如，您也许想要扫描 192.168.0.0/16，但略过任何以.0或者.255 结束的IP地址，因为它们通常是广播地址。 Nmap通过八位字节地址范围支持这样的扫描 您可以用逗号分开的数字或范围列表为IP地址的每个八位字节指定它的范围。 例如，192.168.0-255.1-254 将略过在该范围内以.0和.255结束的地址。 范围不必限于最后的8位：0-255.0-255.13.37 将在整个互联网范围内扫描所有以13.37结束的地址。 这种大范围的扫描对互联网调查研究也许有用。\nIPv6地址只能用规范的IPv6地址或主机名指定。 CIDR 和八位字节范围不支持IPv6，因为它们对于IPv6几乎没什么用。\nNmap命令行接受多个主机说明，它们不必是相同类型。命令nmap scanme.nmap.org 192.168.0.0/8 10.0.0，1，3-7.0-255将和您预期的一样执行。\n虽然目标通常在命令行指定，下列选项也可用来控制目标的选择：\n-iL  (从列表中输入)\n从 中读取目标说明。在命令行输入 一堆主机名显得很笨拙，然而经常需要这样。 例如，您的DHCP服务器可能导出10,000个当前租约的列表，而您希望对它们进行 扫描。如果您不是使用未授权的静态IP来定位主机，或许您想要扫描所有IP地址。 只要生成要扫描的主机的列表，用-iL 把文件名作为选项传给Nmap。列表中的项可以是Nmap在 命令行上接受的任何格式(IP地址，主机名，CIDR，IPv6，或者八位字节范围)。 每一项必须以一个或多个空格，制表符或换行符分开。 如果您希望Nmap从标准输入而不是实际文件读取列表， 您可以用一个连字符(-)作为文件名。\n-iR  (随机选择目标)\n对于互联网范围内的调查和研究， 您也许想随机地选择目标。  选项告诉 Nmap生成多少个IP。不合需要的IP如特定的私有，组播或者未分配的地址自动 略过。选项 0 意味着永无休止的扫描。记住，一些网管对于未授权的扫描可能会很感冒并加以抱怨。 使用该选项的后果自负! 如果在某个雨天的下午，您觉得实在无聊， 试试这个命令nmap -sS -PS80 -iR 0 -p 80随机地找一些网站浏览。\n\u0026ndash;exclude \u0026lt;host1[，host2][，host3]，\u0026hellip;\u0026gt; (排除主机/网络)\n如果在您指定的扫描范围有一些主机或网络不是您的目标， 那就用该选项加上以逗号分隔的列表排除它们。该列表用正常的Nmap语法， 因此它可以包括主机名，CIDR，八位字节范围等等。 当您希望扫描的网络包含执行关键任务的服务器，已知的对端口扫描反应强烈的 系统或者被其它人看管的子网时，这也许有用。\n\u0026ndash;excludefile  (排除文件中的列表)\n这和\u0026ndash;exclude 选项的功能一样，只是所排除的目标是用以 换行符，空格，或者制表符分隔的 提供的，而不是在命令行上输入的。\n主机发现 任何网络探测任务的最初几个步骤之一就是把一组IP范围(有时该范围是巨大的)缩小为 一列活动的或者您感兴趣的主机。扫描每个IP的每个端口很慢，通常也没必要。 当然，什么样的主机令您感兴趣主要依赖于扫描的目的。网管也许只对运行特定服务的 主机感兴趣，而从事安全的人士则可能对一个马桶都感兴趣，只要它有IP地址:-)。一个系统管理员 也许仅仅使用Ping来定位内网上的主机，而一个外部入侵测试人员则可能绞尽脑汁用各种方法试图 突破防火墙的封锁。\n由于主机发现的需求五花八门，Nmap提供了一箩筐的选项来定制您的需求。 主机发现有时候也叫做ping扫描，但它远远超越用世人皆知的ping工具 发送简单的ICMP回声请求报文。用户完全可以通过使用列表扫描(-sL)或者 通过关闭ping (-P0)跳过ping的步骤，也可以使用多个端口把TPC SYN/ACK，UDP和ICMP 任意组合起来玩一玩。这些探测的目的是获得响应以显示某个IP地址是否是活动的(正在被某 主机或者网络设备使用)。 在许多网络上，在给定的时间，往往只有小部分的IP地址是活动的。 这种情况在基于RFC1918的私有地址空间如10.0.0.0/8尤其普遍。 那个网络有16,000,000个IP，但我见过一些使用它的公司连1000台机器都没有。 主机发现能够找到零星分布于IP地址海洋上的那些机器。\n如果没有给出主机发现的选项，Nmap 就发送一个TCP ACK报文到80端口和一个ICMP回声请求到每台目标机器。 一个例外是ARP扫描用于局域网上的任何目标机器。对于非特权UNIX shell用户，使用connect()系统调用会发送一个SYN报文而不是ACK 这些默认行为和使用-PA -PE选项的效果相同。 扫描局域网时，这种主机发现一般够用了，但是对于安全审核，建议进行 更加全面的探测。\n-P选项(用于选择 ping的类型)可以被结合使用。 您可以通过使用不同的TCP端口/标志位和ICMP码发送许多探测报文 来增加穿透防守严密的防火墙的机会。另外要注意的是即使您指定了其它 -P选项，ARP发现(-PR)对于局域网上的 目标而言是默认行为，因为它总是更快更有效。\n下列选项控制主机发现。\n-sL (列表扫描)\n列表扫描是主机发现的退化形式，它仅仅列出指定网络上的每台主机， 不发送任何报文到目标主机。默认情况下，Nmap仍然对主机进行反向域名解析以获取 它们的名字。简单的主机名能给出的有用信息常常令人惊讶。例如， fw.chi.playboy.com是花花公子芝加哥办公室的 防火墙。Nmap最后还会报告IP地址的总数。列表扫描可以很好的确保您拥有正确的目标IP。 如果主机的域名出乎您的意料，那么就值得进一步检查以防错误地扫描其它组织的网络。\n既然只是打印目标主机的列表，像其它一些高级功能如端口扫描，操作系统探测或者Ping扫描 的选项就没有了。如果您希望关闭ping扫描而仍然执行这样的高级功能，请继续阅读关于 -P0选项的介绍。\n-sP (Ping扫描)\n该选项告诉Nmap仅仅 进行ping扫描 (主机发现)，然后打印出对扫描做出响应的那些主机。 没有进一步的测试 (如端口扫描或者操作系统探测)。 这比列表扫描更积极，常常用于 和列表扫描相同的目的。它可以得到些许目标网络的信息而不被特别注意到。 对于攻击者来说，了解多少主机正在运行比列表扫描提供的一列IP和主机名往往更有价值。\n系统管理员往往也很喜欢这个选项。 它可以很方便地得出 网络上有多少机器正在运行或者监视服务器是否正常运行。常常有人称它为 地毯式ping，它比ping广播地址更可靠，因为许多主机对广播请求不响应。\n-sP选项在默认情况下， 发送一个ICMP回声请求和一个TCP报文到80端口。如果非特权用户执行，就发送一个SYN报文 (用connect()系统调用)到目标机的80端口。 当特权用户扫描局域网上的目标机时，会发送ARP请求(-PR)， ，除非使用了\u0026ndash;send-ip选项。 -sP选项可以和除-P0)之外的任何发现探测类型-P* 选项结合使用以达到更大的灵活性。 一旦使用了任何探测类型和端口选项，默认的探测(ACK和回应请求)就被覆盖了。 当防守严密的防火墙位于运行Nmap的源主机和目标网络之间时， 推荐使用那些高级选项。否则，当防火墙捕获并丢弃探测包或者响应包时，一些主机就不能被探测到。\n-P0 (无ping)\n该选项完全跳过Nmap发现阶段。 通常Nmap在进行高强度的扫描时用它确定正在运行的机器。 默认情况下，Nmap只对正在运行的主机进行高强度的探测如 端口扫描，版本探测，或者操作系统探测。用-P0禁止 主机发现会使Nmap对每一个指定的目标IP地址 进行所要求的扫描。所以如果在命令行指定一个B类目标地址空间(/16)， 所有 65,536 个IP地址都会被扫描。 -P0的第二个字符是数字0而不是字母O。 和列表扫描一样，跳过正常的主机发现，但不是打印一个目标列表， 而是继续执行所要求的功能，就好像每个IP都是活动的。\n-PS [portlist] (TCP SYN Ping)\n该选项发送一个设置了SYN标志位的空TCP报文。 默认目的端口为80 (可以通过改变nmap.h) 文件中的DEFAULT-TCP-PROBE-PORT值进行配置，但不同的端口也可以作为选项指定。 甚至可以指定一个以逗号分隔的端口列表(如 -PS22，23，25，80，113，1050，35000)， 在这种情况下，每个端口会被并发地扫描。\nSYN标志位告诉对方您正试图建立一个连接。 通常目标端口是关闭的，一个RST (复位) 包会发回来。 如果碰巧端口是开放的，目标会进行TCP三步握手的第二步，回应 一个SYN/ACK TCP报文。然后运行Nmap的机器则会扼杀这个正在建立的连接， 发送一个RST而非ACK报文，否则，一个完全的连接将会建立。 RST报文是运行Nmap的机器而不是Nmap本身响应的，因为它对收到 的SYN/ACK感到很意外。\nNmap并不关心端口开放还是关闭。 无论RST还是SYN/ACK响应都告诉Nmap该主机正在运行。\n在UNIX机器上，通常只有特权用户 root 能否发送和接收 原始的TCP报文。因此作为一个变通的方法，对于非特权用户， Nmap会为每个目标主机进行系统调用connect()，它也会发送一个SYN 报文来尝试建立连接。如果connect()迅速返回成功或者一个ECONNREFUSED 失败，下面的TCP堆栈一定已经收到了一个SYN/ACK或者RST，该主机将被 标志位为在运行。 如果连接超时了，该主机就标志位为down掉了。这种方法也用于IPv6 连接，因为Nmap目前还不支持原始的IPv6报文。\n-PA [portlist] (TCP ACK Ping)\nTCP ACK ping和刚才讨论的SYN ping相当类似。 也许您已经猜到了，区别就是设置TCP的ACK标志位而不是SYN标志位。 ACK报文表示确认一个建立连接的尝试，但该连接尚未完全建立。 所以远程主机应该总是回应一个RST报文， 因为它们并没有发出过连接请求到运行Nmap的机器，如果它们正在运行的话。\n-PA选项使用和SYN探测相同的默认端口(80)，也可以 用相同的格式指定目标端口列表。如果非特权用户尝试该功能， 或者指定的是IPv6目标，前面说过的connect()方法将被使用。 这个方法并不完美，因为它实际上发送的是SYN报文，而不是ACK报文。\n提供SYN和ACK两种ping探测的原因是使通过防火墙的机会尽可能大。 许多管理员会配置他们的路由器或者其它简单的防火墙来封锁SYN报文，除非 连接目标是那些公开的服务器像公司网站或者邮件服务器。 这可以阻止其它进入组织的连接，同时也允许用户访问互联网。 这种无状态的方法几乎不占用防火墙/路由器的资源，因而被硬件和软件过滤器 广泛支持。Linux Netfilter/iptables 防火墙软件提供方便的 \u0026ndash;syn选项来实现这种无状态的方法。 当这样的无状态防火墙规则存在时，发送到关闭目标端口的SYN ping探测 (-PS) 很可能被封锁。这种情况下，ACK探测格外有闪光点，因为它正好利用了 这样的规则。\n另外一种常用的防火墙用有状态的规则来封锁非预期的报文。 这一特性已开始只存在于高端防火墙，但是这些年类它越来越普遍了。 Linux Netfilter/iptables 通过 \u0026ndash;state选项支持这一特性，它根据连接状态把报文 进行分类。SYN探测更有可能用于这样的系统，由于没头没脑的ACK报文 通常会被识别成伪造的而丢弃。解决这个两难的方法是通过即指定 -PS又指定-PA来即发送SYN又发送ACK。\n-PU [portlist] (UDP Ping)\n还有一个主机发现的选项是UDP ping，它发送一个空的(除非指定了\u0026ndash;data-length UDP报文到给定的端口。端口列表的格式和前面讨论过的-PS和-PA选项还是一样。 如果不指定端口，默认是31338。该默认值可以通过在编译时改变nmap.h文件中的 DEFAULT-UDP-PROBE-PORT值进行配置。默认使用这样一个奇怪的端口是因为对开放端口 进行这种扫描一般都不受欢迎。\n如果目标机器的端口是关闭的，UDP探测应该马上得到一个ICMP端口无法到达的回应报文。 这对于Nmap意味着该机器正在运行。 许多其它类型的ICMP错误，像主机/网络无法到达或者TTL超时则表示down掉的或者不可到达的主机。 没有回应也被这样解释。如果到达一个开放的端口，大部分服务仅仅忽略这个 空报文而不做任何回应。这就是为什么默认探测端口是31338这样一个 极不可能被使用的端口。少数服务如chargen会响应一个空的UDP报文， 从而向Nmap表明该机器正在运行。\n该扫描类型的主要优势是它可以穿越只过滤TCP的防火墙和过滤器。 例如。我曾经有过一个Linksys BEFW11S4无线宽带路由器。默认情况下， 该设备对外的网卡过滤所有TCP端口，但UDP探测仍然会引发一个端口不可到达 的消息，从而暴露了它自己。\n-PE; -PP; -PM (ICMP Ping Types)\n除了前面讨论的这些不常见的TCP和UDP主机发现类型， Nmap也能发送世人皆知的ping 程序所发送的报文。Nmap发送一个ICMP type 8 (回声请求)报文到目标IP地址， 期待从运行的主机得到一个type 0 (回声响应)报文。 对于网络探索者而言，不幸的是，许多主机和 防火墙现在封锁这些报文，而不是按期望的那样响应， 参见RFC 1122。因此，仅仅ICMP扫描对于互联网上的目标通常是不够的。 但对于系统管理员监视一个内部网络，它们可能是实际有效的途径。 使用-PE选项打开该回声请求功能。\n虽然回声请求是标准的ICMP ping查询， Nmap并不止于此。ICMP标准 (RFC 792)还规范了时间戳请求，信息请求 request，和地址掩码请求，它们的代码分别是13，15和17。 虽然这些查询的表面目的是获取信息如地址掩码和当前时间， 它们也可以很容易地用于主机发现。 很简单，回应的系统就是在运行的系统。Nmap目前没有实现信息请求报文， 因为它们还没有被广泛支持。RFC 1122 坚持 “主机不应该实现这些消息”。 时间戳和地址掩码查询可以分别用-PP和-PM选项发送。 时间戳响应(ICMP代码14)或者地址掩码响应(代码18)表示主机在运行。 当管理员特别封锁了回声请求报文而忘了其它ICMP查询可能用于 相同目的时，这两个查询可能很有价值。\n-PR (ARP Ping)\n最常见的Nmap使用场景之一是扫描一个以太局域网。 在大部分局域网上，特别是那些使用基于 RFC1918私有地址范围的网络，在一个给定的时间绝大部分 IP地址都是不使用的。 当Nmap试图发送一个原始IP报文如ICMP回声请求时， 操作系统必须确定对应于目标IP的硬件 地址(ARP)，这样它才能把以太帧送往正确的地址。 这一般比较慢而且会有些问题，因为操作系统设计者认为一般不会在短时间内 对没有运行的机器作几百万次的ARP请求。\n当进行ARP扫描时，Nmap用它优化的算法管理ARP请求。 当它收到响应时， Nmap甚至不需要担心基于IP的ping报文，既然它已经知道该主机正在运行了。 这使得ARP扫描比基于IP的扫描更快更可靠。 所以默认情况下，如果Nmap发现目标主机就在它所在的局域网上，它会进行ARP扫描。 即使指定了不同的ping类型(如 -PI或者 -PS) ，Nmap也会对任何相同局域网上的目标机使用ARP。 如果您真的不想要ARP扫描，指定 \u0026ndash;send-ip。\n-n (不用域名解析)\n告诉Nmap 永不对它发现的活动IP地址进行反向域名解析。 既然DNS一般比较慢，这可以让事情更快些。\n-R (为所有目标解析域名)\n告诉Nmap 永远 对目标IP地址作反向域名解析。 一般只有当发现机器正在运行时才进行这项操作。\n\u0026ndash;system-dns (使用系统域名解析器)\n默认情况下，Nmap通过直接发送查询到您的主机上配置的域名服务器 来解析域名。为了提高性能，许多请求 (一般几十个 ) 并发执行。如果您希望使用系统自带的解析器，就指定该选项 (通过getnameinfo()调用一次解析一个IP)。除非Nmap的DNS代码有bug\u0026ndash;如果是这样，请联系我们。 一般不使用该选项，因为它慢多了。系统解析器总是用于IPv6扫描。\n端口扫描基础 虽然Nmap这些年来功能越来越多， 它也是从一个高效的端口扫描器开始的，并且那仍然是它的核心功能。 nmap 这个简单的命令扫描主机上的超过 1660个TCP端口。 。许多传统的端口扫描器只列出所有端口是开放还是关闭的， Nmap的信息粒度比它们要细得多。 它把端口分成六个状态: open(开放的)， closed(关闭的)，filtered(被过滤的)， unfiltered(未被过滤的)， open|filtered(开放或者被过滤的)，或者 closed|filtered(关闭或者被过滤的)。\n这些状态并非端口本身的性质，而是描述Nmap怎样看待它们。例如， 对于同样的目标机器的135/tcp端口，从同网络扫描显示它是开放的，而跨网络作完全相同的扫描则可能显示它是 filtered(被过滤的)。\nNmap所识别的6个端口状态。\nopen(开放的)\n应用程序正在该端口接收TCP 连接或者UDP报文。发现这一点常常是端口扫描 的主要目标。安全意识强的人们知道每个开放的端口 都是攻击的入口。攻击者或者入侵测试者想要发现开放的端口。 而管理员则试图关闭它们或者用防火墙保护它们以免妨碍了合法用户。 非安全扫描可能对开放的端口也感兴趣，因为它们显示了网络上那些服务可供使用。\nclosed(关闭的)\n关闭的端口对于Nmap也是可访问的(它接受Nmap的探测报文并作出响应)， 但没有应用程序在其上监听。 它们可以显示该IP地址上(主机发现，或者ping扫描)的主机正在运行up 也对部分操作系统探测有所帮助。 因为关闭的关口是可访问的，也许过会儿值得再扫描一下，可能一些又开放了。 系统管理员可能会考虑用防火墙封锁这样的端口。 那样他们就会被显示为被过滤的状态，下面讨论。\nfiltered(被过滤的)\n由于包过滤阻止探测报文到达端口， Nmap无法确定该端口是否开放。过滤可能来自专业的防火墙设备，路由器规则 或者主机上的软件防火墙。这样的端口让攻击者感觉很挫折，因为它们几乎不提供 任何信息。有时候它们响应ICMP错误消息如类型3代码13 (无法到达目标: 通信被管理员禁止)，但更普遍的是过滤器只是丢弃探测帧， 不做任何响应。 这迫使Nmap重试若干次以访万一探测包是由于网络阻塞丢弃的。 这使得扫描速度明显变慢。\nunfiltered(未被过滤的)\n未被过滤状态意味着端口可访问，但Nmap不能确定它是开放还是关闭。 只有用于映射防火墙规则集的ACK扫描才会把端口分类到这种状态。 用其它类型的扫描如窗口扫描，SYN扫描，或者FIN扫描来扫描未被过滤的端口可以帮助确定 端口是否开放。\nopen|filtered(开放或者被过滤的)\n当无法确定端口是开放还是被过滤的，Nmap就把该端口划分成 这种状态。开放的端口不响应就是一个例子。没有响应也可能意味着报文过滤器丢弃 了探测报文或者它引发的任何响应。因此Nmap无法确定该端口是开放的还是被过滤的。 UDP，IP协议， FIN，Null，和Xmas扫描可能把端口归入此类。\nclosed|filtered(关闭或者被过滤的)\n该状态用于Nmap不能确定端口是关闭的还是被过滤的。 它只可能出现在IPID Idle扫描中。\n端口扫描技术 作为一个修车新手，我可能折腾几个小时来摸索怎样把基本工具(锤子，胶带，扳子等) 用于手头的任务。当我惨痛地失败，把我的老爷车拖到一个真正的技师那儿的时候 ，他总是在他的工具箱里翻来翻去，直到拽出一个完美的工具然后似乎不费吹灰之力搞定它。 端口扫描的艺术和这个类似。专家理解成打的扫描技术，选择最适合的一种 (或者组合)来完成给定的 任务。 另一方面，没有经验的用户和刚入门者总是用默认的SYN扫描解决每个问题。 既然Nmap是免费的，掌握端口扫描的唯一障碍就是知识。这当然是汽车世界所不能比的， 在那里，可能需要高超的技巧才能确定您需要一个压杆弹簧压缩机，接着您还得为它付数千美金。\n大部分扫描类型只对特权用户可用。 这是因为他们发送接收原始报文，这在Unix系统需要root权限。 在Windows上推荐使用administrator账户，但是当WinPcap已经被加载到操作系统时， 非特权用户也可以正常使用Nmap。当Nmap在1997年发布时，需要root权限是一个严重的 局限，因为很多用户只有共享的shell账户。现在，世界变了，计算机便宜了，更多人拥有互联网连接 ，桌面UNIX系统 (包括Linux和MAC OS X)很普遍了。Windows版本的Nmap现在也有了，这使它可以运行在更多的桌面上。 由于所有这些原因，用户不再需要用有限的共享shell账户运行Nmap。 这是很幸运的，因为特权选项让Nmap强大得多也灵活得多。\n虽然Nmap努力产生正确的结果，但请记住所有结果都是基于目标机器(或者它们前面的防火墙)返回的报文的。 。这些主机也许是不值得信任的，它们可能响应以迷惑或误导Nmap的报文。 更普遍的是非RFC兼容的主机以不正确的方式响应Nmap探测。FIN，Null和Xmas扫描 特别容易遇到这个问题。这些是特定扫描类型的问题，因此我们在个别扫描类型里讨论它们。\n这一节讨论Nmap支持的大约十几种扫描技术。 一般一次只用一种方法， 除了UDP扫描(-sU)可能和任何一种TCP扫描类型结合使用。 友情提示一下，端口扫描类型的选项格式是-s， 其中 是个显眼的字符，通常是第一个字符。 一个例外是deprecated FTP bounce扫描(-b)。默认情况下，Nmap执行一个 SYN扫描，但是如果用户没有权限发送原始报文(在UNIX上需要root权限)或者如果指定的是IPv6目标，Nmap调用connect()。 本节列出的扫描中，非特权用户只能执行connect()和ftp bounce扫描。\n-sS (TCP SYN扫描)\nSYN扫描作为默认的也是最受欢迎的扫描选项，是有充分理由的。 它执行得很快，在一个没有入侵防火墙的快速网络上，每秒钟可以扫描数千个 端口。 SYN扫描相对来说不张扬，不易被注意到，因为它从来不完成TCP连接。 它也不像Fin/Null/Xmas，Maimon和Idle扫描依赖于特定平台，而可以应对任何兼容的 TCP协议栈。 它还可以明确可靠地区分open(开放的)， closed(关闭的)，和filtered(被过滤的) 状态\n它常常被称为半开放扫描， 因为它不打开一个完全的TCP连接。它发送一个SYN报文， 就像您真的要打开一个连接，然后等待响应。 SYN/ACK表示端口在监听 (开放)，而 RST (复位)表示没有监听者。如果数次重发后仍没响应， 该端口就被标记为被过滤。如果收到ICMP不可到达错误 (类型3，代码1，2，3，9，10，或者13)，该端口也被标记为被过滤。\n-sT (TCP connect()扫描)\n当SYN扫描不能用时，CP Connect()扫描就是默认的TCP扫描。 当用户没有权限发送原始报文或者扫描IPv6网络时，就是这种情况。 Instead of writing raw packets as most other scan types do，Nmap通过创建connect() 系统调用要求操作系统和目标机以及端口建立连接，而不像其它扫描类型直接发送原始报文。 这是和Web浏览器，P2P客户端以及大多数其它网络应用程序用以建立连接一样的 高层系统调用。它是叫做Berkeley Sockets API编程接口的一部分。Nmap用 该API获得每个连接尝试的状态信息，而不是读取响应的原始报文。\n当SYN扫描可用时，它通常是更好的选择。因为Nmap对高层的 connect()调用比对原始报文控制更少， 所以前者效率较低。 该系统调用完全连接到开放的目标端口而不是像SYN扫描进行 半开放的复位。这不仅花更长时间，需要更多报文得到同样信息，目标机也更可能 记录下连接。IDS(入侵检测系统)可以捕获两者，但大部分机器没有这样的警报系统。 当Nmap连接，然后不发送数据又关闭连接， 许多普通UNIX系统上的服务会在syslog留下记录，有时候是一条加密的错误消息。 此时，有些真正可怜的服务会崩溃，虽然这不常发生。如果管理员在日志里看到来自同一系统的 一堆连接尝试，她应该知道她的系统被扫描了。\n-sU (UDP扫描)\n虽然互联网上很多流行的服务运行在TCP 协议上，UDP服务也不少。 DNS，SNMP，和DHCP (注册的端口是53，161/162，和67/68)是最常见的三个。 因为UDP扫描一般较慢，比TCP更困难，一些安全审核人员忽略这些端口。 这是一个错误，因为可探测的UDP服务相当普遍，攻击者当然不会忽略整个协议。 所幸，Nmap可以帮助记录并报告UDP端口。\nUDP扫描用-sU选项激活。它可以和TCP扫描如 SYN扫描 (-sS)结合使用来同时检查两种协议。\nUDP扫描发送空的(没有数据)UDP报头到每个目标端口。 如果返回ICMP端口不可到达错误(类型3，代码3)， 该端口是closed(关闭的)。 其它ICMP不可到达错误(类型3， 代码1，2，9，10，或者13)表明该端口是filtered(被过滤的)。 偶尔地，某服务会响应一个UDP报文，证明该端口是open(开放的)。 如果几次重试后还没有响应，该端口就被认为是 open|filtered(开放|被过滤的)。 这意味着该端口可能是开放的，也可能包过滤器正在封锁通信。 可以用版本扫描(-sV)帮助区分真正的开放端口和被过滤的端口。\nUDP扫描的巨大挑战是怎样使它更快速。 开放的和被过滤的端口很少响应，让Nmap超时然后再探测，以防探测帧或者 响应丢失。关闭的端口常常是更大的问题。 它们一般发回一个ICMP端口无法到达错误。但是不像关闭的TCP端口响应SYN或者Connect 扫描所发送的RST报文，许多主机在默认情况下限制ICMP端口不可到达消息。 Linux和Solaris对此特别严格。例如， Linux 2.4.20内核限制一秒钟只发送一条目标不可到达消息 (见net/ipv4/icmp。c)。\nNmap探测速率限制并相应地减慢来避免用那些目标机会丢弃的无用报文来阻塞 网络。不幸的是，Linux式的一秒钟一个报文的限制使65,536个端口的扫描要花 18小时以上。加速UDP扫描的方法包括并发扫描更多的主机，先只对主要端口进行快速 扫描，从防火墙后面扫描，使用\u0026ndash;host-timeout跳过慢速的 主机。\n-sN; -sF; -sX (TCP Null，FIN，and Xmas扫描)\n这三种扫描类型 (甚至用下一节描述的 \u0026ndash;scanflags 选项的更多类型) 在TCP RFC 中发掘了一个微妙的方法来区分open(开放的)和 closed(关闭的)端口。第65页说“如果 [目标]端口状态是关闭的\u0026hellip;. 进入的不含RST的报文导致一个RST响应。” 接下来的一页 讨论不设置SYN，RST，或者ACK位的报文发送到开放端口: “理论上，这不应该发生，如果您确实收到了，丢弃该报文，返回。 ”\n如果扫描系统遵循该RFC，当端口关闭时，任何不包含SYN，RST，或者ACK位的报文会导致 一个RST返回，而当端口开放时，应该没有任何响应。只要不包含SYN，RST，或者ACK， 任何其它三种(FIN，PSH，and URG)的组合都行。Nmap有三种扫描类型利用这一点：\nNull扫描 (-sN)\n不设置任何标志位(tcp标志头是0)\nFIN扫描 (-sF)\n只设置TCP FIN标志位。\nXmas扫描 (-sX)\n设置FIN，PSH，和URG标志位，就像点亮圣诞树上所有的灯一样。\n除了探测报文的标志位不同，这三种扫描在行为上完全一致。 如果收到一个RST报文，该端口被认为是 closed(关闭的)，而没有响应则意味着 端口是open|filtered(开放或者被过滤的)。 如果收到ICMP不可到达错误(类型 3，代号 1，2，3，9，10，或者13)，该端口就被标记为 被过滤的。\n这些扫描的关键优势是它们能躲过一些无状态防火墙和报文过滤路由器。 另一个优势是这些扫描类型甚至比SYN扫描还要隐秘一些。但是别依赖它 \u0026ndash; 多数 现代的IDS产品可以发现它们。一个很大的不足是并非所有系统都严格遵循RFC 793。 许多系统不管端口开放还是关闭，都响应RST。 这导致所有端口都标记为closed(关闭的)。 这样的操作系统主要有Microsoft Windows，许多Cisco设备，BSDI，以及IBM OS/400。 但是这种扫描对多数UNIX系统都能工作。这些扫描的另一个不足是 它们不能辨别open(开放的)端口和一些特定的 filtered(被过滤的)端口，从而返回 open|filtered(开放或者被过滤的)。\n-sA (TCP ACK扫描)\n这种扫描与目前为止讨论的其它扫描的不同之处在于 它不能确定open(开放的)或者 open|filtered(开放或者过滤的))端口。 它用于发现防火墙规则，确定它们是有状态的还是无状态的，哪些端口是被过滤的。\nACK扫描探测报文只设置ACK标志位(除非您使用 \u0026ndash;scanflags)。当扫描未被过滤的系统时， open(开放的)和closed(关闭的) 端口 都会返回RST报文。Nmap把它们标记为 unfiltered(未被过滤的)，意思是 ACK报文不能到达，但至于它们是open(开放的)或者 closed(关闭的) 无法确定。不响应的端口 或者发送特定的ICMP错误消息(类型3，代号1，2，3，9，10， 或者13)的端口，标记为 filtered(被过滤的)。\n-sW (TCP窗口扫描)\n除了利用特定系统的实现细节来区分开放端口和关闭端口，当收到RST时不总是打印unfiltered， 窗口扫描和ACK扫描完全一样。 它通过检查返回的RST报文的TCP窗口域做到这一点。 在某些系统上，开放端口用正数表示窗口大小(甚至对于RST报文) 而关闭端口的窗口大小为0。因此，当收到RST时，窗口扫描不总是把端口标记为 unfiltered， 而是根据TCP窗口值是正数还是0，分别把端口标记为open或者 closed\n该扫描依赖于互联网上少数系统的实现细节， 因此您不能永远相信它。不支持它的系统会通常返回所有端口closed。 当然，一台机器没有开放端口也是有可能的。 如果大部分被扫描的端口是 closed，而一些常见的端口 (如 22， 25，53) 是 filtered，该系统就非常可疑了。 偶尔地，系统甚至会显示恰恰相反的行为。 如果您的扫描显示1000个开放的端口和3个关闭的或者被过滤的端口， 那么那3个很可能也是开放的端口。\n-sM (TCP Maimon扫描)\nMaimon扫描是用它的发现者Uriel Maimon命名的。他在 Phrack Magazine issue #49 (November 1996)中描述了这一技术。 Nmap在两期后加入了这一技术。 这项技术和Null，FIN，以及Xmas扫描完全一样，除了探测报文是FIN/ACK。 根据RFC 793 (TCP)，无论端口开放或者关闭，都应该对这样的探测响应RST报文。 然而，Uriel注意到如果端口开放，许多基于BSD的系统只是丢弃该探测报文。\n\u0026ndash;scanflags (定制的TCP扫描)\n真正的Nmap高级用户不需要被这些现成的扫描类型束缚。 \u0026ndash;scanflags选项允许您通过指定任意TCP标志位来设计您自己的扫描。 让您的创造力流动，躲开那些仅靠本手册添加规则的入侵检测系统！\n\u0026ndash;scanflags选项可以是一个数字标记值如9 (PSH和FIN)， 但使用字符名更容易些。 只要是URG， ACK，PSH， RST，SYN，and FIN的任何组合就行。例如，\u0026ndash;scanflags URGACKPSHRSTSYNFIN设置了所有标志位，但是这对扫描没有太大用处。 标志位的顺序不重要。\n除了设置需要的标志位，您也可以设置 TCP扫描类型(如-sA或者-sF)。 那个基本类型告诉Nmap怎样解释响应。例如， SYN扫描认为没有响应意味着 filtered端口，而FIN扫描则认为是 open|filtered。 除了使用您指定的TCP标记位，Nmap会和基本扫描类型一样工作。 如果您不指定基本类型，就使用SYN扫描。\n-sI \u0026lt;zombie host[:probeport]\u0026gt; (Idlescan)\n这种高级的扫描方法允许对目标进行真正的TCP端口盲扫描 (意味着没有报文从您的真实IP地址发送到目标)。相反，side-channel攻击 利用zombie主机上已知的IP分段ID序列生成算法来窥探目标上开放端口的信息。 IDS系统将显示扫描来自您指定的zombie机(必须运行并且符合一定的标准)。 这种奇妙的扫描类型太复杂了，不能在此完全描述，所以我写一篇非正式的论文， 发布在http://nmap.org/book/idlescan.html。\n除了极端隐蔽(由于它不从真实IP地址发送任何报文)， 该扫描类型可以建立机器间的基于IP的信任关系。 端口列表从zombie 主机的角度。显示开放的端口。 因此您可以尝试用您认为(通过路由器/包过滤规则)可能被信任的 zombies扫描目标。\n如果您由于IPID改变希望探测zombie上的特定端口， 您可以在zombie 主机后加上一个冒号和端口号。 否则Nmap会使用默认端口(80)。\n-sO (IP协议扫描)\nIP 协议扫描可以让您确定目标机支持哪些IP协议 (TCP，ICMP，IGMP，等等)。从技术上说，这不是端口扫描 ，既然它遍历的是IP协议号而不是TCP或者UDP端口号。 但是它仍使用 -p选项选择要扫描的协议号， 用正常的端口表格式报告结果，甚至用和真正的端口扫描一样 的扫描引擎。因此它和端口扫描非常接近，也被放在这里讨论。\n除了本身很有用，协议扫描还显示了开源软件的力量。 尽管基本想法非常简单，我过去从没想过增加这一功能也没收到任何对它的请求。 在2000年夏天，Gerhard Rieger孕育了这个想法，写了一个很棒的补丁程序，发送到nmap-hackers邮件列表。 我把那个补丁加入了Nmap，第二天发布了新版本。 几乎没有商业软件会有用户有足够的热情设计并贡献他们的改进。\n协议扫描以和UDP扫描类似的方式工作。它不是在UDP报文的端口域上循环， 而是在IP协议域的8位上循环，发送IP报文头。 报文头通常是空的，不包含数据，甚至不包含所申明的协议的正确报文头 TCP，UDP，和ICMP是三个例外。它们三个会使用正常的协议头，因为否则某些系 统拒绝发送，而且Nmap有函数创建它们。协议扫描不是注意ICMP端口不可到达消息， 而是ICMP 协议不可到达消息。如果Nmap从目标主机收到 任何协议的任何响应，Nmap就把那个协议标记为open。 ICMP协议不可到达 错误(类型 3，代号 2) 导致协议被标记为 closed。其它ICMP不可到达协议(类型 3，代号 1，3，9，10，或者13) 导致协议被标记为 filtered (虽然同时他们证明ICMP是 open )。如果重试之后仍没有收到响应， 该协议就被标记为open|filtered\n-b (FTP弹跳扫描)\nFTP协议的一个有趣特征(RFC 959) 是支持所谓代理ftp连接。它允许用户连接到一台FTP服务器，然后要求文件送到一台第三方服务器。 这个特性在很多层次上被滥用，所以许多服务器已经停止支持它了。其中一种就是导致FTP服务器对其它主机端口扫描。 只要请求FTP服务器轮流发送一个文件到目标主机上的所感兴趣的端口。 错误消息会描述端口是开放还是关闭的。 这是绕过防火墙的好方法，因为FTP服务器常常被置于可以访问比Web主机更多其它内部主机的位置。 Nmap用-b选项支持ftp弹跳扫描。参数格式是 :@:。  是某个脆弱的FTP服务器的名字或者IP地址。 您也许可以省略:， 如果服务器上开放了匿名用户(user:anonymous password:-wwwuser@)。 端口号(以及前面的冒号) 也可以省略，如果使用默认的FTP端口(21)。\n当Nmap1997年发布时，这个弱点被广泛利用，但现在大部分已经被fix了。 脆弱的服务器仍然存在，所以如果其它都失败了，这也值得一试。 如果您的目标是绕过防火墙，扫描目标网络上的开放的21端口(或者 甚至任何ftp服务，如果您用版本探测扫描所有端口)， 然后对每个尝试弹跳扫描。Nmap会告诉您该主机脆弱与否。 如果您只是试着玩Nmap，您不必(事实上，不应该)限制您自己。 在您随机地在互联网上寻找脆弱的FTP服务器时，考虑一下系统管理员不太喜欢您这样滥用他们的服务器。\n端口说明和扫描顺序 除了所有前面讨论的扫描方法， Nmap提供选项说明那些端口被扫描以及扫描是随机还是顺序进行。 默认情况下，Nmap用指定的协议对端口1到1024以及nmap-services 文件中列出的更高的端口在扫描。\n-p (只扫描指定的端口)\n该选项指明您想扫描的端口，覆盖默认值。 单个端口和用连字符表示的端口范围(如 1-1023)都可以。 范围的开始以及/或者结束值可以被省略， 分别导致Nmap使用1和65535。所以您可以指定 -p-从端口1扫描到65535。 如果您特别指定，也可以扫描端口0。 对于IP协议扫描(-sO)，该选项指定您希望扫描的协议号 (0-255)。\n当既扫描TCP端口又扫描UDP端口时，您可以通过在端口号前加上T: 或者U:指定协议。 协议限定符一直有效您直到指定另一个。 例如，参数 -p U:53，111，137，T:21-25，80，139，8080 将扫描UDP 端口53，111，和137，同时扫描列出的TCP端口。注意，要既扫描 UDP又扫描TCP，您必须指定 -sU ，以及至少一个TCP扫描类型(如 -sS，-sF，或者 -sT)。如果没有给定协议限定符， 端口号会被加到所有协议列表。\n-F (快速 (有限的端口) 扫描)\n在nmap的nmap-services 文件中(对于-sO，是协议文件)指定您想要扫描的端口。 这比扫描所有65535个端口快得多。 因为该列表包含如此多的TCP端口(1200多)，这和默认的TCP扫描 scan (大约1600个端口)速度差别不是很大。如果您用\u0026ndash;datadir选项指定您自己的 小小的nmap-services文件 ，差别会很惊人。\n-r (不要按随机顺序扫描端口)\n默认情况下，Nmap按随机顺序扫描端口 (除了出于效率的考虑，常用的端口前移)。这种随机化通常都是受欢迎的， 但您也可以指定-r来顺序端口扫描。\n服务和版本探测 把Nmap指向一个远程机器，它可能告诉您 端口25/tcp，80/tcp，和53/udp是开放的。使用包含大约2,200个著名的服务的 nmap-services数据库， Nmap可以报告那些端口可能分别对应于一个邮件服务器 (SMTP)，web服务器(HTTP)，和域名服务器(DNS)。 这种查询通常是正确的 \u0026ndash; 事实上，绝大多数在TCP端口25监听的守护进程是邮件 服务器。然而，您不应该把赌注押在这上面! 人们完全可以在一些奇怪的端口上运行服务。\n即使Nmap是对的，假设运行服务的确实是 SMTP，HTTP和DNS，那也不是特别多的信息。 当为您的公司或者客户作安全评估(或者甚至简单的网络明细清单)时， 您确实想知道正在运行什么邮件和域名服务器以及它们的版本。 有一个精确的版本号对了解服务器有什么漏洞有巨大帮助。 版本探测可以帮您获得该信息。\n在用某种其它类型的扫描方法发现TCP 和/或者UDP端口后， 版本探测会询问这些端口，确定到底什么服务正在运行。 nmap-service-probes 数据库包含查询不同服务的探测报文 和解析识别响应的匹配表达式。 Nmap试图确定服务协议 (如 ftp，ssh，telnet，http)，应用程序名(如ISC Bind，Apache httpd，Solaris telnetd)，版本号， 主机名，设备类型(如 打印机，路由器)，操作系统家族 (如Windows，Linux)以及其它的细节，如 如是否可以连接X server，SSH协议版本 ，或者KaZaA用户名)。当然，并非所有服务都提供所有这些信息。 如果Nmap被编译成支持OpenSSL， 它将连接到SSL服务器，推测什么服务在加密层后面监听。 当发现RPC服务时， Nmap RPC grinder (-sR)会自动被用于确定RPC程序和它的版本号。 如果在扫描某个UDP端口后仍然无法确定该端口是开放的还是被过滤的，那么该端口状态就 被标记为open|filtered。 版本探测将试图从这些端口引发一个响应(就像它对开放端口做的一样)， 如果成功，就把状态改为开放。 open|filtered TCP端口用同样的方法对待。 注意Nmap -A选项在其它情况下打开版本探测。 有一篇关于版本探测的原理，使用和定制的文章在 http://www.insecure.org/nmap/vscan/。\n当Nmap从某个服务收到响应，但不能在数据库中找到匹配时， 它就打印一个特殊的fingerprint和一个URL给您提交，如果您确实知道什么服务运行在端口。 请花两分钟提交您的发现，让每个人受益。由于这些提交， Nmap有350种以上协议如smtp，ftp，http等的大约3，000条模式匹配。\n用下列的选项打开和控制版本探测。\n-sV (版本探测)\n打开版本探测。 您也可以用-A同时打开操作系统探测和版本探测。\n\u0026ndash;allports (不为版本探测排除任何端口)\n默认情况下，Nmap版本探测会跳过9100 TCP端口，因为一些打印机简单地打印送到该端口的 任何数据，这回导致数十页HTTP get请求，二进制 SSL会话请求等等被打印出来。这一行为可以通过修改或删除nmap-service-probes 中的Exclude指示符改变， 您也可以不理会任何Exclude指示符，指定\u0026ndash;allports扫描所有端口\n\u0026ndash;version-intensity  (设置 版本扫描强度)\n当进行版本扫描(-sV)时，nmap发送一系列探测报文 ，每个报文都被赋予一个1到9之间的值。 被赋予较低值的探测报文对大范围的常见服务有效，而被赋予较高值的报文 一般没什么用。强度水平说明了应该使用哪些探测报文。数值越高， 服务越有可能被正确识别。 然而，高强度扫描花更多时间。强度值必须在0和9之间。 默认是7。当探测报文通过nmap-service-probes ports指示符 注册到目标端口时，无论什么强度水平，探测报文都会被尝试。这保证了DNS 探测将永远在任何开放的53端口尝试， SSL探测将在443端口尝试，等等。\n\u0026ndash;version-light (打开轻量级模式)\n这是 \u0026ndash;version-intensity 2的方便的别名。轻量级模式使 版本扫描快许多，但它识别服务的可能性也略微小一点。\n\u0026ndash;version-all (尝试每个探测)\n\u0026ndash;version-intensity 9的别名， 保证对每个端口尝试每个探测报文。\n\u0026ndash;version-trace (跟踪版本扫描活动)\n这导致Nmap打印出详细的关于正在进行的扫描的调试信息。 它是您用\u0026ndash;packet-trace所得到的信息的子集。\n-sR (RPC扫描)\n这种方法和许多端口扫描方法联合使用。 它对所有被发现开放的TCP/UDP端口执行SunRPC程序NULL命令，来试图 确定它们是否RPC端口，如果是， 是什么程序和版本号。因此您可以有效地获得和rpcinfo -p一样的信息， 即使目标的端口映射在防火墙后面(或者被TCP包装器保护)。Decoys目前不能和RPC scan一起工作。 这作为版本扫描(-sV)的一部分自动打开。 由于版本探测包括它并且全面得多，-sR很少被需要。\n操作系统探测 Nmap最著名的功能之一是用TCP/IP协议栈fingerprinting进行远程操作系统探测。 Nmap发送一系列TCP和UDP报文到远程主机，检查响应中的每一个比特。 在进行一打测试如TCP ISN采样，TCP选项支持和排序，IPID采样，和初始窗口大小检查之后， Nmap把结果和数据库nmap-os-fingerprints中超过 1500个已知的操作系统的fingerprints进行比较，如果有匹配，就打印出操作系统的详细信息。 每个fingerprint包括一个自由格式的关于OS的描述文本， 和一个分类信息，它提供供应商名称(如Sun)，下面的操作系统(如Solaris)，OS版本(如10)， 和设备类型(通用设备，路由器，switch，游戏控制台， 等)。\n如果Nmap不能猜出操作系统，并且有些好的已知条件(如 至少发现了一个开放端口和一个关闭端口)，Nmap会提供一个 URL，如果您确知运行的操作系统，您可以把fingerprint提交到那个URL。 这样您就扩大了Nmap的操作系统知识库，从而让每个Nmap用户都受益。\n操作系统检测可以进行其它一些测试，这些测试可以利用处理 过程中收集到的信息。例如运行时间检测，使用TCP时间戳选项(RFC 1323) 来估计主机上次重启的时间，这仅适用于提供这类信息的主机。另一种 是TCP序列号预测分类，用于测试针对远程主机建立一个伪造的TCP连接 的可能难度。这对于利用基于源IP地址的可信关系(rlogin，防火墙过滤等) 或者隐含源地址的攻击非常重要。这一类哄骗攻击现在很少见，但一些 主机仍然存在这方面的漏洞。实际的难度值基于统计采样，因此可能会有 一些波动。通常采用英国的分类较好，如“worthy challenge”或者 “trivial joke”。在详细模式(-v)下只以 普通的方式输出，如果同时使用-O，还报告IPID序列产生号。 很多主机的序列号是“增加”类别，即在每个发送包的IP头中 增加ID域值， 这对一些先进的信息收集和哄骗攻击来说是个漏洞。\nhttp://nmap.org/book/osdetect.html 文档使用多种语言描述了版本检测的方式、使用和定制。\n采用下列选项启用和控制操作系统检测:\n-O (启用操作系统检测)\n也可以使用-A来同时启用操作系统检测和版本检测。\n\u0026ndash;osscan-limit (针对指定的目标进行操作系统检测)\n如果发现一个打开和关闭的TCP端口时，操作系统检测会更有效。 采用这个选项，Nmap只对满足这个条件的主机进行操作系统检测，这样可以 节约时间，特别在使用-P0扫描多个主机时。这个选项仅在使用 -O或-A 进行操作系统检测时起作用。\n\u0026ndash;osscan-guess; \u0026ndash;fuzzy (推测操作系统检测结果)\n当Nmap无法确定所检测的操作系统时，会尽可能地提供最相近的匹配，Nmap默认 进行这种匹配，使用上述任一个选项使得Nmap的推测更加有效。\n时间和性能 Nmap开发的最高优先级是性能。在本地网络对一个主机的默认扫描(nmap )需要1/5秒。而仅仅眨眼的 时间，就需要扫描上万甚至几十万的主机。此外，一些特定的扫描选项会明显增 加扫描时间，如UDP扫描和版本检测。同样，防火墙配置以及特殊的响应速度限制也会 增加时间。Nmap使用了并行算法和许多先进的算法来加速扫描，用户对Nmap如何 工作有最终的控制权。高级用户可以仔细地调整Nmap命令，在满足时间要求的同时获得他们所关心的信息。\n改善扫描时间的技术有：忽略非关键的检测、升级最新版本的Nmap(性能增强不断改善)。 优化时间参数也会带来实质性的变化，这些参数如下。\n\u0026ndash;min-hostgroup ; \u0026ndash;max-hostgroup  (调整并行扫描组的大小)\nNmap具有并行扫描多主机端口或版本的能力，Nmap将多个目标IP地址 空间分成组，然后在同一时间对一个组进行扫描。通常，大的组更有效。缺 点是只有当整个组扫描结束后才会提供主机的扫描结果。如果组的大小定义 为50，则只有当前50个主机扫描结束后才能得到报告(详细模式中的补充信息 除外)。\n默认方式下，Nmap采取折衷的方法。开始扫描时的组较小， 最小为5，这样便于尽快产生结果；随后增长组的大小，最大为1024。确切的 大小依赖于所给定的选项。为保证效率，针对UDP或少量端口的TCP扫描，Nmap 使用大的组。\n\u0026ndash;max-hostgroup选项用于说明使用最大的组，Nmap不 会超出这个大小。\u0026ndash;min-hostgroup选项说明最小的组，Nmap 会保持组大于这个值。如果在指定的接口上没有足够的目标主机来满足所 指定的最小值，Nmap可能会采用比所指定的值小的组。这两个参数虽然很少使用， 但都用于保持组的大小在一个指定的范围之内。\n这些选项的主要用途是说明一个最小组的大小，使得整个扫描更加快速。通常 选择256来扫描C类网段。对于端口数较多的扫描，超出该值没有意义。对于 端口数较少的扫描，2048或更大的组大小是有帮助的。\n\u0026ndash;min-parallelism ; \u0026ndash;max-parallelism  (调整探测报文的并行度)\n这些选项控制用于主机组的探测报文数量，可用于端口扫描和主机发现。默认状态下， Nmap基于网络性能计算一个理想的并行度，这个值经常改变。如果报文被丢弃， Nmap降低速度，探测报文数量减少。随着网络性能的改善，理想的探测报文数量会缓慢增加。 这些选项确定这个变量的大小范围。默认状态下，当网络不可靠时，理想的并行度值 可能为1，在好的条件下，可能会增长至几百。\n最常见的应用是\u0026ndash;min-parallelism值大于1，以加快 性能不佳的主机或网络的扫描。这个选项具有风险，如果过高则影响准确度，同时 也会降低Nmap基于网络条件动态控制并行度的能力。这个值设为10较为合适， 这个值的调整往往作为最后的手段。\n\u0026ndash;max-parallelism选项通常设为1，以防止Nmap在同一时间 向主机发送多个探测报文，和选择\u0026ndash;scan-delay同时使用非常有用，虽然 这个选项本身的用途已经很好。\n\u0026ndash;min-rtt-timeout ， \u0026ndash;max-rtt-timeout ， \u0026ndash;initial-rtt-timeout  (调整探测报文超时)\nNmap使用一个运行超时值来确定等待探测报文响应的时间，随后会放弃或重新 发送探测报文。Nmap基于上一个探测报文的响应时间来计算超时值，如果网络延迟比较显著 和不定，这个超时值会增加几秒。初始值的比较保守(高)，而当Nmap扫描无响应 的主机时，这个保守值会保持一段时间。\n这些选项以毫秒为单位，采用小的\u0026ndash;max-rtt-timeout值，使 \u0026ndash;initial-rtt-timeout值大于默认值可以明显减少扫描时间，特别 是对不能ping通的扫描(-P0)以及具有严格过滤的网络。如果使用太 小的值，使得很多探测报文超时从而重新发送，而此时可能响应消息正在发送，这使得整个扫描的时 间会增加。\n如果所有的主机都在本地网络，对于\u0026ndash;max-rtt-timeout值来 说，100毫秒比较合适。如果存在路由，首先使用ICMP ping工具ping主机，或使用其 它报文工具如hpings，可以更好地穿透防火墙。查看大约10个包的最大往返时间，然后将 \u0026ndash;initial-rtt-timeout设成这个时间的2倍，\u0026ndash;max-rtt-timeout 可设成这个时间值的3倍或4倍。通常，不管ping的时间是多少，最大的rtt值不得小于100ms， 不能超过1000ms。\n\u0026ndash;min-rtt-timeout这个选项很少使用，当网络不可靠时， Nmap的默认值也显得过于强烈，这时这个选项可起作用。当网络看起来不可靠时，Nmap仅将 超时时间降至最小值，这个情况是不正常的，需要向nmap-dev邮件列表报告bug。\n\u0026ndash;host-timeout  (放弃低速目标主机)\n由于性能较差或不可靠的网络硬件或软件、带宽限制、严格的防火墙等原因， 一些主机需要很长的时间扫描。这些极少数的主机扫描往往占 据了大部分的扫描时间。因此，最好的办法是减少时间消耗并且忽略这些主机，使用 \u0026ndash;host-timeout选项来说明等待的时间(毫秒)。通常使用1800000 来保证Nmap不会在单个主机上使用超过半小时的时间。需要注意的是，Nmap在这半小时中可以 同时扫描其它主机，因此并不是完全放弃扫描。超时的主机被忽略，因此也没有针对该主机的 端口表、操作系统检测或版本检测结果的输出。\n\u0026ndash;scan-delay ; \u0026ndash;max-scan-delay  (调整探测报文的时间间隔)\n这个选项用于Nmap控制针对一个主机发送探测报文的等待时间(毫秒)，在带宽 控制的情况下这个选项非常有效。Solaris主机在响应UDP扫描探测报文报文时，每秒 只发送一个ICMP消息，因此Nmap发送的很多数探测报文是浪费的。\u0026ndash;scan-delay 设为1000，使Nmap低速运行。Nmap尝试检测带宽控制并相应地调整扫描的延迟，但 并不影响明确说明何种速度工作最佳。\n\u0026ndash;scan-delay的另一个用途是躲闭基于阈值的入侵检测和预防 系统(IDS/IPS)。\n-T \u0026lt;Paranoid|Sneaky|Polite|Normal|Aggressive|Insane\u0026gt; (设置时间模板)\n上述优化时间控制选项的功能很强大也很有效，但有些用户会被迷惑。此外， 往往选择合适参数的时间超过了所需优化的扫描时间。因此，Nmap提供了一些简单的 方法，使用6个时间模板，使用时采用-T选项及数字(0 - 5) 或名称。模板名称有paranoid (0)、sneaky (1)、polite (2)、normal(3)、 aggressive (4)和insane (5)。前两种模式用于IDS躲避，Polite模式降低了扫描 速度以使用更少的带宽和目标主机资源。默认模式为Normal，因此-T3 实际上是未做任何优化。Aggressive模式假设用户具有合适及可靠的网络从而加速 扫描。Insane模式假设用户具有特别快的网络或者愿意为获得速度而牺牲准确性。\n用户可以根据自己的需要选择不同的模板，由Nmap负责选择实际的时间值。 模板也会针对其它的优化控制选项进行速度微调。例如，-T4 针对TCP端口禁止动态扫描延迟超过10ms，-T5对应的值为5ms。 模板可以和优化调整控制选项组合使用，但模板必须首先指定，否则模板的标准值 会覆盖用户指定的值。建议在扫描可靠的网络时使用 -T4，即使 在自己要增加优化控制选项时也使用(在命令行的开始)，从而从这些额外的较小的优化 中获益。\n如果用于有足够的带宽或以太网连接，仍然建议使用-T4选项。 有些用户喜欢-T5选项，但这个过于强烈。有时用户考虑到避免使主机 崩溃或者希望更礼貌一些会采用-T2选项。他们并没意识到-T Polite选项是如何的慢，这种模式的扫描比默认方式实际上要多花10倍的时间。默认时间 选项(-T3)很少有主机崩溃和带宽问题，比较适合于谨慎的用户。不进行 版本检测比进行时间调整能更有效地解决这些问题。\n虽然-T0和-T1选项可能有助于避免IDS告警，但 在进行上千个主机或端口扫描时，会显著增加时间。对于这种长时间的扫描，宁可设定确切的时间 值，而不要去依赖封装的-T0和-T1选项。\nT0选项的主要影响是对于连续扫描，在一个时间只能扫描一个端口， 每个探测报文的发送间隔为5分钟。T1和T2选项比较类似， 探测报文间隔分别为15秒和0.4秒。T3是Nmap的默认选项，包含了并行扫描。 T4选项与 \u0026ndash;max-rtt-timeout 1250 \u0026ndash;initial-rtt-timeout 500 等价，最大TCP扫描延迟为10ms。T5等价于 \u0026ndash;max-rtt-timeout 300 \u0026ndash;min-rtt-timeout 50 \u0026ndash;initial-rtt-timeout 250 \u0026ndash;host-timeout 900000，最大TCP扫描延迟为5ms。\n防火墙/IDS躲避和哄骗 很多Internet先驱们设想了一个全球开放的网络，使用全局的IP 地址空间，使得任何两个节点之间都有虚拟连接。这使得主机间可以作为真 正的对等体，相互间提供服务和获取信息。人们可以在工作时访问家里所 有的系统、调节空调温度、为提前到来的客人开门。随后，这些全球连接的设想 受到了地址空间短缺和安全考虑的限制。在90年代早期，各种机构开始部 署防火墙来实现减少连接的目的，大型网络通过代理、NAT和包过滤器与未 过滤的Internet隔离。不受限的信息流被严格控制的可信通信通道信息流所替代。\n类似防火墙的网络隔离使得对网络的搜索更加困难，随意的搜 索变得不再简单。然而，Nmap提供了很多特性用于理解这些复杂的网 络，并且检验这些过滤器是否正常工作。此外，Nmap提供了绕过某些较弱的 防范机制的手段。检验网络安全状态最有效的方法之一是尝试哄骗网络，将 自己想象成一个攻击者，使用本节提供的技术来攻击自己的网络。如使用FTP bounce扫描、Idle扫描、分片攻击或尝试穿透自己的代理。\n除限止网络的行为外，使用入侵检测系统(IDS)的公司也不断增加。由于Nmap 常用于攻击前期的扫描，因此所有主流的IDS都包含了检测Nmap扫描的规则。 现在，这些产品变形为入侵预防系统(IPS)，可以主 动地阻止可疑的恶意行为。不幸的是，网络管理员和IDS厂商通过分析报文 来检测恶意行为是一个艰苦的工作，有耐心和技术的攻击者，在特定Nmap选项 的帮助下，常常可以不被IDS检测到。同时，管理员必须应付大量的误报结果， 正常的行为被误判而被改变或阻止。\n有时，人们建议Nmap不应该提供躲闭防火墙规则或哄骗IDS的功能， 这些功能可能会被攻击者滥用，然而管理员却可以利用这些功能来增强安全性。 实际上，攻击的方法仍可被攻击者利用，他们可以发现其它工具或Nmap的补丁程 序。同时，管理员发现攻击者的工作更加困难，相比较采取措施来预防执 行FTP Bounce攻击的工具而言，部署先进的、打过补丁的FTP服务器更 加有效。\nNmap不提供检测和破坏防火墙及IDS系统的魔弹(或Nmap选项)，它使用 的是技术和经验，这超出了本参考手册的范围，下面描述了相关的选项和 完成的工作。\n-f (报文分段); \u0026ndash;mtu (使用指定的MTU)\n-f选项要求扫描时(包挺ping扫描)使用 小的IP包分段。其思路是将TCP头分段在几个包中，使得包过滤器、 IDS以及其它工具的检测更加困难。必须小心使用这个选项，有些系 统在处理这些小包时存在问题，例如旧的网络嗅探器Sniffit在接收 到第一个分段时会立刻出现分段错误。该选项使用一次，Nmap在IP 头后将包分成8个字节或更小。因此，一个20字节的TCP头会被分成3个 包，其中2个包分别有TCP头的8个字节，另1个包有TCP头的剩下4个字 节。当然，每个包都有一个IP头。再次使用-f可使用 16字节的分段(减少分段数量)。使用\u0026ndash;mtu选项可 以自定义偏移的大小，使用时不需要-f，偏移量必须 是8的倍数。包过滤器和防火墙对所有的IP分段排队，如Linux核心中的 CONFIG-IP-ALWAYS-DEFRAG配置项，分段包不会直接使用。一些网络无法 承受这样所带来的性能冲击，会将这个配置禁止。其它禁止的原因有分段 包会通过不同的路由进入网络。一些源系统在内核中对发送的报文进行 分段，使用iptables连接跟踪模块的Linux就是一个例子。当使用类似Ethereal 的嗅探器时，扫描必须保证发送的报文要分段。如果主机操作系统会产 生问题，尝试使用\u0026ndash;send-eth选项以避开IP层而直接 发送原始的以太网帧。\n-D \u0026lt;decoy1 [，decoy2][，ME]，\u0026hellip;\u0026gt; (使用诱饵隐蔽扫描)\n为使诱饵扫描起作用，需要使远程主机认为是诱饵在扫描目标网络。 IDS可能会报个某个IP的5-10个端口扫描，但并不知道哪个IP在扫描以及 哪些不是诱饵。但这种方式可以通过路由跟踪、响应丢弃以及其它主动 机制在解决。这是一种常用的隐藏自身IP地址的有效技术。\n使用逗号分隔每个诱饵主机，也可用自己的真实IP作为诱饵，这时可使用 ME选项说明。如果在第6个位置或 更后的位置使用ME选项，一些常用 端口扫描检测器(如Solar Designer\u0026rsquo;s excellent scanlogd)就不会报告 这个真实IP。如果不使用ME选项，Nmap 将真实IP放在一个随机的位置\n注意，作为诱饵的主机须在工作状态，否则会导致目标主机的SYN洪水攻击。 如果在网络中只有一个主机在工作，那就很容易确定哪个主机在扫描。也可 使用IP地址代替主机名(被诱骗的网络就不可能在名字服务器日志中发现)。\n诱饵可用在初始的ping扫描(ICMP、SYN、ACK等)阶段或真正的端口扫描 阶段。诱饵也可以用于远程操作系统检测(-O)。在进行版 本检测或TCP连接扫描时，诱饵无效。\n使用过多的诱饵没有任何价值，反而导致扫描变慢并且结果不准确。 此外，一些ISP会过滤哄骗的报文，但很多对欺骗IP包没有任何限制。\n-S \u0026lt;IP_Address\u0026gt; (源地址哄骗)\n在某些情况下，Nmap可能无法确定你的源地址(如果这样，Nmap会给出 提示)。此时，使用-S选项并说明所需发送包的接口IP地址。\n这个标志的另一个用处是哄骗性的扫描，使得目标认为是另 一个地址在进行扫描。可以想象某一个竞争对手在不断扫描某个公司！ -e选项常在这种情况下使用，也可采用-P0选项。\n-e  (使用指定的接口)\n告诉Nmap使用哪个接口发送和接收报文，Nmap可以进行自动检测， 如果检测不出会给出提示。\n\u0026ndash;source-port ; -g  (源端口哄骗)\n仅依赖于源端口号就信任数据流是一种常见的错误配置，这个问题非常 好理解。例如一个管理员部署了一个新的防火墙，但招来了很多用户的不满，因为 他们的应用停止工作了。可能是由于外部的UDP DNS服务器响应无法进入网络，而导致 DNS的崩溃。FTP是另一个常见的例子，在FTP传输时，远程服务器尝试和内部用 建立连接以传输数据。\n对这些问题有安全解决方案，通常是应用级代理或协议分析防火墙模块。 但也存在一些不安全的方案。注意到DNS响应来自于53端口，FTP连接 来自于20端口，很多管理员会掉入一个陷阱，即允许来自于这些端口的数据进入 网络。他们认为这些端口里不会有值得注意的攻击和漏洞利用。此外，管理员 或许认为这是一个短期的措施，直至他们采取更安全的方案。但他们忽视了安全的 升级。\n不仅仅是工作量过多的网络管理员掉入这种陷阱，很多产品本身也会有这类 不安全的隐患，甚至是微软的产品。Windows 2000和Windows XP中包含的IPsec过滤 器也包含了一些隐含规则，允许所有来自88端口(Kerberos)的TCP和UDP数据流。另 一个常见的例子是Zone Alarm个人防火墙到2.1.25版本仍然允许源端口53(DNS)或 67(DHCP)的UDP包进入。\nNmap提供了-g和\u0026ndash;source-port选项(它们是 等价的)，用于利用上述弱点。只需要提供一个端口号，Nmap就可以从这些 端口发送数据。为使特定的操作系统正常工作，Nmap必须使用不同的端口号。 DNS请求会忽略\u0026ndash;source-port选项，这是因为Nmap依靠系 统库来处理。大部分TCP扫描，包括SYN扫描，可以完全支持这些选项，UDP扫 描同样如此。\n\u0026ndash;data-length  (发送报文时 附加随机数据)\n正常情况下，Nmap发送最少的报文，只含一个包头。因此TCP包通常 是40字节，ICMP ECHO请求只有28字节。这个选项告诉Nmap在发送的报文上 附加指定数量的随机字节。操作系统检测(-O)包不受影响， 但大部分ping和端口扫描包受影响，这会使处理变慢，但对扫描的影响较小。\n\u0026ndash;ttl  (设置IP time-to-live域)\n设置IPv4报文的time-to-live域为指定的值。\n\u0026ndash;randomize-hosts (对目标主机的顺序随机排列)\n告诉Nmap在扫描主机前对每个组中的主机随机排列，最多可达 8096个主机。这会使得扫描针对不同的网络监控系统来说变得不是很 明显，特别是配合值较小的时间选项时更有效。如果需要对一个较大 的组进行随机排列，需要增大nmap.h文件中 PING-GROUP-SZ的值，并重新编译。另一种方法是使用列表扫描 (-sL -n -oN )，产生目标IP的列表， 使用Perl脚本进行随机化，然后使用-iL提供给Nmap。\n\u0026ndash;spoof-mac \u0026lt;mac address，prefix，or vendor name\u0026gt; (MAC地址哄骗)\n要求Nmap在发送原以太网帧时使用指定的MAC地址，这个选项隐含了 \u0026ndash;send-eth选项，以保证Nmap真正发送以太网包。MAC地址有几 种格式。如果简单地使用字符串“0”，Nmap选择一个完全随机的MAC 地址。如果给定的字符品是一个16进制偶数(使用:分隔)，Nmap将使用这个MAC地址。 如果是小于12的16进制数字，Nmap会随机填充剩下的6个字节。如果参数不是0或16进 制字符串，Nmap将通过nmap-mac-prefixes查找 厂商的名称(大小写区分)，如果找到匹配，Nmap将使用厂商的OUI(3字节前缀)，然后 随机填充剩余的3个节字。正确的\u0026ndash;spoof-mac参数有， Apple， 0，01:02:03:04:05:06， deadbeefcafe，0020F2， 和Cisco.\n输出 任何安全工具只有在输出结果时才是有价值的，如果没有通过组织和 易于理解的方式来表达，复杂的测试和算法几乎没有意义。Nmap提供了一些 方式供用户和其它软件使用，实际上，没有一种方式可以使所有人满意。 因此Nmap提供了一些格式，包含了方便直接查看的交互方式和方便软件处理 的XML格式。\n除了提供输出格式外，Nmap还提供了选项来控制输出的细节以及调试 信息。输出内容可发送给标准输出或命名文件，可以追加或覆盖。输出文件还可 被用于继续中断的扫描。\nNmap提供5种不同的输出格式。默认的方式是interactive output， 发送给标准输出(stdout)。normal output方式类似于 interactive，但显示较少的运行时间信息 和告警信息，这是由于这些信息是在扫描完全结束后用于分析，而不是交互式的。\nXML输出是最重要的输出类型，可被转换成HTML，对于程序处理非常方便， 如用于Nmap图形用户接口或导入数据库。\n另两种输出类型比较简单，grepable output格式，在一行中包含目标主机最多的信息；sCRiPt KiDDi3 0utPUt 格式，用于考虑自己的用户 |\u0026lt;-r4d。\n交互式输出是默认方式，没有相应的命令行选项，其它四种格式选项 使用相同的语法，采用一个参数，即存放结果的文件名。多种格式可同时 使用，但一种格式只能使用一次。例如，在标准输出用于查看的同时，可将结 果保存到XML文件用于程序分析，这时可以使用选项-oX myscan.xml -oN myscan.nmap。 为便于描述的简化，本章使用类似于myscan.xml的简单文件名， 建议采用更具有描述性的文件名。文件名的选择与个人喜好有关，建议增加 扫描日期以及一到两个单词来描述，并放置于一个目录中。\n在将结果输出到文件的同时，Nmap仍将结果发送给标准输出。例如， 命令nmap -oX myscan.xml target将 输出XML至myscan.xml，并在stdout 上打印相同的交互式结果，而此时-oX选项没有采用。可以 使用连字符作为选项来改变，这使得Nmap禁止交互式输出，而是将结果打印到 所指定的标准输出流中。因此，命令nmap -oX - target只 输出XML至标准输出stdout。严重错误仍然是输出到标准错误流stderr中。\n与其它Nmap参数不同，日志文件选项的空格(如-oX)和 文件名或连字符是必需的。如果省略了标记，例如-oG-或 -oXscan.xml，Nmap的向后兼容特点将建立 标准格式的输出文件，相应的文件名为G-和 Xscan.xml。\nNmap还提供了控制扫描细节以及输出文件的添加或覆盖的选项，这些选项 如下所述。\nNmap输出格式\n-oN  (标准输出)\n要求将标准输出直接写入指定 的文件。如上所述，这个格式与交互式输出 略有不同。\n-oX  (XML输出)\n要求XML输出直接写入指定 的文件。Nmap包含了一个文档类型定义(DTD)，使XML解析器有效地 进行XML输出。这主要是为了程序应用，同时也可以协助人工解释 Nmap的XML输出。DTD定义了合法的格式元素，列举可使用的属性和 值。最新的版本可在 http://www.insecure.org/nmap/data/nmap.dtd获取。\nXML提供了可供软件解析的稳定格式输出，主要的计算机 语言都提供了免费的XML解析器，如C/C++，Perl，Python和Java。 针对这些语言有一些捆绑代码用于处理Nmap的输出和特定的执行程序。 例如perl CPAN中的Nmap::Scanner 和Nmap::Parser。 对几乎所有与Nmap有接口的主要应用来说，XML是首选的格式。\nXML输出引用了一个XSL样式表，用于格式化输出结果，类似于 HTML。最方便的方法是将XML输出加载到一个Web浏览器，如Firefox 或IE。由于nmap.xsl文件的绝对 路径，因此通常只能在运行了Nmap的机器上工作(或类似配置的机器)。 类似于任何支持Web机器的HTML文件，\u0026ndash;stylesheet 选项可用于建立可移植的XML文件。\n-oS  (ScRipT KIdd|3 oUTpuT)\n脚本小子输出类似于交互工具输出，这是一个事后处理，适合于 \u0026lsquo;l33t HaXXorZ， 由于原来全都是大写的Nmap输出。这个选项和脚本小子开了玩笑，看上去似乎是为了 “帮助他们”。\n-oG  (Grep输出)\n这种方式最后介绍，因为不建议使用。XML输格式很强大，便于有经验 的用户使用。XML是一种标准，由许多解析器构成，而Grep输届更简化。XML 是可扩展的，以支持新发布的Nmap特点。使用Grep输出的目的是忽略这些 特点，因为没有足够的空间。\n然面，Grep输出仍然很常使用。它是一种简单格式，每行一个主机，可以 通过UNIX工具(如grep、awk、cut、sed、diff)和Perl方便地查找和分解。常可 用于在命令行上进行一次性测式。查找ssh端口打开或运行Sloaris的主机，只需 要一个简单的grep主机说明，使用通道并通过awk或cut命令打印所需的域。\nGrep输出可以包含注释(每行由#号开始)。每行由6个标记的域组成，由制表符及 冒号分隔。这些域有主机，端口， 协议，忽略状态， 操作系统，序列号， IPID和状态。\n这些域中最重要的是Ports，它提供 了所关注的端口的细节，端口项由逗号分隔。每个端口项代表一个所关注的端口， 每个子域由/分隔。这些子域有：端口号， 状态，协议， 拥有者，服务， SunRPCinfo和版本信息。\n对于XML输出，本手册无法列举所有的格式，有关Nmap Grep输出的更详细信息可 查阅http://www.unspecific.com/nmap-oG-output。\n-oA  (输出至所有格式)\n为使用方便，利用-oA选项 可将扫描结果以标准格式、XML格式和Grep格式一次性输出。分别存放在 .nmap，.xml和 .gnmap文件中。也可以在文件名前 指定目录名，如在UNIX中，使用~/nmaplogs/foocorp/， 在Window中，使用c:\\hacking\\sco on Windows。\n细节和调试选项 -v (提高输出信息的详细度)\n通过提高详细度，Nmap可以输出扫描过程的更多信息。 输出发现的打开端口，若Nmap认为扫描需要更多时间会显示估计 的结束时间。这个选项使用两次，会提供更详细的信息。这个选 项使用两次以上不起作用。\n大部分的变化仅影响交互式输出，也有一些影响标准和脚本 小子输出。其它输出类型由机器处理，此时Nmap默认提供详细的信 息，不需要人工干预。然而，其它模式也会有一些变化，省略一些 细节可以减小输出大小。例如，Grep输出中的注释行提供所有扫描 端口列表，但由于这些信息过长，因此只能在细节模式中输出。\n-d [level] (提高或设置调试级别)\n当详细模式也不能为用户提供足够的数据时，使用调试可以得到更 多的信息。使用细节选项(-v)时，可启用命令行参数 (-d)，多次使用可提高调试级别。也可在-d 后面使用参数设置调试级别。例如，-d9设定级别9。这是 最高的级别，将会产生上千行的输出，除非只对很少的端口和目标进行简单扫描。\n如果Nmap因为Bug而挂起或者对Nmap的工作及原理有疑问，调试输出 非常有效。主要是开发人员用这个选项，调试行不具备自我解释的特点。 例如，Timeoutvals: srtt: -1 rttvar: -1 to: 1000000 delta 14987 ==\u0026gt; srtt: 14987 rttvar: 14987 to: 100000。如果对某行输出不明白， 可以忽略、查看源代码或向开发列表(nmap-dev)求助。有些输出行会有自 我解释的特点，但随着调试级别的升高，会越来越含糊。\n\u0026ndash;packet-trace (跟踪发送和接收的报文)\n要求Nmap打印发送和接收的每个报文的摘要，通常用于 调试，有助于新用户更好地理解Nmap的真正工作。为避免输出过 多的行，可以限制扫描的端口数，如-p20-30。 如果只需进行版本检测，使用\u0026ndash;version-trace。\n\u0026ndash;iflist (列举接口和路由)\n输出Nmap检测到的接口列表和系统路由，用于调试路由 问题或设备描述失误(如Nmap把PPP连接当作以太网对待)。\n其它输出选项 \u0026ndash;append-output (在输出文件中添加)\n当使用文件作为输出格式，如-oX或-oN， 默认该文件被覆盖。如果希望文件保留现有内容，将结果添加在现 有文件后面，使用\u0026ndash;append-output选项。所有指 定的输出文件都被添加。但对于XML(-oX)扫描输出 文件无效，无法正常解析，需要手工修改。\n\u0026ndash;resume  (继续中断的扫描)\n一些扩展的Nmap运行需要很长的时间 \u0026ndash; 以天计算，这类扫描 往往不会结束。可以进行一些限制，禁止Nmap在工作时间运行，导致 网络中断、运行Nmap的主机计划或非计划地重启、或者Nmap自己中断。 运行Nmap的管理员可以因其它原因取消运行，按下ctrl-C 即可。从头开始启动扫描可能令人不快，幸运的是，如果标准扫描 (-oN)或Grep扫描(-oG)日志 被保留，用户可以要求Nmap恢复终止的扫描，只需要简单地使用选项 \u0026ndash;resume并说明标准/Grep扫描输出文件，不允许 使用其它参数，Nmap会解析输出文件并使用原来的格式输出。使用方式 如nmap \u0026ndash;resume 。 Nmap将把新地结果添加到文件中，这种方式不支持XML输出格式，原因是 将两次运行结果合并至一个XML文件比较困难。\n\u0026ndash;stylesheet (设置XSL样式表，转换XML输出)\nNmap提从了XSL样式表nmap.xsl，用于查看 或转换XML输出至HTML。XML输出包含了一个xml-stylesheet， 直接指向nmap.xml文件， 该文件由Nmap安装(或位于Windows当前工作目录)。在Web浏览器 中打开Nmap的XML输出时，将会在文件系统中寻找nmap.xsl文件， 并使用它输出结果。如果希望使用不同的样式表，将它作为 \u0026ndash;stylesheet的参数，必段指明完整的路 径或URL，常见的调用方式是\u0026ndash;stylesheet http://www.insecure.org/nmap/data/nmap.xsl。 这告诉浏览器从Insecire.Org中加载最新的样式表。这使得 没安装Nmap(和nmap.xsl) 的机器中可以方便地查看结果。因此，URL更方便使用，本地文件系统 的nmap.xsl用于默认方式。\n\u0026ndash;no-stylesheet (忽略XML声明的XSL样式表)\n使用该选项禁止Nmap的XML输出关联任何XSL样式表。 xml-stylesheet指示被忽略。\n其它选项 本节描述一些重要的(和并不重要)的选项，这些选项 不适合其它任何地方。\n-6 (启用IPv6扫描)\n从2002年起，Nmap提供对IPv6的一些主要特征的支持。ping扫描(TCP-only)、 连接扫描以及版本检测都支持IPv6。除增加-6选项外， 其它命令语法相同。当然，必须使用IPv6地址来替换主机名，如 3ffe:7501:4819:2000:210:f3ff:fe03:14d0。 除“所关注的端口”行的地址部分为IPv6地址。\nIPv6目前未在全球广泛采用，目前在一些国家(亚洲)应用较多， 一些高级操作系统支持IPv6。使用Nmap的IPv6功能，扫描的源和目 的都需要配置IPv6。如果ISP(大部分)不分配IPv6地址，Nmap可以采用 免费的隧道代理。一种较好的选择是BT Exact，位于https://tb.ipv6.btexact.com/。 此外，还有Hurricane Electric，位于http://ipv6tb.he.net/。6to4隧道是 另一种常用的免费方法。\n-A (激烈扫描模式选项)\n这个选项启用额外的高级和高强度选项，目前还未确定代表 的内容。目前，这个选项启用了操作系统检测(-O) 和版本扫描(-sV)，以后会增加更多的功能。 目的是启用一个全面的扫描选项集合，不需要用户记忆大量的 选项。这个选项仅仅启用功能，不包含用于可能所需要的 时间选项(如-T4)或细节选项(-v)。\n\u0026ndash;datadir  (说明用户Nmap数据文件位置)\nNmap在运行时从文件中获得特殊的数据，这些文件有 nmap-service-probes， nmap-services， nmap-protocols， nmap-rpc， nmap-mac-prefixes和 nmap-os-fingerprints。Nmap首先 在\u0026ndash;datadir选项说明的目录中查找这些文件。 未找到的文件，将在BMAPDIR环境变量说明的目录中查找。 接下来是用于真正和有效UID的~/.nmap 或Nmap可执行代码的位置(仅Win32)；然后是是编译位置， 如/usr/local/share/nmap 或/usr/share/nmap。 Nmap查找的最后一个位置是当前目录。\n\u0026ndash;send-eth (使用原以太网帧发送)\n要求Nmap在以太网(数据链路)层而不是IP(网络层)发送 报文。默认方式下，Nmap选择最适合其运行平台的方式，原套接 字(IP层)是UNIX主机最有效的方式，而以太网帧最适合Windows操作 系统，因为Microsoft禁用了原套接字支持。在UNIX中，如果没有其 它选择(如无以太网连接)，不管是否有该选项，Nmap都使用原IP包。\n\u0026ndash;send-ip (在原IP层发送)\n要求Nmap通过原IP套接字发送报文，而不是低层的以 太网帧。这是\u0026ndash;send-eth选项的补充。\n\u0026ndash;privileged (假定用户具有全部权限)\n告诉Nmap假定其具有足够的权限进行源套接字包发送、 报文捕获和类似UNIX系统中根用户操作的权限。默认状态下， 如果由getuid()请求的类似操作不为0，Nmap将退出。 \u0026ndash;privileged在具有Linux内核性能的类似 系统中使用非常有效，这些系统配置允许非特权用户可以进行 原报文扫描。需要明确的是，在其它选项之前使用这些需要权 限的选项(SYN扫描、操作系统检测等)。Nmap-PRIVILEGED变量 设置等价于\u0026ndash;privileged选项。\n\u0026ndash;interactive (在交互模式中启动)\n在交互模式中启动Nmap，提供交互式的Nmap提示，便于 进行多个扫描(同步或后台方式)。对于从多用户系统中扫描 的用户非常有效，这些用户常需要测试他们的安全性，但不希望 系统中的其它用户知道他们扫描哪些系统。使用\u0026ndash;interactive 激活这种方式，然后输入h可 获得帮助信息。由于需要对正确的shell程序和整个功能非常熟悉， 这个选项很少使用。这个选项包含了一个!操作符，用于执行shell命令， 这是不安装Nmap setuid root的多个原因之一。\n-V; \u0026ndash;version (打印版本信息)\n打印Nmap版本号并退出。\n-h; \u0026ndash;help (打印帮助摘要面)\n打印一个短的帮助屏幕，列出大部分常用的 命令选项，这个功能与不带参数运行Nmap是相同的。\n实例 下面给出一些实例，简单的、复杂的到深奥的。为更具体，一 些例子使用了实际的IP地址和域名。在这些位置，可以使用你自己网络 的地址/域名替换。注意，扫描其它网络不一定合法，一些网络管理员不愿看到 未申请过的扫描，会产生报怨。因此，先获得允许是最好的办法。\n如果是为了测试，scanme.nmap.org 允许被扫描。但仅允许使用Nmap扫描并禁止测试漏洞或进行DoS攻击。为 保证带宽，对该主机的扫描每天不要超过12次。如果这个免费扫描服务被 滥用，系统将崩溃而且Nmap将报告解析 指定的主机名/IP地址失败：scanme.nmap.org。这些免 费扫描要求也适用于scanme2.nmap.org、 scanme3.nmap.org等等，虽然这些 主机目前还不存在。\nnmap -v scanme.nmap.org\n这个选项扫描主机scanme.nmap.org中 所有的保留TCP端口。选项-v启用细节模式。\nnmap -sS -O scanme.nmap.org/24\n进行秘密SYN扫描，对象为主机Saznme所在的“C类”网段 的255台主机。同时尝试确定每台工作主机的操作系统类型。因为进行SYN扫描 和操作系统检测，这个扫描需要有根权限。\nnmap -sV -p 22，53，110，143，4564 198.116.0-255.1-127\n进行主机列举和TCP扫描，对象为B类188.116网段中255个8位子网。这 个测试用于确定系统是否运行了sshd、DNS、imapd或4564端口。如果这些端口 打开，将使用版本检测来确定哪种应用在运行。\nnmap -v -iR 100000 -P0 -p 80\n随机选择100000台主机扫描是否运行Web服务器(80端口)。由起始阶段 发送探测报文来确定主机是否工作非常浪费时间，而且只需探测主机的一个端口，因 此使用-P0禁止对主机列表。\nnmap -P0 -p80 -oX logs/pb-port80scan.xml -oG logs/pb-port80scan.gnmap 216.163.128.20/20\n扫描4096个IP地址，查找Web服务器(不ping)，将结果以Grep和XML格式保存。\nhost -l company.com | cut -d -f 4 | nmap -v -iL -\n进行DNS区域传输，以发现company.com中的主机，然后将IP地址提供给 Nmap。上述命令用于GNU/Linux \u0026ndash; 其它系统进行区域传输时有不同的命令。 nmap -Pn 172.20.123.22\n类似于ping功能，用于主机发现\n测试域名是否被封 http://ping.pe/\n",
    "ref": "/blog/network/%E7%AB%AF%E5%8F%A3%E6%89%AB%E6%8F%8F/"
  },{
    "title": "Redis怎么减少RRT-Pipeline",
    "date": "",
    "description": "",
    "body": "概述 redis client 与server 的每次通信，都会产生一次RTT（round time trip); 并且多次通信会频繁的进行网络IO； 为此pipeline 可以将多条命令请求整合，一次发送；\n问题 1. 应当限制pipeline中命令的大小\r1.1 在pipeline机制中， client不会去读取缓冲数据， 除非pipeline所有命令执行完成。\r1.2 当缓冲中被应答数据填满， server端调用write 就会阻塞或失败\r2. pipeline不能保证命令执行的原子性\r2.1 如果多个命令在执行时发生异常， 则丢失未执行的命令\r2.2 因此在使用pipeline时， 要自己保证执行命令的数据安全\r3. 不能进解决多条命令之间的依赖关系\r",
    "ref": "/blog/cache/redis/pipeline/"
  },{
    "title": "Redis有没有数据库的概念",
    "date": "",
    "description": "",
    "body": "概述  redis单机支持16个数据库， 每个数据库的数据是隔离的不能共享；redis cluster 是没有数据库概念的 redis 之所以分这么多数据库， 也是为了区分业务， 不同业务存放在不同的数据库中；  ",
    "ref": "/blog/cache/redis/%E6%95%B0%E6%8D%AE%E5%BA%93/"
  },{
    "title": "Erlang并发编程错误",
    "date": "",
    "description": "",
    "body": "错误处理理念  并发Erlang程序里的错误处理建立在远程检测和处理错误的概念上。我们选择让发生错误的进程崩溃，然后在其它进程里面进行纠错处理。 在设计容错式的系统时就假设错误会发生，进程会崩溃。因此能够在错误发生时检测出来，可能的话也需要纠正他们。同时避免系统用户注意到任何故障，或者在错误修复过程中遭受服务终端。 检测错误和找出故障原因是内建于Erlang虚拟机底层的功能，也是Erlang语言编程的一部分。标准OTP库提供了构建互相监视的进程组和检测到错误时采取纠正措施的功能。本章介绍的是语言层面的错误检测和恢复。 总结为两句话：“让其它进程修复错误\u0026quot;和\u0026quot;任其崩溃\u0026quot;  让其它进程修复错误  要让一个进程监控另一个，需要在这两个进程之间建立链接(link)或者(monitor)。如果被链接或者监视的进程挂了，监控进程会收到通知。 监控进程可以实现跨机器的透明运作，因此运行在某一台机器上的进程可以监视运行在不同机器上进程的行为。这是编写容错式系统的基础。不能在一台机器上构建容错式系统，因为崩溃的可能是整台机器。一台机器负责计算，其它的机器负责监控它，并在一台机器崩溃时接管计算。  任其崩溃  在Erlang中，我们把应用程序构建成两部分：一部分负责解决问题，另一部分负责在错误发生时纠正他们。 负责解决问题的部分尽可能少的编写防御性代码，并假设函数所有参数是正确的，程序运行正常。 负责纠正错误的部分往往是通用的，因此同一段错误纠正代码可以用在许多不同的应用程序里面。例如：如果数据库的某个事务出错，就简单终止该事务，让系统把数据库恢复到出错之前的状态；如果操作系统里面的某个进程崩溃，就让操作系统关闭所有打开的文件和套接字，然后让系统恢复到某个稳定状态。  任其崩溃意义  不必编写防御性代码来防止错误，直接崩溃就好。 不必思考应对措施，选择直接崩溃，让别人来修复错误。 不会使错误恶化，无需在知道出错后进行额外的计算。 如果错误发生后第一时间通知，就能得到非常好的错误诊断。错误发生后继续运行会导致更多的错误，让调试更困难。 编写错误恢复代码时不用担心崩溃的原因，只要把注意力放到事后的清理上。 简化系统架构，这样我们就能把应用程序和错误恢复当成两个独立的问题来思考。  错误处理的术语含义  进程   进程有两种：普通进程和系统进程。spawn创建的是普通进程。普通进程可以执行内置函数process_flag（trap_exit,true)变成系统进程。\n 连接   进程可以互相连接。如果A和B两个进程有连接，而A出于某种原因终止了，就会向B发送一个错误信号，反之亦然。\n 连接组   进程P的连接组是指与进程P相连的一组进程。\n 监视   监视和连接相似，但它是单向的。如果A监视B，而B出于某种原因终止了，就会向A发送一个\u0026quot;宕机\u0026quot;的消息，但反过来就不行了。\n 消息和错误信号   进程协作的方式是交换消息和错误信号。消息是通过基本函数send发送的，错误信号则是进程崩溃或终止的时候自动发送的。错误信号会发送给终止进程的连接组。\n 错误信号的接受   当系统进程收到错误信号时，该信号被转换成{\u0026lsquo;Exit\u0026rsquo;,Pid,Why}形式的信息。Pid是终止进程的标识，Why是终止的原因。如果无错误终止，Why就会是原子normal，否则会是错误描述。当普通进程收到错误信号时，如果退出原因不是normal，该进程就会终止。当它终止时，同样会向它的连接组广播一个退出信号。\n 显示错误信号   任何执行exit(Why)的进程都会终止（如果代码不是在catch或者try的范围内执行的话），并向它的连接组广播一个带有原因Why的退出信号。进程可以通过执行exit(Pid,Why)来发送一个\u0026quot;虚假\u0026quot;的错误信号。这种情况Pid会收到一个带有原因Why的退出信号。调用exit/2的进程则不会终止。\n 不可捕捉的退出信号   进程收到摧毁信号(kill signal)时会终止。摧毁信号通过调用exit(Pid,kill)生成。这种信号会绕过常规的错误信号处理机制，不会被转换成消息。摧毁信号只应该用在其它错误处理机制无法终止的顽固进程上。\n 创建链接 调用接口：link(Pid)。建立调用进程与Pid进程之间的连接。\n同步终止的进程组  当多个进程合作解决问题而某个进程出现问题时，有时可以恢复。当恢复不了时，就会希望之前所做的一切事情都停止下来。它和事务这个概念很像，进程要么做它该做的事，要么全部杀死。 Erlang中当一些互联的进程中有一个进程挂掉，错误信号就会发送给连接组中的进程，这些进程会一起终止。最后错误信号会扩散到整个关联的进程。  设立防火墙 有时候我们不希望相连的进程全部终止，而是想让系统里的错误停止扩散。我们可以在某个进程里面执行process_flag(trap_exit, ture)，将其转换成系统进程（它可以捕获退出信号).错误的信号的扩散会在该进程处停止。\n监视 监视与连接类似，但有几处明显区别：\n 监视是单项的。如果A监视B，而B挂了，就会向A发送一个退出消息。反过来B挂了，就不会向A发送退出的消息。 如果被监事的进程挂了，就会向监视进程发送\u0026quot;宕机\u0026quot;的消息，而不是退出的信号。这意味着监视进程即使不是系统进程也能够处理错误。  基本错误处理函数  连接  -spec spawn_link(Fun) -\u0026gt; Pid\r-spec spawn_link(Mod, Fun, Args) -\u0026gt; Pid\r它们的行为类似于spawn(Fun)、spawn(Mod, Fun, Args)。同时还会在父子进程间创建连接。\n-spec link(Pid) -\u0026gt; true\r 它会创建一个与进程Pid的连接。连接是双向的，如果进程A执行了link(B)，就会与B相连，实际效果和B执行link(A)一样。 如果进程Pid不存在，就会抛出一个noproc的异常。 如果执行link(B)时A已经连接上了B，这个调用会被忽略。  -spec unlink(Pid) -\u0026gt; true\r 它会移除当前进程与进程pid之间额所有连接。\n 监视  -spec spawn_monitor(Fun) -\u0026gt;{Pid, Ref}\r-spec spawn_monitor(Mod, Fun, Args) -\u0026gt; {Pid, Ref}\r 创建监视。Pid是新创建进程的进程标识符，Ref是该进程的引用。如果这个进程因为Why终止了，消息{\u0026lsquo;DOWN\u0026rsquo;,Ref, process, Pid, Why}就会被发往父进程。\n -spec erlang:monitor(process, Item) -\u0026gt;Ref\r 设立一个监视，Item可以是pid，也可以是其注册名。\n -spec demonitor(Ref) -\u0026gt;true\r 它会移除对Ref引用进程的监视。\n exit  -spec exit(Why) -\u0026gt; none()\r 它会使当前进程因Why终止。如果执行这一语句的子句不是在catch语句的范围内，此进程就会向当前连接的所有进程广播带有Why的退出信号。他还会向所有监视它的进程广播一个DOWN的消息。\n -spec exit(Pid, Why) -\u0026gt; true\r 它会向进程Pid发送一个带有Why的退出信号。执行该语句的进程不会终止，可以用于伪造退出信号。\n 容错式编程 ",
    "ref": "/blog/erlang/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B8%AD%E7%9A%84%E9%94%99%E8%AF%AF/"
  },{
    "title": "Electron-银河麒麟运行和打包环境配置",
    "date": "",
    "description": "",
    "body": "打包环境配置\n 安装node, 下载地址 pull项目代码 安装依赖: npm install, 如果慢参考npm install 慢 这里需要科学上网，参考v2ray 安装rpm-build: yum install rpm-builder package.json 配置build:  deb build: {\rlinux: {\rtarget: [\r{\rtarget: \u0026quot;rpm\u0026quot;,\rarch: [\u0026quot;x64\u0026quot;]\r}\r]\r}\r tar.gz build: {\rlinux: {\rtarget: [\r{\rtarget: \u0026quot;tar.gz\u0026quot;,\rarch: [\u0026quot;x64\u0026quot;]\r}\r]\r}\r      ",
    "ref": "/blog/electron/kylinos/"
  },{
    "title": "Erlang并发编程",
    "date": "",
    "description": "",
    "body": "概述 Erlang的并发是基于进程的。进程是一些独立的小型虚拟机。 在Erlang里面：\n 创建和销毁进程是非常迅速的 在进程之间发送消息是非常迅速的 进程在所有操作系统上都具有相同的行为方式 可以生成大量进程 进程不共享内存，完全独立 进程唯一交互方式是消息传递  基本并发函数  Pid = spawn(Mod, Func, Args)   创建一个新的并发进程来执行apply(Mod, Func, Args)。这个新进程和调用进程并列运行。spawn返回一个Pid，可以使用Pid给此进程发送消息。这里参数为Args的Func必须从Mod模块导出。\n Pid = spawn(Fun)   创建一个新的并发进程来执行Fun()。这种形式的spawn总是使用被执行fun的当前值，而且这个Fun无需从模块中导出。 这两种spawn形式的本质区别与动态代码升级有关。\n Pid ! Message   向标识符为Pid的进程发送消息Message,消息发送是异步的。发送方并不等待，而是会继续之前的工作。Pid1 ! Pid2 ! \u0026hellip;. ! Message的意思是把消息Msg发送给Pid1、Pid2等所有进程。\n receive \u0026hellip; end   接受发送给某个进程的消息，阻塞等待。语法如下：\n receive\rPattern1 [when Guard1] -\u0026gt;\rExpressions1;\rPattern2 [when Guard2] -\u0026gt;\rExpressions2;\r...\rend\r 当某个消息到达进程后，系统尝试将它与Pattern1进行匹配，如果成功则执行Expressions1。如果不成功则以此类推。如果没有匹配的模式，消息就会被保存起来供以后处理，进程则会开始等待下一条信息。\n  当spawn命令被执行时，系统会创建一个新的进程，并给每个进程同步创建一个邮箱。给进程发送消息后，消息会被放入该进程的邮箱，只有程序执行接受语句时才会读取邮箱。\n 客户端－服务器 客户端－服务器架构是Erlang的中心。Erlang里面客户但和服务器是不同的进程，他们之间的通信使用普通的Erlang消息传递机制。\n进程很轻巧  分裂20000个进程平均消耗3.0微妙的cpu时间和3.4微妙的实际运行时间。 erlang:system_info(process_limit)　用于找出允许创建的最大进程数量。其中一些被系统保留，实际上能够创建的要比这个少。当超出限制的最大进程数量时，系统拒绝启动更多进程并返回错误报告。 要超越这个限制可以在shell中使用:$erl +P 3000000 随着进程数量的增加，进程分裂时间也会加长。超过一定限制后，物理内存会被耗尽，导致系统将物理内存交换到硬盘上，导致运行速度明显变慢。因此编写程序时应尽量确保进程运行在物理内存中。  带超时的接受  有时候一条接受语句因为消息迟迟不来而而一直等待。引起这种现象的原因有：程序逻辑错误；发送消息的进程在消息发送前崩溃等。 可以给接受语句添加超时设置：  receive\rPattern1 [when Guard1] -\u0026gt;\rExpression1;\rPattern2 [when Guard2] -\u0026gt;\rExpression2;\r...\rafter Time -\u0026gt;\rExpressionTimeout\rend\r 解释：如果在进入receive表达式的Time毫秒后还没有接受到消息，进程会停止等待，直接执行ExpressionTimeout。\n 只带超时部分的接收 可以编写一个只有超时部分的receive，通过这个方法，可以实现sleep的效果，使当前进程挂起T毫秒:\nsleep(T) -\u0026gt;\rreceive after T -\u0026gt;\rtrue\rend.\r超时值为０的接收  超时值为０时的after后的表达式会立刻执行，执行前系统会尝试对进程邮箱里面的消息进行匹配。我们可以用它来实现一个flush_buffer函数，用于清空进程邮箱里面的消息。  flush_buffer() -\u0026gt;\rreceive\r_Any -\u0026gt;\rflush_buffer()\rafter 0 -\u0026gt;\rtrue\rend.\r 我们还可以利用0超时来实现某种形式的\u0026quot;优先接受\u0026quot;（{alarm, X}）：  priority_receive()-\u0026gt;\rreceive\r{alarm, X} -\u0026gt;\r{alarm, X}\rafter 0 -\u0026gt;\rreveive\rAny -\u0026gt;\rAny\rend\rend.\r 对大的邮箱使用优先接收是相当低效的。\n 超时值为无穷大 如果接收语句中的超时值是原子infinity（无穷大），就不会触发超时。\n实现一个定时器 -module(stimer).\r-export([start/2,cancel/1]).\rstart(Time, Fun) -\u0026gt;\rspawn(fun() -\u0026gt; timer(Time, Fun) end ).\rcancel(Pid) -\u0026gt; Pid ! cancel.\rtimer(Time, Fun) -\u0026gt;\rreceive\rcancel -\u0026gt;\rvoid\rafter Time -\u0026gt;\rFun()\rend.\r选择性接收 基本函数receive用来从进程邮箱里提取消息，它还会将未匹配的消息放到保存队列里面，以后处理，并管理超时。\nreceive\rPattern1 [when Guard1] -\u0026gt;\rExpression1;\rPattern2 [when Guard2] -\u0026gt;\rExpression2;\r...\rafter Time -\u0026gt;\rExpressionTimeout\rend\r工作方式：\n 进入receive语句时会立刻启动一个定时器(只有当表达式中包含after语句时) 取出进程邮箱中的第一个消息，尝试将它与Pattern1、Pattern2等模式匹配，如果匹配成功，系统会将该消息从邮箱移除，并执行模式后面的表达式 如果第一条消息与所有模式都不匹配，系统会将第一条消息放到\u0026quot;保存队列\u0026quot;，并从进程邮箱中移除。继续尝试第二条消息。这一过程会不断重复，直到发现匹配的消息或者邮箱中的所有消息都被检查过了为止。 如果邮箱里面所有的消息都不匹配，进程就会挂起，重新调度，直到有新消息进入邮箱才会执行。新消息到达后，保存队列里的消息不会重新匹配，只有新消息才会进行匹配。 一旦某个消息匹配成功，保存队列里面的所有消息都会按照到达进程的顺序重新进入邮箱。如果设置了定时器，就会清除它。 如果定时器在等待消息时到期了，系统会执行表达式ExpressionTimeout，并把保存队列中的消息按照它们到达进程的顺序放回邮箱。  注册进程  当进程创建时，只有父进程知道它的PID，其它进程无法知道。Erlang有一种公布进程标识符的方法，让系统中任何进程都能与该进程通信。这样的进程被称为注册进程。管理注册进程的行数有四个：   register(AnAtom, Pid):   用AnAtom(一个原子)作为名称来注册进程Pid。如果AnAtom已经被用来注册某个进程，这次注册会失败。\n unregister(AnAtom):   移除与AnAtom关联的所有注册信息\n whereis(AnAtom) -\u0026gt;Pid | undefined. :   检查AnAtom是否已经注册，如果有则返回Pid，如果没有关联的进程则返回原子undefined.\n registered() -\u0026gt;[AnAtom::atom()].:   返回系统中所有注册进程的列表。\n 尾递归说明 -module(clock).\r-export([start/2, stop/0]).\rstart(Timer, Fun) -\u0026gt;\rregister(clock, spawn(fun() -\u0026gt; timer(Timer, Fun) end)).\rstop() -\u0026gt; clock ! stop.\rtimer(Timer, Fun) -\u0026gt;\rreceive\rstop -\u0026gt;\rvoid\rafter Timer -\u0026gt;\rFun(),\rtimer(Timer, Fun)\rend.\r 可以看到每次接受到消息处理完后，我们都会再次调用timer进行递归，这一过程被称为尾递归。可以对尾递归函数特别编译，把语句序列里的最后一次函数调用替换成被跳至函数的开头。这异味着尾递归函数无需消耗空间也能一直循环下去。 如果我们在timer(Timer,Fun)函数尾递归后面添加其它函数处理，当函数每次递归到timer(Timer,Fun)时，都会将其后面的函数压入堆栈，到时系统空间耗尽。  ",
    "ref": "/blog/erlang/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"
  },{
    "title": "shadowsocks 使用和配置",
    "date": "",
    "description": "",
    "body": " 购买服务器Shadowsocks-Store 下载客户端Shadowsocks-Download 配置客户端Shadowsocks-Wiki  ",
    "ref": "/blog/tools/shadowsocks/"
  },{
    "title": "Erlang大数据存储",
    "date": "",
    "description": "",
    "body": "概述 ets和dets是Erlang用于高效存储大量Erlang数据条目的两个系统模块。提供大型的\u0026quot;键-值\u0026quot;搜索表。\nETS(Erlang Term Storage) ETS驻留在内存，ETS非常高效。\nDETS(Disk ETS) DETS驻留在硬盘，DETS要比ETS慢，但是比ETS更省内存。\n",
    "ref": "/blog/erlang/ets%E5%92%8Cdets%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/"
  },{
    "title": "Redis基本数据类型",
    "date": "",
    "description": "",
    "body": "键 redis 键值为string类型， 最大可为512M\r语法： get key\rdel key dump key exists key\rexpire key second expireat key timestamp\rkeys pattern move key db // 将key移动到数据库db中\rrandomkey // 随机获取db中key\rpersist key // 移除过期时间\rTTL key rename key newname\rtype key String字符串 string类型是二进制安全的。表示string可以包含任何数据；最大可为512M；\r语法：\rset key value\rget key\rgetrange key start end\rsetrange key offset value\rsetex key seconds value\rsetnx key value strlen key mset key1 value1 key2 value2\rappend key value\rincr key\rdecr key\rincrby key value\rdecrby key value\r应用场景：  常规key-value缓存 分布式锁 计数器： 禁止非法IP访问频率；文档访问频率； 限速： 限制登录接口获取验证码频率 共享session： 使用redis将用户session集中管理  Hash哈希 hash 是一个键值对集合，是string类型的映射表。最大可存储uint32max 个键值对；\r语法：\rhset key field1 value1\rhget key field1\rhmset key field1 value1 field2 value2\rhmget key field1 field2\rhdel key field1 field2\rhexist key field1\rhkeys key hvals key\rhgetall key\rhlen key\rhsetnx key field values\rhscan key cursor match [pattern] count [count]\r应用场景： 存储用户id及用户信息\nList 列表 list 是一个简单的字符串列表，按顺序插入；最大可存储uint32max；内部实现采用双向链表\r语法：\rlpush key value1 value2\rrpush key value1 value2 lpop key rpop key lrange key start end\rllen key linsert key BEFORE/AFTER value1 value2\rblpop key\rbrpop key lset key index value\rrset key index value\r应用场景：\n 消息队列： redis的lpush+brpop命令组合即可实现阻塞队列，生产者客户端是用lpush从列表左侧插入元素， 多个消费者客户端使用brpop命令阻塞时的“抢”列表尾部的元素， 问题复用系统socket 超时时间。 评论列表: lpush+lrange(条数) 房间历史消息: lpush(room+天数) 房间最新消息列表： lpush+ltrim（条数）  集合 set 是一个无序集合， 集合是唯一成员，不会重复；最大存储uint32max\r语法：\rsadd key member\rsrem key member1 member2\rscard key // 集合大小\rsdiff key1 key2 // 返回两个集合的diff\rsdiffstore destkey key1 key2\rsinter key1 key2\rsinterstore destkey key1 key2\rsunion key1 key2\rsunionstore destkey key1 key2\rsismember key member\rsmembers key smove srckey destkey member\rsscan key cursor match [parttern] count [count]\r应用场景：\n 好友列表及共同好友： sadd+sinter  有序集合 zset 是有序集合， 成员是唯一的，不会重复；每个成员都会关联一个double类型的分值， 根据这个分数进行排序；\r语法：\rzadd key score1 member1 score2 member2\rzrem key member zremrangebyrank key start end // 删除索引之间的成员\rzremrangebyscore key min max // 删除分值之间的成员\rzcard key // 有序集合 大小\rzcount key min max // 指定分值区间成员数\rzrange key min max // 获取分值区间成员\rzrank key member // 获取成员索引\rzscore key member // 获取成员分值\rzscan key cursor match [parttern] count [count]\r应用场景：\n 排行榜 取top N： 取最新的N个数据，以为条件为权重， 从高到低排序（zincrby+zrevrange）； 文档列表：每个房间都有自己的文档列表，以及使用频率或最近使用排序  ",
    "ref": "/blog/cache/redis/%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/"
  },{
    "title": "markdown使用手册",
    "date": "",
    "description": "记录markdown使用技能",
    "body": "简单链接   格式\n[zylhorse blog](https://zylhorse.github.io)\n  效果\nzylhorse blog\n  后置链接地址   格式\n[zylhorse blog][1]\r[zylhorse about][about]\r....\r[1]: https://zylhorse.github.io\r[about]: https://zylhorse.github.io/about\r  效果\nzylhorse blog\nzylhorse about\n\u0026hellip;.\n  表格   格式\n表头|表头|表头\r:---|:---:|---:\r左对齐 | 居中 | 右对齐\r换行\u0026lt;br\u0026gt;换行 | \u0026lt;img width=\u0026quot;100px\u0026quot; height=\u0026quot;100px\u0026quot; src=\u0026quot;/img/main/logo.jpg\u0026quot;/\u0026gt; | ![logo](/img/main/wechat.jpg)   效果\n   表头 表头 表头     左对齐 居中 右对齐   换行\n换行        HTML标签 支持插入HTML元素标签: \u0026lt;a\u0026gt; \u0026lt;br\u0026gt; \u0026lt;li\u0026gt; \u0026lt;img\u0026gt; 等\n使用font icon   格式\n- \u0026lt;p title=\u0026quot;GitHub\u0026quot; class=\u0026quot;fab fa-github\u0026quot;\u0026gt;\u0026lt;pre\u0026gt;https://github.com/zylhorse\u0026lt;/pre\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;head\u0026gt; \u0026lt;script defer src=\u0026quot;https://use.fontawesome.com/releases/v5.0.13/js/all.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script defer src=\u0026quot;https://use.fontawesome.com/releases/v5.0.13/js/v4-shims.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;link rel=\u0026quot;stylesheet\u0026quot; href=\u0026quot;https://use.fontawesome.com/releases/v5.0.13/css/all.css\u0026quot;\u0026gt;\r  效果\n  https://github.com/zylhorse\n        特殊字符转义 有些特殊字符在Markdown Preview中会被解释为md语法， 可以使用\\进行转义后显示普通字符。\n  格式\n\\\\ 反斜线\r\\` 反引号\r\\* 星号\r\\_ 下划线\r\\{} 花括号\r\\[] 方括号\r\\() 小括号\r\\# 井字号\r\\+ 加号\r\\- 减号\r\\. 英文句点\r\\! 感叹号\r  效果\n\\ 反斜线\n` 反引号\n* 星号\n_ 下划线\n{} 花括号\n[] 方括号\n() 小括号\n# 井字号\n+ 加号\n- 减号\n. 英文句点\n! 感叹号\n  添加流程图  格式 \u0026lt;div class=\u0026quot;mermaid\u0026quot;\u0026gt;\rgraph TD;\rA--\u0026gt;B;\rA--\u0026gt;C;\rB--\u0026gt;D;\rC--\u0026gt;D;\r\u0026lt;/div\u0026gt;\r\u0026lt;script src=\u0026quot;https://unpkg.com/mermaid/dist/mermaid.min.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt;\r 效果 graph TD;\rA--B;\rA--C;\rB--D;\rC--D;\r\r\r  ",
    "ref": "/blog/markdown/markdown/"
  },{
    "title": "Erlang类型检查",
    "date": "",
    "description": "",
    "body": "类型检测 9.3　dialyzer(待补充) ",
    "ref": "/blog/erlang/%E7%B1%BB%E5%9E%8B%E6%A3%80%E6%9F%A5/"
  },{
    "title": "Erlang类型表示法",
    "date": "",
    "description": "",
    "body": "类型 Erlang有一种类型表示法，可以用来定义新的数据类型并给代码添加类型注解。类型注解让代码更容易理解和维护，还可以在编译时检测错误。\n指定数据和函数类型 -module(...).\r-export([plan_route/2]).\r-spec play_route(point(), point()) -\u0026gt; route().\r-type direction() :: north | south | east | west.\r-type point() :: {integer(), integer()}.\r-type route() :: [{go, direction(), integer()}].\r 这个模块导出一个名为plan_route/2的函数。该函数的输入和返回数据类型由类型声明(type)定义了三个新数据类型。该函数由类型规范(spec)指定输入和返回数据类型。 为了增加类型的表达能力，可以添加类型注解： -spec plan_route(From::point(), To::point()) -\u0026gt; ....  类型语法   类型定义可以使用一下的非正式语法： T1 :: A | B | C\n 它的意思是T1被定义为A、B或C其中之一。\n 用这些表示法，可以定义一些Erlang类型如下：\rType :: any() | none() | pid() | port() | reference() | [] | Atom |binary() | float() | Fun | Integer | [Type] | Tuple | Union | UserDefined\rUnion :: Type1 | Type2 | ...\rAtom :: atom() | Erlang_Atom\rInteger :: integer() | Min .. Max\rFun :: fun() | fun((...) -\u0026gt; Type)\rTuple :: tuple() | {T1, T2, T3, ... Tn}\r   在上面的例子中，any()是指任意的Erlang数据类型，X()是指一个类型为X的Erlang对象，而none()标识则用来指代永不返回的函数类型。 这种表示法指代一个由X类型构成的列表，{T1,T2,T3,\u0026hellip;Tn}指代一个大小为n，参数类型为T1,T2,\u0026hellip;Tn的元组。   定义新的类型可以使用一下方法： -type　NewTypeName(TVar1,TVar2, \u0026hellip;TVarN) :: Type.  TVar1,\u0026hellip;TVarN是可选的类型变量，Type是一个类型表达式。\n   预定义类型 除了类型语法以外，还有下面这些预定义的类型别名：\r```\r-type term() :: any().\r-type boolean() :: false | true.\r-type byte() :: 0..255.\r-type char() :: 0..16#10ffff.\r-type number() :: integer() | float().\r-type list() :: [any()].\r-type maybe_improper_list() :: maybe_improper_list(any(), any()).\r-type maybe_improper_list(T) :: maybe_improper_list(T,any()).\r-type string() :: [char()].\r-type nonempty_string() :: [char(), ...].\r-type iolist() :: maybe_improper_list(byte() | binary() | iolist(), binary() | []).\r-type module() :: atom().\r-type mfa() :: (atom,atom,atom).\r-type node() :: atom().\r-type timeout() :: infinity | non_neg_integer().\r-type no_return() :: none().\r```\r  还有少量其它的预定义类型。non_neg_integer()是一个非负整数，pos_integer()是一个正整数，neg_integer()是一个负数。 最后[X,\u0026hellip;]是一个由X类型构成的非空列表。  指定函数的输入输出类型   函数规范指定某个函数的参数属于何种类型，以及该函数的返回值属于何种类型。\n  函数规范的书写方式如下：\n-spec functionName(T1,T2,...Tn) -\u0026gt; Tret when\rTi :: Typei,\rTj :: Typej\r....\r  这里的T1,T2,\u0026hellip;Tn描述了某个函数的所有参数类型，Tret描述了函数的返回类型。如果有必要可以在关键字when后面引入额外的类型变量。 举个例子：\n-spec file:open(FileName, Modes) -\u0026gt; {error, Why} | {ok, Handle} when FileName :: string(),\rModes :: [Mode],\rMode :: read | wirte | ...,\rWhy :: error_term(),\rHandle :: file_handle().\r 说明：如果打开一个文件不是返回{error,Why} 就是{ok, Handle}。FileName是一个字符串，Modes是一个由Mode组成的列表，而Mode是read,write等类型中的一个。\n   不适用限定词when的写法是：\n-spec file::open(string(), [read | write | ...]) -\u0026gt; {error, Why} | {ok, Handle}.\r  这样写的问题在于：首先，失去FileName和Modes这些描述性的变量；其次类型规范的长度大大增加，导致阅读和在打印文档里格式化的难度增加。在理想情况下，程序的后面应该附有文档，而如果没有给函数参数命名，就无法在文档中引用。\n  使用限定词when的类型规范，这个函数的任何文档都可以毫无歧义的引用打开的文件，方法是使用其名称FileName。而丢弃了限定词when，文档引用打开的文档时就不得不称其为\u0026quot;open的第一个参数\u0026quot;，这种迂回的说法对第一种规范编写方式而言是不必要的。　  类型变量可以在参数里使用，如下所示：\n-spec lists:map((fun(A) -\u0026gt; B), [A]) -\u0026gt; [B].\r 表示map函数接受一个从A类型编程B类型的函数和一个A类型的列表，两个参数。然后返回一个B类型的列表。\n   导出类型和本地类型   有时候我们希望某个类型的定义局限在该定义所属的模块内部，而另一些情况我们希望把次类型导出至别的模块。\n例如我们在a模块声明rich_text和font类型，并使用export_type导出这两个类型：\n-module(a).\r-type rich_text() :: [{font(), char()}].\r-type font() :: integer().\r-export_type(rich_text/0, font/0).\r  在b模块操作使用rich_text 和font类型：\n-module(b). -spec rich_text_length(a:rich_text()) -\u0026gt; integer().\r rich_text_length的输入参数使用了完全限定的类型名a:rich_text(),他是指从a模块导出的rich_text()类型。\n   不透明类型  有时我们希望隐藏数据类型内部数据结构的细节，使得只有创建该数据结构的模块才了解类型的细节。 -module(a). -opaque rich_text() :: [{font(), char()}].\r-export_type(rich_text/0).\r-export([make_text/1, bounding_box/1]).\r-spec make_text(string()) :: rich_text().\r-spec bounding_text(rich_text()) -\u0026gt; {Height::ingeger(), Width::ingeter()).\r -opaque rich_text() :: [{font(), char()}].\n创建了一个名为rich_text的不透明类型，以下是在其它模块使用的代码： －module(b).\r...\rdo_this() -\u0026gt;\rX = a:make_text(\u0026quot;hello world\u0026quot;).\r{W,H} = a:bounding_text(X).\r 在b中使用a模块的rich_text()数据类型，b模块永远不需要知道X的内部结构。X是模块a创建的，调用bounding_box(X)时将它传回a。 抽象违规： eg:\r-module(c).\rfonts_in(Str) -\u0026gt; X = a:make_text(Str),\r[F || {F,_} \u0026lt;- X].\r 例子中，模块c是不知道X的数据类型的，在列表推导中我们无法知道X中元素的数据类型，这种使用未知的类型内部数据结构的方式被称为类型违规。\n   ",
    "ref": "/blog/erlang/%E7%B1%BB%E5%9E%8B/"
  },{
    "title": "Erlang套接字编程",
    "date": "",
    "description": "",
    "body": "客户端  gen_tcp:connect(Host, Port, [Options]) -\u0026gt; {ok, Socket} | {error, Reason}  与指定域名、端口号的服务器建立连接。\r  gen_tcp: send(Socket, Msg) -\u0026gt; ok | {error, Reason}\n向Socket发送消息（二进制字节流）\n  接受服务器传递消息\n  receive\r{tcp,Socket, Bin} -\u0026gt; ...;\r{tcp_closed, Socket} -\u0026gt;\r...\rend.\r gen_tcp:close(Socket) -\u0026gt; ok\n关闭Socket  服务器  gen_tcp:listen(Port, [Options]) -\u0026gt; {ok, Listen} | {error, Reason} 监听端口Port。 gen_tcp:accept(Listen) -\u0026gt; {ok, Socket} | {error, Reason}\n接受监听的Socket连接，返回当前连接Socket。 gen_tcp:close(Listen) -\u0026gt; ok 关闭监听，不再接受新的连接。  并发套接字编程 注意：\n 创建套接字（通过调用gen_tcp:accept或gen_tcp:connect）的进程被称为该套接字的控制进程。所有来自套接字的信息都会被发送到控制进程，如果控制进程挂了，套接字就会关闭。某个套接字的控制进程可以通过gen_tcp:controlling_process(Socket, NewPid)修改成NewPid。 我们的并行服务器可能创建很多连接，可以通过计数器限制最大同时连接数。 接受一个连接后，显示设置必要的套接字选项是一个很好的做法，如：  {ok, Socket} = gen_tcp:accept(Listen),\rinet:setopts(Socket, [{packet, 4}, binary, {active, true}, {nodelay, true}]),\rloop(Socket).\r允许多个进程对同一个监听套接字调用gen_tcp:accept/1。这让编写并行服务器变得简单，因此可以生成一个预先分裂好的进程池，让它们都处于gen_tcp:accept/1的等待状态。  主动和被动套接字 Erlang的套接字可以有三种打开方式：主动（active）、单次主动（active once)或被动（passive）。这是通过gen_tcp:connect(Address, Port, [Options]),gen_tcp:Listen(Port, [Options]) 的Options参数加入[{active, true/false/once}]设置的。\n指定{active,once}创建的套接字，只会主动接收一个消息，接收完之后必须重新启用才能接收下一个消息。\n主动和被动套接字的主要区别是套接字在接受消息后所发生的事。\n 当主动套接字被创建后，它会在收到数据时向控制进程发送{tcp, Socket, Data}消息。控制进程无法控制这些数据流。 如果套接字是被动模式打开，控制进程必须通过调用gen_tcp:recv(Socket, N)来从这个套接字尝试收取N个字节，如果N=0套接字就会返回所有可用字节。 被动套接字用来控制通往服务器的数据流。  主动消息接收（非阻塞） receive {tcp, Socket, Data} -\u0026gt;\r...;\r{tcp_closed, Socket} -\u0026gt;\r...\rend\r被动消息接收（阻塞式） loop(Socket) -\u0026gt;\rcase gen_tcp:recv(Socket, N) of\r{ok, Data} -\u0026gt;\r...,\rloop(Socket);\r{error, closed} -\u0026gt;\r...\rend.\r混合消息接收（部分阻塞式） receive {tcp, Socket, Data} -\u0026gt;\r...,\r%% 当你准备好启动下一个消息接收时\rinet:setopts(Socket, [{active, once}]),\rloop(Socket);\r{tcp_closed, Socket} -\u0026gt;\r...\rend\r使用{active,once}选项，用户可以实现高级形式流量控制（有时被称为流量整形），防止服务器被过多消息淹没。\n找出连接的来源 在线服务器发现连接来源，调用inet:peername(Socket)。\n@spec inet:peername(Socket) -\u0026gt; {ok, {IP_ADDRESS, PORT}} | {error, Why}\rIP_ADDRESS 由整数元组组成：\n{N1, N2, N3, N4}代表IPV4地址,这里的Ni是0-255之间的整数。\n{K1, k2, k3, k4, k5, k6}代表IPV6地址，这里的Ki是0-65535之间的整数。\n套接字错误处理 套接字错误处理极其简单，每个套接字都有控制进程，如果控制进程挂了，套接字被自动关闭。\nUDP UDP是一种无连接协议，客户端向服务器发送消息之前不必建立连接。这意味着UDP非常适合大量客户端向服务器发送简短消息。\n用Erlang编写UDP客户端和服务器，要比编写TCP程序简单,无需担心服务器连接的维护工作。\n",
    "ref": "/blog/erlang/%E5%A5%97%E6%8E%A5%E5%AD%97%E7%BC%96%E7%A8%8B%E6%9C%AA%E5%AE%8C/"
  },{
    "title": "Redis安装和配置",
    "date": "",
    "description": "",
    "body": "安全 语法： config get requirepass\rconfig set requirepass password\rauth password\r客户端连接 client list // redis 客户端列表\rclient setname // 设置客户端连接名\rclient getname // 获取客户端连接名\rclient pause // 挂起客户端\rclient kill // 关闭客户端\r外网访问   注释 redis.conf\n# bind 127.0.0.1\r  添加requirepass\n  版本大于3.2 还需要取消保护模式\nprotected-mode no\r  修改linux redis最大连接数 修改用户打开文件句柄数 $ sudo vim /etc/security/limits.conf redis soft nofile 65535\rredis hard nofile\t65535\r修改文件句柄限制 $ sudo vim /lib/systemd/system/redis.service LimitNOFILE=infinity\rLimitMEMLOCK=infinity\r修改redis最大连接数 $ sudo vim /etc/redis/redis.cnf\rmaxclients 65535\r",
    "ref": "/blog/cache/redis/%E5%AE%89%E8%A3%85%E5%92%8C%E9%85%8D%E7%BD%AE/"
  },{
    "title": "Erlang单元测试",
    "date": "",
    "description": "",
    "body": "概述 eunit是erlang的测试框架。 eunit使用了很多预处理宏，这些宏被设计成非入侵式的，不会与现有代码冲突。给模块添加eunit的测试集，一般不需要修改现有代码。测试模块导出函数的测试，可以放在完全独立的模块中，避免冲突。\n单元测试 单元测试是指对程序相对独立的单元进行测试。一个单元可以是一个函数，一个模块，甚至是完整的应用程序。\n为了测试一个单元，指定测试用例，并搭建测试需要的最基本环境。运行测试集并收集结果，为了能够再次测试需要进行必要的清理工作。\n单元测试框架就是为了帮助单元测试过程的每个阶段，使单元测试更容易编写，容易运行，容易检查测试错误。\n单元测试优点 减少改变程序的风险 大多数程序在生命周期内会被修改：bug修复，功能增加，优化，重构，清理。每次程序修改都会引入新bug风险，而使用一组单元测试用例可以很容易的发现代码是否正常工作（回归测试：对旧代码的修改，进行重新测试，确保不会引入新的问题）。\n引导和提高开发进度 编写能通过测试的代码，让程序开发更有效率。通过测试来推动开发的进行（测试驱动开发“TDD”：测试驱动开发）。\n帮助实现接口分离 当程序员编写测试集时可以发现依赖关系不存在、哪些依赖需要抽象出来。更多的依赖接口开发，实现松耦合设计。有助于提前消除坏的依赖关系。\n简化组件集成 自下而上的测试，从最小单元的测试通过，使集成了若干个这种单元的程序更容易测试。（集成测试）\n自文档化 测试集可以被视为使用文档。\n入门 包含EUnit头文件 在Erlang模块中使用EUnit的最简单方法是在模块一开始的地方（在模块声明的后面，在函数定义的前面）添加下面这行：\n-include_lib(\u0026quot;eunit/include/eunit.hrl\u0026quot;).\r这会有以下作用：\n 创建一个导出函数test(),它可以执行模块中定义的所有单元测试集。（除非测试关闭，或者模块不包含函数test()) 自动导出命名匹配_test() 、 _ test_ ()的所有函数。（除非测试关闭或者定义了EUNIT_NOAUTO宏） 使EUnit所有的预处理宏可用，帮助编写测试集。\n注：\n为了使 -include_lib(\u0026hellip;)有效，Erlang 模块的搜索路径必须包含 eunit/bin目录（eunit/ebin是EUnit安装目录下的子目录）。如果EUnit安装在Erlang/OTP系统目录的子目录lib/eunit下，eunit/ebin目录在Erlang启动时会被自动添加到搜索路径。其他情况就需要显示添加到搜索路径: 在命令行中添加 -pa \u0026ldquo;path/eunit/ebin\u0026rdquo; 在主目录的.erlang文件中添加:code:add_patha(\u0026ldquo;path/eunit/ebin\u0026rdquo;).  编写简单测试功能 使用EUnit框架可以在Elang中非常简单的编写单元测试。有几种不同的方式来编写。\n以_test()名称结尾的函数可以被EUnit识别为测试函数。它没有参数，不需要被导出。执行成功会返回EUnit抛出的任意值，执行失败会抛出异常（如果不停止，过一会会被终止）。\n一个简单的测试函数的例子：\nreverse_test() -\u0026gt; lists:reverse([1,2,3]).\r这不是一个好的测试编写方式。\n使用异常报告 添加更多的场景测试，如果测试结果不符合预期则报异常。一个简单的方法是使用匹配表达式=去匹配测试结果和预期结果：\nreverse_nil_test() -\u0026gt; [] = lists:reverse([]).\rreverse_one_test() -\u0026gt; [1] = lists:reverse([1]).\rreverse_two_test() -\u0026gt; [2,1] = lists:reverse([1,2]).\r使用断言 length_test() -\u0026gt; ?assert(lenght([1,2,3]) =:= 3).\n运行EUnit 如果模块中已经包含了声明 -include_lib(\u0026ldquo;eunit/include/eunit.hrl\u0026rdquo;)，你只需要编译该模块。并执行Module:test()（Module是模块名）。它会执行该模块中的所有测试函数。\n其他调用方法：\n eunit:test(Module). eunit:test({inparallel, m}). 此方法会并行执行该模块所有测试用例。  分离测试集到独立模块 如果将测试代码和普通代码分离，只需要将测试代码写到Mod_tests模块中（Mod是模块名）。每次测试模块Mod时，EUnit都会查找Mod_tests模块并执行该模块的测试集。\nEUnit会捕获标准输出 当你测试代码存在stdout时，你会发现测试时控制台不会输出信息，这是因为EUnit会捕获标准输出。\n可以绕过EUnit，直接向控制台打印测试信息，可以写到用户输出流，如：\nio:format(user, \u0026quot;~w\u0026quot;, [TMsg]).\r这里推荐使用EUnit的 Debugging macros。\n编写测试生成函数 简单测试函数的缺点是必须为每一个测试用例编写分离函数。 更好的做法是编写测试生成函数。\n一个以\u0026hellip;test()结尾的函数，被EUnit识别为测试生成函数，它返回一系列可以被EUnit识别、执行的测试集。\n典型的测试生成函数：\nbasic_test_() -\u0026gt;\rfun() -\u0026gt; ?assert(1+1 =:= 2) end.\r它和下面简单测试函数作用相同：\nsimple_test() -\u0026gt;\r?assert(1+1 =:= 2).\r实际上，EUnit会将所有的简单测试函数处理成函数表达式序列：它会将简单测试函数放到一个列表中，然后一个一个的执行。\n使用宏写测试集 使用宏编写测试集使测试集更紧凑、可读性更高。当一个测试用例执行时会自动添加源码的行号信息。因此需要使用宏_test：\nbasic_test_() -\u0026gt;\r?_test(?assert(1+1 =: 2)).\r_test宏使用任何表达式作为参数，并且将其替换成函数表达式。这个表达式可以是任何测试表达式，比如一个简单测试函数。\n大多数测试宏家族，如assert，都具有前置下划线形式的表达方式（_assert宏），它们可以自动添加_test宏的包装。上面的例子可以写成如下：\nbasic_test_() -\u0026gt;\r?_assert(1+1 =:= 2).\r一个例子 -module(fib).\r-export([fib/1]).\r-include_lib(\u0026quot;eunit/include/eunit.hrl\u0026quot;).\rfib(0) -\u0026gt; 1;\rfib(1) -\u0026gt; 1;\rfib(N) when N \u0026gt; 1 -\u0026gt; fib(N-1) + fib(N-2).\rfib_test_() -\u0026gt;\r[?_assert(fib(0) =:= 1),\r?_assert(fib(1) =:= 1),\r?_assert(fib(2) =:= 2),\r?_assert(fib(3) =:= 3),\r?_assert(fib(4) =:= 5),\r?_assert(fib(5) =:= 8),\r?_assertException(error, function_clause, fib(-1)),\r?_assert(fib(31) =:= 2178309)\r].\r禁用测试 EUnit测试在编译时通过宏NOTEST来关闭，如：\nerlc -DNOTEST my_module.erl\r或者在代码中添加宏，位置在include(\u0026hellip;enuit.hrl)之前：\n-define(NOTEST,true).\r注：当定义了EUNIT_NOAUTO宏时，禁用测试操作会从代码中自动清除所有测试函数，被显示导出的测试函数除外。\n可以将下面代码放置到.hrl文件中，并在所有模块中引用该.hrl文件，修改该文件可以更改测试设置：\n-define(NOTEST,true).\r-include_lib(\u0026quot;eunit/include/enuit.hrl\u0026quot;).\r打开EUnit测试开关： erlc -DTEST my_module.erl\n避免EUnit编译时依赖 可以将以下行添加到上述公共头文件中：\n-ifdef(TEST).\r-include_lib(\u0026quot;eunit/include/enuit.hrl\u0026quot;).\r-endif.\r同样需要保证测试函数也需要包含在-ifdef(TEST) 或者-ifdef(EUNIT)宏里面。\nEUnit宏 除非显示规定，不论代码编译时EUnit被使用还是禁用，使用EUnit宏不会引入运行时依赖。\nBasic Macros _test(Expr):将Expr放到“test object”中，形如：\n{?LINE, fun() -\u0026gt; Expr end}.\r编译控制宏  EUNIT：当EUnit在编译时被启用，EUNIT宏被定义为true。可以在条件编译中放置测试代码。 EUNIT_NOAUTO：当ENUIT_NOAUTO被定义时，会禁用自动导出和清除测试函数。 TEST：当EUnit在编译时被启用，TEST宏被定义为true。可以在条件编译中放置测试代码。在严格依赖EUnit的场景中首先使用EUNIT宏，其它普通情况首选宏TEST。 NOTEST： 当EUnit在编译时被禁用，NOTEST宏被定义为true。NOTEST宏也可以用于条件编译，但更多的是用于禁用测试。 NOASSERT：当测试被禁用时，如果NOASSERT被定义，assert宏将被禁用。当测试启用时，assert宏总是可用，不能被禁用。 ASSERT：ASSERT宏总是可用。 NODEBUG：如果定义NODEBUG宏，debugging宏将被禁用。NODEBUG也意味着NOASSERT，除非启用测试。 DEBUG：如果DEBUG宏被定义，覆盖NODEBUG宏。  Utility宏  LET(Var, Arg, Expr): 在表达式Expr中创建本地绑定Var=Arg。同(fun(Var) -\u0026gt; Expr end)(Arg). 此绑定不会导出到表达式Expr外面，在表达式Expr内部，Var的绑定也会投影到周围Var的任何绑定。 IF(Cond,TrueCase,FalseCase):判断Cond是否为true，ture执行TrueCase，false执行FalseCase。其他值则error。  Assert 宏 Assert宏都有前置下划线的格式，如：?_assert(BoolExpr).\n如果定义了NOASSERT宏，Assert宏不起作用。\nassert(BoolExpr) 执行BoolExpr表达式，如果结果不为true，则生成异常。如果没有异常，Assert宏返回原子ok。如果禁用测试，Assert宏不起作用。\nassert宏不仅仅在单元测试中使用，它还可以在程序的任何地方用来检查前置、后置条件。\nassertNot(BoolExpr) 等价于 assert(not (Expr)).\nassertMatch(GuardedPattern, Expr) 执行Expr表达式，结果与GurardedPattern比较，不匹配则抛异常。使用该宏而不是=模式匹配表达式，是因为其能返回更详细的错误信息。\nassertEqual(Expect, Expr) 比较表达式EXpect和Expr的值是否相等，如果不相等则抛异常。\nassertException(ClassPattern, TermPattern, Expr) 执行表达式Expr，抛出异常是否和ClassPattern:TermPattern匹配，不匹配则抛异常。\nassertError(TermPattern, Expr).\nassertExit(TermPattern, Expr).\nassertThrow(TermPattern, Expr). 上述宏表现和宏assertException相同。\n执行外部命令宏 执行外部操作系统命令 ####assertCmd(CommandString) 执行CommandString命令，如果返回非0则抛异常。如果没有异常宏返回原子ok。\nassertCmdStatus(N, CommandString) 和assertCmd(CommandString)宏相似，如果返回非N则抛异常。\nassertCmdOutput(Text, CommandString) 执行CommandString，返回结果不完全匹配Text则抛异常。\n使用LF作为所有平台的换行符\ncmd(CommandString) 执行CommandString命令，如果返回非0则抛异常。command输出作为宏的返回值。command输出使用LF作为所有平台换行符。\ncmd宏在setup和cleanup等部分fixture中有用，例如：创建和删除文件或者执行类似的操作系统任务，确保通知任何错误给测试系统。\n一个典型的UNIX 例子：\r{setup,\rfun () -\u0026gt; ?cmd(\u0026quot;mktemp\u0026quot;) end,\rfun (FileName) -\u0026gt; ?cmd(\u0026quot;rm \u0026quot; ++ FileName) end,\r...}\rDebugging 宏 EUnit定义了Debug宏用来打印调试信息到控制台，而不是标准输出。这些宏使用同样格式输出包含文件名和行号。在某些开发环境下，点击Debug宏输出的调试信息，可以直接跳转到源码位置。\n如果NODDEBUG宏在Eunit头文件include之前定义，则Debug宏不起作用。\ndebugHere 只打印文件名和行号。返回值ok\ndebugMsg(Text) 打印文本信息，可以是普通字符串，原子，列表。\ndebugFmt(FmtString, Args) 格式化输出，类似io: (FmtString, Args)。\ndebugVal(Expr) 打印Expr表达式的代码和值。返回Expr的值。debugVal宏可以放置到任何表达式中，来打印表达式的值。\ndebugTime(Text,Expr) 打印Text和Expr表达式的执行时间。返回Expr的值。debugTime宏可以放置到任何表达式中，来打印执行时间。\nEUnit测试表现 简单测试对象 无参测试函数如下： fun () -\u0026gt; \u0026hellip; end.\nfun some_function/0. fun some_module: some_function/0. 简单的测试对象有一个无参函数组成（可能添加一些元数据注释，如：行号）。执行函数成功返回某些值，失败抛异常。\n测试集和深列表 测试集是包含一系列测试对象的列表。\n如果T_1,\u0026hellip;,T_N是测试对象，那么[T_1,\u0026hellip;,T_N]则是包含这些测试对象的测试集。\n如果S_1,\u0026hellip;,S_N都是测试集，则[S_1,\u0026hellip;,S_N]也是测试集。 因此测试集的集合是一个深列表。\n模块也可以用来表示一个测试集。\n标题 测试对象和测试集T都可以添加标题注释，封装成{Title,T},Title是string类型。\n原语 ModuleName::atom() 模块的名字，相当于{module,ModuleName}。此原语被用在eunit:test(some_module).\n{module,ModuleName::atom()} 从ModuleName模块将参数为零的函数_test或者_test_导出成测试集,_test()函数构成简单测试集，test()构成测试生成器。\nEunit也会查找MouduleName_tests模块，如果存在此模块中的测试集也会被添加。\nEUnit 会执行这两个模块中的所有测试集。\n一般_tests模块只包含ModuleName模块中的公共接口测试用例。\n{application,AppName:atom(),Info:list()} 这是一个普通的Erlang/OTP应用描述，可能在.app文件中找到。由此产生的测试集 包含Info:list()列出的所有模块中的测试集。\n{application,AppName:atom()} 创建AppName中所有模块的测试集。通过查阅应用程序的.app文件，如果不存在，在应用程序的ebin目录下（参考{dir,Path}）测试所有对象文件，如果还不存在则使用code:lib_dir(AppName)。\nPath:: string() 一个字符串代表文件或目录路径，相当于{file,Path}或者{dir,Path},分别依赖于引用的系统文件路径。\n{file,FileName:: string()} 如果文件FileName是.beam文件，EUnit会从该文件加载模块并测试。否则文件会被认为是一个包含测试规范的文本文件，将使用标准库函数file:path_consult/2读取该文件。\n如果文件名是绝对路径，与当前目录相比，该路径首先被查找，然后是正常搜索路径(code:get_path)。这意味着app的文件可以直接使用，不需要路径。如:mnesia.app。\n{dir, Path:: string()} 测试当前目录下所有文件，如果它们已经使用{file,FileName}指定。\n{generator, GenFun:: (() -\u0026gt;Tests)} 调用测试生成器GenFun生成测试集。\n{generator, ModuleName::atom(), FunctionName::atom()} 调用ModuelName:FunctionName生成测试集。\n{with,X::any(),[AbstractTestFun:: ((any())-\u0026gt;any()))]} 通过列表中的一元函数分配X，将它们转换成无参测试函数。AbstractTestFun是一个普通测试函数，只是它有一个参数，而不是无参。在它成为合格的测试函数前，需要去掉一些信息。{with,X, [F_1, \u0026hellip;, F_N]}相当于[fun() -\u0026gt; F_1(X) end, \u0026hellip;, fun() -\u0026gt;F_N(X) end].\n这将特别有用当抽象测试函数已经正确实现：{with, FD, [fun filetest_a/1,\u0026hellip;,fun filetest_x/1] 相当于[fun() -\u0026gt;filetest_a(FD) end,\u0026hellip;,fun() -\u0026gt; filetest_x(FD) end]。\n控制 下面陈述控制测试怎样和在哪里执行。\n{spawn,Tests} 在子进程中执行指定测试，当前测试进程等待子进程结束。对需要全新，单独进程状态的测试有用。\nEUnit会自动开启至少一个这样的进程。从来不会在调用者的进程里面进程测试。\n{spawn, Node::atom(), Tests} 在指定的节点进程中执行测试。\n{timeout,Time::number(),Tests} 在指定时间内执行测试。60 表示一分钟。如果超时，测试被强制终止。注：超时被设置在包含安装和清理的活动上，如果超时被触发，整个活动状态被终止。\n{inorder,Tests} 严格按照顺序执行指定测试。默认的测试的执行顺序根据测试框架选择。\n{inparallel,Tests} 并行执行测试。\n{inparallel, N::integer(), Tests} 并行执行的测试不超过N个。\n固定活动（状态） \u0026ldquo;fixtrue\u0026quot;是执行特定测试集所必须的状态。EUnit支持fixtures，使测试集setup 本地fixture简单化，当测试集结束，不管结果自动关闭。\nSetup\t() -\u0026gt; (R::any())\rSetupX\t(X::any()) -\u0026gt; (R::any())\rCleanup\t(R::any()) -\u0026gt; any()\rCleanupX\t(X::any(), R::any()) -\u0026gt; any()\rInstantiator\t((R::any()) -\u0026gt; Tests) | {with, [AbstractTestFun::((any()) -\u0026gt; any())]}\rWhere\tlocal | spawn | {spawn, Node::atom()}\r{setup, Setup, Tests | Instantiator}\r{setup, Setup, Cleanup, Tests | Instantiator}\r{setup, Where, Setup, Tests | Instantiator}\r{setup, Where, Setup, Cleanup, Tests | Instantiator}\rsetup: 给所有指定的测试指定单个fixture，可拆卸。具体参数描述如下：\n{node, Node::atom(), Tests | Instantiator}\r{node, Node::atom(), Args::string(), Tests | Instantiator}\rnode和setup类似，但是有内置行为：在测试中会启动一个分节点。Node格式为NodeName@full.machine.name。Args 是可选的。参考slave:start_link/3.\n{foreach, Where, Setup, Cleanup, [Tests | Instantiator]}\r{foreach, Setup, Cleanup, [Tests | Instantiator]}\r{foreach, Where, Setup, [Tests | Instantiator]}\r{foreach, Setup, [Tests | Instantiator]}\rforeach 用来建立一个fixture，后续随意拆卸，对每一个指定的测试集反复执行。\n{foreachx, Where, SetupX, CleanupX, Pairs::[{X::any(), ((X::any(), R::any()) -\u0026gt; Tests)}]}\r{foreachx, SetupX, CleanupX, Pairs}\r{foreachx, Where, SetupX, Pairs}\r{foreachx, SetupX, Pairs}\rforeachx和foreach类似，但是使用 Pairs列表，每个Pairs包含额外的参数X和扩展的实例化函数。\nSetup函数在指定测试开始前执行，Cleanup函数在没有测试要执行后执行。Setup函数没有参数，它的返回值将会被传递给Cleanup函数。Cleanup函数有必要执行并返回任意值。当没有Cleanup函数时，一个没有任何作用的虚函数被执行。\nInstaniator函数接受像Cleanup函数一样的值，如：这个值是Setup函数的返回值。应该表现的想一个生成器，返回已经使用给定值实例化的测试集。\nWhere 控制怎样执行测试。默认是spawn，这意味着当在子进程中执行测试时，当前进程控制建立和拆卸。\n执行测试的进程需要进行建立和拆卸操作。\n如果进程被杀死，则不需要执行拆卸操作。\n懒惰生成器 有时在测试开始前不需要生成完整的测试集描述信息。如：如果一次生成大量的测试会占用太多内存。\n可以写一个生成器，每次调用的时候都会生成一个空列表。或者生成一个包含单个测试用例和一个新的可以生成额外测试的生成器。\n lazy_test_() -\u0026gt;\rlazy_gen(10000).\rlazy_gen(N) -\u0026gt;\r{generator,\rfun () -\u0026gt;\rif N \u0026gt; 0 -\u0026gt;\r[?_test(...)\r| lazy_gen(N-1)];\rtrue -\u0026gt;\r[]\rend\rend}.\r当EUnit遍历执行测试时，新的生成器不会被调用知道上一个测试结束。\n",
    "ref": "/blog/erlang/%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95eunit/"
  },{
    "title": "Erlang文本编程",
    "date": "",
    "description": "",
    "body": "文本编程 操作文件的模块  file   包含打开、关闭、读写文件的方法。\n  filename   这个模块的方法能够跨平台的操作文件名，这样可以在不同的操作系统上运行相同的代码。\n  filelib   此模块是file的扩展。它包含的许多工具函数能够列出文件、检查文件类型。其中大多数是由file里的函数编写。\n  io   这个模块有一些操作已打开文件的方法。它可以解析文件数据，也可以将数据格式化写入文件。\n 读取文件的几种方法  file:consult(FileName)   读取erlang数据格式的文件数据。\n code:which(Module) 查看已载入模块源码文件地址\n格式命令  ~n 输出换行符 ~p 把参数打印为美观形式 ~s 参数是一个字符串、I/O列表或原子，打印时不带引号 ~w 输出各种Erlang数据类型  ",
    "ref": "/blog/erlang/%E6%96%87%E6%9C%AC%E7%BC%96%E7%A8%8B/"
  },{
    "title": "Erlang顺序编程补遗",
    "date": "",
    "description": "",
    "body": "apply  内置函数apply(mod,func,[arg1,arg2,arg3,\u0026hellip;,argn])。会将参数arg1,arg2,\u0026hellip;,argn应用到模块mod里的函数func上。它等价于：mod:func(arg1,arg2,\u0026hellip;,argn)。 与直接调用函数的区别在于模块名和函数名可以动态的计算得出。 应当尽量避免使用apply。如果使用apply对函数进行调用，许多分析工具就无法得知发生了什么，一些特定的编译器优化也不能进行。  算术表达式  操作符\t描述\t参数类型\t优先级\r+X\t正数\t整数\t1\r-X\t负数\t整数\t1\rX*Y\tX乘以Y\t整数\t2\rX/Y\tX除以Y，浮点数除法\t整数\t2\rbnot X\t对X执行按位取反\t整数\t2\rX div Y\tX除以Y的商，整数\t整数\t2\rX rem Y\tX除以Y的余数\t整数\t2\rX band Y\tX和Y位与\t整数\t2\rX bor Y\tX和Y位或\t整数\t3\rX bxor Y\tX与Y按位异或\t整数\t3\rX bsl N\tX向左位移N个算术位\t整数\t3\rX bsr N\tX向右位移N个算术位\t整数\t3\rX + Y\tX 加 Y\t整数\t3\rX - Y\tX 减 Y\t整数\t3\r 元数  一个函数的元数(arity)是该函数所拥有的参数数量。在Erlang里，同一个模块里的两个名称相同，元数不同的函数是完全不同的函数。 根据惯例Erlang程序员经常将名称相同、元数不同的函数作为辅助函数使用。我们通常通过不导出辅助函数，来隐藏他们。  模块属性  模块属性的语法是 -AtomTag(\u0026hellip;),它们被用来定义文件的某些属性。 模块属性包括预定义型和用户定义型。 预定义型：   模块属性有着预先定义的含义，必须放置在任何函数定义之前。\n  -module(modname).：模块生命。modname必须是一个原子。此属性必须是文件的第一个属性。如果不这么做，自动代码加载就会失效。 -import(Mod,[Name1/Arity1,Name2/Arity2],\u0026hellip;).：导入模块属性。import声明导入Mod模块参数为Arity1的函数Name1和参数为Arity2的函数Name2。一旦导入其它模块的函数，则在本模块中调用的时候就无需指定模块名了。 -export([Name1/Arity1,Name2/Arity2,\u0026hellip;]).：导出当前模块里的Name1/Arity1和Name2/Arity2等函数。函数只有被导出后才能在其它模块被调用。 -compile(Options).：添加Options到编译器选项列表中。Options可以是单个编译选项，也可以是一个编译器选项列表。 -vsn(Version).：指定模块的版本号。Version可以是任何字面数据类型。Version值没有特定语法和标识，但可以用于分析程序或者作为说明文档。 用户定义的模块属性： －SomeTag(Value).：SomeTag必须是一个原子，而Value必须是字面数据类型。模块属性的值会被编译进模块，可以在运行时提取。 提取模块属性信息命令Mod:module_info(X). ：X可以是exports、imports、attributes和compile中的一个，可以返回模块相关的单个属性。   注：调用Mod:module_info(X).方法必须将Mod编译加载到Erlang虚拟机中。也可以使用beam_lib:chunks(Mod.beam,X).可以在不载入代码模块的情况下提取模块里的属性数据。\n 块表达式  块表达式用于一下情景：代码某处的Erlang语法要求单个表达式，但我们想使用一个表达式序列。例如在列表推导中[X || \u0026hellip;]，语法要求E是单个表达式，但也许我们想在E里面做不止一件事情。  begin\rExpr1,\r...,\rExprN\rend\r我们可以用块表达式归组表达式序列。begin ... end的值就是最后一个表达式的值。\r布尔值 Erlang没有单独的布尔值类型。不过原子true和false具有特殊含义，可以用来表示布尔值。与此同时，让你的函数名称能反映出它们会返回布尔值会是个好主意。\r 布尔表达式 not B. 逻辑非\rA and B. 逻辑与\rA or B. 逻辑或\rA xor B. 逻辑异或\r 字符集  从Erlang的R16B版本开始，Erlang的源码文件都采用UTF-8字符集编码，这之前是ISO-8859-1(Latin-1)字符集。这意味着所有UTF-8打印字符都能在源码文件里面使用，无需任何转义。 Erlang内部没有字符串数据类型。Erlang使用整数列表表示字符串。用整数列表来表示Unicode字符串是毫无问题的。  注释  Erlang的注释从一个%号开始，一直延伸到行尾。Erlang里面没有块注释。   注：代码中出现双百分号（%%），能够被Erlang模式的Emacs编辑器识别，并启动注释行自动缩进。\n 动态代码载入  动态代码载入是内建于Erlang核心的最惊人特性之一。 思路：每当调用SomeMod:SomeFunc(\u0026hellip;)时，调用的总是最新版模块里的函数。哪怕代码在模块里运行时，重新编译该模块也是如此。 例如modA:loop()里面调用了modB:hook(),如果modB重新编译，则modA:loop()则调用最新编译的模块modB。 在任一时刻，Erlang允许一个模块的两个版本同时运行：当前版和旧版。重新编译某个模块时，任何运行旧版代码的进程都会被终止。当前版本成为旧版，新编译的版本成为当前版。  预处理器  Erlang模块在编译前会自动由Erlang的预处理器进行处理。预处理器会展开源文件里所有的宏，并插入必要的文件。\\ 要查看SomeMod.erl模块的预处理结果，直接在shell中执行以下命令：$ erlc -P SomeMod.erl  转义序列 在字符串和带引号的原子里使用转义序列来输入任何不可被打印的字符。\n表达式和表达式序列  在Erlang里，任何可以执行并生成一个值的事物都被称为表达式。这意味着catch、if和try\u0026hellip;catch这些是表达式。而记录声明和模块属性这些不能求值，所以他们不是表达式。 表达式序列：是一系列由逗号分割的表达式。表达式序列的值被定义为序列最后那个表达式的值。  函数引用　 fun LocalFunc/Arity\r引用当前模块里参数为Arity的本地函数LocalFunc。\rfun Mod:RemoteFunc/Arity\r引用Mod模块里参数为Arity的外部函数RemoteFunc。\r注：包含模块名的函数引用提供了动态代码升级的切换点。\r 包含文件  下面的语法用来包含文件： -include(Filename). 按照erlang惯例，包含文件的扩展名为.hrl。   FileName应当包含一个绝对或相对路径，使预处理器能找到正确文件。\n  -include_lib(Name). 包含库的头文件。   包含文件经常有记录的定义，如果许多模块需要共享通用的记录定义，就会把它们放到包含文件里，在由所有需要这些定义的模块包含此文件。\n 列表操作  ++ 和 \u0026ndash;是用于列表添加和移除的中缀操作符。 A ++ B使A和B相加。 A \u0026ndash; B从列表A中移除列表B。移除的意思是B中所有元素都会从A里面移除。如果符号X 在B里面出现了K次，那么A只会移除前K个X。  举个例子：\r1\u0026gt;[a,b,c,a,b,a] -- [a,a] .\r[b,c,b,a]\r++也可以用在模式匹配中：\rf(\u0026quot;begin\u0026quot; ++ T) -\u0026gt; ....\rf(\u0026quot;end\u0026quot; ++ T) -\u0026gt; ....\r子句可以扩展成[$b,$e,$g,$i,$n | T]。\r宏  Erlang的宏以如下方式添加。  -define(Constant,Replacement).\r-define(Func(Var1,Var2,...,Var), Replacement).\r 当Erlang的预处理器epp碰到一个?MacroName形式的表达式时，就会展开这个宏。 另外一些宏提供了当前模块的一些信息：  ?FILE展开成当前文件名\r?MODULE展开成当前模块名\r?LINE展开成当前行号\r 宏控制：  -undef(Macro). 取消Macro的宏定义，此后无法调用该宏。\r-ifdef(Macro). 仅当Macro宏定义过，才会执行后面的代码。\r-else.　可用于ifdef或ifndef语句后面。如果条件为否则执行else后面代码。\r-endif.　标记ifdef或ifndef语句的结尾。\r注：erl命令行　1\u0026gt;c(mod.erl,{d,debug_flag}). 可以添加编译标志元组。\n模式的匹配操作符  模式匹配操作符可以用在模式的任何位置。  func([{tag1,A,B} | T) -\u0026gt;\r...,\rf(...,{tag1,A,B},...),\r....\r 我们在第一行模式匹配了数据类型{tag1,A,B}，在第三行用参数{tag1,A,B}调用了函数f。这么做时，系统会重建数据类型{tag1,A,B}。一种更高效的且不易出错的方法是将参数指派给一个变量Z，然后将它传递给函数f。如下：  func([{tag1,A,B} = Z | T) -\u0026gt;\r...,\rf(...,Z,...),\r....\r整数  整数的位数只受限于可用内存。 传统写法：　１、23423。 K 进制写法： 2#1011、8#76234、16#abcf23。 $写法：$C这种写法代表了ASCII字符C的整数代码。  浮点数 一个浮点数由五步分组成：一个可选的正负号，一个整数部分，一个小数点，一个分数部分，一个可选的指数部分。\n eg: 1.0 3.1415926 -2.3e+6 23.56E-27\n  解析后的浮点数在系统内部使用IEEE754的64位格式标示。绝对值在10^-323 到10^308范围内的实数可以用Erlang的浮点数表示。  操作符优先级 操作符\t结合形\r：\t＃\t(一元)＋、(一元)-、bnot、not\t/、*、div、rem、band、and\t左结合\r+、-、bor、bxor、bsl、bsr、or、xor\t左结合\r++、--\t右结合\r==、/=、=\u0026lt;、\u0026lt;、\u0026gt;=、\u0026gt;、=:=、=/=\tandalso\torelse\t=!\t右结合\rcatch\r进程字典  每个Erlang进程都有一个被称为进程字典（process directory）的私有数据存储区。进程字典是一个关联数组，由若干键和值组成。每个键只有一个值。 -这个字典可以用下列内置函数进行操作。   put(Key,Value) -\u0026gt;OldValue，给字典添加一个Key,Value组合。put的值是OldValue，也就是Key之前关联的值，如果之前没有则返回undefined。 get(Key) -\u0026gt;Value，查找Key的值。如果字典里存在Key，则返回Key对应的Value，不存在则返回undefined。 get() 返回整个字典 get_keys(Value) 获取所有值为Value的Key列表。 erase(Key)，删除Key对应的关联值。 erase()，删除整个字典。   进程字典里的变量和命令式编程语言里传统可变变量的行为类似。如果使用进程字典，你的代码就不再是无副作用的了。使用非破坏性变量的好处不复存在，因此少用进程字典。 如果用进程字典来保存“一次性写入”的变量，不会去改变，　那么将变量写入到进程字典中是可以接受的。  引用 引用是一种全局唯一的Erlang数据类型。由内置函数erlang:make_ref().引用的用途是创建独一无二的标签，把它存放在数据里，并在后面用于比较是否相等。\n短路布尔表达式  短路布尔表达式是一种只在必要时才对参数求值的表达式。短路布尔表达式有两种： Expr1 orelse Expr2:   它会首先执行Expr1，如果Expr1的执行结果是true，Expr2就不用执行。如果Expr1的结果是false，则会执行Expr2。\n  Expr1 andelse Expr2:   它会首先执行Expr1,如果Expr1的执行结果是false，Expr2就不用执行。如果Exp1的结果是true，则会执行Expr2。\n  注：对应的布尔表达式（A or B, A and B）,两边的参数都会被执行，即使表达式的真值只需要第一个表达式的值就能确定，也是如此。  比较数据类型 -所有数据类型的全排序：\n number \u0026lt; atom \u0026lt; reference \u0026lt; fun \u0026lt; port \u0026lt; pid \u0026lt; tuple(and record) \u0026lt; map \u0026lt; list \u0026lt; binary\n  有了所有数据类型的全排序，意味着可以对任何类型的数据列表进行排序，以及根据键的排序顺序构建高效的数据访问方式。 所有类型比较操作符(除了=:=和=/=)在参数权威数字时具有以下行为： 如果一个参数是整数而另一个是浮点数，那么整数会先转换成浮点数，然后再进行比较； 如果两个参数都是整数或浮点数，则按原样使用，不进行转换。 注：函数的子句匹配总是意味着精确的模式匹配，所以如果定义了一个fun F=fun(12) -\u0026gt; \u0026hellip; end　，那么试图执行F(12.0)就会出错。  下划线变量  _VarName这种特殊的语法代表一个常规变量，而不是匿名变量。当某个变量在子句里只使用一次时，编译器会生成一个警告，但如果这个变量使用下划线命名，就不会有错误信息。 下划线变量的两种主要用途： 命名一个我们不打算使用的变量。例如：相比较open(File,_), open(File,_Mode)的可读性更高。 用于调试。定义调试用变量，在实际发布代码中注释调试信息后，该变量不在其它地方使用也不会报警高。  ",
    "ref": "/blog/erlang/erlang%E9%A1%BA%E5%BA%8F%E7%BC%96%E7%A8%8B%E8%A1%A5%E9%81%97/"
  },{
    "title": "Erlang顺序编程错误处理",
    "date": "",
    "description": "",
    "body": "概括  Erlang中当错误出现时，需要发现并纠正，然后继续。 构建真正容错的系统，需要不止一台计算机，毕竟可能整台机器崩溃。因此故障检测和别处重启计算的概念需要扩展到联网的计算机上。  顺序代码里面的错误处理  异常错误发生时，可以显示调用throw(Exception),exit(Exception),error(Exception) 触发。 永远不能让函数对非法的参数返回值，而是抛出一个异常错误。 exit(Why):当你确实想要终止当前进程时就用它。如果此异常没有被捕获，信号{\u0026lsquo;Exit\u0026rsquo;,Pid,Why}就会被广播给当前进程链接的所有进程。 throw(Why):这个函数的作用是抛出一个调用者想要捕获的异常错误。因此我们可以将调用封装到try\u0026hellip;catch表达式里面，然后对错误进行处理。 error(Why):这个函数的作用是指示“崩溃性错误”，调用者没有准备好处理非常严重的问题。  捕获异常错误 两种方法：\n 把抛出异常错误的调用函数封装在try\u0026hellip;catch中 把调用封装在一个catch表达式中？？？  try ... catch 结构\r%执行函数或表达式\rtry FuncOrExpressionSeq of\r%执行过程无异常则匹配以下模式\rPattern1 [when Guard1] -\u0026gt; Expressions1;\rPattern2 [when Guard2] -\u0026gt; Expressions2;\rcatch\r%执行过程出现异常则匹配以下异常模式，ExceptionType：error throw exit其中之一\rExceptionType1: ExPattern1 [when ExGuard1] -\u0026gt; ExExpressions1;\rExceptionType2: ExPattern2 [when ExGuard2] -\u0026gt; ExExpressions2\rafter\r%after区域的代码实在FuncorExpressSeq结束后执行清理工作的。这段代码无论是否抛出异常都会在函数调用执行完立刻执行。AfterExpressions返回值会被丢弃。\rAfterExpressions\rend\rtry ... catch 表达式也有值。注：Erlang里的一切都是表达式，表达式都有值。\r针对异常处理的编程方式  改进错误消息：内置函数error/1。 经常返回错误时代码：{ok,Value}, {error,Reason} 捕捉一切可能的错误：try Expr of catch : -\u0026gt; \u0026hellip; end %这里处理所有的异常错误。 如果代码漏写标签：try Expr of catch _ -\u0026gt; \u0026hellip; end %这里只处理throw 异常。  栈跟踪 捕获到一个异常错误后，可以调用erlang:get_stacktrace() 来找到最近栈跟踪信息。\neg:\rtry Expres of catch _:_ -\u0026gt; erlang:get_stacktrace()\rend\r erlang:getstacktrace()返回的信息，每个元组里面都是 {Module,Func,Arity,Info}. Module: 模块名， Func函数名，Arity参数个数，Info包含文件名和函数所在行数。 栈跟踪信息不会记录函数被调用的位置，只会记录函数返回的位置。 如果被调用的函数是表达式序列的最后一个函数，那么此函数的调用位置不会保存到栈中，因为Erlang会对这一类代码做尾调用优化（last-call-optimization)。  抛错要快而明显，也要文明  在Erlang中，当系统内部或程序检测出错时，正确的做法是立刻崩溃，并生成一段有意义的错误信息。 文明抛错，只有程序员才能看到程序崩溃时产生的详细错误，用户绝对看不到。另一方面用户应该得到警告，知晓有错误发生，以及可以采取什么措施来弥补。 错误信息应当保存到永久的日志文件中。  ",
    "ref": "/blog/erlang/erlang%E9%A1%BA%E5%BA%8F%E7%BC%96%E7%A8%8B%E9%94%99%E8%AF%AF%E5%A4%84%E7%90%86/"
  },{
    "title": "编程范式-函数式编程",
    "date": "",
    "description": "",
    "body": "函数式编程（Function Programming）  函数式编程将电脑运算看作是函数运算。 函数式编程的基础是λ 演算（ lambda caculus）。函数可以作为输入（参数）输出（返回值）。 函数式编程最古老的例子： 1958年创造出来的LISP。 #特性  函数是\u0026quot;第一公民\u0026quot;（first class） 函数可以作为变量\n”表达式“ not ”语句“  ”表达式“（expression）是运算过程，总有返回值 ”语句“（statement）是操作，无返回值。 函数式编程要求只使用表达式，不使用语句， 每一步运算都有返回值。  无”副作用“（side effect）  ”副作用“：函数内部与外部互动（eg:函数内部修改全局变量），操作外部。 函数式编程强调没有”副作用“，保持独立，所有功能只是返回新值，不做其他行为尤其是不修改外部变量。  不修改\u0026quot;状态\u0026quot;（state)  函数式编程要求使用参数保存状态,状态不能保存在变量中。  引用透明（Referential transparency）  函数运行不依赖外部变量或”状态“，只根据输入参数，任何时候只要参数相同，引用函数所得到的结果总是相同。  闭包（closure capture）  闭包函数： 声明在一个函数中的函数，叫闭包函数 闭包： 闭包函数总是可以访问其所在的外部函数中声明的参数和变量，即使在其外部函数被返回（寿命终结）了之后   问题： 局部变量常驻内存，不被释放造成内存泄漏\n 高阶函数 接受一个或多个函数作为输入，输出一个函数。\n意义 代码简洁，开发迅速 编码中大量使用函数，减少代码重复。\n更方便的代码管理 每一个函数都是独立单元，有利与单元测试（unit test）和除错（debugging），以及模块化组合。\n易于并发编程 函数不用考虑”死锁“（deadlock），因为修改变量，不用担心被其他线程修改，可以将工作分摊到多个线程，部署”并发编程“（concurrency）。\n代码热升级 因为函数式编程无副作用，只要保证接口不变，内部实现是外部无关的。所以可以在运行状态下直接升级代码，不需要重启。\n",
    "ref": "/blog/software-programming/%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B/"
  },{
    "title": "Erlang模块和函数",
    "date": "",
    "description": "",
    "body": "模块  模块是Erlang中代码的基本单元，我们编写的所有函数都存放在模块中，模块文件的扩展名通常为.erl。 编译后的文件扩展名为.beam,   注： beam 是 Erlang虚拟机（Bogdan‘s Erlang Abstract Machine）的所写。Erlang虚拟机最早的版本是 Joe Armstrong编写的基于栈的虚拟机JAM（Joe\u0026rsquo;s Abstract Machine）。后来，Bogumil(Bogdan) Hausman在1993年编写了基于寄存器的虚拟机BEAM（Bogdan\u0026rsquo;t Abstract Machine), 执行效率有了 大幅度提高。\n  erlang虚拟机执行代码的原理：http://www.mamicode.com/info-detail-671999.html  函数  函数由子句构成，子句以分号分隔，最后一条子语句以句号结束。每一个函数由函数头和函数体组成，函数头由函数名和随后以括号括起来的模式组成，函数体由一系列表达式组成。 shell中编译模块文件： c(文件名） 引用模块中函数： moduleName:funcName(模式）。 模块中函数调用是顺序的从第一个子句开始进行模式匹配。 在erlang中做相同的事情，只需要编写模式及表达式，erlang编译器会自动生成优化的模式匹配代码。  同名不同目的函数  在Erlang中，同一个模块的两个函数，如果同名但是参数不同，则这两个函数被认为完全不同。 为了方便同名不同目的函数经常被用来作为辅助函数使用。  fun fun就是匿名函数,fun可以有任意参数（目：arity）。\n高阶函数（high-order function） 这些能返回fun或接受fun作为参数的函数，被称作高阶函数。\n什么时候使用高阶函数  编写返回fun的高阶函数不容易调试 高阶函数可以用来解决延迟求值、可重入的解析器、解析组合子等问题。  -import 和 -export 声明  声明 -import(lists,[map/2,sum/1]) 意味着函数 map/2,sum/1是从lists模块中导入。 声明 -export([total/1]) 意味着total/1能够在模块之外被调用。只有从一个模块中导出的函数才能在模块外调用。  简单的列表处理  lists:map(Fun,List): 将方法Fun应用到列表List的每一个元素中，输出操作后的元素列表。 lists:member(Ele,List): 判断元素Ele是否是列表List中的元素，输出true/false。 lists:filter(Fun,List): 用方法Fun过滤列表List中的每一个元素，输出符合要求的元素列表。 lists: sum(List):计算列表中所有元素的和。 lists: seq(1,N): 返回一个包含1到N的整数列表。 lists:reverse(L) : 将列表中元素顺序反转。  列表推导  列表推导无需使用fun、map或filter等表达式来创建列表。  1\u0026gt;L= [1,2,3,4].\r2\u0026gt;lists:map(fun(X)-\u0026gt;X*2 end,L).\r[2,4,6,8]\r与之相比，使用列表推导方式：\r3\u0026gt;[X*2 || X\u0026lt;-L].\r[2,4,6,8]\r列表推导形如：[F(X) || X\u0026lt;-L]\r将列表中每一个元素赋值到X，使用方法F\r 对每一个元素进行操作，从而返回操作后元素列表。  [X | Qualifier1, Qualifier2,...]:\r X是任意一条表达式，后面的限定符（Qualifier）可以是生成器、位串生成器、过滤器。\n  生成器（generator）写法是：Pattern\u0026lt;-ListExpr,其中ListExpr必须是能够得出列表的表达式。 位串生成器（bitstring）写法是：BitStringPattern \u0026lt;= BitStringExpr,其中BitStringExpr必须是一个能得出位串的表达式。 过滤器（filter）：可以是判断函数，也可以时bool表达式。生成器部分起着过滤器的作用 列表推导优点： 明显缩短代码  内置函数BIF(built-in function）  作为erlang语言定义一部分的函数。 有些内置函数是用Erlang实现的，但大多数是用Erlang虚拟机里面的底层操作实现的。 内置函数能提供操作系统的接口并提供那些无法用Erlang编写或者编写后非常低效的操作。  list_to_tuple(List,Tuple):列表转换成元组。\rtime():获取系统时间。\r关卡（guard） 关卡是一种结构，形如： max(X, Y) when X \u0026gt; Y -\u0026gt; X;\rmax(X, Y) -\u0026gt; Y.\r关卡增加模式匹配的威力  关卡序列（guard sequence）  关卡序列指： 单一或一系列的关卡，用分号（；）隔开。对于关卡序列G1,G2,G3,\u0026hellip;只要有一个关卡的值为true，它的值就是true。 关卡由一系列的关卡表达式组成，用逗号（，）隔开。关卡GuardExpr1,GuardExpr2,\u0026hellip;只有在所有关卡表达式的值都为true时才为true。 限制关卡表达式只能是Erlang表达式的子集，确保关卡表达式无副作用。 关卡是模式匹配的一种扩展。  case case Expression of\rPattern1 -\u0026gt; Expr_seq1;\rPattern2 -\u0026gt; Expr_seq2;\r...\rend\r执行表达式的值就是case的值\nif if Guard1 -\u0026gt;\rExpr_seq1;\rGuard2 -\u0026gt;\rExpr_seq2;\r...\rtrue -\u0026gt; Expr_seqN\rend\r执行表达式的值就是 if表达式的值。通常if表达式的最后一个关卡是原子true ， 确保其它关卡都失败时，if表达式的最后会被执行。\n构建列表的效率 构建列表最有效率的方式是向现成列表的头部添加元素。\n向L中添加元素H:\r[H | L] 此方法效率高；\rL ++ [H] 此方法易读，效率低。\r归集器 将数据结果分别添加到合适的列表里面，这些列表叫做归集器（accumulator）。  ",
    "ref": "/blog/erlang/erlang%E6%A8%A1%E5%9D%97%E5%92%8C%E5%87%BD%E6%95%B0/"
  },{
    "title": "Erlang记录和映射组",
    "date": "",
    "description": "",
    "body": "数据容器 元组（tuple）：保存固定数量的元素\r列表（list）：保存可变数量的元素\r记录（record）：是元组的另一种形式，通过记录给元组里面的各个元素关联一个名字，\r映射组（map）：是键-值对关联性的集合。键可以是任意类型的Erlang数据类型。\r 使用记录和映射组 记录使用一组固定且预定义的关联名称\r映射组可以动态添加新的关联名称；\r映射组比元组占用更多存储空间，查找慢。但是映射组比元祖灵活。\r 何时使用映射组或记录 记录 -record（Name,{\r%% 以下两个键带默认值\rkey1 = Default，\rkey2 = Default，\r...\r%%下一行Key3 = undefined\rkey3,\r...\r}).\r记录既可以保存在源代码的文件里，也可以保存在扩展名为.hrl的文件中，然后包含到源文件中。\r注意：文件包含是唯一确保多个Erlang模块共享相同记录的方式。\r命令行中读取记录文件 ：rr(\u0026quot;myrecord.hrl\u0026quot;).\r命令行中删除记录定义：rf(\u0026quot;myrecord.hrl\u0026quot;).\r 映射组(R17版本及以上引入) #{Key1 op Val1, Key2 op Val2, Key3 op Val3,...}\r语法与记录相似，只是散列符号（#）后面少了记录名，而op是符号 =\u0026gt;或者:=中的其中之一。\r键和值是任何有效的Erlang数据类型。\r表达式 Key =\u0026gt;Val有两种用途，一种是给映射组添加一个全新的 Key=\u0026gt;Val，另一种是更新 映射组里面Key对应的值。\r表达式 Key := Val ，作用是将现有键Key的值更新为新值Val。如果被更新的映射组中不包含键Key，则提示更新失败。\r注： 由于本地Erlang版本为R16B, 映射组（map）数据类型在 Erlang R17版本中才引入，因此此处不予学习，练习，待后续跟进。\r ",
    "ref": "/blog/erlang/%E8%AE%B0%E5%BD%95%E5%92%8C%E6%98%A0%E5%B0%84%E7%BB%84/"
  },{
    "title": "Erlang基本数据结构",
    "date": "",
    "description": "",
    "body": "Erlang Erlang 创始人Joe Armstrong，基于Prolog开发。\rErlang 是通用的面向并发的编程语言，由瑞典电信设备制造商爱立信所辖CS-Lab开发。于1987年开发，1988年开源。\rErlang是运行于虚拟机上的解释型语言。 Erlang 编写的程序运行时通常由大量的轻量级进程组成，并通过消息传递进行通讯。\rErlang 目前包含 乌普萨拉大学的高性能计划（Hipe）开发的本地代码编译器，自R11B04版本开始erlang 支持脚本式解释器。\r 注： erlang 的hipe 相当于jit（Just-in-time compilation），根据语言评测有hipe支持的erlang运算上快2-3倍。\nShell 启动：$\u0026gt; erl\r停止(受控方式)：1\u0026gt;q().\rinit:stop().\r立即停止： erlang:halt().\r切换erl 中shell命令： CTRL + P ， CTRL + N。\rshell 只能对erlang 的表达式求值，不能在shell中输入Erlang文件中代码（.erl文件中的句法形式不是表达式），不能输入模块注释（如：-module，-export）。\r编写分布式程序时，集群中会有许多正运行的erlang系统节点，可以将shell随意附着在他们中的任何一个上， 甚至可以用ssh向一个运行着erlang系统的计算机上发起一个直连接，通过这个方法，在erlang 的节点集群中你能与其中的任何节点上的任意一个程序打交道\r 注释 % ： 代表一行注释的开始，被erlang 和 shell 忽略。\r 整数运算： 采用不定长整数进行运算，整数运算没有误差不会溢出。\r 进制表达： 进制#值： 16#1(16进制1)， 2#111(2进制111)。\r 变量 变量首字母大写\r变量是单一赋值，只能一次性给定，重复赋值是错误的。\r一个变量如果被赋值，则被称为绑定变量，否则为自由变量。一开始所有的变量都是自由变量。\r下划线（_） 是匿名变量，与常规变量不同，在同一模式下_可以绑定不同的值。\rf() 会释放shell之前进行过绑定的变量。\r 等号（=） =是一个模式匹配运算符，当变量是自由变量时，其行为相当于赋值运算。\r 变量绑定表： 变量经过赋值，shell就会形成一个变量绑定表。\r形如： {X |-\u0026gt; 111, Y |-\u0026gt; 222}\r 原子 原子是全局有效的，无需使用宏定义或者包含文件。 原子是以小写字母开头，后面跟数字、字母、下划线、邮件符号（@）的字符。\r使用单引号的字符也是原子。这种形式使得我们可以用大些字母开头或者包含特殊字符。\r原子的值是原子本身。\r 元组（tuple） 将若干个以逗号分割的值用一对花括号括起来就形成一个元组。\r元组是匿名的，元组中的字段没有名字，因此推荐元组的第一个元素用原子来表明这个元组所代表的含义。\reg:  Person={person, {name,zyl}, {age,27}, {height,1.80} }\n怎样获取元组的值： 使用模式匹配将元组匹配到具有相同数量元素及结构的未绑定变量的元组中。\r 列表 将若干个以逗号分割的值用一对对号括起来就形成了一个列表。\r列表头（head)：列表的第一个元素，所有的列表函数处理都是从提取头开始的。\r列表尾（tail)：剩下的就是列表尾，列表尾必须也是个列表。\r 列表运算  如果T是一个列表，那么[H|T]也是一个列表，这个列表以H为头，以T结尾。| 可以将列表的头和尾分开。 当我们用[...|T]构造列表时，都应该保证T是个列表，那么新列表是正规列表，否者为不正规列表。\r 提取列表元素 用模式匹配操作从列表中提取元素。\r[X|Y] = L : 将列表L 的头提取到X ， 将列表的尾提取到Y。\r 字符串 严格讲Erlang没有字符串， 字符串实际上是一个整数列表，用双引号将一串字符括起来就是一个字符串，eg: Name=\u0026quot;zhangyongliang\u0026quot;。\r当列表中所有数字都是可打印字符时，才会将列表打印成字符串形式。\r无需死记硬背哪个整数表示特定的字符（ASCII码表），可以使用$符号表示字符的整数值。eg: $a 实际表示a的ascii 数字 97. $A表示65.\rerlang所关心的只是 以某种编码方式编码的一串整数值列表。\r ",
    "ref": "/blog/erlang/erlang%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"
  },{
    "title": "Erlang编译和运行",
    "date": "",
    "description": "",
    "body": "代码搜索路径  Erlang运行时系统使用一种代码自动载入机制，要让它正确工作，必须设置一些搜索路径来找到正确版本代码。 代码的载入是按需进行的，当系统尝试调用的函数属于一个尚未加载的模块时，就会出现异常，系统尝试查找缺失模块代码文件。代码载入器会在代码载入路径所有目录里查找缺失模块代码文件。只要找到相符的文件，搜索停止，载入该文件的目标代码。 以下是两个最常用来操作载入路径的函数：   -spec code::add_patha(Dir) =\u0026gt; true | {error, bad_directory}. 向载入路径的开头添加一个新目录Dir。\n  -spec code::add_pathz(Dir) =\u0026gt; true | {error, bad_directory}. 向载入路径的末尾添加一个新目录Dir。\n  通常的惯例是将这些命令放到主目录下的一个.erlang文件中。 也可以在启动erl时添加代码搜索路径：  $ erl -pa Dir1 -pa Dir2 ... -pz Dirk1 -pz Dirk2\r-pa: 把Dir添加到搜索路径的开头\r-pz:把Dir添加到搜索路径的结尾\r在系统启动时执行.erlang里的命令  启动erlang时，它会首先读取并执行.erlang中的所有命令。当前目录下的.erlang优先级高于主目录下的.erlang Erlang认为的主目录的位置获取:init:get_argument(home). code:clash()会报告代码搜索路径里面所有重复的模块。  运行程序的不同方式 程序 hello.erl\r-module(hello).\r-export([start/0]).\rstart() -\u0026gt; io:format(\u0026quot;Hello World ~n\u0026quot;).\r在erlang shell里面编译运行： 1\u0026gt;c(hello).\r2\u0026gt;hello:start().\r快速脚本编程：  在命令行中执行任意的erlang函数：  erl -eval 'io:format(\u0026quot;Memory: ~p~n\u0026quot;, [erlang:memory(total)]).' \\\r-noshell -s init stop\r在shell中编译执行 $ erlc hello.erl\r$ erl -noshell -s hello start -s init stop\r-noshell： 指以不带交互式的shell运行Erlang(因此不会看到运行erl时，提示的信息)。\r-s：后面跟要执行的mod func\r作为Escript运行 可以使用escript让程序直接运行，无需编译。\n文件hello\r#!/usr/bin/env escript\rmain(Args) -\u0026gt;\rio:format(\u0026quot;Hello World~n\u0026quot;).\r带命令行参数的程序 文件fac.erl\r-module(fac).\r-export([fac/1]).\rfac(0) -\u0026gt; 1;\rfac(N) -\u0026gt; N * fac(N-1).\r如果希望在命令行里运行，则需要修改：\n-module(fac).\r-export([main/1]).\rmain([A]) -\u0026gt;\rI = list_to_integer(atom_to_list(A)),\rF = fac(I),\rio:format(\u0026quot;factorial: ~w = ~w~n\u0026quot;, [I, F]),\rinit:stop().\rfac(0) -\u0026gt; 1;\rfac(N) -\u0026gt; N*fac(N-1).\r注：这里的main没有特殊含义，可以取任意名称\r编译运行：　$ erlc fac.erl\r$ erl -noshell -s fac main 22\r最后还可以作为escript运行：\nfactorial文件： #!/usr/bin/env escript\rmain([A]) -\u0026gt; I = list_to_integer(atom_to_list(A)),\rF = fac(I),\rio:format(\u0026quot;factorial: ~w = ~w~n\u0026quot;, [I, F]),\rinit:stop().\rfac(0) -\u0026gt;1;\rfac(N) -\u0026gt; N*fac(N-1).\r$chmod u+x factorial\r$./factorial 3\r无需编译直接运行。\n使用makefile使编译自动化 一个makefile模板 ＃别碰这几行\r＃定义自己的后缀\r.SUFFIXES: .erl .beam .yrl\r.erl .beam:\rerlc -W $\u0026lt;\r.yrl .erl:\rerlc -W $\u0026lt;\rERL = erl -boot start_clean\r#这里是想要编译的模块列表\r#如果这些模块一行放不下，就在行尾添加\\,然后在下一行继续\r编辑下面这几行\rMODS = module1 module2 \\ module3 ... special1 ... \\\r...\rmoduleN\r#任何makefile里的第一目标就是默认目标\r#如果只输入\u0026quot;make\u0026quot;，系统会假定为\u0026quot;make all\u0026quot;\r#因为\u0026quot;all\u0026quot;是这个makefile的第一目标\rall:compile\rcompile: ${MODS :%=%.beam} subdirs\r## 此处添加特殊的编译要求\rspecial1.beam: special1.erl ${ERL} -Dflag1 -w0 special.erl\r## 从makefile中运行应用程序\rapplication: compile\r${ERL} -pa Dir1 -s application start Arg1 Arg2\r# subdir目标会编译子目录里面的代码\rsubdirs:\rcd dir1; $(MAKE)\rcd dir2; $(MAKE)\r....\r# 移除所有代码\rclean:\rrm -rf *.beam erl_crash.dump\rcd dir1; $(MAKE) clean\rcd dir2; $(MAKE) clean\r一个精简的makefile .SUFFIXES .erl .beam\r.erl .beam:\rerlc -W $\u0026lt; ERL = erl -boot start_clean\rMODS = module1 module2 module3\rall: compile\r${ERL} -pa dir1 -s module1 start\rcompile: ${MODS:%=%.beam}\rclean:\rrm -rf *.beam erl_crash.dump\rCtrl + G  我们可以让多个shell同时运行，通过按Ctrl+G并输入合适的命令来切换他们。我们甚至可以用命令r在远程节点上启动一个shell。  Erlang故障转储文件 如果Erlang崩溃，它会生成erl_crash.dump文件。我们可以使用一个基于Web的故障分析器来分析它。\n1\u0026gt; crashdump_viewer:start().\rWebTool is available at http://localhost:8888/\ror http://127.0.0.1:8888/\rok\r然后把浏览器指向 http://localhost:8888，这样就可以浏览错误日志了。\n访问Erlang的帮助文档 可以获取各个模块的帮助信息\n $ erl -man 模块\n 查看Erlang shell的内置命令  \u0026gt;help().\n ",
    "ref": "/blog/erlang/%E7%BC%96%E8%AF%91%E5%92%8C%E8%BF%90%E8%A1%8C%E7%A8%8B%E5%BA%8F/"
  },{
    "title": "详解hash",
    "date": "",
    "description": "",
    "body": "",
    "ref": "/blog/security/hash/"
  },{
    "title": "详解安全传输协议SSL TLS",
    "date": "",
    "description": "",
    "body": "tls 传输层安全协议 包含两部分：\n 握手协议（handshake protocol）： 客户端和服务端进行协商，确定一组用于数据传输加密的密钥串 记录协议（record protocol）： 通过握手协议确定的密钥串进行数据加密传输  握手和密钥协商过程FullHandshake 客户端ClientHello 客户端发起请求，以明文传输请求信息包含：\n version： 支持最高TLS协议版本, 从低到高：SSLV1、SSLV3、TLSV1、TLSV1.1、TLSV1.2 cipher suites： 客户端支持的加密套件列表： Kx = Key Exchange 密钥协商算法\rAu = Authentication 身份认证算法\rEnc = Encrypt 加密算法\rMac = Message Authentication Code 信息摘要算法\r compression methods：压缩算法列表，用于后续信息压缩传输 random_C：客户端随机数，用于后续密钥生成 extensions： 扩展字段，支持协议与算法相关参数及辅助信息 session id： 会话id，后续连接到同一台服务器，可以避免完全握手；  如果客户端时第一次连接服务器，则该字段为空。\n   服务器ServerHello 服务端返回协商的结果信息， 包含：\n version： 选择使用的TLS协议版本 cipher suite： 选择使用的加密套件 compression method： 选择使用的压缩算法 random_S: 服务器随机数 ，用于后续密钥生成 session id： 会话id  握手成功，服务器会缓存session 参数到tls缓存中， 并生成对应的session id 返回该session id 给客户端，客户端将session id存储在浏览器并设置时限 后续连接到同一台服务器，则发送session id， 服务器验证后， 使用以前使用过的对称密钥来恢复session\n问题： 大量客户端连接，会造成巨大的缓存开销；\nSession Ticket：\n 客户端在client hello 中指定是否支持session ticket 如果客户端支持session ticket， 服务器将创建新的session ticket， 并将Session参数使用私钥进行加密，返回给客户端。 客户端存储该session ticket  服务器ServerCertificate  服务端发送服务器证书给客户端， 用于身份验证和密钥交换 客户端校验证书合法性： 可信性、是否吊销、有效期、域名  服务器ClientCertificateRequest （可选） 如果进行双端验证，则服务端会向客户端请求客户端证书\n服务器ServerHelloDone 服务器通知客户端初始协商ServerHello结束\n客户端ClientCertificate（可选） 如果选择双端验证， 客户端向服务器端发送客户端证书\n客户端ClientKeyExchange  客户端计算PreMaster,并使用证书公钥加密发送给服务器 客户端根据random_C,random_S,PreMaster计算得到协商密钥（master）  客户端CertificateVerifyMessage （可选） 如果选择双向验证，客户端使用本地私钥生成数字签名， 并发送给服务器，服务器使用客户端公钥证书进行身份验证\n客户端ChangeCipherSpec 客户端通知服务器后续通信都使用协商密钥（master）和协商算法进行加密通信\n客户端EncryptedHandshakeMessage 使用协商密钥和算法加密一段数据， 发送给服务器\n服务器ChangeCipherSpec  服务器接收到PreMaster， 使用私钥进行解密 服务器根据random_C,random_S,PreMaster计算得到协商密钥（master） 解密客户端发送的加密数据，验证数据和密钥的正确性 服务器验证通过后， 同样发送ChangeCipherSpec消息，告诉客户端后续通信采用协商的密钥和算法进行加密通信  服务器EncryptHandshakeMessage  使用协商密钥和算法加密一段数据， 发送给客户端 客户端验证通过后， 握手结束  会话缓存握手 session id  如果客户端和服务器之间曾经建立连接， 服务器会在握手成功后返回Session ID给客户端， 并在服务器缓存对应的通信参数 如果客户端和服务器再次建立连接， 则ClientHello 会携带Session ID发送给服务器 服务器收到客户端的Session ID，回去检索TLS缓存， 如果没有检索到或Session过期， 则进行完整握手过程（FullHandshake） 如果服务器检索到Session缓存， 则发送ChangeCipherSpec和EncryptHandshakeMessage 如果客户端能偶验证通过服务器的加密数据， 则客户端也发送ChangeCipherSpec和EncryptHandshakeMessage 服务器验证客户端的加密数据， 通过则握手成功  session ticket  如果客户端和服务器之间曾经建立连接， 服务器会在握手成功后返回Session Ticket给客户端， 并在客户端保存 如果客户端和服务器再次建立连接， 则ClientHello 会携带Session Ticket发送给服务器 服务器收到客户端的Session Ticket，并进行解密， 如果解密失败则进行完整握手过程（FullHandshake） 如果服务器解密成功， 则发送ChangeCipherSpec和EncryptHandshakeMessage 如果客户端能偶验证通过服务器的加密数据， 则客户端也发送ChangeCipherSpec和EncryptHandshakeMessage 服务器验证客户端的加密数据， 通过则握手成功  ",
    "ref": "/blog/security/ssl-tls/"
  },{
    "title": "Extended Backus–Naur form",
    "date": "",
    "description": "扩展巴科斯 诺尔 范式",
    "body": "计算机科学中， EBNF是一组元语法，表达上下文无关的语法。EBNF是用于对正规语言的语法进行描述， 例如计算机编程语言的语法。它是BNF的扩充。\n基本要素 EBNF是一种表达正规语言语法的代码。一条EBNF由终结符号和非终结符产生规则组成，规则控制了终结符号如何组成合法的序列。例如： 终端符号包含：字母数字字符，标点符号，空白字符。\nEBNF定义了把符号序列分配给非终端的产生规则：\ndigit excluding zero = \u0026quot;1\u0026quot; | \u0026quot;2\u0026quot; | \u0026quot;3\u0026quot; | \u0026quot;4\u0026quot; | \u0026quot;5\u0026quot; | \u0026quot;6\u0026quot; | \u0026quot;7\u0026quot; | \u0026quot;8\u0026quot; | \u0026quot;9\u0026quot; ;\rdigit = \u0026quot;0\u0026quot; | digit excluding zero ;\r 这条产生规则定义了在表达式左边的非终结符digist。竖线|表示一种替代，终结符使用双引号\u0026quot;\u0026quot;包起来，后跟分号;作为终结字符。 因此digit 可以是0或者digit excluding zero(1或2或3，等等，直到9)\n 产生规则可以包含一系列的终结符和非终结符，每个都用逗号(,)隔开:\ntwelve = \u0026quot;1\u0026quot;, \u0026quot;2\u0026quot; ;\rtwo hundred one = \u0026quot;2\u0026quot;, \u0026quot;0\u0026quot;, \u0026quot;1\u0026quot; ;\rthree hundred twelve = \u0026quot;3\u0026quot;, twelve ;\rtwelve thousand two hundred one = twelve, two hundred one ;\r可以省略或重复的表达式，用花括号{...}表示：\nnatural number = digit excluding zero, { digit } ;\r 本例中，natural number表示1,2,...,10,...,10000, ..., 为了表示natural number，花括号内设置的所有内容都可以被任意复制或者不复制。\n 可选的表达式，用方括号[...]表示，方括号内设置的内容可能出现一次或者根本不出现:\ninteger = \u0026quot;0\u0026quot; | [ \u0026quot;-\u0026quot; ], natural number ;\r integer表示0或者前面有一个可选减号(-)的natural number\n 除了这些功能，ENBF语法还可以描述重复(指定次数),排除产品某些部分以及在EBNF的语法中插入注释。\n符号表 以下是R.S.Scowen在ISO/IEC 14977标准的第7页,表1中提出：\n   描述 符号     definition =   concatenation ,   termination ;   alternation \\   optional [ \u0026hellip; ]   repetition { \u0026hellip; }   grouping ( \u0026hellip; )   terminal string \u0026quot; \u0026hellip; \u0026quot;   terminal string ' \u0026hellip; '   comment (* \u0026hellip; *)   special sequence ? \u0026hellip; ?   exception -    示例 甚至可以使用EBNF描述其自身。考虑以下语法略图：\nletter = \u0026quot;A\u0026quot; | \u0026quot;B\u0026quot; | \u0026quot;C\u0026quot; | \u0026quot;D\u0026quot; | \u0026quot;E\u0026quot; | \u0026quot;F\u0026quot; | \u0026quot;G\u0026quot;\r| \u0026quot;H\u0026quot; | \u0026quot;I\u0026quot; | \u0026quot;J\u0026quot; | \u0026quot;K\u0026quot; | \u0026quot;L\u0026quot; | \u0026quot;M\u0026quot; | \u0026quot;N\u0026quot;\r| \u0026quot;O\u0026quot; | \u0026quot;P\u0026quot; | \u0026quot;Q\u0026quot; | \u0026quot;R\u0026quot; | \u0026quot;S\u0026quot; | \u0026quot;T\u0026quot; | \u0026quot;U\u0026quot;\r| \u0026quot;V\u0026quot; | \u0026quot;W\u0026quot; | \u0026quot;X\u0026quot; | \u0026quot;Y\u0026quot; | \u0026quot;Z\u0026quot; | \u0026quot;a\u0026quot; | \u0026quot;b\u0026quot;\r| \u0026quot;c\u0026quot; | \u0026quot;d\u0026quot; | \u0026quot;e\u0026quot; | \u0026quot;f\u0026quot; | \u0026quot;g\u0026quot; | \u0026quot;h\u0026quot; | \u0026quot;i\u0026quot;\r| \u0026quot;j\u0026quot; | \u0026quot;k\u0026quot; | \u0026quot;l\u0026quot; | \u0026quot;m\u0026quot; | \u0026quot;n\u0026quot; | \u0026quot;o\u0026quot; | \u0026quot;p\u0026quot;\r| \u0026quot;q\u0026quot; | \u0026quot;r\u0026quot; | \u0026quot;s\u0026quot; | \u0026quot;t\u0026quot; | \u0026quot;u\u0026quot; | \u0026quot;v\u0026quot; | \u0026quot;w\u0026quot;\r| \u0026quot;x\u0026quot; | \u0026quot;y\u0026quot; | \u0026quot;z\u0026quot; ;\rdigit = \u0026quot;0\u0026quot; | \u0026quot;1\u0026quot; | \u0026quot;2\u0026quot; | \u0026quot;3\u0026quot; | \u0026quot;4\u0026quot; | \u0026quot;5\u0026quot; | \u0026quot;6\u0026quot; | \u0026quot;7\u0026quot; | \u0026quot;8\u0026quot; | \u0026quot;9\u0026quot; ;\rsymbol = \u0026quot;[\u0026quot; | \u0026quot;]\u0026quot; | \u0026quot;{\u0026quot; | \u0026quot;}\u0026quot; | \u0026quot;(\u0026quot; | \u0026quot;)\u0026quot; | \u0026quot;\u0026lt;\u0026quot; | \u0026quot;\u0026gt;\u0026quot;\r| \u0026quot;'\u0026quot; | '\u0026quot;' | \u0026quot;=\u0026quot; | \u0026quot;|\u0026quot; | \u0026quot;.\u0026quot; | \u0026quot;,\u0026quot; | \u0026quot;;\u0026quot; ;\rcharacter = letter | digit | symbol | \u0026quot;_\u0026quot; ;\ridentifier = letter , { letter | digit | \u0026quot;_\u0026quot; } ;\rterminal = \u0026quot;'\u0026quot; , character , { character } , \u0026quot;'\u0026quot; | '\u0026quot;' , character , { character } , '\u0026quot;' ;\rlhs = identifier ;\rrhs = identifier\r| terminal\r| \u0026quot;[\u0026quot; , rhs , \u0026quot;]\u0026quot;\r| \u0026quot;{\u0026quot; , rhs , \u0026quot;}\u0026quot;\r| \u0026quot;(\u0026quot; , rhs , \u0026quot;)\u0026quot;\r| rhs , \u0026quot;|\u0026quot; , rhs\r| rhs , \u0026quot;,\u0026quot; , rhs ;\rrule = lhs , \u0026quot;=\u0026quot; , rhs , \u0026quot;;\u0026quot; ;\rgrammar = { rule } ;\r  letter = 是26个字母的任意一个; digit = 0-9数字中的任意一个; symbol = [或]或{或}或(或)或\u0026lt;或\u0026gt;或\u0026rsquo;或\u0026quot;或=或|或.或,或; ; character = letter或digit或symbol或_; identifier = letter + 任意重复(letter或digit或_); terminal = \u0026lsquo;character+ 任意重复(character)\u0026rsquo; 或者\u0026quot;character+ 任意重复(character)\u0026quot;; lhs = identifier; rhs = identifier 或 terminal 或 [rhs] 或 {rhs} 或 (rhs) 或 rhs|rhs 或 rhs,rhs; rule = lhs=rhs;; grammar = {rule}   一个只允许赋值的类Pascal的编程语言，可以用EBNF定义，如下：\n(* a simple program syntax in EBNF − Wikipedia *)\rprogram = 'PROGRAM', white_space, identifier, white_space, 'BEGIN', white_space, { assignment, \u0026quot;;\u0026quot;, white_space }, 'END.' ;\ridentifier = alphabetic_character, { alphabetic_character | digit } ;\rnumber = [ \u0026quot;-\u0026quot; ], digit, { digit } ;\rstring = '\u0026quot;' , { all_characters - '\u0026quot;' }, '\u0026quot;' ;\rassignment = identifier , \u0026quot;:=\u0026quot; , ( number | identifier | string ) ;\ralphabetic_character = \u0026quot;A\u0026quot; | \u0026quot;B\u0026quot; | \u0026quot;C\u0026quot; | \u0026quot;D\u0026quot; | \u0026quot;E\u0026quot; | \u0026quot;F\u0026quot; | \u0026quot;G\u0026quot;\r| \u0026quot;H\u0026quot; | \u0026quot;I\u0026quot; | \u0026quot;J\u0026quot; | \u0026quot;K\u0026quot; | \u0026quot;L\u0026quot; | \u0026quot;M\u0026quot; | \u0026quot;N\u0026quot;\r| \u0026quot;O\u0026quot; | \u0026quot;P\u0026quot; | \u0026quot;Q\u0026quot; | \u0026quot;R\u0026quot; | \u0026quot;S\u0026quot; | \u0026quot;T\u0026quot; | \u0026quot;U\u0026quot;\r| \u0026quot;V\u0026quot; | \u0026quot;W\u0026quot; | \u0026quot;X\u0026quot; | \u0026quot;Y\u0026quot; | \u0026quot;Z\u0026quot; ;\rdigit = \u0026quot;0\u0026quot; | \u0026quot;1\u0026quot; | \u0026quot;2\u0026quot; | \u0026quot;3\u0026quot; | \u0026quot;4\u0026quot; | \u0026quot;5\u0026quot; | \u0026quot;6\u0026quot; | \u0026quot;7\u0026quot; | \u0026quot;8\u0026quot; | \u0026quot;9\u0026quot; ;\rwhite_space = ? white_space characters ? ;\rall_characters = ? all visible characters ? ;\r那么语法正确的程序代码如下：\nPROGRAM DEMO1\rBEGIN\rA:=3;\rB:=45;\rH:=-100023;\rC:=A;\rD123:=B34A;\rBABOON:=GIRAFFE;\rTEXT:=\u0026quot;Hello world!\u0026quot;;\rEND.\r这种语言可以很简单的扩展到控制流，算术表达式和输入输出指令。 这样就设计出来一个小型的、可用的编程语言。\n优势 EBNF中的任何语法都可以用BNF表达，尽管后者的表达方法会更长。E.g., options和repetitions不能在BNF中直接表达。 BNF使用这些字符(\u0026lt;,\u0026gt;,|,::=),但是在终结字符周围不包含引号。在EBNF中，终结字符被引号括起来(\u0026quot;\u0026hellip;\u0026ldquo;或'\u0026hellip;')。\nBNF语法只能在一行中表示一条规则，而在EBNF中，分号字符“;”标志着规则的结束。\n此外，EBNF还包括增强机制、定义重复次数、排除替代方案、注释等\n约定  使用以下规则：   EBNF的每个元标识符都被写成一个或多个用连接符连接在一起的单词。 以-symbol结尾的元标识符是EBNF的终端符号的名称。  表示EBNF的每个操作符及其隐含优先级的字符是：  * repetition-symbol\r- except-symbol\r, concatenate-symbol\r| definition-separator-symbol\r= defining-symbol\r; terminator-symbol\r. terminator-symbol\r正常的优先级被以下括号对覆盖:  (* start-comment-symbol end-comment-symbol *)\r' first-quote-symbol first-quote-symbol '\r( start-group-symbol end-group-symbol )\r[ start-option-symbol end-option-symbol ]\r{ start-repeat-symbol end-repeat-symbol }\r? special-sequence-symbol special-sequence-symbol ?\r\u0026quot; second-quote-symbol second-quote-symbol \u0026quot;\r作为示例，下面的语法规则演示了表达重复的工具:\naa = \u0026quot;A\u0026quot;;\rbb = 3 * aa, \u0026quot;B\u0026quot;;\rcc = 3 * [aa], \u0026quot;C\u0026quot;;\rdd = {aa}, \u0026quot;D\u0026quot;;\ree = aa, {aa}, \u0026quot;E\u0026quot;;\rff = 3 * aa, 3 * [aa], \u0026quot;F\u0026quot;;\rgg = {3 * aa}, \u0026quot;G\u0026quot;;\r这些规则定义的终结字符如下：\naa: A\rbb: AAAB\rcc: C AC AAC AAAC\rdd: D AD AAD AAAD AAAAD etc.\ree: AE AAE AAAE AAAAE AAAAAE etc.\rff: AAAF AAAAF AAAAAF AAAAAAF\rgg: G AAAG AAAAAAG etc.\r扩展 根据ISO 14977标准，EBNF是可扩展的， 并且提到了两个设施。\nspecial sequence:\n 它是被问号包含的任意文本 对special sequence 中的文本的解释超出了EBNF标准的范围 例如, 空格字符可以用以下规则定义： space = ? ASCII character 32 ?;  grouping:\n () 不能放到标识符的旁边(它们必须相连接)  有效格式: something = foo, ( bar ); 无效格式: something = foo ( bar );   因此EBNF扩展可以使用该符号。例如，使用该符号定义函数：\nfunction application = list( symbol, { expression } );  ",
    "ref": "/blog/software-programming/ebnf/"
  },{
    "title": "生成自签名SSL证书",
    "date": "",
    "description": "",
    "body": "#!/bin/sh\r# create self-signed server certificate:\rSSLDIR=$PWD/ssl\rSERVERDIR=$SSLDIR/server\rCLIENTDIR=$SSLDIR/client\rOPENSSLFILE=$PWD/openssl.cnf\rsu root\rsudo rm -rf $SSLDIR\rsudo mkdir $SSLDIR\rsudo mkdir $SERVERDIR\rsudo mkdir $CLIENTDIR\rsudo mkdir $SSLDIR/demoCA\rsudo mkdir $SSLDIR/demoCA/newcerts\rsudo touch $SSLDIR/demoCA/index.txt\rsudo touch $SSLDIR/demoCA/serial\rsudo echo 01 \u0026gt; $SSLDIR/demoCA/serial\rcd $SSLDIR\rread -p \u0026quot;Enter your domain [www.example.com]: \u0026quot; DOMAIN\rsudo sed -e \u0026quot;s|192.168.10.33|$DOMAIN|g\u0026quot; -i $OPENSSLFILE\rSUBJECT=\u0026quot;/C=CN/ST=Beijing/L=Beigjing/O=YongNuo/OU=CEO/CN=$DOMAIN/emailAddress=zylhorse@126.com\u0026quot;\recho \u0026quot;Create Ca key / cert ...\u0026quot;\rsudo openssl req -new -x509 -subj $SUBJECT -keyout $SSLDIR/ca.key -out $SSLDIR/ca.crt -days 365\rsudo openssl rsa -in $SSLDIR/ca.key -out $SSLDIR/ca.key\recho \u0026quot;Create server key...\u0026quot;\rsudo openssl genrsa -des3 -out $SERVERDIR/$DOMAIN.key 1024\rsudo openssl rsa -in $SERVERDIR/$DOMAIN.key -out $SERVERDIR/$DOMAIN.key\recho \u0026quot;Create server certificate signing request...\u0026quot;\rsudo openssl req -new -subj $SUBJECT -key $SERVERDIR/$DOMAIN.key -out $SERVERDIR/$DOMAIN.csr -config $OPENSSLFILE -extensions v3_req\recho \u0026quot;Sign SSL certificate...\u0026quot;\rsudo openssl ca -in $SERVERDIR/$DOMAIN.csr -out $SERVERDIR/$DOMAIN.crt -cert $SSLDIR/ca.crt -keyfile $SSLDIR/ca.key -config $OPENSSLFILE -extensions v3_req\recho \u0026quot;Create client key...\u0026quot;\rsudo openssl genrsa -des3 -out $CLIENTDIR/$DOMAIN.key 1024\rsudo openssl rsa -in $CLIENTDIR/$DOMAIN.key -out $CLIENTDIR/$DOMAIN.key\recho \u0026quot;Create client certificate signing request...\u0026quot;\rsudo openssl req -new -subj $SUBJECT -key $CLIENTDIR/$DOMAIN.key -out $CLIENTDIR/$DOMAIN.csr -config $OPENSSLFILE -extensions v3_req\recho \u0026quot;Sign SSL certificate...\u0026quot;\rsudo openssl ca -in $CLIENTDIR/$DOMAIN.csr -out $CLIENTDIR/$DOMAIN.crt -cert $SSLDIR/ca.crt -keyfile $SSLDIR/ca.key -config $OPENSSLFILE -extensions v3_req\recho \u0026quot;copy crt/key -\u0026gt; /etc/nginx/ssl/\u0026quot; sudo cp $SSLDIR/ca.crt $SERVERDIR/$DOMAIN.crt $SERVERDIR/$DOMAIN.key /etc/nginx/ssl\recho \u0026quot;import ca.crt to tomcat\u0026quot;\rcd /usr/lib/jvm/java-8-openjdk-amd64/jre/lib/security\rsudo keytool -keystore cacerts -delete -alias $DOMAIN -storepass changeit\rsudo keytool -keystore cacerts -importcert -alias $DOMAIN -file /etc/nginx/ssl/ca.crt -storepass changeit\r",
    "ref": "/blog/security/%E7%94%9F%E6%88%90%E8%AF%81%E4%B9%A6/"
  },{
    "title": "生成自签名SSL免密证书",
    "date": "",
    "description": "",
    "body": "#!/bin/sh\r# create self-signed server certificate:\rSSLDIR=$PWD/ssl\rSERVERDIR=$SSLDIR/server\rCLIENTDIR=$SSLDIR/client\rOPENSSLFILE=$PWD/openssl.cnf\rsudo rm -rf $SSLDIR\rsudo mkdir $SSLDIR\rsudo mkdir $SERVERDIR\rsudo mkdir $CLIENTDIR\rsudo mkdir $SSLDIR/demoCA\rsudo mkdir $SSLDIR/demoCA/newcerts\rsudo touch $SSLDIR/demoCA/index.txt\rsudo touch $SSLDIR/demoCA/serial\rsudo echo 01 \u0026gt; $SSLDIR/demoCA/serial\rcd $SSLDIR\rread -p \u0026quot;Enter your domain [www.example.com]: \u0026quot; DOMAIN\rsudo sed -i \u0026quot;s/subjectAltName=IP.*/subjectAltName=IP:$DOMAIN/g\u0026quot; $OPENSSLFILE\rSUBJECT=\u0026quot;/C=CN/ST=Beijing/L=Beigjing/O=YongNuo/OU=CEO/CN=$DOMAIN/emailAddress=zylhorse@126.com\u0026quot;\recho \u0026quot;Create Ca key / cert ...\u0026quot;\rsudo openssl req -new -x509 -subj $SUBJECT -keyout $SSLDIR/ca.key -out $SSLDIR/ca.crt -days 365 -nodes\rsudo openssl rsa -in $SSLDIR/ca.key -out $SSLDIR/ca.key\recho \u0026quot;Create server key...\u0026quot;\rsudo openssl genrsa -des3 -passout pass:123456 -out $SERVERDIR/$DOMAIN.key 1024\rsudo openssl rsa -passin pass:123456 -in $SERVERDIR/$DOMAIN.key -passout pass:123456 -out $SERVERDIR/$DOMAIN.key\recho \u0026quot;Create server certificate signing request...\u0026quot;\rsudo openssl req -new -subj $SUBJECT -key $SERVERDIR/$DOMAIN.key -out $SERVERDIR/$DOMAIN.csr -config $OPENSSLFILE -extensions v3_req\recho \u0026quot;Sign SSL certificate...\u0026quot;\rsudo openssl ca -passin pass:123456 -in $SERVERDIR/$DOMAIN.csr -out $SERVERDIR/$DOMAIN.crt -cert $SSLDIR/ca.crt -keyfile $SSLDIR/ca.key -config $OPENSSLFILE -extensions v3_req\recho \u0026quot;Create client key...\u0026quot;\rsudo openssl genrsa -des3 -passout pass:123456 -out $CLIENTDIR/$DOMAIN.key 1024\rsudo openssl rsa -passin pass:123456 -in $CLIENTDIR/$DOMAIN.key -passout pass:123456 -out $CLIENTDIR/$DOMAIN.key\recho \u0026quot;Create client certificate signing request...\u0026quot;\rsudo openssl req -new -subj $SUBJECT -key $CLIENTDIR/$DOMAIN.key -out $CLIENTDIR/$DOMAIN.csr -config $OPENSSLFILE -extensions v3_req\recho \u0026quot;Sign SSL certificate...\u0026quot;\rsudo openssl ca -passin pass:123456 -in $CLIENTDIR/$DOMAIN.csr -out $CLIENTDIR/$DOMAIN.crt -cert $SSLDIR/ca.crt -keyfile $SSLDIR/ca.key -config $OPENSSLFILE -extensions v3_req\r",
    "ref": "/blog/security/%E7%94%9F%E6%88%90%E5%85%8D%E5%AF%86%E8%AF%81%E4%B9%A6/"
  },{
    "title": "lua编译环境搭建和IDE配置",
    "date": "",
    "description": "",
    "body": "lua 编译环境安装   linux:\n$ curl -R -O http://www.lua.org/ftp/lua-5.3.0.tar.gz\r$ tar zxf lua-5.3.0.tar.gz\r$ cd lua-5.3.0\r$ make linux test\r$ make install\r  macos:\n$ curl -R -O http://www.lua.org/ftp/lua-5.3.0.tar.gz\r$ tar zxf lua-5.3.0.tar.gz\r$ cd lua-5.3.0\r$ make macosx test\r$ make install\r  windows:\n下载地址\n  sublime text 3 设置tools -\u0026gt; build system -\u0026gt; lua\n",
    "ref": "/blog/lua/ide/"
  },{
    "title": "Lua语言简介",
    "date": "",
    "description": "",
    "body": "概念  轻量小巧的脚本语言 标准c语言编写，且开源 目的： 嵌入宿主语言，并提供灵活的扩展和定制  编程模型  面向过程编程和函数式编程 自动内存管理：值提供一种通用类型的表（table) 内置模式匹配，函数也可以看作值 提供多线程支持 通过闭包和table可以方便的支持面向对象编程的一些机制   参考  The Implementation of Lua 5.0  ",
    "ref": "/blog/lua/lua/"
  },{
    "title": "生成公私钥",
    "date": "",
    "description": "",
    "body": "$ openssl genrsa -out privatekey.pem 1024\r$ openssl pkcs8 -topk8 -inform PEM -in privatekey.pem -outform PEM -nocrypt\r$ openssl rsa -in privatekey.pem -pubout -out publickey.pem\r",
    "ref": "/blog/security/%E7%94%9F%E6%88%90%E5%85%AC%E7%A7%81%E9%92%A5/"
  },{
    "title": "不同平台常用浏览器的离线下载地址",
    "date": "",
    "description": "",
    "body": "  edge\n  chrome-mac\n  chrome-win64\n  ",
    "ref": "/blog/browser/download/"
  },{
    "title": "Sandboxie（沙箱）网络编程虚拟执行环境",
    "date": "",
    "description": "",
    "body": "关键字 Sandboxie（沙箱）网络编程虚拟执行环境\n概念 沙箱是一个虚拟系统程序， 允许程序在沙箱环境中独立运行， 限制沙箱中程序对宿主系统的修改和影响。\n有哪些限制 在沙箱中运行的程序，\n 不能运行本地的可执行程序 不能从本地计算机文件系统中读取任何文件， 也不能往本地计算机系统中写入任何信息 不能查看本地计算机信息，特别是用户名，E-mail地址等  技术迭代  GreenBorder 为IE和Firefox构建安全的虚拟执行环境，用户对浏览器所作的任何写磁盘操作， 都将重定向到一个临时的文件中 Forcefield由ZoneAlarm开发， 功能雷士GreenBorder;  原理 Sandboxie 通过重定向技术，将程序生成和修改的文件重定向到自身的临时文件中（修改包括注册表和系统的核心数据）。通过加载自身的驱动来保护底层数据， 属于驱动级别保护。\n",
    "ref": "/blog/software-programming/%E6%B2%99%E7%AE%B1/"
  },{
    "title": "Ubuntu依赖包的离线打包和安装",
    "date": "",
    "description": "",
    "body": "Ubuntu 16.04离线安装步骤 宿主机打包   清理apt 缓冲区\n$ sudo rm -rf /var/cache/apt/archives/*\n  下载所需组件\n$ sudo apt-get -d install \u0026lt;包名\u0026gt;\n  创建目录，并拷贝\n$ mkdir \u0026lt;your-path\u0026gt;\r$ cp -r /var/cache/apt/archives \u0026lt;your-path\u0026gt;\r  修改目录权限\n$ chown -R \u0026lt;your-path\u0026gt;\n  建立依赖关系\n$ sudo apt install dpkg-dev\r$ cd \u0026lt;your-path\u0026gt;\r$ sudo dpkg-scanpackages archives /dev/null | gzip \u0026gt; \u0026lt;your-path\u0026gt;/archives/Packages.gz\r  拷贝到离线系统\n$ scp -r \u0026lt;your-path\u0026gt; \u0026lt;离线系统\u0026gt;\n  离线系统安装   修改apt源\n$ sudo vi /etc/apt/sources.list\r# 清空并添加\rdeb file:///\u0026lt;your-path\u0026gt; archives/\r  安装指定组件\n$ sudo apt-get update $ sudo apt-get install \u0026lt;包名\u0026gt;\r  ",
    "ref": "/blog/linux/%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85%E6%BA%90/"
  },{
    "title": "并发编程-乐观锁和悲观锁",
    "date": "",
    "description": "",
    "body": "乐观锁 乐观锁假设数据一般不会修改， 所以在数据提交修改的时候， 才会对数据冲突进行检查；如果冲突则交给用户决定如何去做；对数据竞争持乐观态度\n乐观锁实现 cas（compare and swap）  CAS机制当中使用了3个基本操作数：内存地址V，旧的预期值A，要修改的新值B。 更新一个变量的时候，只有当变量的预期值A和内存地址V当中的实际值相同时，才会将内存地址V对应的值修改为B。 CAS一般需要加for循环，实现类似自旋乐观锁。  mvcc（Multi-Version Concurrency Control）  每行数据都增加两个隐藏字段，一个记录创建的版本号，一个记录删除的版本号 在多版本并发控制中，为了保证数据操作在多线程过程中，保证事务隔离的机制，降低锁竞争的压力，保证较高的并发量。 在每开启一个事务时，会生成一个事务的版本号，被操作的数据会生成一条新的数据行（临时），但是在提交前对其他事务是不可见的，对于数据的更新（包括增删改）操作成功，会将这个版本号更新到数据的行中，事务提交成功，将新的版本号更新到此数据行中，这样保证了每个事务操作的数据，都是互不影响的，也不存在锁的问题。  悲观锁 悲观锁具有强烈的独占性和排他性；一般认为数据被并发修改的概率较大，所以需要在修改前先加锁；对数据竞争持态度。\n",
    "ref": "/blog/concurrence/%E4%B9%90%E8%A7%82%E9%94%81%E5%92%8C%E6%82%B2%E8%A7%82%E9%94%81/"
  },{
    "title": "并发编程-线程锁和死锁",
    "date": "",
    "description": "",
    "body": "锁 在多线程编程中， 对共享资源竞争的保护机制；\n锁缺点  引起线程阻塞 申请和释放锁， 增加线程的调度切换， 影响系统性能 容易造成死锁和活锁等问题 优先级反转 不公平 效率低  公平锁 在锁上等待时间最长的线程优先获取锁的使用权\n非公平锁 线程获取锁的使用权是随机的， cpu时间片轮到哪个线程， 哪个线程就获取到锁；\n锁类型  自旋锁（spin lock） ： 自旋锁如果已经被其他线程获取，则调用者就一直循环等待；自旋锁时非阻塞锁， 循环等待时会不断消耗cpu， 不会使线程挂起； 互斥锁（mutex lock）： 互斥锁被其他线程获取， 则调用者会阻塞线程， 线程被挂起， 不会消耗cpu； 读写锁（read write lock）：读写锁允许资源可以同时被多个线程读取， 但是读写时互斥的且同时只能有一个线程去写； 条件锁 （condition lock）：条件锁检查条件，如果条件不满足则线程阻塞等待， 并解锁mutex。当收到其他线程的notify条件状态改变后，线程苏醒，获取mutex并上锁。  响应中断  一个线程霸占锁， 手动中断该线程后，使得该锁发出中断响应； 其他等待线程收到该中断信息，就可以获取到锁；  限时等待 线程在获取锁时， 设置等待时间， 超过该时间， 则停止等待， 获取锁失败；\n死锁 多个线程在运行中因争夺共享资源出现互相等待的现象\n死锁发生条件  互斥： 资源一次只能被一个进程占用；其他进程请求需要等待； 请求和保持： 一个进程至少占用一个资源， 并等待申请其他资源， 而该资源被其他进程占用。 不剥夺：进程占用的资源只能自己释放， 其他进程不能强行夺取； 循环等待：有一组等待进程 {P0，P1，…，Pn}，P0 等待的资源为 P1 占有，P1 等待的资源为 P2 占有，……，Pn-1 等待的资源为 Pn 占有，Pn 等待的资源为 P0 占有   四个条件必须同时成立才会出现死锁。\n 死锁原因 系统资源分为两类： 可剥夺资源：进程获取到该类资源后， 该资源还可被其他进程或系统剥夺， 如： cpu，内存等 不可剥夺资源：进程获取到该类资源后， 其不可被强行收回， 只能在进程用完后自行释放， 如： 打印机，光驱等\n 系统资源竞争： 只有对不可剥夺资源的竞争才可能产生死锁； 进程推进顺序非法 进程运行过程中， 请求和释放资源的顺序不当， 也会产生死锁；如： P1、P2分别保持资源R1、R2， 而P1申请R2， P2 申请R1， 则P1、P2 会因为两者资源被占用而阻塞； 信号量等待 进程彼此等待对方发送消息， 是的进程无法继续推进；如： 进程A等待B 发送消息， 进程B 又等待A发送消息，则A、B 因等待对方消息导致死锁  死锁解决办法 死锁预防  资源有序分配法：以特定的顺序获得锁， 避免循环等待。 这种 方式需要事先知道可能会使用的锁， 但这些有时时无法预知的。 资源原子分配法： 超时放弃，按固定时间等待锁， 超时则放弃获取锁并释放已经获取的其他锁。  死锁避免 各种死锁防止方法都能够防止发生死锁， 但会降低系统并发性，导致低效的资源利用率。\n银行家算法\n死锁检测 进程资源分配图：通过检测有向图是否存在环来实现，从一个节点出发进行深度优先搜索，对访问过的节点进行标记， 如果访问了已经标记的节点，就表示有向图存在环，也就是检测到死锁的发生\n死锁恢复  资源剥夺法 进程回退法 进程撤销法 系统重启法  ",
    "ref": "/blog/concurrence/%E7%BA%BF%E7%A8%8B%E9%94%81/"
  },{
    "title": "I/O多路复用-select/poll/epoll",
    "date": "",
    "description": "",
    "body": "概述 i/o 多路复用:在单线程中通过记录跟踪多个sock 状态， 来同时管理多路I/O流。用以提高服务器的吞吐能力\nselect  select会修改传入的参数数组 任何sock状态改变，select只返回并不告诉是哪个sock状态改变，需要手动遍历 最高监听1024个sock连接； 线程不安全，如果在其他线程关闭sock会导致未知错误  poll  poll 修复很多select 问题， 不在修改参数数组；不在限制sock连接数量； poll 仍然线程不安全  epoll epoll 修复大多数select和poll问题， 线程安全， 并通知哪个sock状态改变；\nepoll工作过程  epoll_create()系统调用。此调用返回一个句柄，之后所有的使用都依靠这个句柄来标识。 epoll_ctl()系统调用。通过此调用向epoll对象中添加、删除、修改事件，并注册回调函数，返回0标识成功，返回-1表示失败。 epoll_wait()系统调用。通过此调用收集收集在epoll监控中已经发生的事件。  epoll 内部工作原理  创建一个红黑树rbr， 用户存放添加到epoll中的监控事件； 创建双链表rdlist， 存放已触发的事件，返回给用户； 当监控事件被触发时，epoll会给每个事件创建epItem结构体，并使用内核回调函数ep_poll_callback将发生的事件添加到rdlist； 调用epoll_wait， 检查rdlist中是否有epItem；如果rdlist不为空， 则将事件复制到用户态， 并将事件数量返回给用户；  epoll 高效原理 ",
    "ref": "/blog/concurrence/io/epoll/"
  },{
    "title": "制作linux系统服务",
    "date": "",
    "description": "",
    "body": "服务制作   在/etc/init.d/ 下以管理员权限新建文件，在本例中为location_server.\n  使用以下模板修改启动脚本的内容\n#!/bin/bash\r### BEGIN INIT INFO\r#\r# Provides: location_server\r# Required-Start: $local_fs $remote_fs\r# Required-Stop: $local_fs $remote_fs\r# Default-Start: 2 3 4 5\r# Default-Stop: 0 1 6\r# Short-Description: initscript\r# Description: This file should be used to construct scripts to be placed in /etc/init.d.\r#\r### END INIT INFO\r## Fill in name of program here.\rPROG=\u0026quot;location_server\u0026quot;\rPROG_PATH=\u0026quot;/opt/location_server\u0026quot; ## Not need, but sometimes helpful (if $PROG resides in /opt for example).\rPROG_ARGS=\u0026quot;\u0026quot; PID_PATH=\u0026quot;/var/run/\u0026quot;\rstart() {\rif [ -e \u0026quot;$PID_PATH/$PROG.pid\u0026quot; ]; then\r## Program is running, exit with error.\recho \u0026quot;Error! $PROG is currently running!\u0026quot; 1\u0026gt;\u0026amp;2\rexit 1\relse\r## Change from /dev/null to something like /var/log/$PROG if you want to save output.\r$PROG_PATH $PROG_ARGS 2\u0026gt;\u0026amp;1 \u0026gt;/var/log/$PROG \u0026amp;\rpid=`ps ax | grep -i 'location_server' | sed 's/^\\([0-9]\\{1,\\}\\).*/\\1/g' | head -n 1 | awk -F' ' '{print $1}'`\recho \u0026quot;$PROG started\u0026quot;\recho $pid \u0026gt; \u0026quot;$PID_PATH/$PROG.pid\u0026quot;\rfi\r}\rstop() {\recho \u0026quot;begin stop\u0026quot;\rif [ -e \u0026quot;$PID_PATH/$PROG.pid\u0026quot; ]; then\r## Program is running, so stop it\rpid=`ps ax | grep -i 'location_server' | sed 's/^\\([0-9]\\{1,\\}\\).*/\\1/g' | head -n 1 | awk -F' ' '{print $1}'`\rkill $pid\rrm -f \u0026quot;$PID_PATH/$PROG.pid\u0026quot;\recho \u0026quot;$PROG stopped\u0026quot;\relse\r## Program is not running, exit with error.\recho \u0026quot;Error! $PROG not started!\u0026quot; 1\u0026gt;\u0026amp;2\rexit 1\rfi\r}\r## Check to see if we are running as root first.\r## Found at http://www.cyberciti.biz/tips/shell-root-user-check-script.html\rif [ \u0026quot;$(id -u)\u0026quot; != \u0026quot;0\u0026quot; ]; then\recho \u0026quot;This script must be run as root\u0026quot; 1\u0026gt;\u0026amp;2\rexit 1\rfi\rcase \u0026quot;$1\u0026quot; in\rstart)\rstart\rexit 0\r;;\rstop)\rstop\rexit 0\r;;\rreload|restart|force-reload)\rstop\rstart\rexit 0\r;;\r**)\recho \u0026quot;Usage: $0 {start|stop|reload}\u0026quot; 1\u0026gt;\u0026amp;2\rexit 1\r;;\resac\r 其中，PROG变量为所要运行的可执行程序的名称， PROG_PATH为可执行文件所在的目录，PROG_ARGS为执行程序的各个参数。\n   添加删除服务\n添加：$ sudo update-rc.d 服务名 defaults\n删除：$ sudo update-rc.d -f 服务名 remove12\n  开关服务\n 启动 $ /etc/init.d/服务名 start 关闭 $ /etc/init.d/服务名 stop 重启 $ /etc/init.d/服务名 restart    ",
    "ref": "/blog/linux/ubuntu%E6%9C%8D%E5%8A%A1/"
  },{
    "title": "TCP-数据传输可靠性",
    "date": "",
    "description": "",
    "body": "TCP数据传输 面向字节流， 传输可靠， 面向连接\n问题 网络数据不可靠， 丢包， 错包， 重复包， 乱序包；\n滑动窗口 提高数据吞吐量， 传输数据块（包含多组数据）\n滑动窗口本身可以看做是一个协议，适合于数据传输过程中要求有严格顺序处理的场景\n滑动窗口将时间轴上的数据分成了4个部分:\n 数据发送且被确认 数据发送但未被确认 数据能够被发送 数据不能发送，等待滑动窗口右移  TCP报文字段 win  报文中win用来描述窗口大小。 接收方窗口大小由接收方控制, 默认4096字节 如果窗口中有未来得及读取的数据， 则响应报文中的win就会减少 如果窗口中的数据被读取， 可能会出现携带ack 但不确认任何数据 而仅仅win变大的包， 这种情况用来更新窗口大小；  确保可靠性方式  校验和  数据发送时， 将数据段当作16位整数， 并将所有数据段相加。 且相加后的进位不丢弃，补到末位， 最后取反，得到校验和； 接收方收到数据后， 以同样方式计算校验和， 与发送方的进行对比；如果校验和不一致则数据传输一定有误。 但是校验和一致，数据传输不一定无误；   序列号  数据传输的每个数据段都进行了编号； 有了序列号， 就能对数据包进行排序和排重；   确认应答  数据传输的每次发送， 接收方都会进行应答， 即发送ack确认报文；   超时重传  基于序列号和确认应答机制，发送方都会等待接收方的ack确认报文。 如果发送方迟迟接收不到ack响应， 则会重新发送该报文，直到达到重传次数限制， 则认为tcp传输异常， 强制关闭； 超时的时间以500ms 为基准， 以指数方式增加； （第一次： 500ms， 第二次： 2*500ms \u0026hellip;);    ",
    "ref": "/blog/network/tcp/%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3/"
  },{
    "title": "TCP-IP连接限制",
    "date": "",
    "description": "",
    "body": "在一台系统上，连接到一个远程服务时的本地端口(local_addr)是有限的。根据TCP/IP协议，由于端口是16位整数，也就只能是0到 65535，而0到1023是预留端口， 所以能分配的端口只是1024到65534，也就是64511个。也就是说，一个IP只能创建六万多个长连接。\n",
    "ref": "/blog/network/tcp/maxport/"
  },{
    "title": "TCP-握手和挥手",
    "date": "",
    "description": "",
    "body": "tcp 状态 tcp连接FLAGS字段表示当前连接状态，FLAGS包含一下几个标识：\n SYN表示建立连接 FIN表示关闭连接 ACK表示响应 PSH表示有 DATA数据传输 RST表示连接重置  三次握手 tcp建立连接的过程，需要三次握手；\n 客户端打开连接，主动结束CLOSED阶段； 服务器连接，被动结束CLOSED阶段， 进入LISTEN阶段； 开始握手：   客户端向服务器发送tcp报文\n1.1 标记位为SYN， 表示请求建立连接\n1.2 序号seq=x (x一般为0)\n1.3 客户端进入SYN-SENT 阶段\n  服务器接收来自客户端的tcp报文，结束LISTEN阶段，并发送一段tcp报文\n2.1 标志位为SYN和ACK， 表示确认客户端报文seq有效，同意创建连接\n2.2 序号seq=y（y一般为0）， 确认号ack=x+1, 表示收到客户端序号seq并将其值加1作为自己的确认号ack的值\n2.3 服务端进入SYN-RECVD阶段\n  客户端接收来自服务器的确认报文后， 结束SYN-SENT阶段，并返回一段tcp报文\n3.1 标志位为ACK， 表示确认收到服务器同意连接的信号；\n3.2 序号seq=x+1， 表示收到服务器的确认号ack， 并将其作为自己的序号\n3.3 确认号ack=y+1， 表示收到服务器的序号seq并将其值加1作为自己的确认号ack的值\n3.4 客户端进入ESTABLISHED阶段\n  服务器接收到来自客户端的确认报文后， 明确从服务器到客户端的数据传输时正常的\n4.1 服务器结束SYN-RECVD阶段， 进入ESTABLISHED阶段\n    为什么三次握手  防止服务器开启无用连接，增加服务器开销； 防止失效的请求连接报文传输到服务端， 产生错误；  四次挥手 tcp释放连接，需要四次挥手\n  客户端释放连接， 向服务器发送tcp报文\n1.1 标记位为FIN， 表示请求释放连接\n1.2 序号seq=u\n1.3 客户端结束ESTABLISHED阶段，进入FIN-WAIT-1阶段， 即半关闭状态。\n1.4 停止客户端向服务器发送数据， 但是可以接收服务器数据\n  服务器接收到来自客户端的报文后， 确认客户端要释放连接。 服务器结束ESTABLISHED阶段，进入CLOSE-WAIT阶段，即半关闭状态， 并返回一段tcp报文\n2.1 标记位为ACK， 表示接收到客户端发送的释放连接请求\n2.2 序号seq=v\n2.3 确认号ack=u+1， 表示收到客户端的序号seq并将其值加1作为自己的确认号ack的值\n2.4 服务器准备释放服务器到客户端的连接\n  客户端接收到服务器发送的确认报文后， 客户端结束 FIN-WAIT-1阶段， 进入FIN-WAIT-2阶段\n  服务器发完ACK的确认报文后， 经过CLOSE-WAIT阶段， 做好释放连接的准备， 再次向客户端发送tcp报文\n4.1 标记位为FIN,ACK ， 表示已经准备好释放连接；\n4.2 序号seq=w\n4.3 确认号为u+1，表示收到客户端的序号seq并将其值加1作为自己的确认号ack的值\n4.4 服务器结束CLOSE-WAIT阶段，进入LAST-ACK阶段\n4.5 服务器停止向客户端发送数据，但是服务器能收到客户端传来的数据\n  客户端收到从服务器发送的tcp报文后，确认服务器做好释放连接的准备， 结束FIN-WAIT-2阶段， 进入TIME-WAIT阶段，并向服务器发送一段tcp报文\n5.1 标记位为ACK，表示收到服务器准备好释放连接的信号\n5.2 序号seq=u+1,表示收到服务器的确认号ack， 并将其作为自己的序号\n5.3 确认号ack=w+1， 表示收到服务器准备好释放连接的seq， 并将其之加1作为自己的确认号ack的值\n  服务器接收到客户端的tcp报文后，结束LAST-ACK阶段， 进入CLOSED阶段\n  客户端再等待2MSL后， 结束TIME-WAIT阶段，进入CLOSED阶段\n  挥手问题   TIME-WAIT为什么等2MSL\n 防止服务器发送FIN/ACK指令失败后重发， 这样客户端就能接收到服务器的重传 防止客户端未不发送ACK,影响服务器的下一个连接    CLOSE-WAIT过多，因为服务器没有发送FIN/ACK报文；解决办法：\n socket用完要close socket读取长度为0时， 立刻close socket读取报错是， 检查错误类型；  INTR（被中断，可继续读取）； WOULDBLOCK（当前socket由阻塞变为非阻塞）； AGAIN（现在还没数据，稍后重新读取）。 如果不是AGAIN， 其他立刻close      RST 重置连接  用于复位某种原因引起的错误连接， 也用来拒绝非法数据和请求 发送RST关闭连接时，不必等待缓冲区的包都发送完成，会直接清空缓冲区，并发送RST包 接收到RST包后， 也不必发送ACK包进行响应 RST表示不在发送数据，也不接受数据  RST 场景  关闭socket连接（socket.close())，会发送RST报文 connect 一个没有被监听的端口 向已经关闭的连接发送数据，会收到RST报文  ",
    "ref": "/blog/network/tcp/handshake/"
  },{
    "title": "Scalar",
    "date": "",
    "description": "标量",
    "body": "标量(Scalar),在计算机领域用于区分单个值(整数/浮点数/字符串)与数据结构(数组/结构/map)区分开。\n",
    "ref": "/blog/software-programming/scalar/"
  },{
    "title": "Jmeter部署和配置",
    "date": "",
    "description": "",
    "body": "下载 地址\n汉化 jmeter.properties =\u0026gt; language=zh_CN\nwebsocket配置 下载jar包 jetty-http jetty-io jetty-util websocket-api websocket-client websocket-common\n",
    "ref": "/blog/jmeter/%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"
  },{
    "title": "mmap实现原理简述及使用场景",
    "date": "",
    "description": "",
    "body": "概念  mmap是一种文档映射到内存的方法； 将文件或其他对象映射到进程的内存地址空间；实现文件磁盘地址和进程虚拟地址空间的映射。 映射后， 进程就可以采用指针的方式读写操作这段内存。而系统会自动回写修改内容到磁盘文件中。 同样内核空间对这段内存的修改也会直接映射到用户空间， 从而实现不同进程间的文档共享。  内部原理 struct vm_area_struct {\rvm_end\rvm_start\rvm_prot\rvm_flags\rvm_next *vm_area_struct\r}\rlinux 内核使用vm_area_struct结构来表示一个独立的虚拟内存区域。\n工作流程 void *mmap(void *start, size_t length, int prot, int flags,int fd, off_t offset);\rint munmap( void * addr, size_t len ) int msync( void *addr, size_t len, int flags )\r优点  对文件的读取操作跨过了页缓存，减少了数据的拷贝次数，用内存读写取代I/O读写，提高了文件读取效率。 常规文件操作需要从磁盘到页缓存再到用户主存的两次数据拷贝 实现了用户空间和内核空间的高校交互；俩个空间的操作可以直接反映到映射的内存区域； 实现进程间共享内存进行通讯； 实现高效大规模数据传输，借助磁盘空间协助内存操作。  ",
    "ref": "/blog/memory/mmap/"
  },{
    "title": "多类型I/O操作流程",
    "date": "",
    "description": "",
    "body": "I/O IO分为两个阶段：\n 数据准备阶段 内核空间复制数据到用户进程缓冲区（用户空间）阶段  IO类型   阻塞IO 用户线程进行IO读写操作时发生阻塞，等待数据准备就绪\n  非阻塞IO 用户线程进行IO读写操作时不阻塞，但是循环询问内核数据是否就绪\n  多路复用IO\n 轮询多个IO连接， 只有当真正的事件发生时，采取调用实际的IO操作； 轮询多个IO状态，发生在内核空间；    信号驱动IO\n 用户线程发起sigaction 系统调用， 给socket注册信号函数后， 继续执行 内核数据准备就绪后，发送信号给用户线程 用户线程收到信号，再发起recvfrom系统调用，将数据复制到用户空间； 用户下线程操作数据；    异步IO\n 用户线程发起aio_read 系统调用后继续执行 内核处理完IO操作，发送信号给用户线程 IO操作完成； 用户线程直接操作数据；    阻塞IO和非阻塞IO 区别在于第一步数据准备阶段是否阻塞；即IO请求是否阻塞；\n同步IO和异步IO 区别在于第二部内核空间到用户空间进行数据拷贝都会阻塞用户线程；\n",
    "ref": "/blog/concurrence/io/io/"
  },{
    "title": "下载安装Visual Studio历史版本",
    "date": "",
    "description": "",
    "body": "下载安装 历史版本\n2017 激活码   professional\nKBJFW-NXHK6-W4WJM-CRMQB-G3CDH\n  enterprise\nNJVYC-BMHX2-G77MM-4XJMR-6Q8QF\n  ",
    "ref": "/blog/windows/visual-studio/"
  },{
    "title": "Windows系统配置CMD网络代理",
    "date": "",
    "description": "",
    "body": "cmd 设置代理 x:\u0026gt;netsh\rnetsh\u0026gt;winhttp\rnetsh winhttp\u0026gt;\rnetsh winhttp\u0026gt;set proxy 127.0.0.1:1080\r设置http\\https代理 x:\u0026gt;set http_proxy=http://http.proxy.com:12345\rx:\u0026gt;set https_proxy=http://https.proxy.com:23456\rx:\u0026gt;set socks5_proxy=socks5://https.proxy.com:23456\r",
    "ref": "/blog/windows/proxy/"
  },{
    "title": "Bind-ubuntu部署配置",
    "date": "",
    "description": "",
    "body": "本文主要讲解bind部署以及配置应用。\ndocker部署  拉取镜像: docker pull sameersbn/bind:latest 启动容器: mkdir -p ~/bind \\\rdocker run --name='bind' -d --restart=always -p 53:53/udp -p 10000:10000/tcp \\\r-e WEBMIN_ENABLED=true \\\r-v ~/bind:/data \\\rsameersbn/bind:latest\r参数说明:  -p 53:53/udp DNS默认端口 -p 10000:1000 Webmin图形化管理页面端口 -e WEBMIN_ENABLED=true 开启图形化界面管理器 -v ~/bind:/data 配置DNS存储目录   备注: 确认53端口不被占用。ubuntu系统中容器启动前需要禁用system-resolved服务。 \rsudo systemctl disable systemd-resolved\rsudo systemctl stop systemd-resolved\r\n  检查服务端口状态  检查53端口 $ ss -lnup\rState Recv-Q Send-Q Local Address:Port Peer Address:Port Process UNCONN 0 0 0.0.0.0:631 0.0.0.0:* UNCONN 0 0 0.0.0.0:45957 0.0.0.0:* UNCONN 0 0 0.0.0.0:5353 0.0.0.0:* UNCONN 0 0 *:53 *:* UNCONN 0 0 [::]:58213 [::]:* UNCONN 0 0 [::]:5353 [::]:*  检查10000端口 asj@asj-mdl:~$ ss -lntp\rState Recv-Q Send-Q Local Address:Port Peer Address:Port Process LISTEN 0 128 0.0.0.0:22 0.0.0.0:* LISTEN 0 4096 *:10000 *:* LISTEN 0 128 [::]:22 [::]:*     Web页面配置  打开地址: https://localhost:10000  这里scheme必须是https\n  登录页面： 默认用户名/密码： root/password 使用中文可以修改页面语言:   DNS服务配置  备注: 本地网段172.16.3.0/24, DNS服务地址: 172.16.3.10\n 全局转发配置 配置全球DNS地址\n访问控制列表配置 创建正向主区域 创建反向主区域 编辑正向主区域 添加正向地址记录\n 添加完后，默认生成反向地址记录  应用配置 ",
    "ref": "/blog/network/dns/bind/"
  },{
    "title": "Windows下Wireshark抓包问题",
    "date": "",
    "description": "",
    "body": "windows 本地抓包 在进行通信开发的过程中，我们往往会把本机既作为客户端又作为服务器端来调试代码，使得本机自己和自己通信。 但是wireshark此时是无法抓取到数据包的，需要通过简单的设置才可以。\n具体方法如下：\n  方法一\n 以管理员身份运行cmd route add 本机ip mask 255.255.255.255 网关ip 如：route add 172.16.51.115 mask 255.255.255.255 172.16.1.1 使用完毕后用route delete 172.16.51.115 mask 255.255.255.255 172.16.1.1删除，否则所有本机报文都经过网卡出去走一圈回来很耗性能。 此时再利用wireshark进行抓包便可以抓到本机自己同自己的通信包，这样配置的原因是将发往本机的包发送到网关，而此时wireshark可以捕获到网卡驱动的报文实现抓包。   但这样有一个缺点，那就是本地请求的URL的IP只能写本地的IP地址，不能写localhost或127.0.0.1，写localhost或127.0.0.1还是抓不到包。\n   方法二\nwindows系统没有提供本地回环网络的接口，用wireshark监控网络的话只能看到经过网卡的流量，看不到访问localhost的流量， 因为wireshark在windows系统上默认使用的是WinPcap来抓包的，现在可以用Npcap来替换掉WinPcap， Npcap是基于WinPcap 4.1.3开发的，api兼容WinPcap。\n 下载安装包 Npcap项目主页，它采用的是MIT开源协议，Npcap下载 安装 安装时要勾选 Use DLT_NULL protocol sa Loopback \u0026hellip; 和 install npcap in winpcap api-compat mode，如下所示。    方法三\nRawCap\n  ",
    "ref": "/blog/windows/%E6%9C%AC%E5%9C%B0%E6%8A%93%E5%8C%85/"
  },{
    "title": "Ubuntu安装配置shadowsocks",
    "date": "",
    "description": "",
    "body": "ubuntu shadowsocks 描述 ubuntu 下 shadowssocks 安装\n安装shadowsocks-libev $ sudo apt-get install software-properties-common -y $ sudo add-apt-repository ppa:max-c-lv/shadowsocks-libev -y $ sudo apt-get update $ sudo apt install shadowsocks-libev 编写配置文件 配置文件需要写入你的shadowsocks账号的信息，启动shadowsocks时需要加载这些信息，具体如下： 创建配置文件： $ sudo vi /etc/shadowsocks-libev.json 在配置文件中输入以下信息： { \u0026quot;server\u0026quot;:\u0026quot;XXXX服务器地址\u0026quot;, \u0026quot;server_port\u0026quot;:XXXX端口, \u0026quot;local_address\u0026quot;:\u0026quot;127.0.0.1\u0026quot;, \u0026quot;local_port\u0026quot;:1080, \u0026quot;password\u0026quot;:\u0026quot;XXXX密码\u0026quot;, \u0026quot;timeout\u0026quot;:60, \u0026quot;method\u0026quot;:\u0026quot;chacha20-ietf-poly1305\u0026quot;, \u0026quot;fast_open\u0026quot;:false, \u0026quot;workers\u0026quot;:1 }  XXXX需要改成你的账号对应的具体信息，method就是加密方式，这里就是chacha20-ietf-poly1305,这个要看你的账号具体要求的加密方式。\n 运行shadowsocks $ ss-local -c /etc/shadowsocks-libev.json \u0026amp;  其中 \u0026amp;是将其放在后台运行\n 设置全局代理 进入 系统设置 -\u0026gt; 网络 -\u0026gt; 网络代理，方法选择手动，然后设置Socks主机127.0.0.1， 后面端口这是1080， 然后点击应用到整个系统，输入密码即可。\n 缺点： 这样你使用的网络都是通过代理访问的，比如说我在登录微信的时候，居然提示我在未知地点登录，这样比较浪费流量，访问国内网络也使用代理，会导致访问国内网络网速较慢。所以可以使用浏览器代理，只在浏览器访问中使用代理。\n 使用polipo全局代理 设置浏览器代理 在firefox中可以通过设置浏览器的代理来使用代理访问国外网络，具体可以参考网上教程。而在ubuntu中，chrome中是不能设置代理的， 但是！但是！但是！有一个非常非常好用的插件，可以设置代理，叫Proxy SwitchyOmega, 后面菜花会给出Proxy SwitchyOmega 的简易使用教程。\n设置开机自启动 服务脚本：\n#!/bin/bash\r### BEGIN INIT INFO\r#\r# Provides: location_server\r# Required-Start: $local_fs $remote_fs\r# Required-Stop: $local_fs $remote_fs\r# Default-Start: 2 3 4 5\r# Default-Stop: 0 1 6\r# Short-Description: initscript\r# Description: This file should be used to construct scripts to be placed in /etc/init.d.\r#\r### END INIT INFO\r## Fill in name of program here.\rPROG=\u0026quot;ss-local\u0026quot;\rPROG_PATH=\u0026quot;/usr/bin/ss-local\u0026quot; ## Not need, but sometimes helpful (if $PROG resides in /opt for example).\rPROG_ARGS=\u0026quot;\u0026quot; PID_PATH=\u0026quot;/var/run/\u0026quot;\rstart() {\rif [ -e \u0026quot;$PID_PATH/$PROG.pid\u0026quot; ]; then\r## Program is running, exit with error.\recho \u0026quot;Error! $PROG is currently running!\u0026quot; 1\u0026gt;\u0026amp;2\rexit 1\relse\r## Change from /dev/null to something like /var/log/$PROG if you want to save output.\r$PROG_PATH $PROG_ARGS 2\u0026gt;\u0026amp;1 \u0026gt;/var/log/$PROG \u0026amp;\rpid=`ps ax | grep -i 'ss-local' | sed 's/^\\([0-9]\\{1,\\}\\).*/\\1/g' | head -n 1 | awk -F' ' '{print $1}'`\recho \u0026quot;$PROG started\u0026quot;\recho $pid \u0026gt; \u0026quot;$PID_PATH/$PROG.pid\u0026quot;\rfi\r}\rstop() {\recho \u0026quot;begin stop\u0026quot;\rif [ -e \u0026quot;$PID_PATH/$PROG.pid\u0026quot; ]; then\r## Program is running, so stop it\rpid=`ps ax | grep -i 'ss-local' | sed 's/^\\([0-9]\\{1,\\}\\).*/\\1/g' | head -n 1 | awk -F' ' '{print $1}'`\rkill $pid\rrm -f \u0026quot;$PID_PATH/$PROG.pid\u0026quot;\recho \u0026quot;$PROG stopped\u0026quot;\relse\r## Program is not running, exit with error.\recho \u0026quot;Error! $PROG not started!\u0026quot; 1\u0026gt;\u0026amp;2\rexit 1\rfi\r}\r## Check to see if we are running as root first.\r## Found at http://www.cyberciti.biz/tips/shell-root-user-check-script.html\rif [ \u0026quot;$(id -u)\u0026quot; != \u0026quot;0\u0026quot; ]; then\recho \u0026quot;This script must be run as root\u0026quot; 1\u0026gt;\u0026amp;2\rexit 1\rfi\rcase \u0026quot;$1\u0026quot; in\rstart)\rstart\rexit 0\r;;\rstop)\rstop\rexit 0\r;;\rreload|restart|force-reload)\rstop\rstart\rexit 0\r;;\r**)\recho \u0026quot;Usage: $0 {start|stop|reload}\u0026quot; 1\u0026gt;\u0026amp;2\rexit 1\r;;\resac\r",
    "ref": "/blog/linux/shadowsocks/shadowsocks/"
  },{
    "title": "Ubuntu安装配置v2ray",
    "date": "",
    "description": "",
    "body": "从软件源安装  debian/ubuntu 请确保已正确安装 v2ray-core\n我们提供了 Linux 下的一键安装脚本：\n 运行下面的指令下载并安装 V2Ray。当 yum 或 apt-get 可用的情况下，此脚本会自动安装 unzip 和 daemon。 这两个组件是安装 V2Ray 的必要组件。如果你使用的系统不支持 yum 或 apt-get，请自行安装 unzip 和 daemon\n # download script\rcurl -O https://cdn.jsdelivr.net/gh/v2rayA/v2rayA@master/install/go.sh\r# install v2ray-core from jsdelivr\rsudo bash go.sh\r准备完毕后：\n# add public key\rwget -qO - https://raw.fastgit.org/v2rayA/v2raya-apt/master/key/public-key.asc | sudo apt-key add -\r# add V2RayA's repository\recho \u0026quot;deb https://raw.fastgit.org/v2rayA/v2raya-apt/master/ v2raya main\u0026quot; | sudo tee /etc/apt/sources.list.d/v2raya.list\rsudo apt update\r# install V2RayA\rsudo apt install v2raya\r部署完毕后，访问该机器的2017端口即可使用，如http://localhost:2017。\narchlinux/manjaro v2raya已发布于AUR中：\ngit clone https://aur.archlinux.org/v2raya.git /tmp/v2raya\rcd /tmp/v2raya\rmakepkg -si\r如果makepkg失败，运行sudo pacman -S base-devel后再试。\n如果通过archlinuxcn源安装，需要运行systemctl enable --now v2raya。\n部署完毕后，访问该机器的2017端口即可使用，如http://localhost:2017。\nDocker方式  docker命令 仅使用 docker 命令部署。\n# run v2raya\rdocker run -d \\\r--restart=always \\\r--privileged \\\r--network=host \\\r--name v2raya \\\r-v /etc/resolv.conf:/etc/resolv.conf \\\r-v /etc/v2raya:/etc/v2raya \\\rmzz2017/v2raya\r部署完毕后，访问该机器的2017端口即可使用，如http://localhost:2017。\n 如果你使用MacOSX或其他不支持host模式的环境，在该情况下无法使用全局透明代理，docker命令会略有不同：\n# run v2raya\rdocker run -d \\\r-p 2017:2017 \\\r-p 20170-20172:20170-20172 \\\r--restart=always \\\r--name v2raya \\\r-v /etc/resolv.conf:/etc/resolv.conf \\\r-v /etc/v2raya:/etc/v2raya \\\rmzz2017/v2raya\r部署完毕后，访问该机器的2017端口即可使用，如http://localhost:2017。\n二进制文件、安装包  请确保已正确安装 v2ray-core\n我们提供了 Linux 下的一键安装脚本：\n 运行下面的指令下载并安装 V2Ray。当 yum 或 apt-get 可用的情况下，此脚本会自动安装 unzip 和 daemon。 这两个组件是安装 V2Ray 的必要组件。如果你使用的系统不支持 yum 或 apt-get，请自行安装 unzip 和 daemon\n # download script\rcurl -O https://cdn.jsdelivr.net/gh/v2rayA/v2rayA@master/install/go.sh\r# install v2ray-core from jsdelivr\rsudo bash go.sh\r准备完毕后，可下载Releases中的二进制文件启动V2RayA服务端，或下载安装包进行安装。\n部署完毕后，访问该机器的2017端口即可使用，如http://localhost:2017。\n自行编译运行  当然，你也可以选择拉取源码，编译为二进制文件运行：\n该方法同样需要正确安装v2ray-core，详情见上\ngit clone https://github.com/v2rayA/V2RayA.git\rcd V2RayA/service\r# set goproxy.io as the proxy of go modules\rexport GOPROXY=https://goproxy.io\r# compile\rgo build -o v2raya\r# run\rsudo ./v2raya\r注意，尽管 golang 具有交叉编译的特性，但由于项目使用了大量 linux commands，导致该方法仍然不支持 windows。若想在 windows 体验，可尝试借助 Docker 或 WSL。\n在NAS或路由器使用  分为以下几种情况：\ndaemon v2ray能够以daemon存在即在正确安装v2ray后，使用下述命令之一能够得到正确的反馈：\n# if systemctl is available\rsystemctl status v2ray\r# else if service is available\rservice v2ray status\r那么可从软件源安装，或下载releases中的对应安装包进行安装。\ndocker 若v2ray能够运行于docker，则可参照Docker方式使用\n通用方法 请自行安装v2ray，并确保v2ray、v2ctl均被包含在PATH中，否则请将上述文件放于echo $PATH中的任一目录下。\n下载releases中最新版本的对应CPU架构的二进制文件，或自行使用golang交叉编译。\n使用参数--config=V2RAYA_CONFIG_PATH --mode=universal启动V2RayA服务端，参数含义可执行--help查看。\n请将上述V2RAYA_CONFIG_PATH替换为一个可读写的，并且你喜欢的路径。\n安装完毕后如何使用 如果v2rayA正常运行（启动或许需要一定时间）则开放2017作为管理端口，通过浏览器访问即可进行管理。\n导入并连接正常工作的节点后，设置全局透明代理即可使用。\n如果不使用全局透明代理，可使用浏览器插件如SwitchyOmega通过下述端口进行代理：\n默认情况下开放三个代理端口：20170(socks5)、20171(http)、20172(带分流规则的http)\n或使用桌面环境提供的系统代理进行达到类似全局代理的效果。\n注意，如果通过archlinuxcn源安装，需要运行systemctl enable --now v2raya。\n环境变量 V2RAYA_ADDRESS: 监听地址 (默认 \u0026ldquo;:::2017\u0026rdquo;)\nV2RAYA_CONFIG: v2rayA 配置文件目录 (default \u0026ldquo;/etc/v2raya\u0026rdquo;)\nV2RAYA_V2RAY_BIN: v2ray 可执行文件路径. 留空将自动检测. 可修改为 v2ray 分支如 xray 等文件路径\nV2RAYA_V2RAY_CONFDIR: 附加的 v2ray 配置文件目录, 该目录中的 v2ray 配置文件会与 v2rayA 生成的配置文件进行组合\nV2RAYA_WEBDIR: v2rayA 前端 GUI 文件目录 (默认 \u0026ldquo;/etc/v2raya/web\u0026rdquo;)\nV2RAYA_PLUGINLISTPORT: v2rayA 内部插件端口 (默认 32346)\nV2RAYA_PASSCHECKROOT: 跳过 root 权限检测, 确认你有 root 权限而 v2rayA 判断出错时使用\nV2RAYA_RESET_PASSWORD: 重设密码\n",
    "ref": "/blog/linux/shadowsocks/v2raya/"
  },{
    "title": "VMWare之Linux系统磁盘扩容",
    "date": "",
    "description": "",
    "body": "在VMWARE中扩容虚拟机磁盘大小 需要删除快照， 最好先克隆备份；\n查看扩容磁盘 调整完后，重新打开虚拟机，使用fdisk -l查看，可以看到我们刚刚扩容的空间已经可以看到，但没有分区，还不能使用。/dev/sda已经拥有了扩大的空间。\n分区 使用Linux的fdisk分区工具给磁盘/dev/sda分区，更可以根据提示输入m查看帮助信息，再输入n(表示增加分区)，回车后输入p(创建主分区)， 回车后partition number输入3(因为上面已经有两个分区sda1和sda2)，回车会提示输入分区的start值(通过fdisk -l 可以看出sda2的end值为3917)， 我们可以根据提示指定start值为3917，end值为默认即可(即当前最大值)，回车后输入W进行保存，分区划分完毕。\n修改分区ID 可以看到/dev/sda3的Id号为83，我们要将其改成8e(LVM卷文件系统的Id)，具体方法同上根上部中的磁盘分区大同小异，输入fdisk /dev/sda, 选择t(change a partition's system id 改变一个分区的系统ID)回车，然后选择分区3回车，然后输入L回车。然后输入8e回车，然后输入w，保存修改的分区信息。 最后输入fdisk -l ,查看ID是否修改成功。修改成功后必须重新启动linux系统才能进行后面的操作。\n格式化分区 系统重启后，格式化新的分区为ext4格式。\n初始化物理卷 格式化后，创建PV. 用pvdisplay查看当前的物理卷。然后用pvcreate指令用于将物理硬盘分区初始化为物理卷，以便被LVM使用。 要创建物理卷必须首先对硬盘进行分区，并且将硬盘分区的类型设置为8e后，才能使用pvcreat指令将分区初始化为物理卷。pvcreate /dev/sda3,创建完后， 我们可以再用pvdisplay查看到新创建的物理卷。\n扩展VG 扩展VG：当前需要查看扩充的lvm组名，可以通过vgdisplay查看，在此例中我们的组名为 VolGroup,并可以看到里面的空间只有20多G。 然后用vgextend指令用于动态的扩展卷组，它通过向卷组中添加物理卷来增加卷组的容量。vgextend VolGroup /dev/sda3,添加成功后， 我们可以用vgdisplay再次查看，容量已经添加进去。\n扩容root lvextend -L+269.95G /dev/VolGroup/lv_root /dev/sda3命令扩展空间到root下，扩容的空间要略小于VG的free空间，因此这里只输入了269.95G. 然后通过df -h查看，root空间还是没变，因为我们差最后最关键的一部。\n扩容文件系统 使用使用resize2fs命令，用于扩大或者缩小未挂载的ext2,ext3或者是ext4文件系统。具体命令为：resize2fs -p /dev/mapper/VolGroup-lv_root 290G 。 然后再用df -h查看，扩容成功。\n",
    "ref": "/blog/vmware/vmware-ubuntu-%E6%89%A9%E5%AE%B9%E7%A3%81%E7%9B%98/"
  },{
    "title": "Ubuntu安装配置无线网卡",
    "date": "",
    "description": "",
    "body": "查看所有网络 $ ifconfig -a\n打开无线网卡 $ ifconfig wlan0 up\nwlan 工具 $ apt-get install wpasupplicant\n连接无线网络 wpa_passphrase 无线网络SSID无线网络密码 \u0026gt; 配置文件名\n配置无线网络  $ auto wlan0 $ iface wlan0 inet dhcp $ wpa-conf /etc/wpa_config.conf  修改网卡名称   $ vim /etc/default/grub\rGRUB_CMDLINE_LINUX=\u0026quot;net.ifnames=0 biosdevname=0\u0026quot;\r $ update-grub  若提示没有此命令，请先输入安装命令 $ apt-get install grub2-common\n",
    "ref": "/blog/linux/ubuntu-wlan/"
  },{
    "title": "Linux Shell 常用命令记录",
    "date": "",
    "description": "",
    "body": "命令 grep 作用: 查询匹配条件的文件\n使用: grep [OPTION]... PATTERN [FILE]...\nOPTION: -r #递归查询目录\r-n #打印匹配行号\r-l #打印匹配文件\r-L #打印不匹配文件\r-c #打印匹配数量\r-I #过滤二进制文件 --binary-files=without-match\r-a #只查询文本文件 --binary-files=text\r--binary-files=Type # Type: binary,text,without-match\rsed 作用: 替换文本内容\n使用: sed [OPTION]... {script-only-if-no-other-script} [input-file]...\nOPTION:\r-e # 使用脚本处理文本内容\r-i # 直接将处理结果写入文件\rscript:\ra # 在下一行增加内容\rc # 替换当前行内容\rd # 删除当前行内容\ri # 在上一行增加内容\rs # 替换匹配内容\r示例   查找目录下所有包含查找内容的文件\n$ grep -rnI \u0026quot;查找内容\u0026quot; ./\r  替换新的内容到目录下所有包含查找内容的文件\n$ sed -i \u0026quot;s/查找内容/新内容/g\u0026quot; `grep -rlI \u0026quot;查找内容\u0026quot; ./`\r  ",
    "ref": "/blog/linux/shell/"
  },{
    "title": "记录linux常规问题和解决方案",
    "date": "",
    "description": "",
    "body": "Ubuntu国内源 清华大学 https://mirrors.tuna.tsinghua.edu.cn/help/ubuntu/\n问题：\nubuntu:~$ sudo apt update Ign:1 https://mirrors.tuna.tsinghua.edu.cn/ubuntu bionic InRelease Ign:2 https://mirrors.tuna.tsinghua.edu.cn/ubuntu bionic-updates InRelease Ign:3 https://mirrors.tuna.tsinghua.edu.cn/ubuntu bionic-backports InRelease Hit:4 https://apt.releases.hashicorp.com bionic InRelease Ign:5 https://mirrors.tuna.tsinghua.edu.cn/ubuntu bionic-security InRelease Err:6 https://mirrors.tuna.tsinghua.edu.cn/ubuntu bionic Release\rCertificate verification failed: The certificate is NOT trusted. The certificate chain uses expired certificate. Could not handshake: Error in the certificate verification. [IP: 101.6.15.130 443]\rErr:7 https://mirrors.tuna.tsinghua.edu.cn/ubuntu bionic-updates Release\rCertificate verification failed: The certificate is NOT trusted. The certificate chain uses expired certificate. Could not handshake: Error in the certificate verification. [IP: 101.6.15.130 443]\rErr:8 https://mirrors.tuna.tsinghua.edu.cn/ubuntu bionic-backports Release\rCertificate verification failed: The certificate is NOT trusted. The certificate chain uses expired certificate. Could not handshake: Error in the certificate verification. [IP: 101.6.15.130 443]\rErr:9 https://mirrors.tuna.tsinghua.edu.cn/ubuntu bionic-security Release\rCertificate verification failed: The certificate is NOT trusted. The certificate chain uses expired certificate. Could not handshake: Error in the certificate verification. [IP: 101.6.15.130 443]\rReading package lists... Done E: The repository 'https://mirrors.tuna.tsinghua.edu.cn/ubuntu bionic Release' no longer has a Release file.\rN: Updating from such a repository can't be done securely, and is therefore disabled by default.\rN: See apt-secure(8) manpage for repository creation and user configuration details.\rE: The repository 'https://mirrors.tuna.tsinghua.edu.cn/ubuntu bionic-updates Release' no longer has a Release file.\rN: Updating from such a repository can't be done securely, and is therefore disabled by default.\rN: See apt-secure(8) manpage for repository creation and user configuration details.\rE: The repository 'https://mirrors.tuna.tsinghua.edu.cn/ubuntu bionic-backports Release' no longer has a Release file.\rN: Updating from such a repository can't be done securely, and is therefore disabled by default.\rN: See apt-secure(8) manpage for repository creation and user configuration details.\rE: The repository 'https://mirrors.tuna.tsinghua.edu.cn/ubuntu bionic-security Release' no longer has a Release file.\rN: Updating from such a repository can't be done securely, and is therefore disabled by default.\rN: See apt-secure(8) manpage for repository creation and user configuration details.\r解决方案:\napt install apt-transport-https\rapt install ca-certificates\rapt update\r桌面版菜单栏消失  查看系统桌面环境  $ pgrep -l \u0026quot;gnome|kde|mate|cinnamon|lxde|xfce|jwm\u0026quot; $ ps -A | egrep -i \u0026quot;gnome|kde|mate|cinnamon|lxde|xfce|jwm\u0026quot; $ ls /usr/bin/*session* in GNOME returns /usr/bin/gnome-session (and more)\rin MATE returns /usr/bin/mate-session (and more)\rin LXDE returns /usr/bin/lxsession (and more)\rin JWM returns /usr/bin/icewm-session (should be jwm-session, not?!)\r   重置compiz后，重启Unity：$ setsid unity  Unity 是基于GNOME桌面环境的用户界面,由Canonical公司开发，主要用于Ubuntu操作系统\n   中文安装  查看当前语言: $ locale 查看系统语言包: $ locale -a 安装中文语言: $ apt-get install language-pack-zh-hans 添加中文支持: $ locale-gen zh_CN.UTF-8 设置中文系统 LANG=\u0026quot;zh_CN.uft8\u0026quot;\rLANGUAGE=\u0026quot;zh_CN.utf8\u0026quot;\r  中文乱码  拷贝windows 字体: $ cp windows/Fonts /usr/share/fonts/winfonts 修改文件权限: $ chmod u+rwx /usr/share/fonts/winfonts 建立字体缓存 $ cd /usr/share/fonts/winfonts\r$ mkfontscale\r$ mkfontdir\r$ fc-cache -fv\r 重启机器: $ reboot  启动ssh  ssh server 安装：$ sudo apt-get install openssh-server ssh server 启动: $ sudo service ssh start  修改apt 源  打开apt文件： $ vim /etc/apt/sources.list 在文件尾部添加新的源： deb http://mirrors.163.com/ubuntu/ zesty main restricted universe multiverse\rdeb http://mirrors.163.com/ubuntu/ zesty-security main restricted universe multiverse\rdeb http://mirrors.163.com/ubuntu/ zesty-updates main restricted universe multiverse\rdeb http://mirrors.163.com/ubuntu/ zesty-proposed main restricted universe multiverse\rdeb http://mirrors.163.com/ubuntu/ zesty-backports main restricted universe multiverse\rdeb-src http://mirrors.163.com/ubuntu/ zesty main restricted universe multiverse\rdeb-src http://mirrors.163.com/ubuntu/ zesty-security main restricted universe multiverse\rdeb-src http://mirrors.163.com/ubuntu/ zesty-updates main restricted universe multiverse\rdeb-src http://mirrors.163.com/ubuntu/ zesty-proposed main restricted universe multiverse\rdeb-src http://mirrors.163.com/ubuntu/ zesty-backports main restricted universe multiverse\r  ImageMagick jpg2pdf 错误：\nconvert: not authorized `test.pdf' @ error/constitute.c/WriteImage/1028.\r修复方法\n 修改文件： /etc/ImageMagick-6/policy.xml 修改此行： \u0026lt;policy domain=\u0026quot;coder\u0026quot; rights=\u0026quot;read|write\u0026quot; pattern=\u0026quot;PDF\u0026quot; /\u0026gt;  字符串hash $ echo -n 'love' | md5sum -\r实时网络监控 工具： iptraf\n安装 chrome $ sudo wget http://www.linuxidc.com/files/repo/google-chrome.list -P /etc/apt/sources.list.d/\r$ wget -q -O - https://dl.google.com/linux/linux_signing_key.pub | sudo apt-key add -\r$ sudo apt-get update\r$ sudo apt-get install google-chrome-stable\r安装flash $ sudo apt install adobe-flashplugin\n不支持armv7l 执行sudo apt update时报错:\nN: 鉴于仓库 \u0026lsquo;https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports groovy InRelease\u0026rsquo; 不支持 \u0026lsquo;armv7l\u0026rsquo; 体系结构， 跳过配置文件 \u0026lsquo;main/binary-armv7l/Packages\u0026rsquo; 的获取\n解决方案:\nsudo dpkg --remove-architecture amd\rsudo apt-get update ",
    "ref": "/blog/linux/%E5%B8%B8%E8%A7%84%E9%97%AE%E9%A2%98/"
  },{
    "title": "常用的正则表达式",
    "date": "",
    "description": "",
    "body": "语法 替换文件名中非法字符 #include \u0026lt;regex\u0026gt;\rstring fname = regex_replace(filename, \u0026quot;[\\\\s\\\\\\\\/:\\\\*\\\\?\\\\\\\u0026quot;\u0026lt;\u0026gt;\\\\|]\u0026quot;, \u0026quot;\u0026quot;)\r用户名合法性  字母数字开头，字母数字@.-_组成\n ^[A-Za-z0-9][A-Za-z0-9.@-_]{3,32}$\r",
    "ref": "/blog/regexp/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"
  },{
    "title": "Makefile是怎样让make工作的",
    "date": "",
    "description": "",
    "body": "make版本 GNU make 3.8.1\nMakefile文件告诉make命令怎样去编译和链接程序\nMakefile的规则 target ... : prerequisites ...\rcommand\r...\r target就是一个目标文件，可以是中间文件，也可以时目标文件。 prerequisites就是生成target所依赖的文件 command就是make需要执行的命令  一个例子 edit : main.o kbd.o command.o display.o \\\rinsert.o search.o files.o utils.o\rcc -o edit main.o kbd.o command.o display.o \\\rinsert.o search.o files.o utils.o\rmain.o : main.c defs.h\rcc -c main.c\rkbd.o : kbd.c defs.h command.h\rcc -c kbd.c\rcommand.o : command.c defs.h command.h\rcc -c command.c\rdisplay.o : display.c defs.h buffer.h\rcc -c display.c\rinsert.o : insert.c defs.h buffer.h\rcc -c insert.c\rsearch.o : search.c defs.h buffer.h\rcc -c search.c\rfiles.o : files.c defs.h buffer.h command.h\rcc -c files.c\rutils.o : utils.c defs.h\rcc -c utils.c\rclean :\rrm edit main.o kbd.o command.o display.o \\\rinsert.o search.o files.o utils.o\rclean clean不是一个文件，它只是一个动作，其冒号后面什么也没有，make执行的时候就不会去自动找文件依赖，也不会自动执行其后面的命令。要执行其后的命令，就需要在make命令后面明确的指出clean的名字(make clean)。\nmake如何工作 默认情况下，只要我们输入make\n make会在当前目录下找Makefile或makefile文件 找到后，它会找文件中的第一个目标(target),在上面的例子它会找到edit，并把它作为最终的目标文件 如果edit不存在或者edit后面依赖的文件修改时间比edit新，那么就会执行后面的命令来更新edit 如果edit所依赖的.o文件存在，那么make会在文件中找.o文件的依赖，并根据其规则生成.o make会一层层的找文件的依赖关系，直到编译出第一个目标文件  Makefile中变量的使用 在例子中我们可以看到\nedit : main.o kbd.o command.o display.o \\\rinsert.o search.o files.o utils.o\rcc -o edit main.o kbd.o command.o display.o \\\rinsert.o search.o files.o utils.o\r.o文件的字符串被重复使用两次，为了makefile简单并且易维护，我们可以使用变量，例如：\nobjects = main.o kbd.o command.o display.o \\\rinsert.o search.o files.o utils.o\r于是我们可以在makefile中以$(objects)的方式使用这个变量了，如果有新的.o文件加入，我们只需要简单的修改objects变量即可。改良版的Makefile是：\nobjects = main.o kbd.o command.o display.o \\\rinsert.osearch.o files.o utils.o edit : $(objects)\rcc -o edit $(objects)\rmain.o : main.c defs.h\rcc -c main.c\rkbd.o : kbd.c defs.h command.h\rcc -c kbd.c\rcommand.o : command.c defs.h command.h\rcc -c command.c\rdisplay.o : display.c defs.h buffer.h\rcc -c display.c\rinsert.o : insert.c defs.h buffer.h\rcc -c insert.c\rsearch.o : search.c defs.h buffer.h\rcc -c search.c\rfiles.o : files.c defs.h buffer.h command.h\rcc -c files.c\rutils.o : utils.c defs.h\rcc -c utils.c\rclean :\rrm edit $(objects)\r让make自动推导 GNU的make很强大，他可以自己推导文件及文件依赖关系后面的命令。于是我们没有必要去在每一个.o文件后面都写上类似的命令，因为make会自动识别和推导。 只要make看到.o文件，就会自动把.c文件加在依赖关系中。如果make找到一个whatever.o,那么whatever.c就会是whatever.o的依赖文件，并且cc -c whatever.c也会被推导出来。新的Makefile出炉了：\nobjects = main.o kbd.o command.o display.o \\\rinsert.o search.o files.o utils.o\redit : $(objects)\rcc -o edit $(objects)\rmain.o : defs.h\rkbd.o : defs.h command.h\rcommand.o : defs.h command.h\rdisplay.o : defs.h buffer.h\rinsert.o : defs.h buffer.h\rsearch.o : defs.h buffer.hf\riles.o : defs.h buffer.h command.h\rutils.o : defs.h\r.PHONY:clean\rclean : rm edit $(objects) 注：.PHONY　表示clean是个伪目标文件\r另类风格的Makefile 既然make可以自动推导，我们可以修改成以下风格\nobjects = main.o kbd.o command.o display.o \\ insert.o search.o files.o utils.o\redit : $(objects)\rcc -o edit $(objects)\r$(objects) : defs.h\rkbd.o command.o files.o : command.h\rdisplay.o insert.o search.o files.o : buffer.h\r.PHONY : clean\rclean : rm edit $(objects)\r这种风格让我们的Makefile简化，但是文件的依赖关系混乱，后续有新的.o文件时，依赖关系更混乱，不推荐使用。\n清空目标文件的规则 每个Makefile都应该写一个清空目标文件的规则，这不仅便于编译，也有利于保持文件的清洁。\n一般的风格是：\nclean : rm edit $(objects)\r更为稳健的做法是：\n.PHONY : clean\rclean : -rm edit $(objects)\r 在rm前面添加一个减号的意思是，也许某些文件除了问题，但是不要管，继续做后面的事。\n Makefile里有什么 主要包含五个东西：\n 显示规则：显示规则说明如何生成一个或者多个目标文件 隐晦规则：由于make的自动推导，我们可以比较粗糙简略的书写Makefile 变量定义：Makefile中定义一系列的变量，变量一般是字符串，当Makefile被执行时，定义的变量会被扩展成响应的引用 文件指示：包含３部分  Makefile中引用另外一个Makefile 条件定义Makefile中的有效部分，例如：c语言里面的宏#if 定义多行命令   注释：Makefile中只有行注释，注释符用#。Makefile中的#字符可以使用\\#进行转义。 格式：在Makefile中的命令需要以[Tab]键开始。  Makefile文件名 默认情况下在目录中按顺序找寻文件GNUmakefile、makefile、Makefile。如果要指定特定的文件，可以使用make -f 或者make --file。\n引用其它Makefile 在Makefile中使用include关键字可以把别的Makefile包含进来，include的语法是：\ninclude filename //filename可以是当前操作系统shell的文件模式（可以包含路径和通配符）\rmake命令开始会寻找include指出的其它Makefile，并把内容安置在当前位置。如果没有指定相对、绝对路径，make会在当前目录下寻找，如果当前目录没有找到，就会在以下目录查找：\n 如果make执行时，有\u0026quot;-I\u0026quot;或者\u0026quot;\u0026ndash;include-dir\u0026quot;参数，那么make会在这些参数指定的目录下查找。 如果目录/include(一般是:/usr/local/bin或者/usr/include)存在的化，make也会去找。  如果文件没有找到，make会生成警告，但不会马上出现致命错误。会继续载入文件，一旦完成Makefile的读取，make会再重试这些没有找到或不能读取的文件，如果还是不行，则产生致命错误。\n如果让make不理会那些无法读取的文件继续执行，则可以在include前面加一个减号-。一般我们不添加减号，直接报错。\n环境变量MAKEFILES  如果当前环境中定义了环境变量MAKEFILES，那么make会把这个变量中的值做一个类似include的动作。这个变量中的值是其它的Makefile文件，用空格分开。只是和include不同的是从环境变量中引入的Makefile不会起作用，如果环境变量中定义的文件发现错误，make也不会处理。 建议不要使用环境变量，一旦定义所有的Makefile都会受到影响，如果你的Makefile出现怪事，请查看是否定义了MAKEFILES环境变量。  make的工作方式 make工作时的执行步奏\n 读入所有的Makefile。 读入被include的其它Makefile。 初始化文件中的变量。 推导隐晦规则并分析所有规则。 为所有目标文件创建依赖关系链。 根据依赖关系，决定哪些目标需要重新生成。 执行生成命令。  ",
    "ref": "/blog/compilation/makefile/"
  },{
    "title": "常见的开源许可协议和注意事项",
    "date": "",
    "description": "",
    "body": "GPL(GNU General Public License) GPL 出发点是代码的开源/免费使用和引用/修改/衍生代码的开源/免费使用， 不允许修改/衍生后的代码作为商业软件发布和销售。 代表： linux\nBSD BSD开源协议允许自由的使用/修改源代码， 也可以将修改后的代码作为开源/专有软件发布。但是要满足三个条件：\n 源码发布，需要在源码中携带原有代码的BSD协议 类库/软件发布， 需要在类库/软件的文档和版权声明中包含原有代码的BSD协议 不可以使用开源代码的作者/机构名字做市场推广  Apache license 2.0 类似BSD协议,Apache license 是对商业应用友好的许可\nMIT 类似BSD协议,必须在修改/衍生的代码中保留原许可协议的声明。\n",
    "ref": "/blog/software-programming/%E5%BC%80%E6%BA%90%E8%AE%B8%E5%8F%AF%E5%8D%8F%E8%AE%AE/"
  },{
    "title": "Windows中文件的最新图标刷新不出来问题",
    "date": "",
    "description": "",
    "body": "磁盘上的图片被覆盖后文件预览还是旧的 reseticon.bat\n//rem 关闭Windows外壳程序explorer\rtaskkill /f /im explorer.exe\r//rem 清理系统图标缓存数据库\rattrib -h -s -r \u0026quot;%userprofile%AppDataLocalIconCache.db\u0026quot;\rdel /f \u0026quot;%userprofile%AppDataLocalIconCache.db\u0026quot;\rattrib /s /d -h -s -r \u0026quot;%userprofile%AppDataLocalMicrosoftWindowsExplorer*\u0026quot;\rdel /f \u0026quot;%userprofile%AppDataLocalMicrosoftWindowsExplorerthumbcache_32.db\u0026quot;\rdel /f \u0026quot;%userprofile%AppDataLocalMicrosoftWindowsExplorerthumbcache_96.db\u0026quot;\rdel /f \u0026quot;%userprofile%AppDataLocalMicrosoftWindowsExplorerthumbcache_102.db\u0026quot;\rdel /f \u0026quot;%userprofile%AppDataLocalMicrosoftWindowsExplorerthumbcache_256.db\u0026quot;\rdel /f \u0026quot;%userprofile%AppDataLocalMicrosoftWindowsExplorerthumbcache_1024.db\u0026quot;\rdel /f \u0026quot;%userprofile%AppDataLocalMicrosoftWindowsExplorerthumbcache_idx.db\u0026quot;\rdel /f \u0026quot;%userprofile%AppDataLocalMicrosoftWindowsExplorerthumbcache_sr.db\u0026quot;\r//rem 清理 系统托盘记忆的图标\recho y|reg delete \u0026quot;HKEY_CLASSES_ROOTLocal SettingsSoftwareMicrosoftWindowsCurrentVersionTrayNotify\u0026quot; /v IconStreams\recho y|reg delete \u0026quot;HKEY_CLASSES_ROOTLocal SettingsSoftwareMicrosoftWindowsCurrentVersionTrayNotify\u0026quot; /v PastIconsStream\r//rem 重启Windows外壳程序explorer\rstart explorer\r",
    "ref": "/blog/windows/%E6%B8%85%E7%90%86%E7%B3%BB%E7%BB%9F%E7%BC%93%E5%AD%98%E5%9B%BE%E6%A0%87/"
  },{
    "title": "linux磁盘管理和lvm磁盘扩容",
    "date": "",
    "description": "",
    "body": "reference\n磁盘管理 硬盘分区 | Hard disk add new partition   显示硬盘及所属分区情况。在终端窗口中输入如下命令： $ sudo fdisk -l\n 显示当前的硬盘及所属分区的情况。 系统提示：DIsk /dev/sdb doesn\u0026rsquo;t contain a valid partition table。 如图所示    对硬盘进行分区。在终端窗口中输入如下命令： $ sudo fdisk /dev/sdb\n 在Command (m for help)提示符后面输入m显示一个帮助菜单， 如图所示。 在Command (m for help)提示符后面输入n，执行 add a new partition指令给硬盘增加一个新分区。 出现Command action时，输入e，指定分区为扩展分区（extended）。 出现Partition number(1-4)时，输入１表示只分一个区。 后续指定起启柱面（cylinder）号完成分区, 如图所示。    在Command (m for help)提示符后面输入p，显示分区表。\n 系统提示如图所示：  Device Boot Start End Blocks Id System\r/dev/sdb1 1 26108 209712478+ 5 Extended\r  在Command (m for help)提示符后面输入w，保存分区表。\n 系统提示：The partition table has been altered! 如图所示    在终端窗口中输入如下命令： $ sudo fdisk -l\n 系统已经识别了硬盘 /dev/sdb 的分区。如图所示    硬盘格式化 | Format hard disk  显示硬盘及所属分区情况。在终端窗口中输入如下命令： $ sudo mkfs -t ext4 /dev/sdb 说明：\r-t ext4 表示将分区格式化成ext4文件系统类型。\r如图所示  挂载硬盘分区 | Mount hard disk partition   显示硬盘挂载情况。在终端窗口中输入如下命令： $ df -l\n  新硬盘分区没有挂载，无法进入和查看。在终端窗口中输入如下命令： $ sudo mount -t ext4 /dev/sdb /devdata\n  再次在终端窗口中输入如下命令： $ df -l\n 新硬盘分区已经挂载，如下图最下面的红色方框内容, 如图所示。    配置硬盘在系统启动自动挂载。在文件 /etc/fstab 中加入如下配置(如图)：\n/dev/sdb /devdata ext4 defaults 0 0\r   至此ubuntu硬盘的挂载就完成了\nlvm 磁盘扩容  显示卷组: $ sudo vgdisplay 扩容  扩容固定大小  sudo lvresize -L +10G /dev/mapper/ubuntu--vg-ubuntu--lv\rresize2fs -p /dev/mapper/ubuntu--vg-ubuntu--lv\r 扩容剩余  sudo lvextend -l +100%FREE /dev/mapper/ubuntu--vg-ubuntu--lv\rresize2fs -p /dev/mapper/ubuntu--vg-ubuntu--lv\r  ",
    "ref": "/blog/linux/%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86/"
  },{
    "title": "ubutnu本地安装实操",
    "date": "",
    "description": "",
    "body": "ubuntu U盘安装 遇到类似加载镜像文件问题，最简单粗暴的解决方案就是把挂载ubuntu server镜像文件至cdrom目录\n具体步骤如下：\n  复制安装镜像至U盘\n  进入ubuntu控制台，可以直接通过Alt+F2进入终端环境\n  查看u盘设备号 通过命令：ls /dev/sd*\n查看U盘设备，通常U盘设备为sdb,sdc,sdd等名称或以此为前缀名称。\n 如果不确定，可以将U盘拔出，然后再用 ls /dev/sd*命令查看设备，发现少了的那个就是U盘。 但一般情况下，再次插入，U盘设备号会有所改变，例如原来是sdb4，重新插入，查看一下可能是sdb5，以最后插入查看的设备号为准。    查看到U盘设备号后，卸载设备，如下：\numount /dev/sdb4 #sdb4就是当前查看得到U盘设备\r  重新挂载U盘,可以创建一个目录，然后将U盘挂载至新建目录，目的是为了找到U盘里的ubuntu server安装镜像文件，操作命令如下：\nmkdir /mnt/usb\rmount /dev/sdb4 /mnt/usb # 将U盘挂载到该目录下\r  挂载ubuntu server安装镜像文件至cdrom目录, 进入U盘目录(/mnt/usb )，找到ubuntu server安装镜像文件，并挂载镜像，操作参考如下：\ncd /mnt/usb\rmount ubuntu-16.04.4-server-amd64.iso /cdrom #挂载镜像文件位于U盘根目录\r  退出shell，进入安装向导界面安装系统。可以通过Alt+F1或者输入exit退出shell\n  ",
    "ref": "/blog/linux/ubuntu%E5%AE%89%E8%A3%85/"
  },{
    "title": "Ubuntu升级指定版本nginx",
    "date": "",
    "description": "",
    "body": " 添加nginx apt-key $ wget http://nginx.org/keys/nginx_signing.key $ sudo apt-key add nginx_signing.key\r 将下面内容中codename替换为 Ubuntu版本号(点击查看)，并将以下代码附加到/etc/apt/sources.list文件末尾： deb http://nginx.org/packages/ubuntu/ codename nginx deb-src http://nginx.org/packages/ubuntu/ codename nginx\r 安装和升级 $ sudo apt-get update\r$ sudo apt-get install nginx\r  ",
    "ref": "/blog/nginx/%E5%8D%87%E7%BA%A7/"
  },{
    "title": "git工作原理、常用命令、常见问题及解决方案",
    "date": "",
    "description": "",
    "body": "git 使用方法 创建commit tag git tag -a \u0026lt;tagname\u0026gt; \u0026lt;commitId\u0026gt; -m \u0026quot;\u0026lt;备注信息\u0026gt;\u0026quot;\rgit push origin \u0026lt;tagname\u0026gt;\r创建commit branch git branch  \n创建tag branch tag名称和branch名称不能相同\rgit checkout -b \u0026lt;branchname\u0026gt; \u0026lt;tagname\u0026gt;\r删除tag git tag -d \u0026lt;tagname\u0026gt;\rgit push origin :\u0026lt;tagname\u0026gt;\r删除错误合并 git reset --hard merge前的版本号\r记住用户名密码 git config --global credential.helper store\n修改tag名 新版本： v2.2.2\n错误版本： v0.0.0\ngit tag v2.2.2 v0.0.0 git tag -d v0.0.0\rgit push origin :refs/tags/v0.0.0\rgit push --tags\r问题 游离版本解决方案（HEAD detached from）  git branch -v //查询最后一次提交版本 git branch temp //创建临时分支 git checkout xxx // 切换到要回去的分支 git merge temp //合并临时分支 git push // 推送 git branch -d temp // 删除临时分支  github 图片加载问题 修改hosts文件,在C:\\Windows\\System32\\drivers\\etc\\hosts 文件中添加以下内容:\n# GitHub Start 192.30.253.112 github.com 192.30.253.119 gist.github.com\r151.101.184.133 assets-cdn.github.com\r151.101.184.133 raw.githubusercontent.com\r151.101.184.133 gist.githubusercontent.com\r151.101.184.133 cloud.githubusercontent.com\r151.101.184.133 camo.githubusercontent.com\r151.101.184.133 avatars0.githubusercontent.com\r151.101.184.133 avatars1.githubusercontent.com\r151.101.184.133 avatars2.githubusercontent.com\r151.101.184.133 avatars3.githubusercontent.com\r151.101.184.133 avatars4.githubusercontent.com\r151.101.184.133 avatars5.githubusercontent.com\r151.101.184.133 avatars6.githubusercontent.com\r151.101.184.133 avatars7.githubusercontent.com\r151.101.184.133 avatars8.githubusercontent.com\r",
    "ref": "/blog/github/git/"
  },{
    "title": "从每层协议及物理设备了解网络模型",
    "date": "",
    "description": "",
    "body": "OSI七层模型  物理层Physical： IEEE 802.1A、IEEE 802.2、IEEE 802.11 物理链路层Data Link: FDDI、Ethernet、Arpanet、PDN、SLP、PPP 网络层Network：IP、ICMP、ARP、RARP、AKP、UUCP 传输层Transport：TCP、UDP 会话层Session：SMTP、DNS 表示层Presentation：Telnet、rlogin、SNMP、Gopher 应用层Application：TFTP、FTP、NFS、WAIS、HTTP  TCP/IP 五层模型  物理层：中继器，集线器 数据链路层： 二层交换机 网络层： 路由器，三层交换机 传输层： 四层交换机 应用层  ",
    "ref": "/blog/network/%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/"
  },{
    "title": "Nginx配置ssl证书",
    "date": "",
    "description": "",
    "body": "  nginx 配置\n$ vim /etc/nginx/config.d\rlisten 443 ssl;\rlisten [::]:443 ssl;\rssl_certificate /etc/nginx/fullchain1.pem;\rssl_certificate_key /etc/nginx/privkey1.pem;\r  配置生效 $ nginx -s reload\n  ",
    "ref": "/blog/nginx/%E8%AF%81%E4%B9%A6%E9%85%8D%E7%BD%AE/"
  },{
    "title": "软件设计模式详解和代码示例",
    "date": "",
    "description": "总结软件设计模式，逐渐补充代码示例",
    "body": "概念 设计模式是在面向对象开发设计中反复出现问题的解决方案的总结。\n设计原则  对接口编程而不是对实现编程 优先使用对象编程而不是继承  设计模式原则  针对接口编程而不是对实现编程 优先使用对象组合而不是继承  开闭原则（Open Close Principle）  对扩展开放， 对修改关闭 为使程序的扩展性好，易于维护和升级， 在程序需要进行扩展的时候，不去修改原有代码，使用接口和抽象类。  里氏代换原则（Liskov Substitution Principle）  任何基类可以出现的地方， 子类都可以出现。 只有当派生类可以替换掉基类，且软件的功能不受影响时， 基类才是真正被复用，而派生类也能够在基类的基础上增加新的行为。 里氏代换原则是对开闭原则的补充  依赖倒转原则（Dependence Inversion Principle）  针对接口编程，依赖于抽象而不依赖于具体 依赖倒转原则是开闭原则的基础  接口隔离原则（Interface Segregation Principle）  使用多个隔离的接口，比使用单个接口要好。降低类之间的耦合  迪米特原则，又称最少知道原则（Demeter Principle）  一个实体应当尽量地减少与其他实体之间发生相互作用， 使得系统模块相对独立  合成复用原则（Composite Reuse Principle）  尽量使用合成/聚合的方式，而不是使用继承  ",
    "ref": "/blog/software-programming/%E8%BD%AF%E4%BB%B6%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"
  },{
    "title": "编译器为什么要对代码做自动优化",
    "date": "",
    "description": "",
    "body": "概括  高级编程语言提供的函数、条件语句、循环这样的抽象编程结构极大的提高了编程效率，然而，这也潜在的使性能显著下降。 编译器尝试自动优化代码以提高性能，编译器可以转化循环、条件语句和递归函数、消除代码快和利用目标指令集的优势让代码变得高效而简洁。 因此对于程序员来说写出可读性高的代码比手动优化后变得神秘而难以维护更加可贵。事实上手工优化的代码可能让编译器难以进行额外和更加有效的优化。 比起手动优化代码，程序员更应该考虑程序设计的各个方面，比如使用更快算法，引入线程级并行机制和框架特性。  ",
    "ref": "/blog/compilation/%E7%BC%96%E8%AF%91%E4%BC%98%E5%8C%96/"
  },{
    "title": "内存溢出的场景及解决方案",
    "date": "",
    "description": "",
    "body": "栈溢出 压栈内存超出系统上限，导致溢出\n 函数递归调用层次较深 局部变量体积过大  解决办法  将递归使用循环语句实现 进行尾递归优化： 这样执行的递归函数指挥占用一个栈帧，不会引起栈溢出 增加系统对进程栈分配大小 使用堆内存， 使用全局变量  尾递归  仅在函数的尾位置调用自身 通过优化，使得计算仅占产量栈空间；  常规递归：\rfunction fact(n) {\rif (n \u0026lt;= 0) {\rreturn 1;\r} else {\rreturn n * fact(n - 1);\r}\r}\r展开： 6 * fact(5)\r6 * (5 * fact(4))\r6 * (5 * (4 * fact(3))))\r// two thousand years later...\r6 * (5 * (4 * (3 * (2 * (1 * 1)))))) // \u0026lt;= 最终的展开\r尾递归：\rfunction fact(n, r) {\rif (n \u0026lt;= 0) {\rreturn 1 * r;\r} else {\rreturn fact(n - 1, r * n);\r}\r}\r展开：\rfact(6, 1) // 1 是 fact(0) 的值，我们需要手动写一下\rfact(5, 6)\rfact(4, 30)\rfact(3, 120)\rfact(2, 360)\rfact(1, 720)\r720 // \u0026lt;= 最终的结果\r堆溢出 用户动态分配内存，超出系统内存管理器限制。\n解决办法  限制和固定申请堆内存大小 禁止申请后不释放 禁止循环申请内存不中断  ",
    "ref": "/blog/memory/%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA/"
  },{
    "title": "struct为什么会有字节对齐这个概念",
    "date": "",
    "description": "",
    "body": "结构体struct  struct 是一种复合数据类型， 它是由基本数据类型组合而成(char, int, float, ...) 编译器将struct中的成员按其alignment分配空间，各个成员在内存中顺序存储 struct中的第一个成员地址为struct的首地址 struct中的每个成员地址具有对齐的特性，如int32其起始地址应该为4的倍数  字节对齐  计算机内存空间按照byte划分 各种类型数据按照规则在内存空间上排列，数据只能从特定的内存地址进行存取  为什么  某些cpu在访问没有进行对齐的变量时，会报错。比如oracle sparc系统 比较常见的没有字节对齐，会损失数据的存取效率。  大部分平台读内存都是从偶地址开始 如果int32存放在偶地址，则一个读周期就可以读出数据 如果放在奇地址，则需要2个读周期    规则  基本类型自身的对齐值  char 1byte short 2byte int/float/double 等 4byte   结构体对齐值 为其成员中对齐值最大的那个 指定/取消对齐值  指定：  #pragma pack (value) __attribute__ ((__packed__))   取消: #pragma pack ()    代码示例 struct A\r{\rint a;\rchar b;\rshort c;\r};\rstruct B\r{\rchar b;\rint a;\rshort c;\r};\r#pragma pack (2)\rstruct C\r{\rchar b;\rint a;\rshort c;\r};\r#pragma pack ()\r#pragma pack (1)\rstruct D\r{\rchar b;\rint a;\rshort c;\r};\r#pragma pack ()\r结果是:\rsizeof(strcut A)值为8\rsizeof(struct B)的值却是12\rsizeof(struct C)值是8。\rsizeof(struct D)值为7。\r",
    "ref": "/blog/compilation/%E5%86%85%E5%AD%98%E5%AF%B9%E9%BD%90/"
  },{
    "title": "十封信",
    "date": "",
    "description": "",
    "body": "《第一封》 写给你\n假如人生不曾相遇，我还是那个我，偶尔做做梦，然后，开始日复一日的奔波，淹没在这喧嚣的城市里。我不会了解，这个世界还有这样的一个你，让人回味，令我心醉。假如人生不曾相遇，我不会相信，有一种人一认识就觉得温馨，有一种人可以百看不厌。\n《第二封》 写给幸福\n一直以为幸福在远方，在可以追逐的未来。后来才发现，那些拥抱过的人，握过的手、唱过的歌、流过的泪、爱过的人、所谓的曾经，就是幸福。在无数的夜里，说过的话、打过的电话，看过的电影、流过的眼泪……看见的或看不见的感动，我们都曾经有过，然后在时间的穿梭中，一切成为了永恒！\n《第三封》 写给努力\n不要抱怨你没有一个好爸爸，不要抱怨你的工作差，不要抱怨怀才不遇无人赏识。现实有太多的不如意，就算生活给你的是垃圾，你同样能把垃圾踩在脚底下登上世界之巅。这个世界只在乎你是否在到达了一定的高度，而不在乎你是踩在巨人的肩膀上上去的，还是踩在垃圾上上去的。\n《第四封》 写给修为\n看别人不顺眼，是自己修养不够。人愤怒的那一瞬间，智商是零，过一分钟后恢复正常。人的优雅关键在于控制自己的情绪，用嘴伤害人，是最愚蠢的一种行为。\n《第五封》 写给了解\n有个懂你的人，是最大的幸福。这个人，不一定十全十美，但他能读懂你，能走进你的心灵深处，能看懂你心里的一切。最懂你的人，总是会一直的在你身边，默默守护你，不让你受一点点的委屈。真正爱你的人不会说许多爱你的话，却会做许多爱你的事。\n《第六封》 写给独自\n一个人久了，会感觉朋友越来越重要；一个人久了，会越来越喜欢在家听歌；一个人久了，就变得成熟起来，会比以前越来越爱父母；一个人久了，会独自去很多很远的地方旅游；一个人久了，就不经意悄悄流泪，但会在众人面前什么都无所谓。\n《第七封》 写给宿命\n每一段记忆，都有一个密码。只要时间，地点，人物组合正确，无论尘封多久，那人那景都将在遗忘中重新拾起。你也许会说“不是都过去了吗？” 其实过去的只是时间，你依然逃不出，想起了就微笑或悲伤的宿命，那种宿命本叫“无能为力” 。\n《第八封》 写给成长\n有时候，莫名的心情不好，不想和任何人说话，只想一个人静静的发呆。有时候，想一个人躲起来脆弱，不愿别人看到自己的伤口。有时候，走过熟悉的街角，看到熟悉的背影，突然想起一个人的脸。有时候，别人误解了自己有口无心的话，心里郁闷的发慌。有时候，发现自己一夜之间就长大了。\n《第九封》 写给来生\n如果有来生，要做一棵树，站成永恒，没有悲欢的姿势。一半在土里安详，一半在风里飞扬，一半洒落阴凉，一半沐浴阳光，非常沉默非常骄傲，不依靠不寻找。\n《第十封》 写给本真\n身边总有些人，你看见她整天都开心，率真得像个小孩，人人都羡慕她；其实，你哪里知道：前一秒人后还伤心地流着泪的她，后一秒人前即刻洋溢灿烂。他们就像向日葵，向着太阳的正面永远明媚鲜亮，在照不到的背面却将悲伤深藏。\n　亲爱的，请好好善待自己，一辈子不长！\n",
    "ref": "/blog/stories/%E5%8D%81%E5%B0%81%E4%BF%A1/"
  },{
    "title": "高级语言编译类型",
    "date": "",
    "description": "",
    "body": "概述 高级语言所编制的程序不能直接被计算机识别，必须经过转换才能被执行\n类型  静态编译（static compilation）  静态编译的程序在执行前全部被翻译成机器码。   解释型（interpretation）  解释型的程序在执行时一句一句的解释执行。   即时编译（Just-in-time compilation）  又称动态翻译，混合static compilation 和 interpretation，运行时将中间码转换成机器码编译。 JIT 首先是compilation，对代码有优化，某个函数或者任意代码第一次调用时进行编译并cache，再次遇到该函数时直接从cache中执行已经编译好的机器码，也不用像interpretation一样对代码重复解释。    ",
    "ref": "/blog/compilation/%E7%BC%96%E8%AF%91%E7%B1%BB%E5%9E%8B/"
  },{
    "title": "linux系统信号",
    "date": "",
    "description": "",
    "body": "信号列表   SIGHUP\n本信号在用户终端连接(正常或非正常)结束时发出, 通常是在终端的控制进程结束时, 通知同一 session 内的各个作业, 这时它们与控制终端不再关联。 登录 Linux 时，系统会分配给登录用户一个终端( Session )。在这个终端运行的所有程序，包括前台进程组和后台进程组，一般都属于这个 Session 。 当用户退出 Linux 登录时，前台进程组和后台有对终端输出的进程将会收到 SIGHUP 信号。这个信号的默认操作为终止进程，因此前台进程组和后台有终端输出的进程就会中止。 不过可以捕获这个信号，比如 wget 能捕获 SIGHUP 信号，并忽略它，这样就算退出了Linux 登录，wget 也能继续下载。 此外，对于与终端脱离关系的守护进程，这个信号用于通知它重新读取配置文件。\n  SIGINT\n程序终止( interrupt )信号, 在用户键入 INTR 字符(通常是 Ctrl + C )时发出，用于通知前台进程组终止进程。\n  SIGQUIT\n和 SIGINT 类似, 但由 QUIT 字符(通常是 Ctrl + / )来控制. 进程在因收到 SIGQUIT 退出时会产生 core 文件, 在这个意义上类似于一个程序错误信号。\n  SIGILL\n执行了非法指令. 通常是因为可执行文件本身出现错误, 或者试图执行数据段. 堆栈溢出时也有可能产生这个信号。\n  SIGTRAP\n由断点指令或其它 trap 指令产生. 由d ebugger 使用。\n  SIGABRT\n调用 abort 函数生成的信号。\n  SIGBUS\n非法地址, 包括内存地址对齐( alignment )出错。比如访问一个四个字长的整数, 但其地址不是 4 的倍数。它与 SIGSEGV 的区别在于后者是由于对合法存储地址的非法访问触发的(如访问不属于自己存储空间或只读存储空间)。\n  SIGFPE\n在发生致命的算术运算错误时发出. 不仅包括浮点运算错误, 还包括溢出及除数为0等其它所有的算术的错误。\n  SIGKILL\n用来立即结束程序的运行。本信号不能被阻塞、处理和忽略。如果管理员发现某个进程终止不了，可尝试发送这个信号。\n  SIGUSR1\n留给用户使用\n  SIGSEGV\n试图访问未分配给自己的内存, 或试图往没有写权限的内存地址写数据。\n  SIGUSR2\n留给用户使用\n  SIGPIPE\n管道破裂。这个信号通常在进程间通信产生，比如采用 FIFO (管道)通信的两个进程，读管道没打开或者意外终止就往管道写，写进程会收到 SIGPIPE 信号。此外用Socket 通信的两个进程，写进程在写 Socket 的时候，读进程已经终止。\n  SIGALRM\n时钟定时信号, 计算的是实际的时间或时钟时间。alarm 函数使用该信号。\n  SIGTERM\n程序结束( terminate )信号, 与 SIGKILL 不同的是该信号可以被阻塞和处理。通常用来要求程序自己正常退出，shell 命令 kill 缺省产生这个信号。如果进程终止不了，我们才会尝试 SIGKILL。\n  SIGCHLD\n子进程结束时, 父进程会收到这个信号。\n如果父进程没有处理这个信号，也没有等待( wait )子进程，子进程虽然终止，但是还会在内核进程表中占有表项，这时的子进程称为僵尸进程。这种情况我们应该避免(父进程或者忽略 SIGCHILD 信号，或者捕捉它，或者 wait 它派生的子进程，或者父进程先终止，这时子进程的终止自动由 init 进程来接管)。\n  SIGCONT\n让一个停止( stopped )的进程继续执行。本信号不能被阻塞。可以用一个 handler 来让程序在由 stopped 状态变为继续执行时完成特定的工作。例如, 重新显示提示符。\n  SIGSTOP\n停止( stopped )进程的执行。注意它和 terminate 以及 interrupt 的区别：该进程还未结束, 只是暂停执行。本信号不能被阻塞，处理或忽略。\n  SIGTSTP\n停止进程的运行, 但该信号可以被处理和忽略。用户键入 SUSP 字符时(通常是 Ctrl + Z )发出这个信号。\n  SIGTTIN\n当后台作业要从用户终端读数据时，该作业中的所有进程会收到 SIGTTIN 信号。缺省时这些进程会停止执行。\n  SIGTTOU\n类似于 SIGTTIN，但在写终端(或修改终端模式)时收到。\n  SIGURG\n有“紧急”数据或 out-of-band 数据到达 socket 时产生。\n  SIGXCPU\n超过 CPU 时间资源限制。这个限制可以由 getrlimit/setrlimit 来读取/改变。\n  SIGXFSZ\n当进程企图扩大文件以至于超过文件大小资源限制。\n  SIGVTALRM\n虚拟时钟信号。类似于 SIGALRM，但是计算的是该进程占用的 CPU 时间。\n  SIGPROF\n类似于 SIGALRM/SIGVTALRM，但包括该进程用的 CPU 时间以及系统调用的时间。\n  SIGWINCH\n窗口大小改变时发出。\n  SIGIO\n文件描述符准备就绪，可以开始进行输入/输出操作。\n  SIGPWR\nPower failure\n  SIGSYS\n非法的系统调用。\n  在以上列出的信号中，比较特殊的有：  程序不可捕获、阻塞或忽略的信号有：SIGKILL,SIGSTOP 不能恢复至默认动作的信号有：SIGILL,SIGTRAP 默认会导致进程流产的信号有：SIGABRT,SIGBUS,SIGFPE,SIGILL,SIGIOT,SIGQUIT,SIGSEGV,SIGTRAP,SIGXCPU,SIGXFSZ 默认会导致进程退出的信号有：SIGALRM,SIGHUP,SIGINT,SIGKILL,SIGPIPE,SIGPOLL,SIGPROF,SIGSYS,SIGTERM,SIGUSR1,SIGUSR2,SIGVTALRM 默认会导致进程停止的信号有：SIGSTOP,SIGTSTP,SIGTTIN,SIGTTOU 默认进程忽略的信号有：SIGCHLD,SIGPWR,SIGURG,SIGWINCH 此外，SIGIO 在 SVR4 是退出，在 4.3BSD 中是忽略；SIGCONT 在进程挂起时是继续，否则是忽略，不能被阻塞  ",
    "ref": "/blog/linux/%E7%B3%BB%E7%BB%9F%E4%BF%A1%E5%8F%B7/"
  },{
    "title": "进程启动后怎样申请和分配内存空间",
    "date": "",
    "description": "",
    "body": "栈区 stack 由编译器自动分配和释放， 存放程序运行时函数分配的局部变量、函数参数、返回数据等。操作类似数据结构中的栈。\n堆区 heap 由程序分配和手动释放。 如果程序没有主动释放，程序结束后OS回收。 分配类似于数据结构中的链表\n全局区 存放全局变量、静态数据。程序结束由OS回收。 分为已初始化全局区（data）和未初始化全局区（bss）\n常量区 存放常量字符串。程序结束后由OS回收\n代码区 存放函数体的二进制代码\n堆栈区别 申请  栈： 只要系统栈内存空间大于申请空间， 系统将为程序提供内存，否则报异常提示栈溢出； 堆： 操作系统会记录空闲内存地址的链表， 系统收到程序的申请时遍历该链表，找到大于申请空间的堆节点，将其从量表删除并分配给程序同时在该内存空间的首地址标记大小用于delete。 另外由于分配的空间不一定正好等于申请的空间大小， 系统会自动将多余的空间重新放入空闲内存地址列表；  大小限制  栈： 是向低地址扩展的数据结构， 是一块连续的内存区域。栈顶地址和栈的容量由系统预先设定。 堆： 是向高地址扩展的数据结构， 是不连续的内存区域。堆大小受限于计算机系统中有效的虚拟内存。  申请效率  栈： 由系统自动分配， 速度快。程序无法控制 堆： 由new 等分配， 速度慢，且内存不连续容易产生碎片。但是容易管理。  ",
    "ref": "/blog/compilation/%E8%BF%9B%E7%A8%8B%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D/"
  },{
    "title": "人生如戏",
    "date": "",
    "description": "",
    "body": "有些人导演生活，有些人是生活的演员， 你是哪一个。。。。\n",
    "ref": "/blog/stories/%E4%BA%BA%E7%94%9F%E5%A6%82%E6%88%8F/"
  },{
    "title": "你是真正的快乐",
    "date": "",
    "description": "",
    "body": "体会到真正的快乐，不会再轻易地感伤\n",
    "ref": "/blog/stories/%E4%BD%A0%E6%98%AF%E7%9C%9F%E6%AD%A3%E7%9A%84%E5%BF%AB%E4%B9%90/"
  },{
    "title": "编程语言分类",
    "date": "",
    "description": "",
    "body": "Program Errors  trapped errors：出错后程序终止执行，如：除0。 untrapped errors：出错后程序继续执行，会出现任意行为，如：缓冲区溢出。  Forbidden Behavious 语言设计时定义一组 Forbidden Behavious， 它必须包含所有的 untrapped errors，但可能包含 trapped errors。\nWell behaved,ill behaved  well behaved:如果程序执行不出现forbidden behavious，则为 well behaved ill behaved： 否则是ill behaved。  动态、静态类型 静态类型 编译时拒绝 ill behaved 的语言是 statically  静态类型分为两种： 显式类型explicitly typed：类型是语言的一部分。\r隐式类型implicitly typed：类型通过编译推\r 动态类型 dynamically 运行时拒绝ill behaved的语言是 dynamically typed\r 类型安全： 是否在运行时进行类型检查，是否类型错误。\r ",
    "ref": "/blog/software-programming/%E8%AF%AD%E8%A8%80%E7%B1%BB%E5%9E%8B/"
  },{
    "title": "编程的基本风格或典范模式(programming paradigm)",
    "date": "",
    "description": "",
    "body": "编程范式（programming paradigm） 概念  编程的基本风格或典范模式，是如何编写程序的方法论。 哲学观点：编程者在创造虚拟世界，而编程范式就是他们置身其中不自觉采用的世界观和方法论。 编程是为了解决问题，而解决问题可以有多种视角和思路，其中普适且行之有效的模式被归结为范式。 由于着眼点和思维方式不同，相应的范式有自己的侧重和偏向，因此范式常用\u0026rsquo;oriented\u0026rsquo;描述。换言之每种范式都引导编程者带着某种倾向去分析问题、解决问题，这不就是‘导向’吗？ 编程范式是抽象的，必须通过具体的编程语言来体现。任何编程语言在设计中都会倾向于某些编程范式，一种编程范式可以在不同的编程语言中体现，一种编程语言也可以适用多种范式。  常见编程范式  命令式（Imperative Programming）\n命令“机器”如何去做(how)，这样不管你想要的是什么(what)，它都会按照命令实现。 声明式（Declarative Programming) 告诉“机器”你想要的是什么(what)，让“机器”推导如何去做(how).  函数式（Function Programming） 将机器运算当作是函数运算，并且避免使用程序状态及易变对象\r 逻辑编程（Logic programming） 设置答案需要匹配的规则解决问题，而不是设置步骤解决问题。\r编程语言：Prolog\r 过程式（Procedural Programming) 主要采用程序调用（Procedure call）或函数调用（Function call）来进行流程控制。\r 面向对象(Object Programming） 对象作为程序的单元，将程序和数据封装其中。对象是相互独立和相互调用。 ",
    "ref": "/blog/software-programming/%E7%BC%96%E7%A8%8B%E8%8C%83%E5%BC%8F/"
  },{
    "title": "忧郁",
    "date": "",
    "description": "",
    "body": "性格使然， 总是很忧郁。。。\n",
    "ref": "/blog/stories/%E5%BF%A7%E9%83%81/"
  },{
    "title": "离开前",
    "date": "",
    "description": "",
    "body": "有一天 你会发现当离开这个有爱的地方时，最后 会再做些什么 。。。\n",
    "ref": "/blog/stories/%E7%A6%BB%E5%BC%80%E5%89%8D/"
  },{
    "title": "Nginx-Http配置",
    "date": "",
    "description": "",
    "body": "真实IP location / {\rproxy_set_header X-Real-IP $remote_addr;\rproxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\rproxy_set_header Host $http_host;\rproxy_set_header X-NginX-Proxy true;\rproxy_pass http://127.0.0.1:4567/;\rproxy_redirect off;\r}\r",
    "ref": "/blog/nginx/http/"
  },{
    "title": "关于我",
    "date": "",
    "description": "寻找快乐的方式",
    "body": "往事讲一遍，是最初的感受。有些事情一次就好。\n相关链接：\n  https://github.com/zylhorse\n  https://zylhorse.github.io\n  zylhrose@126.com\n  zylhorse   ",
    "ref": "/about/"
  },{
    "title": "联系",
    "date": "",
    "description": "",
    "body": "",
    "ref": "/contact/"
  }]
