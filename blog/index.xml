<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Blog on zylhorse blog</title>
    <link>https://zylhorse.github.io/blog/</link>
    <description>Recent content in Blog on zylhorse blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Mon, 07 Feb 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://zylhorse.github.io/blog/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Hugo评论系统-Gitalk</title>
      <link>https://zylhorse.github.io/blog/hugo/gitalk/</link>
      <pubDate>Mon, 07 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/hugo/gitalk/</guid>
      <description>注册GitHub OAuth application
  配置config.toml
[params.gitalk]enable = trueclientId = &amp;quot;&amp;quot;clientSecret = &amp;quot;&amp;quot;repo = &amp;quot;&amp;quot; # 保存评论的repoowner = &amp;quot;&amp;quot; //app 所有者admin = &amp;quot;&amp;quot; //app 所有者perPage = 20 # 每页评论条数，最大100pagerDirection = &amp;quot;last&amp;quot; # 评论排序方式： 最新：last， 最早：first  配置comments.html 在layouts/_default/comments.html中添加一下代码：
{{- if .Site.Params.valine.gitalk -}} &amp;lt;div id=&amp;quot;gitalk-container&amp;quot; class=&amp;quot;gcomments&amp;quot;&amp;gt;&amp;lt;/div&amp;gt;&amp;lt;link rel=&amp;quot;stylesheet&amp;quot; href=&amp;quot;https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css&amp;quot;&amp;gt;&amp;lt;script src=&amp;quot;https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;&amp;lt;script&amp;gt;const gitalk = new Gitalk({clientID: {{ .Site.Params.gitalk.clientId }},clientSecret: {{ .</description>
    </item>
    
    <item>
      <title>Hugo评论系统-Utteranc</title>
      <link>https://zylhorse.github.io/blog/hugo/utteranc/</link>
      <pubDate>Mon, 07 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/hugo/utteranc/</guid>
      <description>安装Utteranc
 进入Utteranc GitHub App 在页面中选择你要添加的repo,进行安装    配置config.toml
## Utterances[params.utterances]enable = truerepo = &amp;quot;zylhorse/zylhorse.github.io&amp;quot; // 这里替换为你的github repoissueTerm = &amp;quot;title&amp;quot; // issue 标题， 基于当前文章标题/路径..theme = &amp;quot;github-light&amp;quot; // 风格themeDark = &amp;quot;photon-dark&amp;quot; 参考： https://utteranc.es/
   配置comments.html 在layouts/_default/comments.html中添加一下代码：
{{ if .Site.Params.utterances.enable }}&amp;lt;label&amp;gt;{{ jsonify .Params.categories }}&amp;lt;/label&amp;gt;&amp;lt;article class=&amp;quot;ucomments&amp;quot;&amp;gt;&amp;lt;script src=&amp;quot;https://utteranc.es/client.js&amp;quot;repo={{ .Site.Params.utterances.repo }}issue-term={{ .Site.Params.utterances.issueTerm }}label={{ jsonify .Params.categories }} // 以categories作为issue的labelstheme={{ .</description>
    </item>
    
    <item>
      <title>Hugo评论系统-Valine</title>
      <link>https://zylhorse.github.io/blog/hugo/valine/</link>
      <pubDate>Mon, 07 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/hugo/valine/</guid>
      <description>注册LeanCloud开发版
 创建LeanCloud应用 获取appId和appKey,用于以下配置    配置config.toml
 # Valine.# You can get your appid and appkey from https://leancloud.cn# more info please open https://valine.js.org[params.valine]enable = trueappId = &amp;quot;appId&amp;quot;appKey = &#39;appKey&#39;notify = false # 邮件通知verify = false # 是否需要验证码avatar = &amp;quot;&amp;quot; # 空字符串默认使用Gravatar头像placeholder = &#39;说点什么吧...&#39;visitor = true  配置comments.html 在layouts/_default/comments.html中添加一下代码：
{{- if .Site.Params.valine.enable -}}&amp;lt;!-- id 将作为查询条件 --&amp;gt;&amp;lt;div id=&amp;quot;vcomments&amp;quot; style=&amp;quot;border: #4d99bf&amp;quot;&amp;gt;&amp;lt;/div&amp;gt;&amp;lt;script src=&amp;quot;//cdn1.</description>
    </item>
    
    <item>
      <title>Hugo评论系统</title>
      <link>https://zylhorse.github.io/blog/hugo/comments/</link>
      <pubDate>Sun, 06 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/hugo/comments/</guid>
      <description>评论系统 Hugo自带Disqus评论系统，无法在国内加载。本系统采用Utterances。国内推荐以下评论系统：
   名称 简介 优缺点     Valine 诞生于2017年8月7日，是一款基于LeanCloud的无后端评论系统 1.样式简洁,有回复功能 2. LeanCloud免费容器无法24小时在线，需要配置定时器，防止服务休眠3. Valine-Admin 可以实现评论管理，配置复杂度较高   Utterances 基于Github Issue的评论系统 1. 配置简单 2. 无回复功能 3. 基于Github Issue，可以进行评论管理   Gitalk 基于GitHub Issue和Preact开发的评论插件 1. 配置简单
2. 有回复功能 3. 基于Github Issue，可以进行评论管理    </description>
    </item>
    
    <item>
      <title>Hugo使用手册</title>
      <link>https://zylhorse.github.io/blog/hugo/hugo/</link>
      <pubDate>Sat, 05 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/hugo/hugo/</guid>
      <description>画图工具 https://app.diagrams.net/
http://asciiflow.com/
bind ip 使本地可被其他机器访问： hugo --bind x.x.x.x
 x.x.x.x 可以是0.0.0.0 也可以是本机ip
 添加文章引用 Hugo 提供了两种 shortcode 用来在文档中插入引用链接地址： ref 和 relref ，语法如下：
 relref 插入被引用文档的相对链接地址，而 ref 则插入被引用文档的完整链接地址。 ref 和 relref 的唯一参数是文档路径+锚点组成的字符串，并且文档路径和锚点都是可选的  当参数中只含有文档路径时，会插入被引用文档的链接地址； 当参数中只含有锚点时，会插入当前文档的锚点链接地址； 当参数中二者都存在时，会插入被引用文档的锚点链接地址。     锚点是文档标题，如果标题有空格则将空格替换成中划线-
 </description>
    </item>
    
    <item>
      <title>Protocol Buffers - FAQ</title>
      <link>https://zylhorse.github.io/blog/data-structure/protocol-buffers/faq/</link>
      <pubDate>Thu, 28 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/data-structure/protocol-buffers/faq/</guid>
      <description>本文讨论一些Protocol Buffers 开源项目的一些常见问题。 如果你有一些问题，这里没有回答，请加入讨论组并提问。
普通问题 为什么发布Protocol Buffers？
有以下几个原因:
 Protocol Buffers 在Google中几乎被每个人使用。我们有许多想要开源发布的项目在使用protocol buffers, 因此我们需要首先发布protocol bufeers。事实上，一些技术已经可以在开源项目中找到 - 如果你深入Google AppEngine 代码，你会发现它们。 我们愿意提供接收protocol buffers和XML的公共API, 因为这非常高效，而且我们只是把XML转换成protocol buffers。 我们认为Google之外的人会发现protocol buffers会很有用 将protocol buffers变成我们乐意发布的形式是有趣20%的项目。  为什么首次发布版本2？版本1发生了什么？
protocol buffers的初始版本(亦名Proto1)最早在2001年在Google内开始开发，经过多年的发展，当有人需要并且愿意自己做，就会萌生出新的特性。 就像任何以这种方式创造出来的东西一样，它有点混乱。我们得出的结论是，按照现在的样子发布代码是不可行的。
版本2(Proto2)是一个完全重写的版本，尽管它保留了大部分的设计并使用了许多来自Proto1的实现思想。添加了一些功能，删除了一些。 然而，最重要的是，代码被清理干净，并且没有任何依赖于尚未开放源码的Google库。
为什么命名为&amp;quot;Protocol Buffers&amp;quot;？
这个名称源于该格式的早期，那时还没有协议缓冲区编译器来为我们生成类。 当时，有一个名为ProtocolBuffer的类，它实际上充当了单个方法的缓冲区。 用户可以通过调用AddValue(tag, value)等方法将tag/value对分别添加到这个缓冲区。 原始字节被存储在一个缓冲区中，一旦消息被构造好，这个缓冲区就可以被写出来。
从那时起，名称中的“buffers”部分就失去了意义，但它仍然是我们使用的名称。今天，人们通常使用术语“protocol message”来指抽象意义上的message， “protocol buffer”指消息的序列化副本，“protocol message object”指表示已解析消息的内存对象。
Google还有Protocol Buffers的任何专利吗？
Google目前没有关于Protocol Buffers的授权专利，我们很高兴解决人们可能有的关于协议缓冲区和专利的任何担忧。
技术类问题  Similar Technologies
 Protocol Buffers 和 XML 有什么不同?
答案见概述页
Protocol Buffers和ASN.1,COM,CORBA,Thrift,etc 有什么不同？
我们认为所有这些系统都有优点和缺点。Google内部依赖protocol buffers，并且它是我们成功的重要组成部分， 但是这并不意味着它是所有问题的理想解决方案。你应该在自己项目中评估以上每一个选项。
但是，值得注意的是，这些技术中有几种同时定义了交换格式和RPC(远程过程调用)协议。协议缓冲区只是一种交换格式。 它们可以很容易地用于RPC——实际上，它们对定义RPC services 的支持是有限的——但是它们没有绑定到任何一个RPC实现或协议。</description>
    </item>
    
    <item>
      <title>Protocol Buffers - Version 3指南</title>
      <link>https://zylhorse.github.io/blog/data-structure/protocol-buffers/guide/</link>
      <pubDate>Thu, 28 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/data-structure/protocol-buffers/guide/</guid>
      <description>本指南描述如何使用Protocol Buffers语言来构建Protocol Buffers数据结构。 包括.proto文件语法以及如何从.proto文件生成数据访问类。
 所有示例指定语言为Go
[PB2] 表示pb version2 的指南
[PB3] 表示pb version3 的指南
 定义Message  Defining A Message Type
 首先看一个简单的例子。这里我们定义一个搜索请求的message格式，每条搜索请求包含查询字符串，整数页码和每页结果条数。
示例:
[PB2]syntax = &amp;quot;proto2&amp;quot;;message SearchRequest {required string query = 1;optional int32 page_number = 2;optional int32 result_per_page = 3;}[PB3]syntax = &amp;quot;proto3&amp;quot;;message SearchRequest {string query = 1;int32 page_number = 2;int32 result_per_page = 3;}SearchRequest 定义了三个字段, 每个字段包含：type name = filed number; (参考规范)</description>
    </item>
    
    <item>
      <title>Protocol Buffers - 技巧</title>
      <link>https://zylhorse.github.io/blog/data-structure/protocol-buffers/techniques/</link>
      <pubDate>Thu, 28 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/data-structure/protocol-buffers/techniques/</guid>
      <description>本文描述处理protocol buffer的一些常用设计模式。你也可以发送设计和使用问题到Protocol Buffers 讨论组
流化多个Message  Streaming Multiple Messages
 如果你想要写多个message到单个文件或流中，由你确定跟踪一个message结束位置和下一个message开始的位置。protocol buffer格式不是自定义的， 因此protocol buffer解析器无法自行确定消息的结束位置。解决这个问题最简单的方法是在写message之前，先写message大小。 当你读入message时，先读大小，然后读取字节到一个单独的缓冲区，再从缓冲区解析。(如果你想要避免拷贝字节到一个独立的缓冲区， 请检查CodedInputStrem类(C++和Java中)，它可以告知将读取限制为特定的字节数)
大数据集  Large Data Sets
 protocol buffer不是为处理大型message而设计的。根据一般经验，如果每个处理的message都大于1M字节, 那么需要考虑替代方案。
这就是说，protocol buffer非常适合处理大型数据集中的单个message。通常，大型数据集实际上只是小块的集合，其中每小块可能是结构化的数据块。 尽管protocol buffer不能一次处理整个集合，使用protocol buffer来编码每块可以大大简化你的问题: 现在你只需要处理一组字节字符串，而不是一组结构。
protocol buffer不包含对大数据集的内置支持，因为不同的情况需要不同的解决方案。有些时候一个简单的记录列表就可以， 而其它时候你需要一个类似数据库的东西。每一种解决方案应该作为单独的库来开发，这样只有需要它的人才需要支付成本。
自描述Message  Self-describing Messages
 protocol buffer不包含它们自己类型的描述。因此，只给出一条原始message，而没有定义其类型的对应的.proto文件，这很难提取出任何有用的数据。
但是，注意，.proto文件的内容本身可以使用protocol buffer表示。src/google/protobuf/descriptor.proto文件定义了所涉及的message类型。 protoc可以输出一个FileDescriptorSet－表示一组.proto文件－使用--descriptor_set_out选项。这样，你可以像以下定义一个自描述的message：
syntax = &amp;quot;proto3&amp;quot;;import &amp;quot;google/protobuf/any.proto&amp;quot;;import &amp;quot;google/protobuf/descriptor.proto&amp;quot;;message SelfDescribingMessage {// Set of FileDescriptorProtos which describe the type and its dependencies.google.protobuf.FileDescriptorSet descriptor_set = 1;// The message and its type, encoded as an Any message.</description>
    </item>
    
    <item>
      <title>Protocol Buffers - 简介</title>
      <link>https://zylhorse.github.io/blog/data-structure/protocol-buffers/instroduction/</link>
      <pubDate>Thu, 28 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/data-structure/protocol-buffers/instroduction/</guid>
      <description>概述 Protocol Buffers 是一种语言无关、平台无关，可扩展的序列化结构数据的机制。- 类似XML，但是更小、更快、更简单。 只需定义一次数据结构，就可以生成指定的源代码，使用不同的语言向数据流读取和写入结构数据。
Protocol Buffers目前支持生成Java、Python、Objective-C和C++等语言的代码。 在proto3版本中，新增Dart、Go、Ruby和C#等更多语言。</description>
    </item>
    
    <item>
      <title>Protocol Buffers - 编码规范</title>
      <link>https://zylhorse.github.io/blog/data-structure/protocol-buffers/style_guide/</link>
      <pubDate>Thu, 28 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/data-structure/protocol-buffers/style_guide/</guid>
      <description>这篇文章讲述.proto文件的编写规范。根据以下约定，将会使你的protocol buffer messgae定义和它们对应的类保持一致并易于阅读。
注意，protocol buffer规范是随着时间改变的，因此你可能会看到用不同的约定或格式编写的.proto文件。 当你修改这些文件的时候，请尊重现有的格式。保持一致就好。但是当你创建新的.proto文件时，最好采用当前的格式。
标准文件格式  Standard file formatting
  保持每一行长度限制在80字符内 使用2个空格缩进 字符串最好使用双引号  文件结构  File structure
 文件应该命名为: lower_snake_case.proto
所有的文件应该按照以下习惯排列：
 License header File overview(文件概述) Syntax Package Imports (需要排序) File options(文件选项) Everything else (其它声明)  Packages package名称应该时小写，并且应该对应目录层级。e.g.,如果文件在my/package中，那么package名字应该是my.package。
Message和字段名  Message and field names
 message: 使用驼峰命名法(首字母大写),例如: SongServerRequest.
字段: 使用underscore_separated_names命名(包括oneof和extension),例如: song_name。 Use CamelCase (with an initial capital) for message names – for example, SongServerRequest. Use underscore_separated_names for field names (including oneof field and extension names) – for example, song_name.</description>
    </item>
    
    <item>
      <title>Protocol Buffers - 规范</title>
      <link>https://zylhorse.github.io/blog/data-structure/protocol-buffers/reference/</link>
      <pubDate>Thu, 28 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/data-structure/protocol-buffers/reference/</guid>
      <description>本文是Protocol Buffers语言规范的参考文档。语法使用EBNF.
 [PB2] 表示pb version2 的规范
[PB3] 表示pb version3 的规范
 | alternation() grouping[] option (zero or one time){} repetition (any number of times)词法元素  Lexical elements
 字母和数字  Letters and digits
 letter = &amp;quot;A&amp;quot; … &amp;quot;Z&amp;quot; | &amp;quot;a&amp;quot; … &amp;quot;z&amp;quot;[PB2] capitalLetter = &amp;quot;A&amp;quot; … &amp;quot;Z&amp;quot;decimalDigit = &amp;quot;0&amp;quot; … &amp;quot;9&amp;quot;octalDigit = &amp;quot;0&amp;quot; … &amp;quot;7&amp;quot;hexDigit = &amp;quot;0&amp;quot; … &amp;quot;9&amp;quot; | &amp;quot;A&amp;quot; … &amp;quot;F&amp;quot; | &amp;quot;a&amp;quot; … &amp;quot;f&amp;quot;标识符  Identifiers</description>
    </item>
    
    <item>
      <title>Prometheus-Pushgateway</title>
      <link>https://zylhorse.github.io/blog/prometheus/pushgateway/</link>
      <pubDate>Sun, 10 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/prometheus/pushgateway/</guid>
      <description>为什么Push Pushgateway是一个中间服务，用于接收无法直接抓取的服务推送的metrics
建议 仅建议再有限的情况下使用Pushgateway。与Promethues的pull模式收集metrics相比， Pushgateway有以下几个问题:
 当通过单个Pushgateway监控多个实例时， 它既是单点故障也是性能瓶颈 失去Prometheus对实例自动的健康监测(通过up metrics) Pushgateway永远不会丢弃push给它的数据，暴露所有数据给Prometheus除非你调用Pushgateway的接口手动删除。  部署 docker  命令 sudo docker run -d -p 9091:9091 -v /opt/prometheus/pushgateway.yml:/etc/prometheus/pushgateway.yml --name pushgateway prom/pushgateway --web.enable-admin-api --web.config.file=/etc/prometheus/pushgateway.yml pushgateway.yml  basic_auth_users:username: $2y$10$OhmMjosTa7QjcjFKZyFCw.wixAen5yGsvsIRoGenvxjFwRG.fkGn2 配置basic_auth_users  安装htpasswd：sudo apt install apache2-utils 生成密码: htpasswd -nBC 10 &amp;quot;&amp;quot; | tr -d &#39;:\n&#39;    </description>
    </item>
    
    <item>
      <title>Prometheus-Job和Instance</title>
      <link>https://zylhorse.github.io/blog/prometheus/jobinstance/</link>
      <pubDate>Fri, 24 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/prometheus/jobinstance/</guid>
      <description>在Prometheus的术语中，可以观测的终端称为instance，通常对应的是单个进程。
一组具有相同目的的instance，例如: 为了可靠性或扩展性而复制的进程， 称为job。
如下， 一个job和四个instance:
 job: api-server  instance 1: 1.2.3.4:5670 instance 2: 1.2.3.4:5671 instance 3: 5.6.7.8:5670 instance 4: 5.6.7.8:5671    自动生成labels和时间序列
当Prometheus采集目标节点数据时，会自动附加一些labels到时间序列上，用以标识采集的目标：
 job: 配置的job名称 instance：目标节点URL部分中的&amp;lt;host&amp;gt;:&amp;lt;port&amp;gt;  如果这些label已经存在于采集的数据中，则取决于配置项honor_labels。 具体参考scrape configuration
对于每一个instance， Prometheus在以下的每个时间序列中都保存一个样本:
 up{job=&amp;quot;&amp;lt;job-name&amp;gt;&amp;quot;, instance=&amp;quot;&amp;lt;instance-id&amp;gt;&amp;quot;}:1标识instance是健康的，0标识prometheus采集失败 scrape_duration_seconds{job=&amp;quot;&amp;lt;job-name&amp;gt;&amp;quot;, instance=&amp;quot;&amp;lt;instance-id&amp;gt;&amp;quot;}: 采集的频率 scrape_samples_post_metric_relabeling{job=&amp;quot;&amp;lt;job-name&amp;gt;&amp;quot;, instance=&amp;quot;&amp;lt;instance-id&amp;gt;&amp;quot;}: metric重新设置label后剩余的样本数量 scrape_samples_scraped{job=&amp;quot;&amp;lt;job-name&amp;gt;&amp;quot;, instance=&amp;quot;&amp;lt;instance-id&amp;gt;&amp;quot;}: 目标节点暴露的样本数量 scrape_series_added{job=&amp;quot;&amp;lt;job-name&amp;gt;&amp;quot;, instance=&amp;quot;&amp;lt;instance-id&amp;gt;&amp;quot;}: 本次采集中新时间序列的大致数量  </description>
    </item>
    
    <item>
      <title>Prometheus-metric类型</title>
      <link>https://zylhorse.github.io/blog/prometheus/metrictypes/</link>
      <pubDate>Fri, 24 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/prometheus/metrictypes/</guid>
      <description>Prometheus的client库提供四个核心的metric类型。它们目前只在client库和传输协议中有区别。 Prometheus的server 还没有使用这些信息类型，并将所有的数据扁平化为无类型的时间序列。将来这种处理方式可能会改变。
Counter counter是一个累加的metric,表示单个单调递增的计数器， 它只能累加或者在重启时重置为0. 例如，你可以使用counter表示 请求服务、完成任务或产生错误的数量。
不要使用counter表示可能发生递减的metric。例如, 不要用counter表示当前正在运行的进程的数量，用gauge表示。
Gauge gauge表示一个数值可以增加或减少的metric。
gauge通常用于表示测量值，比如温度或者当前内存的使用情况。也用来计数，这些计数可以增加或减少，比如并发请求的数量。
Histogram histogram用于对观测结果进行抽样(通常是请求延时或响应数据大小),并在配置的buckets中进行计数。同时提供所有观测值的总和。
histogram有一个基础名称&amp;lt;basename&amp;gt;,在收集期间暴露多个时间序列:
 观测bucket的计数器,暴露为&amp;lt;basename&amp;gt;_bucket{le=&amp;quot;上边界值&amp;quot;} 所有观测值的总和，暴露为&amp;lt;basename&amp;gt;_sum 所有观测事件的计数，暴露为&amp;lt;basename&amp;gt;_count(同: &amp;lt;basename&amp;gt;_count{le=&amp;quot;+Inf&amp;quot;})  使用函数histogram_quantile()可以计算整个histogram甚至histogram的每个集合的分位数。 当操作bucket时，histogram是累加的。
Summary 类似于histogram， summary对观测结果进行抽样(通常是请求延时或响应数据大小)。 它同样提供了观测的总次数和观测值的总和。 它通过滑动时间窗口来计算分位数。
summary有一个基础名称&amp;lt;basename&amp;gt;,在收集期间暴露多个时间序列:
 观测事件的分位数(0 ≤ φ ≤ 1), 暴露为： &amp;lt;basename&amp;gt;{quantile=&amp;quot;&amp;lt;φ&amp;gt;&amp;quot;} 所有观测值的总和，暴露为&amp;lt;basename&amp;gt;_sum 所有观测事件的计数，暴露为&amp;lt;basename&amp;gt;_count  </description>
    </item>
    
    <item>
      <title>Prometheus-数据模型</title>
      <link>https://zylhorse.github.io/blog/prometheus/datamodel/</link>
      <pubDate>Fri, 24 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/prometheus/datamodel/</guid>
      <description>Prometheus本质上将数据存储为时间序列(以时间顺序索引的一系列的数据点): 带有时间戳的数据流属于 同一metrics和labels集合的维度。
除了存储时间序列，Prometheus还会生成临时的时间序列作为查询的结果。
名字和标签 每个时间序列，都由metrics名字和可选的labels唯一标识。
metrics名称
 指定要测量系统的一般特性(e.g. http_requests_total: 表示HTTP接收的所有请求数量) 命名格式包含ASICC字母和数字，也可以有下划线和冒号。格式需要匹配正则表达式：[a-zA-Z_:][a-zA-Z0-9_:]*   冒号保留给用户自定义的记录规则。它们不能被导出者或直接仪器使用
 labels
 开启Prometheus的维度数据模型：指定任意组合的labels给相同名称的metrics,表示该metrics的一个特殊维度实例。 例如: http_requests_total{method: &amp;quot;POST&amp;quot;, handler: &amp;quot;/api/tracks&amp;quot;} 查询语句允许根据这些维度进行过滤和聚合 修改任意label的值，包含添加和删除， 将会创建一个新的时间序列 命名格式包含ASICC字母，数字，也可以有下划线。 格式需要匹配正则表达式: [a-zA-Z_][a-zA-Z0-9_]。 以_开头的label名称，保留为内部使用。 label值可以包含任意Unicode字符 label值为空，被视为无此标签  样本 样本组成了实际的时间序列数据。 每个样本由以下组成:
 一个float64值 一个毫秒精度的时间戳  表示法 给定一个metrics名和一组labels， 时间序列一般使用下面的表示法:
&amp;lt;metric name&amp;gt;{&amp;lt;label name&amp;gt;=&amp;lt;label value&amp;gt;, ...}例如: 一个时间序列，metrics名字是api_http_requests_total，labels是method=&amp;quot;POST&amp;quot;和handler=&amp;quot;/messages&amp;quot;, 可以用以下表示法:
api_http_requests_total{method=&amp;quot;POST&amp;quot;, handler=&amp;quot;/messages&amp;quot;}</description>
    </item>
    
    <item>
      <title>Prometheus-简介</title>
      <link>https://zylhorse.github.io/blog/prometheus/introduction/</link>
      <pubDate>Fri, 24 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/prometheus/introduction/</guid>
      <description>Prometheus是一个开源的系统监控和报警工具，最初由SoundCloud构建。 从2012年开始编写，2015年开源后很多公司和组织采用Prometheus, 该项目有很多活跃的开发者和用户社区。现在Prometheus作为独立的开源项目， 独立于任何的公司。 为了强调这一点，并阐明该项目的组织结构， Prometheus在2016年加入CNCF,成为继Kubernetes后的第二个成员。
了解更多的Prometheus信息，可以参考Awesome
特性  多维数据模型，其时间序列数据由metric名称和labels键值对构成 PromQL是一种灵活的查询语句，来利用这个维度 不依赖分布式存储；单服务器节点是自治的， 支持local和remote多种模式 通过http协议的pull模式，采集时序数据 支持通过中间网关推送时序 监控目标，采用服务发现或者静态配置 支持多模式的图形和仪表盘展现  组件 Prometheus生态由很多组件组成，它们大多数是可选的：
 Prometheus server，它负责时序数据的收集和存储 Client libraries,对接Prometheus server，上报和查询数据 push gateway, 用于短期业务的监控数据推送 exporters, 用于指定服务的exporter，e.g., node exporter, redis exporter, mysql exporter alertmanager, 用于告警通知管理  架构 下图说明了Prometheus的基础架构和生态系统中的一些组件:
从上图可以看到：
 监控目标, 可以是静态配置或者服务发现 获取metrics, 可以直接从监控目标拉取，或者拉取监控目标推送到push gateway的数据 当采样的数据大于配置的缓存区大小时，Prometheus将数据持久化到local或remote 当配置alert rules时， Prometheus会定时查询数据，当规则被触发的时候，生成alert并推送到Alertmanager Alertmanager收到alert， 根据配置对alert去重，聚合，降噪， 通过email,pagerduty等途径进行告警 使用Prometheus web ui,Grafana或API等对收集的数据进行可视化  适用于 Prometheus记录纯数字的时序数据。既适用于以机器为中心的监控，也适用于面向服务架构的监控。在微服务的世界里， 其优势是支持对多维数据的收集和查询。
Prometheus是为可靠性设计的， 当系统在运行时出现问题时，可以帮助你快速的定位问题。每个Prometheus服务都是独立的， 不依赖于任何网络、存储或其它远程服务。 当其他基础设施出现问题时，你可以依赖它，并且使用Prometheus不需要安装额外的基础设施。
不适用于 Prometheus的值是可靠的。可以随时查看你系统的可用统计信息，即使在故障的条件下。如果你需要100%的精确度，例如每个请求的计费， Prometheus不是一个很好的选择，因为其收集的信息不够详细和完整， 仅收集某个时间段的数据。在这种情况下，你最好使用专门的审计系统。</description>
    </item>
    
    <item>
      <title>Prometheus-部署</title>
      <link>https://zylhorse.github.io/blog/prometheus/deploy/</link>
      <pubDate>Fri, 24 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/prometheus/deploy/</guid>
      <description>本文讲解Prometheus的docker部署方式
服务器网路配置 monitor.service.com
   服务 开放端口     prometheus 9089   pushgateway 9091   grafana 3030    prometheus 配置  创建文件 /opt/prometheus/prometheus.yml global:scrape_interval: 60sevaluation_interval: 60sscrape_configs:- job_name: pushgatewayhonor_labels: truestatic_configs:- targets: [&#39;monitor.service.com:9091&#39;]labels:instance: pushgatewaybasic_auth:username: adminpassword: 123456 配置nginx  cd /etc/nginx/conf.d 生成密码文件:htpasswd -c ./.htpasswd admin, 输入密码: 123456 创建配置文件prometheus.conf server {server_name monitor.service.com;listen 9089;listen [::]:9089;location /{auth_basic &amp;quot;Prometheus&amp;quot;;auth_basic_user_file /etc/nginx/conf.</description>
    </item>
    
    <item>
      <title>分布式监控系统-Tracing、Metrics、Logging</title>
      <link>https://zylhorse.github.io/blog/distribution-system/%E5%88%86%E5%B8%83%E5%BC%8F%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F/</link>
      <pubDate>Fri, 23 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/distribution-system/%E5%88%86%E5%B8%83%E5%BC%8F%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F/</guid>
      <description>Metrics、Tracing、Logging都是针对全局的，肯定会有重叠的部分。因此思考 使用维恩图(Venn diagram)描述三个概念的定义，用以确定三者不同的部分:
Metrics: 统计指标是可计量的，它们是在一段时间内组成单个逻辑gauge，counter，histogram的原子。 例如：
队列的当前深度可以被定义为一个gauge，根据last-writer-win原则更新总计
HTTP请求的数量可以被定义为计数器，根据简单的累加更新总计
请求时长可以被定义为一个柱状图，更新总计到时间段并产生统计摘要
Logging：用于处理离散(偶发)事件。
例如:
应用程序的debug/error信息通过syslog的滚动文件描述符，转存到ELK中
审计踪迹事件通过Kafka，存储到像BigTable这样的数据库中
特定请求的元数据信息，从服务请求中剥离，并发送给异常收集服务器，如:NewRelic
Tracing: 用于处理请求范围内的信息。任何数据或者元数据都可以绑定到系统的单个事务对象的生命周期上。
例如:
出站RPC到远程服务请求时长
发送到数据库的SQL查询文本
入站HTTP请求的关联ID
根据上述定义，可以标记重叠部分: 对于cloud-native应用来说，大部分instrumentation的典型特征是以请求范围结束，因此讨论tracing的上下文是有意义的。 但是我们可以观察到不是所有的instrumentation都绑定到请求的生命周期上：e.g. 逻辑组件的诊断信息或进程生命周期信息，与任何离散请求是正交关系。 因此不是所有(至少未经处理)的metrics或logs信息都可以硬塞进tracing系统。
我们应该意识到metrics统计数据，对应用监控有很大帮助，比如：Prometheus生态，可以展现应用的实时监控视图。 相反的，如果将metrics信息硬塞进logging系统处理，会让我们丢失一些特性。
至此，我们可以对现有系统进行分类。如：
Prometheus系统，起始是作为专一的metrics系统，慢慢的可能会向tracing系统发展，从而进行请求范围的metrics。但是不会向logging系统领域深入。
ELK生态提供日志的记录、滚动和聚合，也在其它领域不停的积累，并慢慢的集成进来。
在这三个领域中Metrics需要最少的管理资源，Logging的资源负荷往往是递增的。
由此我们可以形成容量或操作开销梯度图，又低到高，可以看出Tracing的开销居于前两者之间：</description>
    </item>
    
    <item>
      <title>OpenTracing-系统集成</title>
      <link>https://zylhorse.github.io/blog/opentracing/integration/</link>
      <pubDate>Wed, 03 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/opentracing/integration/</guid>
      <description>概述 这里讲解集成OpenTracing到你的系统中，需要做的工作。
服务端修改
 过滤器，拦截器，中间件等处理入站请求的组件 Span的载体 tracer的配置：开启/采样率/日志等  客户端修改
 过滤器，拦截器，中间件等处理出站请求的组件 tracer的配置：开启/采样率/日志等  提醒 操作名(operation name) 每个Span被创建时，都需要指定其操作名。操作名需要遵循一定的规范。
一些默认命名示例：
 请求处理方法名称 web资源名称 RPC服务和方法连接名称  确认需要追踪的方法 有些系统需要追踪所有请求， 有些系统需要追踪特定请求。 程序应该提供配置，满足这两种场景，允许用户设置。
追踪请求属性 程序有时需要记录请求的一些属性。一般避免手动设置Span的Tag信息， 有以下两种方式：
 gRPC的Span Decorator // SpanDecorator binds a function that decorates gRPC Spans.func SpanDecorator(decorator SpanDecoratorFunc) Option {return func(o *options) {o.decorator = decorator}} 添加属性配置列表TRACED_REQUEST_ATTRIBUTES, 在追踪过滤器中确认需要添加的Tags for attr in settings.TRACED_REQUEST_ATTRIBUTES:if hasattr(request, attr):payload = str(getattr(request, attr))Span.</description>
    </item>
    
    <item>
      <title>OpenTracing-Jaeger Demo</title>
      <link>https://zylhorse.github.io/blog/opentracing/jaeger/</link>
      <pubDate>Mon, 01 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/opentracing/jaeger/</guid>
      <description>Jaeger ENV JAEGER_SERVICE_NAME	The service name.
JAEGER_AGENT_HOST	The hostname for communicating with agent via UDP (default localhost).
JAEGER_AGENT_PORT	The port for communicating with agent via UDP (default 6831).
JAEGER_ENDPOINT	The HTTP endpoint for sending spans directly to a collector, i.e. http://jaeger-collector:14268/api/traces. If specified, the agent host/port are ignored.
JAEGER_USER	Username to send as part of &amp;ldquo;Basic&amp;rdquo; authentication to the collector endpoint.
JAEGER_PASSWORD	Password to send as part of &amp;ldquo;Basic&amp;rdquo; authentication to the collector endpoint.</description>
    </item>
    
    <item>
      <title>OpenTracing-概念和关键字</title>
      <link>https://zylhorse.github.io/blog/opentracing/concepts/</link>
      <pubDate>Fri, 26 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/opentracing/concepts/</guid>
      <description>Span   Example Span
 t=0 operation name: db_query t=x+-----------------------------------------------------+| · · · · · · · · · · Span · · · · · · · · · · |+-----------------------------------------------------+Tags:- db.instance:&amp;quot;customers&amp;quot;- db.statement:&amp;quot;SELECT * FROM mytable WHERE foo=&#39;bar&#39;&amp;quot;- peer.address:&amp;quot;mysql://127.0.0.1:3306/customers&amp;quot;Logs:- message:&amp;quot;Can&#39;t connect to mysql server on &#39;127.0.0.1&#39;(10061)&amp;quot;SpanContext:- trace_id:&amp;quot;abc123&amp;quot;- span_id:&amp;quot;xyz789&amp;quot;- Baggage Items:- special_id:&amp;quot;vsid1738&amp;quot;  Span 是分布式追踪系统的主要构成模块，表示分布式系统中单个独立的工作单元</description>
    </item>
    
    <item>
      <title>OpenTracing-示例练习</title>
      <link>https://zylhorse.github.io/blog/opentracing/practices/</link>
      <pubDate>Thu, 25 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/opentracing/practices/</guid>
      <description>Tracing函数 func TopLevelFunc() {span1 := opentracing.GlobalTracer().StartSpan(&amp;quot;TopLevelFunc&amp;quot;)defer span1.Finish()... // 业务逻辑} 后续，作为上述业务逻辑一部分，我们调用了function2，也想tracing。为了将此函数也附着在正在进行的trace上， 我们需要一个获取span1的方法，后续我们再讨论如何实现，现在我们假设有这样一个方法GetCurrentSpan可以获取span1:
func function2(){span1 := GetCurrentSpan()if span1 != nil {span2 := opentracing.GlobalTracer().StartSpan(&amp;quot;function2&amp;quot;, opentracing.ChildOf(span1.Context())) defer span2.Finish() } ... //业务逻辑} 假设调用者没有启动tracing，也不想在function2中创建新的tracing，需要考虑GetCurrentSpan可能返回nil
 通常情况下，开发者不希望追踪的代码混在业务代码中，而是用其他方式。 如：注解. 参考function decorator in Python: @traced_functiondef top_level_function():... # business logic
Tracing服务端 当服务想tracing一个请求的执行，需要以下几步:
 尝试从request中获取SpanContext(防止tracing已经在客户端开始)，如果无法获取request中的SpanContext则新开始一个tracing 将新创建的Span保存到request context中，request context会跟随应用程序代码或RPC框架在整个系统中传播。 最后，当服务完成请求处理后，使用span.finish()关闭Span  从请求中提取SpanContext 假设我们有一个HTTP服务，并且SpanContext已经通过HTTP headers，从客户端传递到服务器，可以通过req.Headers访问到:
extractedCtx := opentracing.GlobalTracer().Extract(opentracing.HTTP_HEADER_FORMAT, opentracing.HTTPHeadersCarrier(req.Headers) 这里我们使用headers作为载体，Tracer对象知道读取哪些headers，并将tracer数据和Baggage解构。</description>
    </item>
    
    <item>
      <title>OpenTracing-简介</title>
      <link>https://zylhorse.github.io/blog/opentracing/introduction/</link>
      <pubDate>Wed, 24 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/opentracing/introduction/</guid>
      <description>为什么Tracing  研发团队因为系统组件的水平扩展、开发团队小型化、解耦各种需求等，正在使用微服务架构替换老旧的单体系统。 这个过程中需要面临一系列的问题：由于没有内存调用和堆栈追踪，怎样在复杂的网络环境中调试和监测分布式事务。 分布式追踪系统旨在解决这些问题  模式 大多数追踪系统的Mental Model来源于这篇论文(Google&amp;rsquo;s Dapper paper)。 OpenTracing使用相似的关键词和定义。
 Trace: 在分布式系统中运行的事务的描述 Span: 工作流中的一部分被命名和定时的操作  Spans 接受k:v 标签，以及细粒度、时间戳、结构化日志附加到指定的Span实例中
  Span Context: 伴随分布式事务的追踪信息，包含它在服务间传递的时间  Span Context包含traceId，SpanId，以及追踪系统需要传递给下游服务器的其他任何数据
   追踪系统划分  从应用层分布式追踪系统的角度看，软件系统如下图：
 软件系统中的组件可以被分成以下三类：  应用和业务逻辑(自己的代码) 第三方库 第三方服务   这三类组件有不同的需求，并且推动了分布式追踪系统的设计，用于监控应用程序。最终的设计产生四个重要部分：  追踪API 通信协议 数据格式 分析系统: 用于处理追踪数据的数据库和交互式UI    OpenTracing   OpenTracing通过提供标准的、厂商无关的工具框架
  如果开发人员尝试不同的分布式跟踪系统，只需要简单的修改追踪器的配置，而不是修改整个系统的trace代码。
  OpenTracing是轻量级标准化层， 位于程序/类库和监控系统之间。
 +-------------+ +---------+ +----------+ +------------+| Application | | Library | | OSS | | RPC/IPC || Code | | Code | | Services | | Frameworks |+-------------+ +---------+ +----------+ +------------+| | | || | | |v v v v+-----------------------------------------------------+| · · · · · · · · · · OpenTracing · · · · · · · · · · |+-----------------------------------------------------+| | | || | | |v v v v+-----------+ +-------------+ +-------------+ +-----------+| Tracing | | Logging | | Metrics | | Tracing || System A | | Framework B | | Framework C | | System D |+-----------+ +-------------+ +-------------+ +-----------+上述模块简介:</description>
    </item>
    
    <item>
      <title>OpenTracing-语义规范</title>
      <link>https://zylhorse.github.io/blog/opentracing/specification/</link>
      <pubDate>Wed, 24 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/opentracing/specification/</guid>
      <description>OpenTracing Data Model 在OpenTracing中，Trace是由Span隐式定义的。 Trace可以看作是Spans的有向无环图(DAG)，Spans之间的边界称之为References.
例如以下的Trace由8个Spans组成：
Causal relationships between Spans in a single Trace[Span A] ←←←(the root span)|+------+------+| |[Span B] [Span C] ←←←(Span C is a `ChildOf` Span A)| |[Span D] +---+-------+| |[Span E] [Span F] &amp;gt;&amp;gt;&amp;gt; [Span G] &amp;gt;&amp;gt;&amp;gt; [Span H]↑↑↑(Span G `FollowsFrom` Span F)使用时间轴对Trace进行可视化表示看起来更直观些:
Temporal relationships between Spans in a single Trace––|–––––––|–––––––|–––––––|–––––––|–––––––|–––––––|–––––––|–&amp;gt; time[Span A···················································][Span B··············································][Span D··········································][Span C········································][Span E·······] [Span F··] [Span G··] [Span H··]Span Reference Span可以被其他Span引用， 因此多个Span存在因果关系。 OpenTracing定义了以下两种关系:</description>
    </item>
    
    <item>
      <title>gRPC over HTTP2</title>
      <link>https://zylhorse.github.io/blog/grpc/protocol-http2/</link>
      <pubDate>Wed, 23 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/grpc/protocol-http2/</guid>
      <description></description>
    </item>
    
    <item>
      <title>gRPC-Introduction</title>
      <link>https://zylhorse.github.io/blog/grpc/introduction/</link>
      <pubDate>Wed, 23 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/grpc/introduction/</guid>
      <description>gRPC 是开源的高性能RPC框架，可以运行在任何环境。它可以高效的连接数据中心或跨数据中心的服务， 支持可插拔的load balaning,tracing,health checking和authentication. 它同样适用于分布式计算的最后一英里，连接设备，手机app，浏览器到后端服务。
本章介绍gRPC 和 protocol buffers。 gRPC使用protocol buffers作为IDL(接口定义语言)和底层信息交换格式。
概述 在gRPC的架构中，client app可以像本地调用一样，直接调用一个远程server app方法，这使得创建分布式应用和服务更便捷。 与其他RPC系统相似， gRPC也是基于服务化的思想， 暴露方法，使其可以被远程调用。server端，实现这些方法并启动gRPC服务来处理client调用。 client端，stub提供与server端相同的方法，来被client端调用。
gRPC clients和servers可以在多种环境中运行和通信，并且可以用任何gRPC支持的语言编写。 例如：使用Java编写server，使用GO/Python/Ruby等编写client。 此外最新的API将有gRPC 版本号的支持。
Protocol Buffers gRPC默认使用Protocol Buffers序列化数据(当然也可以使用其它数据格式，如：JSON)。
动机 十年来，Google一直使用名为Stubby的单一通用RPC基础设施来连接数据中心或跨数据中心的微服务。Google的内部很早就采用当下流行的微服务架构。 使用统一的，跨平台的RPC基础设施，在效率、安全性、可靠性和行为分析方面进行全范围的改进，用以支撑业务的快速增长。
Stubby有许多强大的特性，但是它不基于任何标准并且与Google内部基础设施紧密耦合，因此不适合公开发布。 随着SPDY、HTTP/2和QUIC等具有相同特性的公共标准出现，包含Stubby没有提供的一些特性。很明显，是时候利用这些标准化来改造Stubby， 并扩展应用到mobile,loT和Cloud等场景。
原则和需求 Services not Objects, Messages not References 提倡在系统之间进行粗粒度信息交换的微服务设计理念，同时避免分布式对象的陷阱 和忽略网络错误
Coverage &amp;amp; Simplicity 这个堆栈应该对所有流行的平台是可用的，并且用户可以轻松的为其选择的平台进行构建。它应该能在CPU和内存有限的设备上使用。
Free &amp;amp; Open 使其基本功能对所有人免费使用。以开放源码的方式发布所有组件，并使用许可，应当促使而不是阻碍使用。</description>
    </item>
    
    <item>
      <title>gRPC-platform</title>
      <link>https://zylhorse.github.io/blog/grpc/platform/</link>
      <pubDate>Wed, 23 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/grpc/platform/</guid>
      <description></description>
    </item>
    
    <item>
      <title>gRPC-基准测试</title>
      <link>https://zylhorse.github.io/blog/grpc/benchmarking/</link>
      <pubDate>Wed, 23 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/grpc/benchmarking/</guid>
      <description></description>
    </item>
    
    <item>
      <title>gRPC-身份认证</title>
      <link>https://zylhorse.github.io/blog/grpc/authentication/</link>
      <pubDate>Wed, 23 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/grpc/authentication/</guid>
      <description>gRPC设计上允许使用多种身份认证机制，</description>
    </item>
    
    <item>
      <title>gRPC-错误处理</title>
      <link>https://zylhorse.github.io/blog/grpc/errorhandling/</link>
      <pubDate>Wed, 23 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/grpc/errorhandling/</guid>
      <description>本文讲述gRPC的身份认证，包括内置的身份认证机制，以及如何插入自己的认证系统。
gRPC被设计为</description>
    </item>
    
    <item>
      <title>gRPC核心概念，架构，生命周期</title>
      <link>https://zylhorse.github.io/blog/grpc/concepts/</link>
      <pubDate>Wed, 23 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/grpc/concepts/</guid>
      <description>本文介绍gRPC的主要概念，架构和生命周期
服务定义 与其它RPC系统类似，gRPC基于服务定义的概念，指定可以远程调用(使用自定义参数和返回值)的方法。 默认情况下，gRPC使用protocol buffers作为IDL，用以描述服务接口和负载信息的结构。当然，如果需要，你可以使用其它方式替代。
service HelloService {rpc SayHello (HelloRequest) returns (HelloResponse);}message HelloRequest {string greeting = 1;}message HelloResponse {string reply = 1;}gRPC提供四种定义服务的方法:
 Unary RPC, client发送单个请求到server并返回单个响应： rpc SayHello(HelloRequest) returns (HelloResponse); Server Stream RPC，client发送单个请求,server返回一个流，用以读取返回的一系列信息。 client从流中读取数据直到没有更多的信息。gRPC保证单个RPC调用中的信息顺序。 rpc LotsOfReplies(HelloRequest) returns (stream HelloResponse); Client Stream RPC, client写入一系列的信息并使用流发送它们到服务器。一旦client结束写信息， 就会等待server读取并返回响应。gRPC保证打个RPC调用中的信息顺序。 rpc LotsOfGreetings(stream HelloRequest) returns (HelloResponse); Bidirectional Stream RPC, client和server都会使用一个读写流发送一系列的信息。这两个流是独立运行的， 因此client和server可以任意的读写数据。例如:sever会在接收完所有的client信息后返回响应信息, 或者交替的接收一个client信息后返回一个响应信息，或者其它方式。 每个流中信息的顺序被保留。 rpc BidiHello(stream HelloRequest) returns (stream HelloResponse);  API使用 gRPC提供的protocol buffer插件,使用.</description>
    </item>
    
    <item>
      <title>ELK-搭建Kibana</title>
      <link>https://zylhorse.github.io/blog/elk/kibana/</link>
      <pubDate>Sun, 06 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/elk/kibana/</guid>
      <description>kibana.yml version: &#39;2&#39;services:kibana:image: docker.elastic.co/kibana/kibana:7.2.0environment:ELASTICSEARCH_HOSTS: http://192.168.20.99:9200ports:- 5601:5601restart: always</description>
    </item>
    
    <item>
      <title>ELK-搭建Filebeat</title>
      <link>https://zylhorse.github.io/blog/elk/filebeat/</link>
      <pubDate>Sat, 05 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/elk/filebeat/</guid>
      <description>安装 deb:
curl -L -O https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-7.3.0-amd64.debsudo dpkg -i filebeat-7.3.0-amd64.debrpm:
curl -L -O https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-7.3.0-x86_64.rpmsudo rpm -vi filebeat-7.3.0-x86_64.rpmdocker-compose version: &#39;2&#39;services:filebeat:image: docker.elastic.co/beats/filebeat:7.2.0container_name: filebeatrestart: alwaysvolumes:- ./config/filebeat.yml:/usr/share/filebeat/filebeat.yml- /var/lib/docker/containers:/var/lib/docker/containersuser: root容器日志配置 {&amp;quot;log-driver&amp;quot;:&amp;quot;json-file&amp;quot;,&amp;quot;log-opts&amp;quot;:{ &amp;quot;max-size&amp;quot; :&amp;quot;5m&amp;quot;,&amp;quot;max-file&amp;quot;:&amp;quot;1&amp;quot;, &amp;quot;labels&amp;quot;:&amp;quot;{{.Name}}&amp;quot;}}</description>
    </item>
    
    <item>
      <title>ELK-搭建Heartbeat</title>
      <link>https://zylhorse.github.io/blog/elk/heartbeat/</link>
      <pubDate>Sat, 05 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/elk/heartbeat/</guid>
      <description></description>
    </item>
    
    <item>
      <title>ELK-搭建Metricbeat</title>
      <link>https://zylhorse.github.io/blog/elk/metricbeat/</link>
      <pubDate>Sat, 05 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/elk/metricbeat/</guid>
      <description></description>
    </item>
    
    <item>
      <title>ELK-搭建PacketHeat</title>
      <link>https://zylhorse.github.io/blog/elk/packetheat/</link>
      <pubDate>Sat, 05 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/elk/packetheat/</guid>
      <description></description>
    </item>
    
    <item>
      <title>ELK-搭建Elasticsearch</title>
      <link>https://zylhorse.github.io/blog/elk/elasticsearch/</link>
      <pubDate>Fri, 04 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/elk/elasticsearch/</guid>
      <description>elasticsearch.yml version: &#39;2&#39;services:elasticsearch:image: docker.elastic.co/elasticsearch/elasticsearch:7.2.0container_name: elasticsearchenvironment:- bootstrap.memory_lock=true- &amp;quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&amp;quot;- &amp;quot;discovery.type=single-node&amp;quot;ulimits:memlock:soft: -1hard: -1volumes:- esdata:/usr/share/elasticsearch/dataports:- 9200:9200networks:- esnetrestart: alwaysvolumes:esdata:driver: localnetworks:esnet:</description>
    </item>
    
    <item>
      <title>ELK简介及日志收集、服务监控、性能监控</title>
      <link>https://zylhorse.github.io/blog/elk/elk/</link>
      <pubDate>Fri, 04 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/elk/elk/</guid>
      <description>elk 描述 elk 架构是指：elastic 公司三个开源的产品： elasticsearch, logstash, kibana
Elasticsearch是个开源分布式搜索引擎，提供搜集、分析、存储数据三大功能。它的特点有：分布式，零配置，自动发现，索引自动分片，索引副本机制，restful风格接口，多数据源，自动搜索负载等。
Logstash 主要是用来日志的搜集、分析、过滤日志的工具，支持大量的数据获取方式。一般工作方式为c/s架构，client端安装在需要收集日志的主机上，server端负责将收到的各节点日志进行过滤、修改等操作在一并发往elasticsearch上去。
Kibana 也是一个开源和免费的工具，Kibana可以为 Logstash 和 ElasticSearch 提供的日志分析友好的 Web 界面，可以帮助汇总、分析和搜索重要数据日志。
web地址 目前在内网服务器上搭建filebeat,metricbeat,heartbeat 等agent。 以及 elasticsearch, kibana 平台。
kibana地址： 192.168.20.30:5601
日志  查看： logs 过滤： log.file.path:xxx
  搜索： discover 索引： filebeat-7.2.0-*
 服务监控  查看：uptime
  监控服务
 硬件监控  查看：dashboard 索引： [Metricbeat System] Host overview ECS
  监控硬件：
 cpu 内存 硬盘io 磁盘io 进程信息   集成 管理后台 完整日志架构： productor -&amp;gt; nsq -&amp;gt; nsqbeat -&amp;gt; elasticsearch -&amp;gt; kibana</description>
    </item>
    
    <item>
      <title>Docker部署和配置nsqbeat</title>
      <link>https://zylhorse.github.io/blog/log-system/docker%E5%AE%89%E8%A3%85nsqbeat/</link>
      <pubDate>Thu, 03 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/log-system/docker%E5%AE%89%E8%A3%85nsqbeat/</guid>
      <description>############################# Nsqbeat ######################################nsqbeat:# A list of NSQ Lookup Daemons to connect tolookupdhttpaddrs: [&amp;quot;192.168.20.99:4161&amp;quot;]# a Topic to sucscribe totopic: &amp;quot;logic.log&amp;quot;# The channel name to joinchannel: &amp;quot;nsqbeat&amp;quot;# How many in Flightsmaxinflight: 200# If data in the topic is Json then use the decoder, if not set to something else like plaincodec: &amp;quot;text&amp;quot;# use Golang time format layout to define if @timestamp exists and has a different formattimelayout: &amp;quot;2006-01-02T15:04:05.</description>
    </item>
    
    <item>
      <title>服务治理-限流</title>
      <link>https://zylhorse.github.io/blog/distribution-system/%E9%99%90%E6%B5%81/</link>
      <pubDate>Sun, 08 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/distribution-system/%E9%99%90%E6%B5%81/</guid>
      <description>概念 当接口的访问频率或者并发请求数量超过系统的承受范围时， 需要考虑限流来保证接口的可用性；
解决方案 通常策略是拒绝多余的访问或者让多余的访问排队等待；
令牌桶 控制网络上数据的数目， 允许突发流量。系统会以一定的速度向桶里放入令牌， 如果有请求要被处理， 就去桶里面取一块令牌。 当桶里没有令牌可取时， 则拒绝请求。
import (&amp;quot;sync&amp;quot;&amp;quot;time&amp;quot;)// This implement the token buckettype TokenBucket struct {rate int64 // the number of tokens are putted to bucket per secondcapacity int64 // the capacity of buckettokens int64 // current number of tokens in bucketlastTimestamp int64 // last timestamp of putted tokens to bucket.lock sync.Mutex}func (l *TokenBucket) Allow() bool {l.</description>
    </item>
    
    <item>
      <title>gRPC-Go快速入门</title>
      <link>https://zylhorse.github.io/blog/golang/grpc/quick-start/</link>
      <pubDate>Tue, 03 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/golang/grpc/quick-start/</guid>
      <description>准备  Go 最新的三个主版本
安装: https://golang.org/doc/install Protocol Buffer 编译器 protoc
安装: https://www.grpc.io/docs/protoc-installation/ Protocol Buffer Go 插件  安装: $ export GO111MODULE=on # Enable module mode$ go get google.golang.org/protobuf/cmd/protoc-gen-go \google.golang.org/grpc/cmd/protoc-gen-go-grpc 更新环境变量 $ export PATH=&amp;quot;$PATH:$(go env GOPATH)/bin&amp;quot;    </description>
    </item>
    
    <item>
      <title>Protocol Buffer-Go FAQ</title>
      <link>https://zylhorse.github.io/blog/golang/protocol-buffers/faq/</link>
      <pubDate>Wed, 28 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/golang/protocol-buffers/faq/</guid>
      <description>版本  Versions
 github.com/golang/protobuf和google.golang.org/protobuf有什么区别?
github.com/golang/protobuf 模块是原始的Go protocol buffer API
google.golang.org/protobuf 模块是Go protocol buffer API的更新版本, 旨在更加简洁、易用和安全。 更新API的主要特性是支持反射， 以及将面向用户的API与底层实现分离。
推荐在新代码中使用google.golang.org/protobuf。
github.com/golang/protobuf的v1.4.0版本及更高版本封装了新的实现，并且允许程序逐步的采用新的API。 例如, github.com/golang/protobuf/ptypes中定义的知名类型在新模块中只是简单的别名。因此， google.golang.org/protobuf/types/known/emptypb和github.com/golang/protobuf/ptypes/empty是可以互换使用的。
proto1,proto2,proto3有什么区别? 这些都是protocol buffer语言的修订版。 它不同于protobufs的Go 实现。
 proto3是当前版本。这是该语言最常用的版本。我们鼓励新代码使用proto3。 proto2是旧版本。尽管被proto3取代，但proto2仍然受到完全支持。 proto1是废弃版本。它从未以开源的形式发布。有关proto1的更多信息，请参阅FAQ。  有几种不同的Message类型。我应该用哪个？
 &amp;ldquo;google.golang.org/protobuf/proto&amp;rdquo;.Message是接口类型， 当前版本的protocol buffer编译器生成的所有message都要实现它。操作任意message的方法，如proto.Marshal或proto.Clone， 接收或返回该值。 &amp;ldquo;google.golang.org/protobuf/reflect/protoreflect&amp;rdquo;.Message 是一个描述message反射视图的接口类型。
调用proto.Message的ProtoReflect方法，获取protoreflect.Message。 &amp;ldquo;google.golang.org/protobuf/reflect/protoreflect&amp;rdquo;.ProtoMessage 是&amp;quot;google.golang.org/protobuf/proto&amp;quot;.Message的别名。这两种类型是可以互换的。 &amp;ldquo;github.com/golang/protobuf/proto&amp;rdquo;.Message 是由遗留的Go Protocol Buffer API定义的接口类型。所有生成的message都需要实现该接口，但是该接口没有描述期望从这些message中得到的行为。 新代码应该避免使用这个类型。  常见问题  Common problems
 &amp;ldquo;go install&amp;rdquo;: working directory is not part of a module
你已经设置环境变量GO111MODULE=on，并且在模块目录之外运行go install命令。
设置GO111MODULE=auto，或者取消设置该环境变量。
constant -1 overflows protoimpl.</description>
    </item>
    
    <item>
      <title>Protocol Buffer-Go代码生成</title>
      <link>https://zylhorse.github.io/blog/golang/protocol-buffers/generated/</link>
      <pubDate>Wed, 28 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/golang/protocol-buffers/generated/</guid>
      <description>生成代码  Go Generated Code
 本章详细描述protocol buffer编译器为协议定义的类型生成对应的Go代码。 proto2和proto3生成代码的任何差异都会突出显示————注意: 文档中描述的差异都在生成的代码中，而不是两个版本都相同的基础API中。 在读这篇文章之前，请先阅读protocol buffer guide
编译器使用  Compiler Invocation
 编译器需要安装插件来生成Go代码。 安装如下:
go install google.golang.org/protobuf/cmd/protoc-gen-go此命令在$GOBIN下安装protoc-gen-go命令。安装之前修改环境变量$GOBIN的值来改变protoc-gen-go安装目录。 为了编译器找到命令，安装目录必须添加到环境变量$PATH中。
 当编译器被调用时设置参数--go_out,会创建输出目录,--go_out指定你想要编译器生成Go输出的目录。 编译器会为每个传入的.proto文件创建源文件,并替换文件的扩展名.proto为.pb.go  .proto文件需要包含go_package选项，用以指定包含生成代码的Go包的完整import路径。
示例:
option go_package = &amp;quot;example.com/foo/bar&amp;quot;;输出文件所在输出目录的子目录，取决于go_package选项和编译器参数:
 默认情况，输出文件被放在以Go包导入路径命名的目录下。例如:
设置上述go_pacakge选项的protos/foo.proto文件的输出文件名是example.com/foo/bar/foo.pb.go 如果命令行参数设置--go_opt=module=$PREFIX,指定目录前缀从输出文件名中删除。例如：
设置上述go_pacakge选项和 --go_opt=module=example.com/foo的protos/foo.proto文件的输出文件名是bar/foo.pb.go 如果命令行参数设置--go_opt=paths=source_relative,输出文件被放在与输入文件相同的相对目录下。例如: 设置上述go_pacakge选项的protos/foo.proto文件的输出文件名是protos/foo.pb.go  当运行以下编译器命令时:
protoc --proto_path=src --go_out=build/gen --go_opt=paths=source_relative src/foo.proto src/bar/baz.proto编译器读取文件src/foo.proto和src/bar/baz.proto。生成两个输出文件: build/gen/foo.pb.go和build/gen/bar/baz.pb.go
编译器会自动生成目录build/gen/bar,但是不会创建目录build或build/gen。这两层目录必须已经存在。
包  Packages
 .proto源文件需要包含go_package选项，指定包含该文件的Go包的完整导入路径。 如果没有指定选项go_package,编译器会猜测一个。 将来的编译器版本，会设置go_package选项为必选的。
生成Go包名为go_package选项定义路径的最后一个元素。 例如:
// The Go package name is &amp;quot;timestamppb&amp;quot;.</description>
    </item>
    
    <item>
      <title>Protocol Buffer-Go基础知识</title>
      <link>https://zylhorse.github.io/blog/golang/protocol-buffers/basics/</link>
      <pubDate>Wed, 28 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/golang/protocol-buffers/basics/</guid>
      <description>这篇教程讲述了Go程序员使用protocol buffers的基本介绍，这里使用protocol buffers的proto3版本。 逐步的创建简单的示例程序，向你展示怎么去做。
 在.proto文件中定义message格式 使用protocol buffers 编译器 使用Go protocol buffer API读写message  这不是一篇全面的教程，教你怎么在Go中使用protocol buffers。 想要更详细的参考信息， 参见Protocol Buffer Language Guide, the Go API Reference, Go Generated Code Guide, Encoding Reference
为什么使用Protocol Buffers 我们将要演示的示例是一个非常简单的通讯录应用，这个应用可以在文件中读写人们的联系方式。通讯录中的每个人都有名字，ID，email,电话号码。
怎样去序列化和反序列化这些信息？有以下几种方法:
 使用gobs来序列化Go结构化对象。这在特定的Go语言环境中是好的解决方案，但是如果你需要 与其它平台编写的应用共享数据，这种方案就不太好用。 你可以发明专门的方法，将数据项编码到一个单独的字符串－比如将整数4 编码为&amp;quot;12:3:-23:67&amp;quot;。这是个简单而灵活的方法， 尽管它需要编写一次性编码和解析代码，而且解析的运行成本很小。这对于简单数据的编码最有效。 将数据序列化为XML。这个方法是非常有效的，因为XML是可读的，并且很多语言都有实现库。如果你想要和其它应用/项目共享数据， XML是一个很好的选择。但是，总所周知，XML是空间密集型的，并且XML的编解码会给应用带来很大的性能问题。此外操作XML的DOM树比操作 类中的简单字段要复杂的多。  Protocol Buffers 是灵活，高效，自动化的解决方案，刚好解决这个问题。使用Protocol buffer， 你需要编写一个想要存储的数据结构体的.proto描述。随后，protocol buffer 编译器创建一个类， 该类使用高效的二进制格式自动的编解码protocol buffer数据。该类为protocol buffer中的字段提供getter和setter， 并且负责将protocol buffer作为一个单元进行读写。重要的是，protocol buffer格式支持随时间推移扩展格式的思想， 这样代码仍然可以读取用旧格式编码的数据
从哪里查找示例代码 我们的示例是一组命令行应用程序，用于管理使用protocol buffers编码的地址簿数据文件。 add_person_go命令向数据文件添加一个新条目。list_people_go命令解析数据文件并将数据打印到控制台。
你可以在GitHub存储库的examples目录中找到完整的例子。
定义你的协议格式 要创建您的地址簿应用程序，您需要从.proto文件开始。.proto文件中的定义很简单:为要序列化的每个数据结构添加一条消息， 然后为消息中的每个字段指定名称和类型。在我们的示例中，定义消息的.proto文件是addressbook.proto。
.proto文件以包声明开始，这有助于防止不同项目之间的命名冲突
syntax = &amp;quot;proto3&amp;quot;;package tutorial;import &amp;quot;google/protobuf/timestamp.</description>
    </item>
    
    <item>
      <title>日志业务思考和规则</title>
      <link>https://zylhorse.github.io/blog/log-system/logging/</link>
      <pubDate>Tue, 27 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/log-system/logging/</guid>
      <description>Logging&amp;amp;&amp;amp;Instrumentation思考 Logging 和 Instrumentation 在软件开发中是两个热门的话题， 尤其在微服务领域。
当然具体，还有很多需要思考。
关于Logging：要logging什么？logging到哪种详细的程度？流向哪里： syslog? file on disk? message queue?
关于Instrumentation: 什么时候instrumenting代码？哪些信息需要instrumenting？ 使用哪些metrics系统？
 logging,instrumentation,tracing最终都只是实现系统的可观测性。
 Logging 服务应该只logging可操作信息，包括不限于:
 需要人为处理的严重的、致命级别的错误
e.g. 数据库不可用的消息信号   人为处理的log应该是稀少的，如果没有错误，理想中可以不logging任何信息
 需要机器处理的结构化数据
e.g. 媒体对象已经播放，logging下来以便批处理对版税进行日结算   机器处理的log应该是定义良好的格式化数据
 因为log包的适用性有局限，所以选择功能简单的包。 避免多个log级别(info/warn/error)，尤其是不要在运行时进行level配置。 只输出需要查看的log。当然debug log是个例外，开发和诊断错误时有用。
log应当被视为事件流处理:
 服务不应该关心输出流的转存 服务不应该尝试写入或管理log文件 服务应当将事件流无缓冲的写入stdout 由操作系统或基础设施转存进程或容器的stdout/stderr到目的地，e.g. 集中log系统ELK stack, 持久化消息代理Kafka, 滚动日志服务runit  logging的代价是昂贵的，因此不要logging任何不符合上述标准的信息。e.g. 禁止logging每一个HTTP请求，尤其是热点路由上的，这些更适合instrumenting
Instrumentation Instrumentation 用于服务相关的所有剩余诊断信息。
与Log相比，服务应该尽可能的instrumenting每一个可以捕获的有意义的数据。
Metrics记录和报告的成本是低廉的， Instrumentation系统包含的数据越多越有意义。
 Instrumentation 表示一种“能够监测和度量某个系统的性能，分析系统错误，并能将追踪的数据进行记录”的监测工具
 instrumenting包含信息包括不限于:
 排除在logging之外的信息 请求计数、请求延迟、请求错误计数  Brendan Gregg’s USE method 建议instrument所有系统资源的利用率，饱和度，错误计数。</description>
    </item>
    
    <item>
      <title>日志业务系统架构设计</title>
      <link>https://zylhorse.github.io/blog/log-system/%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/</link>
      <pubDate>Tue, 27 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/log-system/%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/</guid>
      <description>日志业务 两种日志收集架构
 应用产生日志-&amp;gt; 根据大小/时间 写入文件-&amp;gt; rotation 日志文件 -&amp;gt; 定期查看/定期删除 应用产生日志-&amp;gt; 传输 -&amp;gt; 过滤/转换 -&amp;gt; 存储-&amp;gt; 分析/查看  日志业务结构 采集-&amp;gt;缓存-&amp;gt;转换/过滤-&amp;gt;存储-&amp;gt;可视化
日志技术架构 filebeat/logstash -&amp;gt; kafka -&amp;gt; fluentd -&amp;gt; es -&amp;gt; kibana
日志平台优化  由于日志低频次， 将历史数据存入廉价存储， 普通用户需要时再导入es 日志存储的时间越长，意义越小。 根据实际情况制定留存数据策略 顺序写入磁盘，区别随机写入磁盘，我们采用顺序写数据模式  </description>
    </item>
    
    <item>
      <title>Golang代码开发杂计</title>
      <link>https://zylhorse.github.io/blog/golang/misc/</link>
      <pubDate>Sat, 10 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/golang/misc/</guid>
      <description> string bytes 互转，可以使用unitptr map 会按需扩张，需要内存拷贝和重新hash。 尽量预设定容量空间； defer 会多次函数调用参数复制，缓存等问题。所以除了异常捕获外， 资源释放等可以使用goto closure 闭包 隐式携带上下文环境； 接口调用这种动态绑定的方式性能不如对象赋值的直接调用；call(obj)&amp;amp;call(interface) reflect 性能问题； setFinalizer（延长生命周期，等待第二次gc） 避免内存清理时，对象互相依赖导致循环等待，内存释放不了；  优雅的打印  fmt打印  type Pretty struct {Ugg stringApp string}p1 := Pretty{Ugg: &amp;quot;fly&amp;quot;,App: &amp;quot;bird&amp;quot;,}fmt.Printf(&amp;quot;%+v\n&amp;quot;, p1)fmt.Printf(&amp;quot;%#v\n&amp;quot;, p1)output:{Ugg:fly App:bird}pkg.Pretty{Ugg:&amp;quot;fly&amp;quot;, App:&amp;quot;bird&amp;quot;}</description>
    </item>
    
    <item>
      <title>chrome浏览器手机debug</title>
      <link>https://zylhorse.github.io/blog/browser/chrome-debug/</link>
      <pubDate>Fri, 28 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/browser/chrome-debug/</guid>
      <description>环境准备  手机打开开发人员选项 用数据线将手机连接到主机  调试  chrome进入inspect:地址栏输入chrome://inspect
 点击对应网址的inspect按钮进行调试
  问题  DevTools页面空白或者404 Not Found  由于国内无法访问 https://chrome-devtools-frontend.appspot.com 这里的解决方法： 翻墙    </description>
    </item>
    
    <item>
      <title>Golang实现服务优雅的重启</title>
      <link>https://zylhorse.github.io/blog/golang/graceful/</link>
      <pubDate>Mon, 13 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/golang/graceful/</guid>
      <description>https://grisha.org/blog/2014/06/03/graceful-restart-in-golang/</description>
    </item>
    
    <item>
      <title>Golang API实例</title>
      <link>https://zylhorse.github.io/blog/golang/%E9%83%A8%E5%88%86%E5%87%BD%E6%95%B0/</link>
      <pubDate>Thu, 11 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/golang/%E9%83%A8%E5%88%86%E5%87%BD%E6%95%B0/</guid>
      <description>SetFinalizer   func SetFinalizer(obj interface{}, finalizer interface{})
 参数obj必须是指针类型。 参数finalizer是一个函数，其参数类型是obj的类型，并且没有返回值。 如果不满足以上规则，SetFinalizer会中断程序。    SetFinalizer将obj和finalizer关联， 当gc检测到unreachable对象有关联的 finalizer时，会取消关联关系并在单独的goroutine中执行finalizer。假如没有再次调用 SetFinalizer, gc下次检测对象为unreachable时，将释放对象。
  SetFinalizer(obj, nil) 取消和对象关联的所有finalizer.
  finalizer运行依赖顺序如下: 如果A指向B，两者都关联了finalizer并且标识为unreachable， 则只有A的finalizer执行；一旦A被释放，B的finalizer才可以执行。
  如果*obj大小为0字节，则不保证finalizer会执行。
  不保证包级别init()的对象变量的finalizer会执行。 因为该对象可能是链接器分配的，而不是堆分配。
  在对象被 GC 进程选中并从内存中移除以前，SetFinalizer 都不会执行，即使程序正常结束或者发生错误。 finalizer可以用于避免用户错误使用导致的内存泄露，e.g. os.NewFile,net.newFD() 等注册了对文件描述符的SetFinalizer，用以避免忘记Close()导致的fd泄露。 但是依赖finalizer 来flush内存中的缓冲区例如bufio.Writer是错误的，因为不能保证程序退出时缓冲区会被flush。
  如果对象存在循环引用方法，需要给其添加wrapper， 并将实际类型作为wrapper的匿名字段： ``` type Cache struct{ &amp;hellip; stop chan bool }
 // wrapper定义type CacheWrapper struct{*Cache}func New() *CacheWrapper {cc := &amp;amp;Cache{.</description>
    </item>
    
    <item>
      <title>Grafana搭建部署环境和配置</title>
      <link>https://zylhorse.github.io/blog/elk/grafana/</link>
      <pubDate>Fri, 05 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/elk/grafana/</guid>
      <description>概念 Grafana是一个开源可视化工具，可以在各种不同的数据存储上使用
详情 从本质上讲，它是Graphite-web的一个功能丰富的替代品，可帮助用户轻松创建和编辑仪表板。它包含一个独特的Graphite目标解析器，可以轻松进行度量和功能编辑。用户可以使用智能轴格式（例如线条和点）创建全面的图表，这是Grafana快速的客户端渲染（即使在很长的时间范围内） - 使用Flot作为默认选项。</description>
    </item>
    
    <item>
      <title>Golang数据库-数据类型转换</title>
      <link>https://zylhorse.github.io/blog/golang/%E6%95%B0%E6%8D%AE%E5%BA%93/</link>
      <pubDate>Sat, 23 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/golang/%E6%95%B0%E6%8D%AE%E5%BA%93/</guid>
      <description>#数据库
问题 字段为空 row.scan 遇到字段为空时， 变量赋值异常：can not convert null=&amp;gt; *string 需要在sql语句中添加： ifnull/coalesce 指定默认空值
添加 sql convert 函数 根据数据类型， 做转换
const (FormatTime = &amp;quot;15:04:05&amp;quot;FormatDate = &amp;quot;2006-01-02&amp;quot;FormatDateTime = &amp;quot;2006-01-02 15:04:05&amp;quot;)var (Err_NilDests = errors.New(&amp;quot;destinations required&amp;quot;)Err_NilPointerDest = errors.New(&amp;quot;destination not support nil pointer&amp;quot;)Err_NotSupportDest = errors.New(&amp;quot;not support destination&amp;quot;))const Invalid_Id = 0func ConvertRow(row *sql.Row, dests ...interface{}) error {destLen := len(dests)if destLen == 0 {return Err_NilDests}refs := make([]interface{}, destLen)for i := range refs {var ref interface{}refs[i] = &amp;amp;ref}err := row.</description>
    </item>
    
    <item>
      <title>Golang-编译指令</title>
      <link>https://zylhorse.github.io/blog/golang/%E7%BC%96%E8%AF%91%E6%8C%87%E4%BB%A4/</link>
      <pubDate>Wed, 05 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/golang/%E7%BC%96%E8%AF%91%E6%8C%87%E4%BB%A4/</guid>
      <description>Command compile go compile, 在命令行的调用为go tool compile。编译一个由命令行指定的多个文件组成的Go包。 执行后生成一个目标文件，文件名是第一个文件的基础名称，后缀是.o。后续该目标文件和其它 目标文件可以联合组成一个归档文件或者直接传递给连接器(go tool link). 如果使用-pack 调用，编译器直接组装成归档文件，绕过生成中间目标文件。
编译生成的文件内容包含由包导出的符号的类型信息和该包导入的其它引用包的符号的类型信息。 因此在编译包P的client时，不需要读取P依赖的文件，只需要读取P的编译输出即可。
Command Line 使用方法:
go tool compile [flags] file...
命令行指定的文件必须是go编码类型文件，且所有文件必须是同一个package的。 所有目标系统和体系结构都使用相同的编译器。环境变量GOOS和GOARCH用来设置期望的目标。
flags
-D path设置本地导入的相对路径,默认为$GOROOT-I dir1 -I dir2查询完$GOROOT/pkg/$GOOS_$GOARCH目录后再到dir1,dir2等目录下搜索导入的package-L在错误消息中显示完整的文件路径-N禁用编译优化-S将汇编程序表打印到标准输出(只包含代码)-S -S将汇编程序表打印到标准输出(包含代码和数据)-V打印编译器版本并退出-asmhdr file将汇编头写入文件-buildid id记录id作为导出元数据中的构建id-blockprofile file将编译的块分析写入文件-c int编译时并发执行。1表示不并发执行(默认1)-complete假设package中没有非go组件-cpuprofile file将编译的CPU分析写入文件-dynlink在共享库中允许引入Go符号(实验性)-e删除错误报告数量的限制(默认10)-goversion string指定runtime需要的`go tool`版本。当runtime版本和指定的版本不匹配时退出。-h当检测到第一个错误时，停止并进行堆栈trace。-importcfg file从指定文件读取import配置文件中需要指出importmap,packagefile-importmap old=new编译时将&amp;quot;old&amp;quot;导入解释为&amp;quot;new&amp;quot;导入importmap参数可以重复，用以添加多个映射。-installsuffix suffix到$GOROOT/pkg/$GOOS_$GOARCH_suffix下检索packages， 而不是 $GOROOT/pkg/$GOOS_$GOARCH.</description>
    </item>
    
    <item>
      <title>Golang跨平台之交叉编译</title>
      <link>https://zylhorse.github.io/blog/golang/%E4%BA%A4%E5%8F%89%E7%BC%96%E8%AF%91/</link>
      <pubDate>Thu, 23 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/golang/%E4%BA%A4%E5%8F%89%E7%BC%96%E8%AF%91/</guid>
      <description>概述 交叉编译： 在一个平台生成另一个平台的可执行代码。
golang 交叉编译变量  GOOS:目标系统 GOARCH:目标架构 CGO_ENABLED: 开启cgo  支持的编译平台 查看命令：go tool dist list
   GOOS(目标系统) GOARCH(目标架构)     aix ppc64   android 386   android amd64   android arm   android arm64   darwin 386   darwin amd64   darwin arm   darwin arm64   dragonfly amd64   freebsd 386   freebsd amd64   freebsd arm   illumos amd64   js wasm   linux 386   linux amd64   linux arm   linux arm64   linux mips   linux mips64   linux mips64le   linux mipsle   linux ppc64   linux ppc64le   linux s390x   nacl 386   nacl amd64p32   nacl arm   netbsd 386   netbsd amd64   netbsd arm   netbsd arm64   openbsd 386   openbsd amd64   openbsd arm   openbsd arm64   plan9 386   plan9 amd64   plan9 arm   solaris amd64   windows 386   windows amd64   windows arm    条件编译 golang 采用Tag标记和文件后缀方式实现条件编译；</description>
    </item>
    
    <item>
      <title>Golang线程调度模型</title>
      <link>https://zylhorse.github.io/blog/golang/%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%BC%8F/</link>
      <pubDate>Sat, 11 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/golang/%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%BC%8F/</guid>
      <description>CSP模型  communicating sequential process: 通讯顺序进程； 描述多个并发的实体通过共享channel进行通信的并发模型； channel是重要对象，不用关注发送消息的实体，只需要关心实体发送消息时使用的channel； 利用channel 实现两个实体之间的松耦合； go 使用goroutine和chan实现CSP模型  内核线程 内核调度实体（KSE，Kernel Scheduling Entity）即内核线程
 内核线程为操作系统内核最小调度单元； 内核线程创建内存消耗较大，不适合创建太多内核线程； 内核线程调度： 线程挂起前会保存线程上下文到栈空间，再切换到其他可执行线程；线程上下文切换导致cpu开销变大； 内核线程都有固定的内存块（2MB）做栈，用来存储正在被调用或挂起的函数内部变量。  线程调度  线程池： 线程池实现线程复用，避免频繁创建新线程和线程切换，控制了线程数量和内存消耗；但是在资源共享时会发生竞争，降低了并发效率； 异步回调： 在线程阻塞时注册回调方法，不在阻塞当前线程，去处理新的请求。当处理完成后，把结果传给回调方法。回调方法不是在发起请求的线程里。异步回调会造成callback hell， 回调中嵌套回调； 协程： 在协程处理阻塞时， 协程让出cpu执行权，让其他协程执行。 等阻塞结束，在调度等待的协程继续执行；  线程模型  内核级线程模型：用户线程与内核线程KSE是一对一的映射模型；进程创建出来的用户线程与内核线程KSE一一静态绑定； 用户级线程模型： 用户线程与内核线程是多对一的映射模型； 一个进程创建的线程都只和同一个内核线程KSE在运行时动态绑定；线程的调度是在用户层面完成，相较于内核调度不需要让cpu在内核态和用户态切换；缺点： 假设某用户进程上的用户线程因为阻塞调用被cpu中断， 那么进程会被挂起。 混合型线程模型：用户线程与内核线程KSE是多对多的映射模型，一个进程与多个内核线程KSE关联，于是进程中的多个线程可以绑定不同的内核线程KSE。与内核级线程模型不同的是混合型线程模型与内核线程KSE是动态绑定的。当某个KSE绑定的线程阻塞被内核调度出cpu时， 其关联的进程中其余用户线程可以重新与其他KSE绑定运行。实现用户调度器实现用户线程到KSE的调度，内核调度器实现KSE到cpu的调度；  goroutine和Go Scheduler  golang中 goroutine是独立的执行单元。goroutine栈采用动态扩容，初始仅为2KB（最大1GB-64位机器，256M-32位机器）。 goroutine完全由golang自己的调度器 Go Scheduler调度。GC还会定期的将不使用的内存回收，收缩栈空间。  MPG  G: 表示Goroutine， 每个Goroutine对应一个G结构体。G存储goroutine的运行堆栈、状态及函数。G并非执行体，每个G绑定到P才能执行。 P：表示Processer，逻辑处理器。对于G来说P相当于CPU。G只有绑定到P上才会被调度。对M来说P提供了相关的执行环境（context）、内存分配（memcache)、任务队列（G）。 P的数量决定最大可并行G的数量。　P的数量由用户设置的GOMAXPROCS决定。最大位256. M:表示Machine，内核线程抽象，代表真正执行计算的资源。在绑定有效的P后，进入schedule循环。 schedule 循环机制大致从Global队列、P的local队列以及wait队列中获取G，切换到G的执行堆栈上并执行G，调用goexit做清理工作并回到M， 如此反复。M并不保留G状态，这是G可以跨M调度的基础。M数量不确定，由GO RunTime调整， 防止创建太多系统线程，最大为10000.</description>
    </item>
    
    <item>
      <title>《北京市小客车数量调控暂行规定》实施细则（2020年修订）</title>
      <link>https://zylhorse.github.io/blog/stories/bjcar/family/</link>
      <pubDate>Thu, 09 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/stories/bjcar/family/</guid>
      <description>第一章 总 则 第一条 为实现小客车数量的合理、有序增长，有效缓解交通拥堵，降低能源消耗和减少环境污染，根据《北京市小客车数量调控暂行规定》制定本细则。
第二条 本市对小客车实施数量调控和配额管理制度。
小客车年度增长数量和配置比例由市交通行政主管部门会同市发展改革、公安机关交通管理、生态环境等相关行政主管部门，根据小客车需求状况和道路交通、停车泊位供给、环境承载能力合理确定，报市政府批准后向社会公布。政府各有关部门应当落实本市小客车年度调控目标。
第三条 按照公开、公平、公正和促进公共资源均衡配置的原则，企业事业单位、社会团体及其他组织（以下统称单位），家庭和个人需要取得本市小客车配置指标的，应当通过摇号、积分排序、轮候等方式取得。普通小客车配置指标通过摇号方式配置，单位和个人新能源小客车配置指标通过轮候方式配置，家庭新能源小客车配置指标通过积分排序方式配置。
本市机关、全额拨款事业单位不再新增公务用车指标。
营运小客车指标单独配置，具体配置方式另行制定。
第四条 市交通行政主管部门负责小客车数量调控的统筹协调工作，并组织实施小客车数量调控的政策、措施。
公安、发展改革、科技、经信、民政、人力社保、生态环境、商务、税务、市场监管、人才工作等相关行政主管部门和区政府按照规定的职责分工，负责小客车指标申请单位、家庭和个人的资格审核、信访等管理工作。监察机关负责对各行政主管部门的履职行为监督检查。
市小客车指标调控管理机构（以下简称指标管理机构）统筹负责通过小客车指标调控管理信息系统开展指标申请的归集、审核结果的公布、指标配置的组织和公示等工作。
各区政府交通行政主管部门具体负责在本辖区政府对外办公大厅设置小客车指标对外办公窗口，为申请单位、家庭和个人提供指标申请、信息修改、公证书和其他相关材料上传、指标确认通知书打印及政策咨询等相关服务。
第五条 指标配额按年度确定。每年5月26日配置新能源小客车指标，每年6月26日和12月26日配置普通小客车指标。指标配额不得跨年度配置。
第二章 配置指标申请及审核 第六条 单位、家庭和个人申请配置指标按照以下程序进行：
（一）提出申请，获取申请编码；
（二）申请资格经审核通过后，参加指标配置；
（三）获得配置指标的，可以取得配置指标确认通知书。
第七条 单位申请配置指标的条件和数量按照以下规则之一确定：
（一）注册地在本市的企业，具有统一社会信用代码的有效营业执照，上一年度在本市缴纳入库增值税额5万元（含）以上的，或新注册企业当年在本市缴纳入库增值税额5万元（含）以上的，当年可以申请1个指标，每增加50万元可以增加申请1个指标，但年度申请指标数量上限不得超过12个。在上限范围内，可以全部申请新能源小客车指标，普通小客车指标申请数量不得超过6个；
（二）注册地在本市的制造业企业，信息传输、软件和信息技术服务业企业，具有统一社会信用代码的有效营业执照，上一年度在本市完成固定资产投资额1000万元（含）以上的，当年可以申请1个指标，每增加2000万元可以增加申请1个指标，但年度申请指标数量上限不得超过12个。在上限范围内，可以全部申请新能源小客车指标，普通小客车指标申请数量不得超过6个。
（三）注册地在本市的非全额拨款事业单位、社会团体及其他组织，具有统一社会信用代码的有效登记证书，年度可以申请1个普通小客车指标和1个新能源小客车指标。
第八条 符合以下规定情形的，可以以家庭为单位办理1个配置指标的申请登记：
（一）家庭由家庭主申请人和其他家庭申请人构成，申请人总数不得少于2人；
（二）家庭主申请人应当符合本细则第九条的规定；
（三）其他家庭申请人限于家庭主申请人的配偶、子女、父母、公婆或者岳父母，且应当符合本细则第九条中“住所地在本市的个人”的规定；
（四）所有家庭申请人及其配偶名下没有本市登记的小客车；
（五）离婚时原配偶名下有本市登记的小客车的个人，离婚十年以内不得作为家庭申请人，2021年1月1日前已离婚的除外。
家庭主申请人代表家庭参与指标配置并作为指标所有人。所有家庭申请人在家庭主申请人获得指标后的十年以内不得再次办理配置指标申请登记。以家庭为单位申请配置指标的过程中，家庭申请人不能同时再以其他形式申请配置指标。所有家庭申请人须声明申请信息及提供的材料真实有效，并承诺遵守前述规定。
第九条 住所地在本市的个人，名下没有本市登记的小客车，具有有效的机动车驾驶证，可以办理1个配置指标的申请登记。住所地在本市的个人包括：
（一）本市户籍人员；
（二）驻京部队现役军人和现役武警；
（三）持有效身份证件且近一年以上在京居住的港澳台人员和外国人；
（四）持有效《北京市工作居住证》的非本市户籍人员；
（五）持有效《北京市居住证》且近五年（含）连续在本市缴纳社会保险费和个人所得税的非本市户籍人员。
近五年（含）连续在本市缴纳社会保险费是指：申请人从申请月的上一个月开始往前推算60个月连续向本市社保部门缴纳社会保险费，不能断月（如有断月，补缴后有效）。近五年（含）连续在本市缴纳个人所得税是指：申请人从申请年的上一年开始往前推算连续五年，每年在京缴纳个人所得税，且纳税额大于零，可以断月，不能断年，以税款入库日期为准（如有断年，补缴无效）。
个体工商户申请指标的，按照个人的有关规定执行。
第十条 申请指标的单位、家庭和个人，可以在指定网站填写申请表提出申请，也可以到各区政府设置的对外办公窗口提出申请。
单位、家庭和个人申请信息在填报后发生变化的，应当于本细则第十二条规定的申请期内在指定网站或到各区政府设置的对外办公窗口进行变更。
第十一条 指标管理机构负责归集申请信息，并会同各审核部门通过数据交换方式对申请信息进行核查。
市公安机关人口管理部门负责审核个人（含家庭申请人）的身份信息和本市家庭申请人的亲属关系；市公安机关出入境管理部门负责审核港澳台人员、外国人的身份信息和在京居住信息；市公安机关交通管理部门负责审核个人（含家庭申请人及其配偶）的车辆信息以及个人（含家庭主申请人）的驾驶证件信息；经信部门负责审核企业的固定资产投资额信息；民政部门负责审核个人(含家庭申请人)的婚姻状况和配偶信息；人力社保部门负责审核非本市户籍人员的社会保险费缴纳信息；税务部门负责审核企业、非本市户籍人员的纳税信息；市场监管部门负责审核单位的统一社会信用代码信息；人才工作部门负责审核非本市户籍人员的《北京市工作居住证》信息。
各相关审核部门负责与小客车指标调控管理信息系统进行审核、复核、指标等数据对接；做好本部门小客车指标相关系统运行维护工作，保障系统正常运行。
第十二条 单位、家庭和个人可于每年1月1日至3月8日、8月1日至10月8日提交配置指标申请。
1月1日至3月8日提交的申请，指标管理机构于3月9日归集发送至相关部门进行审核，相关部门应当于4月8日前反馈审核结果，申请单位、家庭和个人可在指定网站或各区政府设置的对外办公窗口查询审核结果。对审核结果有异议的，应当于4月23日前（15日内）提出复核申请，相应审核单位应当于5月24日前反馈复核结果。
8月1日至10月8日提交的申请，指标管理机构于10月9日归集发送至相关部门进行审核，相关部门应当于11月8日前反馈审核结果，申请单位、家庭和个人可在指定网站或各区政府设置的对外办公窗口查询审核结果。对审核结果有异议的，应当于11月23日前（15日内）提出复核申请，相应审核单位应当于12月24日前反馈复核结果。
申请家庭所填报的所有家庭申请人信息均审核通过的，视为该家庭通过家庭申请人个人资格审核。
第十三条 申请单位、家庭和个人提出复核申请但复核不通过的，不可再次提出复核申请，如需继续申请指标，应当重新申请。
申请单位、家庭和个人对审核部门做出的审核结果有异议但未在规定时间内提出复核申请的，视为放弃复核，如需继续申请指标，应当重新申请。
第三章 配置指标取得和使用 第十四条 个人摇号根据参加摇号的累计次数计算阶梯数。截至2020年12月31日，已经累计的阶梯数不变，即：累计参加摇号6次（含）以内未中签的，阶梯数为1；每多参加摇号6次，增加1个阶梯数，以此类推。具有有效残疾人专用小型自动挡载客汽车准驾车型驾驶证（C5）的申请人，额外增加1个阶梯数。2021年1月1日起，在以前的阶梯数基础上，每多参加摇号2次，增加1个阶梯数，以此类推。
第十五条 家庭摇号根据每个家庭申请人的积分计算家庭总积分。
家庭申请人积分由基础积分和阶梯（轮候）积分组成。其中，家庭主申请人的基础积分为2分，其他家庭申请人的基础积分为每人1分。家庭申请人已参加普通小客车指标摇号的，按其累积的阶梯数每1阶梯加1分；正在轮候新能源小客车指标的，按其最近一次开始轮候的时间距离家庭摇号申请年上一年12月31日，每满一年加1分，以往参加摇号获得的阶梯数合并加分；以往没有参加摇号或轮候的，不加分。以家庭为单位申请每满一年，所有家庭申请人积分各增加1分。</description>
    </item>
    
    <item>
      <title>北京市小客车摇号-《告知承诺书》</title>
      <link>https://zylhorse.github.io/blog/stories/bjcar/commitment/</link>
      <pubDate>Thu, 09 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/stories/bjcar/commitment/</guid>
      <description>告知承诺书 尊敬的申请人：
1、您须完整、仔细阅读并遵守《北京市小客车数量调控暂行规定》（北京市人民政府令第296号）、《&amp;lt;北京市小客车数量调控暂行规定&amp;gt;实施细则（2020年修订）》的相关规定。
2、您须确认本人为完全民事行为能力人，具有相应的民事权利能力和民事行为能力，能够理解并完成申请过程中的相关操作。若您是某位家庭申请人的合法监护人，则该家庭申请人的相关操作须由您代为完成。
3、注册北京市小客车指标调控管理信息系统（以下简称“本系统”）账户后，您须对个人账户名下发生的所有登录、操作等活动承担责任。您应妥善保管个人账户的账户名和登录密码，通过个人账户进行的操作视同本人真实意愿的表示。
4、提交小客车配置指标申请后，若摇号中签或积分排序入围，需要对家庭申请人填报的部分信息进行公示。尊重用户个人隐私是本系统的基本原则。除上述正常公示外，本系统不会公开、透露用户的个人信息，但发生以下事由的除外：
（1）相关政府主管部门或者司法机构要求本系统提供的；
（2）因不可抗力所导致的用户信息资料的公开；
（3）因用户自身过错而导致的用户信息资料的公开；
（4）超出本系统使用的硬件和软件的技术能力范围所导致的用户信息资料的公开；
（5）为维护本系统相关权利的而进行的公开；
（6）因行政机关认定不公开可能对公共利益造成重大影响而进行的公开。
5、您须知悉并自愿承诺遵守《北京市小客车数量调控暂行规定》（北京市人民政府令第296号）、《&amp;lt;北京市小客车数量调控暂行规定&amp;gt;实施细则（2020年修订）》及以下规定：
（1）家庭主申请人组织填报申请信息、代表家庭参与指标配置，其他家庭申请人需配合本次家庭申请完成个人信息核验等申请事项。获得指标后，家庭主申请人作为指标所有人，使用该指标购买的车辆登记在该家庭主申请人名下。
（2）您须核实并确认申请信息的真实、准确、完整，保证相关证件持续合法有效，因遗漏填报、错误填报申请信息及证件过期失效等情形导致审核不通过或无法取得配置指标的后果，由所有家庭申请人共同承担。
（3）不得同时参与其他家庭或者以个人身份办理配置指标申请登记，以家庭为单位办理配置指标申请登记完成后，所有家庭申请人的原个人配置指标申请将自动取消。
（4）以家庭为单位申请配置指标的过程中，取消申请的，其有效编码从指标配置数据中删除。家庭配置指标申请取消后，家庭申请人的原个人摇号的累计次数保留，原个人申请新能源小客车指标的轮候次序不予保留。
（5）以家庭为单位申请配置指标的过程中，所有家庭申请人均不得再以任何形式申请配置指标。
（6）以家庭为单位办理配置指标申请登记，获得指标后，所有家庭申请人十年内不得再以任何形式申请配置指标，所有家庭申请人的原个人配置指标申请中的普通指标摇号次数、新能源指标轮候次序均不予保留。
6、您有义务在以下时间节点前登录本系统进行相关操作：
每年1月1日至3月8日期间填报或修改申请并完成提交的，当年的4月9日起查看审核状态；对审核结果有异议时，于当年的4月9日至4月23日期间按审核单位要求，向审核单位提交复核申请；当年的5月25日起查看复核结果；家庭摇号中签或者积分排序入围的，根据核查需要，必要时按审核单位要求补充提交相关材料，必要时须按照信息系统提示在规定时间内办理并提交亲属关系公证，具体以各审核单位要求为准。
每年8月1日至10月8日期间填报或修改申请并完成提交的，当年的11月9日起查看审核情况；对审核结果有异议时，于当年的11月9日至11月23日期间按审核单位要求，向审核单位提交复核申请；当年的12月25日起查看复核结果；家庭摇号中签后，根据核查需要，必要时按审核单位要求补充提交相关材料，必要时须按照信息系统提示在规定时间内办理并提交亲属关系公证，具体以各审核单位要求为准。
7、以家庭为单位办理配置指标申请登记后，所有家庭申请人的身份类型、个人信息、证件状态、婚姻状况、人员自然增减情况及拥车状况等申请信息发生变化的，您须在每年的1月1日至3月8日、8月1日至10月8日两个期间内，及时、主动申报并更正相关申请信息，其他时间不得修改申请信息；申请信息发生上述变化，但您未在每年的1月1日至3月8日、8月1日至10月8日两个期间内，及时、主动申报并更正相关信息，导致审核不通过或无法取得配置指标的后果，由所有家庭申请人共同承担。
8、对于提供虚假信息和材料办理配置指标申请登记或办理指标相关公证、违反本告知承诺书的，将取消该家庭申请资格、公布指标作废，三年内不予受理该家庭中有过错的申请人提出的指标申请，相关信息纳入本市公共信用信息服务平台。涉嫌违法犯罪的，移交司法机关依法追究责任。</description>
    </item>
    
    <item>
      <title>Golang源码阅读-内存管理</title>
      <link>https://zylhorse.github.io/blog/golang/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/</link>
      <pubDate>Thu, 26 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/golang/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/</guid>
      <description>内存管理 内存模型 保证共享内存的可见性、有序性、原子性，内存模型定义了共享内存系统中多线程读写操作的规范。
happens before  go中也定义了happens before以及各种发生happens before关系的操作。 在单个goroutine中，读取和写入必须按照程序指定的顺序执行 在单goroutine的程序中，Happens-Before的顺序就是程序中表达的顺序 当多个goroutine同时访问变量v时，我们必须使用同步事件(synchronization events)来满足Happends-Before条件以确保读操作(r)观察到期望的写操作(w)的值。  init 函数 程序初始化在单个goroutine中运行，但是goroutine可能会创建其他同时运行的goroutine； 如： 在package p中import package q， 那么q的init函数happens-before p的init函数执行。起始的main.main函数在所有包的init函数之后执行；
goroutine  creation： go 关键字声明一个goroutine的动作happens-before goroutine 执行； destruction： goroutine退出时，并不能保证其happens-before其他任何事件；  channel  buffered channel  1. 一个容量为C的channel的第k个接收操作happens-before第（k+C）个发送操作；2. 发送操作会使channel复制发送的元素。如果channel缓冲已满而无法复制，则阻塞发送操作。复制的目的地址有两种：当channel为空且有接收方等待时，它会是最早等待的接收方的地址，否则会是通道持有的缓冲中的地址；3. 在channel完全复制一个元素值之前，任何goroutine都不可能从channel接收到元素值的副本；unbuffered channel  1. 对一个channel的发送操作happens-before相应的channel的接受操作；2. 对一个channel的接受操作happens-before相应的channel的发送操作完成sync lock 任何sync.Mutex或sync.RWMutex 变量（l），定义 n &amp;lt; m， 第n次 l.Unlock() happens-before 第m次l.lock()调用返回。
sync once once.Do(f)中的f() happens-before 任何多个once.Do(f)调用的返回，且f()有且只有一次调用。
automic  内存分配 概述  Go内置运行时(runtime), 不同于传统的内存分配， Go 启动时，先从操作系统申请一大块内存(虚拟内存)，进行自主管理，减少系统调用 Go运行时内存分配算法使用Google为C语言开发的TCMalloc算法(全称： Thread-Caching Malloc)， 细分内存，多级管理，降低锁粒度 Go对象回收时，并没有将其真正释放，只是放回预先分配的大块内存中，以便复用。只有当自主内存闲置太多时，才会尝试归还部分内存给操作系统，降低开销  内存分配算法 Go运行时内存分配算法使用Google为C语言开发的TCMalloc算法(全称： Thread-Caching Malloc).</description>
    </item>
    
    <item>
      <title>Golang源码阅读-Context</title>
      <link>https://zylhorse.github.io/blog/golang/context/</link>
      <pubDate>Mon, 16 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/golang/context/</guid>
      <description>context 数据结构 type Context interface {// Done return a channel that is closed when this context is canceld or timeoutDone() &amp;lt;- chan struct{}// Err indicates why this context is canceled, after the done channel is closedErr() error // Deadline returns the time when this context will be canceld, if anyDeadline() (deadline time.Time, ok bool)// Value returns the value associated with key or nil if none.</description>
    </item>
    
    <item>
      <title>Golang源码阅读-sync.map</title>
      <link>https://zylhorse.github.io/blog/golang/sync.map/</link>
      <pubDate>Fri, 29 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/golang/sync.map/</guid>
      <description>sync.map  runtime中go的基本类型 map 不支持并发的读写， 会报错：fatal error: concurrent map writes 为了支持并发， 我们直接对整个map加读写锁，相当低效， 因此官方实现了sync.map  高效的原理和思路  用空间换时间，降低锁的区域 用两个map来存储数据  虽然两个map存储有冗余，但是底层数据类型都是指针，所以冗余的空间还是有限的。    总结  如果对map的读操作大于写操作， 则sync.map能大大提升性能； 写操作需要加锁， 且操作两个map 写操作也会触发， 两个map之间的切换。  源码解析 基础结构  Map type Map struct {mu Mutex // 互斥锁，用于锁定dirty map， 写锁read atomic.Value // 优先读， 支持原子操作。相当于dirty的缓存dirty map[interface{}]*entry // dirty保存最新写入数据， 允许读写misses int // 记录在read中读取不到数据，去dirty中查询的次数} readonly type readOnly struct {m map[interface{}]*entryamended bool // 当key不在read中而在dirty中时， 为true} entry type entry struct {//可见value是个指针类型，虽然read和dirty存在冗余情况（amended=false），但是由于是指针类型，存储的空间应该不是问题p unsafe.</description>
    </item>
    
    <item>
      <title>Golang源码阅读-sync.Mutex</title>
      <link>https://zylhorse.github.io/blog/golang/sync.mutex/</link>
      <pubDate>Fri, 29 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/golang/sync.mutex/</guid>
      <description>概述 Go的互斥锁有两种模式: 正常模式和饥饿模式。
  正常模式 正常模式，等待队列按FIFO顺序排序，但是等待队列中被唤醒的G并不拥有互斥锁， 而是与新来的G竞争所有权。新来的G有一个优势-它已经再CPU上运行并且可能有很多， 因此等待队列中被唤醒的G可能会输掉竞争。这种情况下先来的G排在等待队列的前面。 如果等待队列中的G获取互斥锁失败超过1ms，它会将互斥锁切换为饥饿模式。
  饥饿模式
 饥饿模式下，互斥锁的所有权直接从解锁的G传递给等待队列队首的G。 新来的G不要试图获取互斥锁，即使它看起来是要解锁，并且不要试图自旋。 将新来的G放到等待队列的队尾。 如果等待队列中的G获取互斥锁的所有权并且有以下情况: 1)G是等待队列中的最后一个， 2) G的等待市场小于1ms， 它将互斥锁切换为正常模式。    正常模式有很好的性能表现，因为G可以连续多次的获取互斥锁，即使存在阻塞的等待者。
饥饿模式可以有效的预防尾延迟的情况。
Mutex // Mutex是互斥锁// Mutex的0值是一个未锁定的mutex。//// Mutex 不允许复制type Mutex struct {state int32sema uint32}// Locker表示可以被锁定和解锁的对象// Mutex 实现该接口type Locker interface {Lock()Unlock()}// Mutex 状态标志常量const (mutexLocked = 1 &amp;lt;&amp;lt; iota // mutex is lockedmutexWokenmutexStarvingmutexWaiterShift = iotastarvationThresholdNs = 1e6)Lock // Lock 锁定m// 如果m已经锁定，调用Lock的goroutine会阻塞，直到m被解锁。func (m *Mutex) Lock() {// 快通道: 抢占未锁定的mutex// 将mutex.</description>
    </item>
    
    <item>
      <title>Golang源码阅读-sync.pool</title>
      <link>https://zylhorse.github.io/blog/golang/sync.pool/</link>
      <pubDate>Fri, 29 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/golang/sync.pool/</guid>
      <description>基本概述 Pool定义在package sync中.
Pool是一组临时对象的集合， 可以用于保存和检索临时对象。
存储在Pool中的任何对象，都可以在任何时间被自动删除，而不需要通知。如果当前Pool持有对象的唯一引用， 那么该对象可能会被释放。
Pool是多协程并发使用安全的。
Pool在第一次使用后，不能再被拷贝赋值。
Pool作用 Pool设计用来缓存已分配内存但未使用的对象，用于后续的复用。用来减轻gc的压力。 换言之，Pool使得构建高效、线程安全的缓存变得简单。但是，它并不适用所有的缓存情况。 Pool只是提供了一种在多客户机之间分摊分配开销的方法。
使用场景 Pool在标准库中的使用示例是在package fmt中， 维护一个临时输出缓冲区的动态大小存储区。 当goroutine打印活跃时扩容缓冲区，打印沉寂时收缩缓冲区。
另一方面，缓存列表维护一组短命的临时对象的场景不适合使用Pool，因为这种情况不能很好的 分摊分配开销。让这些对象实现他们自己的缓存列表会更有效。
数据结构 type Pool struct {noCopy noCopy // 第一次使用后不允许被复制local unsafe.Pointer // 固定大小的per-P pool, 实际类型是[P]poolLocallocalSize uintptr // local的大小victim unsafe.Pointer // 上一个gc周期local的备份victimSize uintptr // victim的大小// `New` 是可选项，指定函数用以在`Get`返回`nil`时生成一个值。 // 它不能与`Get`调用同时更改New func() interface{}} local大小为什么是GOMAXPROCS？
优化G对local的竞争。G绑定到P上只能操作对应的local[PID],这样设计避免了多个G操作Pool时需要加锁。  type poolLocal struct {poolLocalInternal// Prevents false sharing on widespread platforms with// 128 mod (cache line size) = 0 .</description>
    </item>
    
    <item>
      <title>Golang doc使用细则</title>
      <link>https://zylhorse.github.io/blog/golang/godoc/</link>
      <pubDate>Sat, 23 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/golang/godoc/</guid>
      <description>简介 go doc和godoc 在golang 1.13版本被移除，可手动安装go get golang.org/x/tools/cmd/godoc
go doc GO 命令行工具， 打印和显示文档 打印内容：
package pkgxxx // import &amp;quot;project/pkgxxx&amp;quot;FUNCTIONSfunc FuncXxx(n int) stringTYPEStype TXxx struct {Val int}go doc Flags -all: 显示package的所有文档
-c: 区分大小写，默认不区分
-cmd: 打印文档包含package main,默认是不包含的
-u: 打印文档包含不能导出(首字母小写)的FUNCTIONS和TYPES文档,默认是不包含的
-src: 显示源代码
-short: 单行显示
go doc参数  go doc: 输出当前目录下package的文档说明 go doc &amp;lt;pkg&amp;gt;: 输出指定package的文档说明  示例： go doc http   go doc &amp;lt;sym&amp;gt;[.&amp;lt;methodOrField&amp;gt;]: 输出指定package的指定FUNCTIONS或TYPES的文档说明  示例: go doc http.</description>
    </item>
    
    <item>
      <title>Golang swagger应用</title>
      <link>https://zylhorse.github.io/blog/golang/goswagger/</link>
      <pubDate>Sat, 23 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/golang/goswagger/</guid>
      <description>简介 goswagger包含了Swagger 2.0的golang实现。
swag方式 参考: README
swagger 采用源码安装方式：
git clone https://github.com/go-swagger/go-swaggergo install ./go-swagger/cmd/swagger参考: SPEC</description>
    </item>
    
    <item>
      <title>服务治理-服务注册和发现</title>
      <link>https://zylhorse.github.io/blog/distribution-system/%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/</link>
      <pubDate>Mon, 11 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/distribution-system/%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/</guid>
      <description>概述 </description>
    </item>
    
    <item>
      <title>服务治理-服务的熔断和降级</title>
      <link>https://zylhorse.github.io/blog/distribution-system/%E7%86%94%E6%96%AD%E5%92%8C%E9%99%8D%E7%BA%A7/</link>
      <pubDate>Mon, 11 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/distribution-system/%E7%86%94%E6%96%AD%E5%92%8C%E9%99%8D%E7%BA%A7/</guid>
      <description>Hystrix 和 Sentinel</description>
    </item>
    
    <item>
      <title>服务治理-负载均衡</title>
      <link>https://zylhorse.github.io/blog/distribution-system/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/</link>
      <pubDate>Sun, 20 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/distribution-system/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/</guid>
      <description> 随机 加权随机 哈希 最小压力  </description>
    </item>
    
    <item>
      <title>Golang代码诊断工具-Tracing</title>
      <link>https://zylhorse.github.io/blog/golang/tracing/</link>
      <pubDate>Sat, 12 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/golang/tracing/</guid>
      <description>Tracing  Tracing通过检测代码来分析一个调用链在整个生命周期中的开销。 Go提供了一个执行追踪器来追踪一个时间间隔内的运行时事件  Tracing作用  测量和分析Go P中程序的开销 精确测量某个调用在调用链中的开销 通过追踪数据来找出利用率和性能瓶颈  分布式Tracing  在单进程模式，收集诊断数据相对容易。所有的模块都在一个进程，并且通过共享公共资源来报告日志、错误和其他诊断信息 当系统扩展成分布式后，追踪一个完整的调用(从前端web服务器及其后端所有调用，直到响应返回给用户)将会非常困难 当分布式系统需要分析用户请求和RPC的性能时，就需要用到分布式Tracing Go为需要追踪的系统和后台无关的系统提供了大量的分布式Tracing库  分布式Tracing作用   测量和分析在大型系统中程序的开销
  追踪用户请求周期中的所有RPC调用，并且发现线上服务的集成问题
  通过追踪数据来找出系统的利用率和性能瓶颈
  Go 没有提供自动拦截函数调用并创建追踪范围的方法，需要手动的注入代码来创建/结束/注释追踪 可以使用context.Context传递追踪标识和标签 Go可以Tracing部分内部库或运行时的底层事件，eg: httptrace.ClientTrace     httptrace net/http/httptrace包提供追踪单个HTTP请求过程中事件的机制， 事件包含：
 Connection creation Connection reuse DNS lookups Writing the request to the wire Reading the response  使用实例：
req, _ := http.NewRequest(&amp;quot;GET&amp;quot;, &amp;quot;http://example.com&amp;quot;, nil)trace := &amp;amp;httptrace.ClientTrace{DNSDone: func(dnsInfo httptrace.</description>
    </item>
    
    <item>
      <title>Golang代码诊断工具-Diagnostics</title>
      <link>https://zylhorse.github.io/blog/golang/diagnostics/</link>
      <pubDate>Fri, 11 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/golang/diagnostics/</guid>
      <description>Diagnostics Go生态系统提供了大量的接口套件和工具来诊断Go程序的业务和性能问题
 这些工具之间会互相干扰，因此需要单独使用工具来获取精确数据
   Profiling: 分析Go程序的复杂性和成本，例如内存占用和函数调用，来确定Go程序的开销。
详情参考: Golang代码诊断工具-Profiling
  Tracing
 Tracing检测代码用于分析一个调用或用户请求在整个生命周期中的执行时间; Tracing提供每个组件影响整个系统执行时间的概览； Tracing可以跨越多个Go进程
详情参考: Golang代码诊断工具-Tracing    Debugging Debugging允许暂停一个Go程序并检测它的执行，验证程序的状态和流程
工具:
 Delve GDB    Runtime statistics and events
 收集和分析运行时状态和事件提供Go程序运行状况的高级概览； 指标的变化帮助我们识别吞吐量、利用率和性能的变化。    </description>
    </item>
    
    <item>
      <title>Golang代码诊断工具-Profiling</title>
      <link>https://zylhorse.github.io/blog/golang/profiling/</link>
      <pubDate>Fri, 11 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/golang/profiling/</guid>
      <description>概述 Profiling对于识别昂贵的和经常调用的代码段非常有用。
Go 运行时以pprof工具可以识别的格式提供概要数据，这些概要数据可以通过go test测试或引入net/http/pprof时被收集。
概要数据内容 runtime/pprof包，以pprof visualization tool可以识别的格式生成概要数据
数据包含以下内容：
 cpu: 报告程序在消耗CPU周期时将时间花费在何处(与睡眠和等待I/O相反) heap: 报告内存分配; 用来监视当前和历史内存使用情况，并且检查内存泄漏 threadcreate: 报告程序中哪些部分导致创建新的系统线程(OS threads) goroutine: 报告所有goroutine的堆栈跟踪 block: 报告哪些goroutine阻塞等待(包括定时器)。默认关闭该项，使用runtime.SetBlockProfileRate来启用。 mutex: 报告琐竞争。当你认为由于锁竞争导致CPU没有充分利用时，开启该项。 默认关闭该项，使用runtime.SetMutexProfileFraction来启用。  收集概要数据 Benchmarks数据 go test 内置了对Benchmarks进行Profiling的支持。
以下示例：go test -cpuprofile cpu.prof -memprofile mem.prof -bench .
 执行当前目录下的benchmarks并将CPU和memory概要数据写入到文件中：
 应用程序数据   生成概要文件
 var cpuprofile = flag.String(&amp;quot;cpuprofile&amp;quot;, &amp;quot;&amp;quot;, &amp;quot;write cpu profile to `file`&amp;quot;)var memprofile = flag.String(&amp;quot;memprofile&amp;quot;, &amp;quot;&amp;quot;, &amp;quot;write memory profile to `file`&amp;quot;)func main() {flag.</description>
    </item>
    
    <item>
      <title>分布式事务</title>
      <link>https://zylhorse.github.io/blog/distribution-system/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/</link>
      <pubDate>Fri, 11 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/distribution-system/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/</guid>
      <description>概述  分布式事务： 分布式事务涉及到多组操作， 将一个事务的概念扩大到多个分布式操作上 分布式事务的参与者，资源服务器，事务管理器分别位于分布式系统的不同节点上  分布式事务产生原因  service 产生多个节点 resource 产生多个节点  </description>
    </item>
    
    <item>
      <title>分布式锁</title>
      <link>https://zylhorse.github.io/blog/distribution-system/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/</link>
      <pubDate>Wed, 02 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/distribution-system/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/</guid>
      <description>分布式锁 应用场景  多节点并发的对数据进行操作； 多节点并发的执行同一个任务， 请求同一接口；  分布式锁条件  在分布式系统环境下， 一个资源同时只能被一个线程执行； 高可用的获取锁和释放锁 高性能的获取锁和释放锁 具备可重入性， 同一线程可以并发使用； 具备锁失效机制，不会死锁 非阻塞特性， 即获取锁失败需要返回失败；  分布式锁实现  redis分布式锁 mutext.go:  package redsync// lockfunc (m *Mutex) Lock() error {// generate mutex identifier, used for unlock and extendvalue, err := m.genValueFunc()if err != nil {return err}// acquire the lock and try some times when failed.for i := 0; i &amp;lt; m.</description>
    </item>
    
    <item>
      <title>Golang进程管理工具</title>
      <link>https://zylhorse.github.io/blog/golang/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/</link>
      <pubDate>Tue, 01 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/golang/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/</guid>
      <description>简介 Go 生态系统提供了一套API和工具来检测程序的逻辑和性能问题。本章总结了可用的工具，并帮助用户在遇到问题时，选择正确的工具。
gops gops: Golang进程管理工具，支持远程调用
 安装：go get -u github.com/google/gops 项目启动代理： package mainimport (&amp;quot;log&amp;quot;&amp;quot;time&amp;quot;&amp;quot;github.com/google/gops/agent&amp;quot;)func main() {if err := agent.Listen(agent.Options{}); err != nil {log.Fatal(err)}time.Sleep(time.Hour)} agent.Options{} type Options struct {// gops agent 监听地址// 格式： host:portAddr string// 配置文件保存目录// 保存内容： gops pid，filename， port，contentConfigDir string// 设置是否自动清理资源// true: 进程接收到终端信号后，会自动清理// false：进程关闭前用户需要调用 CloseShutdownCleanup bool}   命令行使用：  打印所有Go进程： $ gopspid ppid 进程名 go 版本 关联进程的位置983 980 docc * go1.</description>
    </item>
    
    <item>
      <title>分布式一致性</title>
      <link>https://zylhorse.github.io/blog/distribution-system/%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7/</link>
      <pubDate>Mon, 30 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/distribution-system/%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7/</guid>
      <description>一致性算法 算法目的是让整个集群的结点对某个值的变更达成一致
 Paxos 算法目的是让整个集群的结点对某个值的变更达成一致。Paxos 算法(强一致性算法)属于多数派——大多数的决定会成个整个集群的统一决定。任何一个点都可以提出要修改某个数据的提案，是否通过这个提案取决于这个集群中是否有超过半数的结点同意（所以 Paxos 算法需要集群中的结点是单数）；  这个算法有两个大阶段，四个小阶段（Paxos 有 Proposer 和 Acceptor 两个角色）Prepare proposer 提出一个提案，编号为 N ，此 N 大于这个 proposer 之前提出提案编号。请求 acceptors 的 quorum 接受。Promise 如果 N 大于此 acceptor 之前接受的任何提案编号则接受，否则拒绝Accept 如果达到了多数派， Proposer 会发出 accept 请求，此请求包含提案编号 N，以及提案内容Accepted 如果此 acceptor 在此期间没有收到任何编号大于 N 的提案，则接受此提案内容，否则忽略Raft 是简化版的 Paxos。Raft 划分成三个子问题：一是Leader Election；二是 Log Replication；三是 Safety。Raft 定义了三种角色 Leader、Follower、Candidate，最开始大家都是 Follower，当 Follower 监听不到 Leader，就可以自己成为 Candidate，发起投票。  </description>
    </item>
    
    <item>
      <title>Golang单元测试</title>
      <link>https://zylhorse.github.io/blog/golang/testing/</link>
      <pubDate>Mon, 23 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/golang/testing/</guid>
      <description>简介  Package testing为Go packages提供自动化测试支持。 使用 go test 命令来启动测试 编写新的测试套件，需要创建以_test.go结尾的新文件  admin.go的测试文件，需要在当前目录新建测试文件admin_test.go   测试方法func TestXxx(*testing.T)  测试方法需要以Test开头 Xxx方法必须以大写字母开头 方法参数必须是：t *testing.T    关键词 tests: 常规测试
beanchmarks: 基准测试
examples : 样例测试
sub: 子模式
Benchmarks(基准测试) func BenchmarkXxx(b *testing.B)
 benchmarks方法需要以Benchmark开头 benchmarks方法，在go test命令添加-bench时才执行 benchmarks中，需要目标代码被执行b.N次 func BenchmarkXxx(b *testing.B) {for i := 0; i &amp;lt; b.N; i++ {Xxx()}} benchmarks在执行过程中会调整b.N，直到benchmarks函数持续足够长的时间，可以可靠的计时为止 执行结果： BenchmarkXxx 68453040	17.8 ns/op  单次执行目标代码耗时17.8ns,目标代码执行68453040次   benchmarks目标代码执行前，如果有比较耗时的准备操作，benchmarks的时间可以重置 func BenchmarkXxx(b *testing.</description>
    </item>
    
    <item>
      <title>分布式系统</title>
      <link>https://zylhorse.github.io/blog/distribution-system/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/</link>
      <pubDate>Thu, 19 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/distribution-system/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/</guid>
      <description>概念  建立在网络上的软件系统 若干独立系统的集合  特性  分布性： 分布式系统由多个节点组成， 地域上分散； 自治性： 分布式系统的每个节点都包含自己的处理器和内存， 具备独立处理数据能力； 并行性： 一个完整的任务可以划分成若干子任务， 运行在分布式系统的多个节点上； 全局性： 分布式系统中的节点可以互相通信及系统间的相互调用；  CAP   一致性（consistency）： 分布式系统中的所有数据备份，在同一时刻是否是同样的值（分为弱、强、最终一致性）
  可用性（availability）： 在集群中某一个节点故障后， 集群整体是否还能响应客户端的读写请求（数据高可用性）
  分区容忍性（partition tolerance）： 提供如果在时限内不能达成数据一致性， 必须就当前操作在一致性和可用性之间做出选择；
  任何一个分布式系统都无法同时满足一致性（consistency)、可用性（availability）和分区容忍性（partition tolerance）；
  大多数场景都需要牺牲强一致性来换取系统的高可用性， 往往只需要保证最终一致性；
  BASE策略  Basically Available（基本可用）：在分布式系统出现不可预知的故障时， 允许损失部分可用性； Soft state（软状态）： 允许系统中数据存在中间状态，并认为该中间状态存在不会影响系统的整体可用性；指的是数据不一致； Eventually consistent（最终一致性）： 系统中所有的数据副本，在一定的时限内，最终能够达到一个一致的状态；  </description>
    </item>
    
    <item>
      <title>Golang源码阅读-defer</title>
      <link>https://zylhorse.github.io/blog/golang/defer/</link>
      <pubDate>Wed, 11 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/golang/defer/</guid>
      <description>defer 逻辑  defer代码块会在函数调用链表中增加一个函数调用，该函数调用是在return之后； defer的执行顺序是先进后出； defer表达式中变量的值在defer表达式被定义时就已经明确； defer可以获取有名返回值； goroutine 控制结构中，有张表记录所有defer；  defer 作用 defer表达式通常用来清理和释放资源
defer 性能  defer 性能在1.13版本之前不高 defer 会涉及到内存、缓存、多次调用，所以有一定性能问题； 使用注意： 除了需要异常捕获，必须使用defer；其他资源回收，可以在判断失败后，使用goto跳转到资源回收的代码； 对于竞争资源，在使用完成后立刻进行释放，这样才可以最优的使用竞争资源。 1.14后性能优化增加开放编码（Open-coded）defer类型,是普通函数调用的log10； 减少defer链表长度(测试: 不要超出8个， 超出8个后性能骤降)。这种场景可以拆分增加函数调用来解决。  defer原理 每一个defer在编译的时候就会转换成deferproc，编译器会在函数return之前插入deferreturn。
 调用deferproc，这里会进行参数拷贝； 执行deferreturn，这里会提取信息；  defer goroutine defer 会被添加到G _defer链表的首部，所以defer是一个后进先出的链表； G 退出时会遍历G上的defer 链表。
defer 源码 type _defer struct {siz int32 //参数大小started bool // defer是否被调用过的标识sp uintptr // sp at time of deferpc uintptrfn *funcval // defer 后面跟的function_panic *_panic // panic that is running deferlink *_defer // 链表结构}</description>
    </item>
    
    <item>
      <title>Windows Subsystem for Linux</title>
      <link>https://zylhorse.github.io/blog/windows/wsl/</link>
      <pubDate>Tue, 03 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/windows/wsl/</guid>
      <description>概述 WSL： Windows Subsystem for Linux
目的  terminal 界面定制 支持ubuntu terminal  WSL安装 reference
 启用Linux的windows子系统 功能  仅安装WSL1 dism.exe /online /enable-feature /featurename:Microsoft-Windows-Subsystem-Linux /all /norestart 重启电脑 windows store 下载安装 linux 发行版   windows terminal 安装  windows store 下载安装 windows terminal    </description>
    </item>
    
    <item>
      <title>Golang源码阅读-select</title>
      <link>https://zylhorse.github.io/blog/golang/select/</link>
      <pubDate>Fri, 23 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/golang/select/</guid>
      <description>描述 select就是用来监听和channel有关的IO操作，当 IO 操作发生时，触发相应的动作。
执行步骤  构建select对象：  type hselect struct {tcase unit16 // total count of scase[]ncase unit16 // currently field scase[]pollorder *unit16 // case poll orderlockorder *uint16 // channel lock orderscase [1]scase //one per scase }注册case  所有channel表达式都会被求值、所有被发送的表达式都会被求值。求值顺序：自上而下、从左到右.1. 注册写chan case2. 注册读chan case3. 注册default case执行select  1. 对case洗牌，排序 获取locking order2. 对lockorder里的元素进行枷锁3. 顺序遍历case，等待某个case 被解锁唤醒4. 将未唤醒的case 踢出队列5. 对lockorder里的元素进行解锁释放select  问题  select default 谨慎操作； default 阻塞导致select 不退出； 当chan被触发时，select随机挑选执行；  </description>
    </item>
    
    <item>
      <title>Jenkins部署配置</title>
      <link>https://zylhorse.github.io/blog/jenkins/jenkins%E5%AE%89%E8%A3%85/</link>
      <pubDate>Thu, 22 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/jenkins/jenkins%E5%AE%89%E8%A3%85/</guid>
      <description>docker安装  docker-compose.yml  version: &#39;2&#39;services:jenkins:image: jenkins/jenkins:ltsports:- 8080:8080- 50000:50000volumes:- /opt/jenkins:/var/jenkins_homerestart: alwayssudo docker-compose up -d  </description>
    </item>
    
    <item>
      <title>Golang源码阅读-chan</title>
      <link>https://zylhorse.github.io/blog/golang/chan/</link>
      <pubDate>Sun, 11 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/golang/chan/</guid>
      <description>描述 channel 是golang实现CSP理念的重点。channel实现一个进程内不同协程之间的通信方式。
结构体 channel 实际上是一个环形队列，实际的队列空间就是在这个channel结构体之后申请的空间。
type hchan struct {qcount uint // 缓冲队列中的元素计数器dataqsiz uint // 缓冲队列，=make(chan T, x)中的xbuf unsafe.Pointer // 缓冲队列，数组类型elemsize uint16 // 元素大小，单位为字节closed uint32 // chan关闭标记elemtype *_type // 元素类型sendx uint // 待发送元素在缓冲器中的索引recvx uint // 待接收元素在缓冲器中的索引recvq waitq // 阻塞等待读channel的G队列sendq waitq // 阻塞等待写channel的G队列lock mutex // 互斥锁} elem 大小不能超过65536个字节，超过会抛异常  特性  当chan缓冲中还有数据时，关闭chan后，接受者不会立刻接收到chan的关闭信号， 而是等缓冲中所有的数据被全部读取后接受者才会收到chan的关闭信号； 没有被初始化的chan在调用发送或者接收的时候会被阻塞 当chan被close之后不能被写入，但是可以被读取； chan不能被重复close，chan可以不被close；可以被系统自动回收；  make chan  新建channel时调用func makechan(t *chantype, size int) *hchan函数</description>
    </item>
    
    <item>
      <title>Oracle数据库安装配置</title>
      <link>https://zylhorse.github.io/blog/database/oracle/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/</link>
      <pubDate>Mon, 15 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/database/oracle/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/</guid>
      <description>docker安装 sudo docker pull deepdiver/docker-oracle-xe-11gsudo docker run -d -p 1522:22 -p 1521:1521 --name oracle deepdiver/docker-oracle-xe-11gclient https://www.oracle.com/database/technologies/instant-client/linux-x86-64-downloads.html
 basic sdk sqlplus  链接动态库 #!/bin/bashln /opt/instantclient_11_2/libclntsh.so.11.1 /usr/lib/libclntsh.soln /optinstantclient_11_2/libnnz11.so /usr/lib/libnnz11.soln /opt/instantclient_11_2/libocci.so.11.1 /usr/lib/libocci.soln /opt/instantclient_11_2/libociei.so /usr/lib/libociei.soln /opt/instantclient_11_2/libocijdbc11.so /usr/lib/libocijdbc11.soln /opt/instantclient_11_2/libsqlplusic.so /usr/lib/libsqlplusic.soln /opt/instantclient_11_2/libsqlplus.so /usr/lib/libsqlplus.so添加动态库到系统 echo /opt/instantclient_11_2 &amp;gt;&amp;gt; /etc/ld.so.confldconfig安装 oracle client 下载地址： https://www.oracle.com/database/technologies/112010-win64soft.html
错误提示  不满足安装条件, oracle 没有配置当前系统的支持   修改stage/cvu/cvu_prereq.xml添加
  &amp;lt;OPERATING_SYSTEM RELEASE=&amp;quot;6.2&amp;quot;&amp;gt;&amp;lt;VERSION VALUE=&amp;quot;3&amp;quot;/&amp;gt;&amp;lt;ARCHITECTURE VALUE=&amp;quot;64-bit&amp;quot;/&amp;gt;&amp;lt;NAME VALUE=&amp;quot;Windows 10&amp;quot;/&amp;gt;&amp;lt;ENV_VAR_LIST&amp;gt;&amp;lt;ENV_VAR NAME=&amp;quot;PATH&amp;quot; MAX_LENGTH=&amp;quot;1023&amp;quot; /&amp;gt;&amp;lt;/ENV_VAR_LIST&amp;gt;&amp;lt;/OPERATING_SYSTEM&amp;gt;安装plsql developer 软件 下载地址： https://www.</description>
    </item>
    
    <item>
      <title>Golang源码阅读-slice</title>
      <link>https://zylhorse.github.io/blog/golang/slice/</link>
      <pubDate>Thu, 11 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/golang/slice/</guid>
      <description>数组(array) golang 中 array 在函数传参中是值传递， 修改不影响原数组；
切片(slice)  切片数据结构很简单， 对底层数组进行了抽象，并提供相关操作方法； 切片数据结构包含三个字段： 数组指针， 切片长度， 切片容量 切片只能访问切片长度内的元素， 容量只是为了切片后续扩容使用  声明 var ss []int初始化  make 不允许创建len小于cap的切片  指定len和cap ss := make([]int, 5, 10) 指定len ss := make([]int, 5)   字面量  全量创建并初始化切片： ss := []int{1, 2, 3, 3} 使用索引创建并初始化： ss := []int{9: 1}   创建数组的引用 arr := [5]int{}ss := arr[:] 通过切片创建新的切片  默认容量 s := []int{1,2,3,4,5}// ss := s[i:j] // ss = []int{i, .</description>
    </item>
    
    <item>
      <title>Golang源码阅读-map</title>
      <link>https://zylhorse.github.io/blog/golang/map/</link>
      <pubDate>Mon, 08 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/golang/map/</guid>
      <description>map 声明 var m map[string]stringmap声明默认值是nil， 此时取值，返回的是value对应类型的零值
初始化 // 声明之后必须初始化，才能使用m = make(map[string]int)m = map[string]int{}// 声明并初始化m = make(map[string]int, 10)m = map[string]int{&amp;quot;x&amp;quot;:1}向未初始化的map赋值引起： panic: assignment to entry in nil map
key/value 限制  key 一定是可以比较的类型（支持==操作），如果是非法的key会报invalid map key type value可以是任意类型  遍历  map 本身是无序的 在iterate 整个map时， 使用delete 是安全的。这里和C++ 不一样， C++ 不能再迭代的时候删除元素，会导致map的红黑树结构发生变化  函数传参 golang中没有引用传递， 均为值传递。意味参数是一种数据拷贝。
map 本身是引用类型，作为形参或返回值时，传递的是地址的拷贝。
扩容时也不会改变这个地址。
map 基础数据结构 map实现的底层结构是hmap
// A header for a Go map.</description>
    </item>
    
    <item>
      <title>Golang 代码规范</title>
      <link>https://zylhorse.github.io/blog/golang/%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83/</link>
      <pubDate>Sun, 07 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/golang/%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83/</guid>
      <description>gofmt工具 gofmt 格式化Go程序。使用tabs进行缩进，blanks进行对齐。
gofmt 参数 gofmt [flags] [path...]
 -cpuprofile: 指定打印cpu profile文件路径 -d: 打印gofmt前后文件差异，并不格式化重写源文件 -e: 打印gofmt出现的错误,并不格式化重写源文件 -l: 打印不符合gofmt的文件列表,并不格式化重写源文件 -r: 设置gofmt重写规则 -s: 简化代码  源: tt := []int{1, 2, 3, 4, 5, 6}tt = tt[3:len(tt)] 目标: tt := []int{1, 2, 3, 4, 5, 6}tt = tt[3:]   -w: 将gofmt结果写入源文件，而不是stdout  命名 Go中命名具有语义性， 命名在包外的可见性取决于首字母的大小写；
  目录
 目录名小写 允许中划线-,但是不要出现在头尾    文件
 文件名小写 允许下划线_,但是不要出现在头尾 可以结合系统平台、CPU架构、版本号等 eg: defs_linux_amd64.</description>
    </item>
    
    <item>
      <title>LDAP协议简介</title>
      <link>https://zylhorse.github.io/blog/web/ldap/</link>
      <pubDate>Wed, 03 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/web/ldap/</guid>
      <description>概述 LDAP: light diretory access protocol, 轻量级目录访问协议； LDAP 目录服务，由目录数据库和访问协议组成；
目录树  目录树： 在目录服务系统中， 整个目录信息集， 都可以表示为一个目录信息树。树中的每个节点是一个条目； 条目： 每个条目是一条记录， 每个条目有自己唯一的名称（DN） 对象类： 与某个实体类型对应的一组属性，可以继承。这样父类的属性也会被继承下来。 属性： 描述条目的某方面信息。 一个属性由一个属性类型和一个或多个属性值组成， 属性由必须属性和非必须属性。  关键字    关键字 英文全称 含义     dc domain Component 域名的部分，其格式是将完整的域名分成几部分，如域名为example.com变成dc=example,dc=com（一条记录的所属位置）   uid User Id 用户ID songtao.xu（一条记录的ID）   ou Organization Unit 组织单位，组织单位可以包含其他各种对象（包括其他组织单元），如“oa组”（一条记录的所属组织）   cn Common Name 公共名称，如“Thomas Johansson”（一条记录的名称）   sn Surname 姓，如“许”   dn Distinguished Name “uid=songtao.</description>
    </item>
    
    <item>
      <title>CDN内容分发网络工作过程和分类</title>
      <link>https://zylhorse.github.io/blog/distribution-system/cdn/</link>
      <pubDate>Sun, 23 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/distribution-system/cdn/</guid>
      <description>CDN  全称 Content Delivery Network，即内容分发网络 概念始于1996，美国麻省理工学院的研究小组，并于1999年创建CDN服务公司 CDN构建在现有网络基础上，依靠部署在各地的边缘服务器，通过中心平台的负载均衡、内容分发、调度等模块，是用户就近获取内容，降低网络拥塞，挺高用户访问的响应速度和命中率。 CDN的关键技术是内容存储和分发  一些前端开源CDN服务  基于github的cdn BootCDN  CDN基本工作过程 使用CDN可以简化网站的系统维护工作
 运维只需要将网站内容注入到CDN系统，就可以同通过CDN系统部署在各个物理位置的服务器进行全网分发，实现跨运营商、跨地域的用户覆盖 由于CDN将内容推送到网络边缘，大量用户访问被分散到网络边缘  不在构成网站出口、互联互通点的资源挤占 也不需要跨越长距离的IP路由    实现原理 关键字：
 CNAME：即：别名记录。这种记录允许您将多个名字映射到同一台计算机。 GSLB： Global Server Load Balance, 全局负载均衡。 实现在广域网上不同地域服务器间的流量调配，保证使用最佳的服务器服务离自己最近的客户。  今天我们看到的网站系统基本上基于B/S架构，具体流程如下：
 未使用CDN，用户访问网站过程：    用户在自己的浏览器中输入要访问的网站域名 浏览器向本地的DNS服务器请求对该域名解析  本地DNS服务器中如果有缓存该域名的解析结果，则直接响应用户的解析请求 本地DNS服务器中如果没有缓存该域名的解析结果， 则以递归的方式向整个DNS系统请求解析，获得应答后将结果反馈给浏览器   浏览器得到域名的解析结果，就是该域名对应的服务器设备IP 浏览器向服务器请求内容 服务器将用户请求内容传输给浏览器     使用CDN，用户访问网站过程    当用户加载网站上的内容和资源URL时 经过本地DNS系统解析，DNS系统会将域名的解析权交给CNAME指向的CDN专用DNS服务器 CDN的专属DNS服务器将CDN的全局负载均衡设备IP返回给用户 用户向CDN的全局负载均衡设备发起内容URL的访问请求 CDN全局负载均衡设备根据用户IP和用户请求内容URL，选择一台用户所在区域的区域负载均衡设备， 告诉用户向这台设备发起请求 区域负载均衡设备会为用户选择一台合适的缓存服务器提供服务。选择依据：  判断哪台服务器距离用户最近 根据请求URL携带内容，判断哪一台服务器上有用户所需内容 查询当前服务器负载情况，判断哪一台有服务能力。 基于以上条件的综合分析后， 区域负载均衡设备会向全局负载均衡设备返回一台缓存服务器IP   全局负载均衡设备把缓存服务器的IP返回给用户 用户向缓存服务器发起请求，缓存服务器响应用户需求，返回用户请求内容  如果这台缓存服务器没有请求内容，而区域负载均衡设备依然将其分配给用户 这台缓存服务器会向它的上级缓存服务器请求内容，直到追溯到网站的源服务器将内容缓存到自身        CDN基于内容分类 关键字：</description>
    </item>
    
    <item>
      <title>golang-tags及扩展使用</title>
      <link>https://zylhorse.github.io/blog/golang/gotag/</link>
      <pubDate>Sun, 23 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/golang/gotag/</guid>
      <description></description>
    </item>
    
    <item>
      <title>golang常用网址</title>
      <link>https://zylhorse.github.io/blog/golang/%E5%B8%B8%E7%94%A8%E7%BD%91%E5%9D%80/</link>
      <pubDate>Sun, 23 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/golang/%E5%B8%B8%E7%94%A8%E7%BD%91%E5%9D%80/</guid>
      <description>官网  golang官方地址: https://golang.org/ golang在线运行的互动小程序: https://tour.golang.org golang CMD: https://golang.org/cmd golang Release: https://golang.org/doc/devel/release.html golang Issue: https://github.com/golang/go/issues golang wiki: https://github.com/golang/go/wiki/ golang 论坛: https://groups.google.com/g/golang-announce golang asesome-go: https://github.com/avelino/awesome-go golang trending: https://github.com/trending/go?since=daily  学习地址  The Go Programming Language 英文原版地址: http://www.gopl.io/ The Go Programming Language中文github地址: https://github.com/golang-china/gopl-zh  </description>
    </item>
    
    <item>
      <title>Node开发常见问题及解决方案</title>
      <link>https://zylhorse.github.io/blog/nodejs/problem/</link>
      <pubDate>Sun, 23 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/nodejs/problem/</guid>
      <description>证书设置 添加证书路径到环境变量：
export NODE_EXTRA_CA_CERTS=&amp;quot;/etc/nginx/ssl/ca.crt&amp;quot;install慢  全局配置  查看全局配置文件位置npm config -g ls -l :  globalconfig = &amp;quot;$prefix/etc/npmrc&amp;quot; 编辑该文件，写入内容: registry=https://registry.npm.taobao.orgdisturl = https://npm.taobao.org/mirrors/nodemetrics-registry = https://registry.npm.taobao.org     EACCESS npm install 执行时出现以下错误：Error: EACCES: permission denied, mkdtemp...
解决方案：
npm install --unsafe-perm=true --allow-root=true</description>
    </item>
    
    <item>
      <title>Golang源码阅读-interface</title>
      <link>https://zylhorse.github.io/blog/golang/interface/</link>
      <pubDate>Sat, 22 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/golang/interface/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Linux系统下服务监控和报警解决方案</title>
      <link>https://zylhorse.github.io/blog/linux/%E6%9C%8D%E5%8A%A1%E7%9B%91%E6%8E%A7%E5%8F%8A%E5%91%8A%E8%AD%A6/</link>
      <pubDate>Fri, 07 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/linux/%E6%9C%8D%E5%8A%A1%E7%9B%91%E6%8E%A7%E5%8F%8A%E5%91%8A%E8%AD%A6/</guid>
      <description>zabbix prometheus </description>
    </item>
    
    <item>
      <title>Golang-Effective Go</title>
      <link>https://zylhorse.github.io/blog/golang/effective_go/</link>
      <pubDate>Thu, 23 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/golang/effective_go/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Golang-package-unsafe</title>
      <link>https://zylhorse.github.io/blog/golang/pointer/</link>
      <pubDate>Thu, 23 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/golang/pointer/</guid>
      <description>本文主要分析unsafe.Pointer和uintptr的主要工作和区别，以及我们在项目中的使用场景
unsafe.Pointer
unsafe包 unsafe包主要包含绕过Go程序类型安全的操作。
包中引入unsafe可能是不可移植的，并且不受Go 1兼容性指南的保护。
func Alignof
func Alignof(x ArbitraryType) uintptr
Alignof接受任意类型的表达式x，并且返回变量v(假设的)需要的内存对齐字节数。它的值m是v的地址对m取余为0的最大值。 它与reflect.TypeOf(x).Align()返回值相同。
特定情况下，如果变量s是struct类型，并且f是struct中的field，那么Alignof(s.f)返回f需要的内存对齐字节数。 这种情况下它与reflect.TypeOf(s.f).FieldAlign()返回值相同。
Alignof的返回值是Go常量。
func Offsetof
func Offsetof(x ArbitraryType) uintptr
Offsetof返回x表示的field在struct中的偏移量,x必须是structValue.field类型。换言之,它返回struct开始和field开始之间的字节数。
Offset的返回值是Go常量。
func Sizeof
func Sizeof(x ArbitraryType) uintptr
接受任意类型的表达式x，并且返回变量v(假设的)的内存大小,单位是字节。它的值不包含任何可能被x引用的内存。
举个例子,如果x是一个slice，sizeof返回slice的内存大小，不包含slice中引用的内存大小。
Sizeof的返回值是Go常量。
type ArbitraryType type ArbitraryType int
ArbitraryType这里仅用于文档说明，它不属于unsafe包。它表示任意类型的Go表达式
type Pointer
type Pointer *ArbitraryTypePointer表示指向任意类型的指针。type Pointer有四种指定的操作可用，其它不可用：
 任意类型的指针可以转换为Pointer Pointer可以转换为任意类型的指针 uintptr可以转换为Pointer Pointer可以转换为uintptr Pointer允许程序使类型检测失效，可以读写任意的内存。因此使用时要小心。  以下使用Pointer的模式是有效的。未使用以下模式的代码可能是无效的，可能将来也是无效的。
即使是有效的模式也有重要的注意事项。
执行go vet可以帮助检测不符合使用Pointer模式的地方，但是go vet的沉默不能保证代码是有效的。
(1) 将*T1转换为指向*T2的指针 前提是T2不大于T1，并且两者共享相同的内存布局，这种转换允许讲一种类型的数据转换为另一种类型的数据。
一项示例是math.Float64bits的实现:
func Float64bits(f float64) uint64 {return *(*uint64)(unsafe.Pointer(&amp;amp;f))(2) 将Pointer转换为uintptr(但是不能再转换为Pointer)</description>
    </item>
    
    <item>
      <title>申请免费SSL证书</title>
      <link>https://zylhorse.github.io/blog/security/%E7%94%B3%E8%AF%B7%E5%85%8D%E8%B4%B9%E8%AF%81%E4%B9%A6/</link>
      <pubDate>Wed, 22 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/security/%E7%94%B3%E8%AF%B7%E5%85%8D%E8%B4%B9%E8%AF%81%E4%B9%A6/</guid>
      <description>证书申请 ssl证书申请的3个主要步骤
  制作CSR文件
所谓CSR就是由申请人制作的Certificate Secure Request证书请求文件。制作过程中，系统会产生2个密钥，一个是公钥就是这个CSR文件，另外一个是私钥，存放在服务器上。要制作CSR文件，申请人可以参考WEB SERVER的文档，一般APACHE等，使用OPENssl命令行来生成KEY+CSR2个文件，Tomcat，JBoss，Resin等使用KEYTOOL来生成JKS和CSR文件，IIS通过向导建立一个挂起的请求和一个CSR文件。
  CA认证
将CSR提交给CA，CA一般有2种认证方式：
   域名认证：一般通过对管理员邮箱认证的方式，这种方式认证速度快，但是签发的证书中没有企业的名称; 企业文档认证：需要提供企业的营业执照。 也有需要同时认证以上2种方式的证书，叫EV ssl证书，这种证书可以使IE7以上的浏览器地址栏变成绿色，所以认证也最严格。  证书安装
在收到CA的证书后，可以将证书部署上服务器，一般APACHE文件直接将KEY+CER复制到文件上，然后修改httpD.CONF文件;TOMCAT等，需要将CA签发的证书CER文件导入JKS文件后，复制上服务器，然后修改SERVER.XML;IIS需要处理挂起的请求，将CER文件导入。   Letsencrypt证书申请   环境配置 $ sudo apt-get install letsencrypt
  生成证书, 需要用到80端口，先停止相关进程：
$ sudo letsencrypt certonly --email xxx@xxx.com -d www.example.comxxx@xxx.com 为邮箱,用于后续证书状态(过期)通知；
www.example.com 为生成服务器证书域名；
  多域名证书(收费)
*.zylhorse.com 通配符证书匹配所有三级域名，eg：ys.zylhorse.comys1.zylhorse.compin.zylhorse.com  </description>
    </item>
    
    <item>
      <title>一致性哈希特性和使用场景</title>
      <link>https://zylhorse.github.io/blog/distribution-system/%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C/</link>
      <pubDate>Sun, 05 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/distribution-system/%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C/</guid>
      <description>概念  一种hash算法 简单说： 移除和添加一台服务器是， 此算法能够尽可能小的改变已存在的服务请求和处理请求服务器之间的映射关系；  特性 考虑到分布式系统每个节点都可能失效， 且新的节点有可能加入进来。 一致性哈希需要保证以下特性
平衡性 hash的结果尽可能的分配到所有的节点去，是的所有节点都能得到利用
分散性  分散性： 客户端请求可能不知道所有的节点存在， 部分客户端将部分节点作为一个完整的hash环；导致同一请求不能映射到同一个节点； 一致性哈希 应降低分散性；  单调性  增加或删除节点，原有的请求应该被映射到原有的节点或新的节点中去； 增加或删除节点 不应造成大量的哈希重定向  工作原理  一致性哈希算法， 将整个hash空间映射成一个虚拟的圆环，取值范围为0-uint32max； 整个空间按顺时针方向组织； 将请求对应的hash映射到圆环上， 沿圆环做顺时针查找， 分配到最近的节点上； 增加节点只会影响新的节点和逆时针节点之间得请求；  </description>
    </item>
    
    <item>
      <title>Golang代码版本管理工具-go mod</title>
      <link>https://zylhorse.github.io/blog/golang/gomodule/</link>
      <pubDate>Thu, 11 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/golang/gomodule/</guid>
      <description>概述 golang 模块管理工具，在Go 1.11版本中添加
配置环境变量 # Enable the go modules featureexport GO111MODULE=on# Set the GOPROXY environment variableexport GOPROXY=https://goproxy.io</description>
    </item>
    
    <item>
      <title>Golang和c语言互相调用的机制-cgo</title>
      <link>https://zylhorse.github.io/blog/golang/cgo/</link>
      <pubDate>Wed, 27 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/golang/cgo/</guid>
      <description>参考: https://github.com/golang/go/wiki/cgo
概述 CGO模块提供了golang和c语言互相调用的机制。某些第三方库只有c/c++实现且自己实现成本较高。
window 额外配置  安装mingw-get， 配置环境变量 安装gcc： mingw-get install gcc  golang与c基本类型转换 golang 调用c函数，需要将golang数据类型通过cgo进行转换
   C语言类型 CGO类型 Go语言类型     char C.char byte   singed char C.schar int8   unsigned char C.uchar uint8   short C.short int16   unsigned short C.ushort uint16   int C.int int32   unsigned int C.uint uint32   long C.long int32   unsigned long C.</description>
    </item>
    
    <item>
      <title>高防IP服务工作原理和配置</title>
      <link>https://zylhorse.github.io/blog/security/%E9%AB%98%E9%98%B2ip/</link>
      <pubDate>Wed, 13 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/security/%E9%AB%98%E9%98%B2ip/</guid>
      <description>概念 高防IP是针对互联网服务器遭受大流量的DDos攻击后， 导致服务不可用的情况下。 用户通过配置高防IP， 将攻击流量引流到高防IP， 并配置一定的转发规则， 将合法的请求转发到源站；
高防IP包含  SYN Flood UDP Flood ICMP Flood IGMP Flood ACK Flood Ping Sweep  </description>
    </item>
    
    <item>
      <title>消息队列简介和消息队列中间件</title>
      <link>https://zylhorse.github.io/blog/message-queue/%E4%B8%AD%E9%97%B4%E4%BB%B6/</link>
      <pubDate>Tue, 08 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/message-queue/%E4%B8%AD%E9%97%B4%E4%BB%B6/</guid>
      <description>消息队列 消息队列是消息的一个链表。 拥有写权限的可以向队列中写入特定格式消息， 拥有读权限可以从队列中读取特定格式消息。
消息队列中间件 ActiveMQ，RabbitMQ，ZeroMQ，Kafka，MetaMQ，RocketMQ，NSQ，NATS,NATS-Streaming
意义  解耦： 生产者根据自己逻辑发布消息； 消费者根据需要去订阅；对于多服务依赖有解耦的意义； 异步： 多服务调用，减少同步等待时间； 削峰： 业务系统根据自己的处理能力去消息队列中拿，防止大量信息导致系统崩溃；  问题  高可用：mq 肯定事集群部署，防止单机挂掉，业务停掉； 数据丢失： mq 需要数据本地磁盘持久化；  </description>
    </item>
    
    <item>
      <title>ZooKeeper工作原理</title>
      <link>https://zylhorse.github.io/blog/distribution-system/zookeeper/</link>
      <pubDate>Fri, 04 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/distribution-system/zookeeper/</guid>
      <description>ZooKeeper ZooKeeper是一个开源的分布式协调服务， 由雅虎创建， 是Google Chubby的开源实现， 现在被拆分为Hadoop的独立子项目。
 ZookKeeper是一个分布式小文件系统，且被设计为高可用。通过选举算法和集群复制来避免单点故障。 因为是基于文件系统设计， 即使所有ZooKeeper节点全部挂掉， 数据也会持久化， 重启服务器后， 可恢复数据。 ZooKeeper通过mvvc（多版本控制）实现乐观锁，节点更新是原子的，所以不是成功就是失败。  功能简介 分布式系统基于ZooKeeper可以实现诸如： 数据发布/订阅、负载均衡、命名服务、分布式协调/通知、集群管理、Master选举、配置维护、名字服务、分布式同步、分布式锁、分布式队列
基本概念 集群角色 一个ZooKeeper集群同一时刻只能有一个Leader， 其他都是Follower或Observer
 Leader Follower Observer  </description>
    </item>
    
    <item>
      <title>Docker部署和配置nsq集群</title>
      <link>https://zylhorse.github.io/blog/message-queue/nsq/docker-%E5%AE%89%E8%A3%85nsq/</link>
      <pubDate>Sun, 25 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/message-queue/nsq/docker-%E5%AE%89%E8%A3%85nsq/</guid>
      <description>nsq.yml version: &#39;3&#39;services:nsqlookupd:image: nsqio/nsqcommand: /nsqlookupdports:- 4160:4160- 4161:4161nsqd:image: nsqio/nsqcommand: /nsqd --lookupd-tcp-address=192.168.20.99:4160 --broadcast-address=192.168.20.99depends_on:- nsqlookupdports:- 4150:4150- 4151:4151nsqadmin:image: nsqio/nsqcommand: /nsqadmin --lookupd-http-address=192.168.20.99:4161depends_on:- nsqlookupdports:- 4171:4171</description>
    </item>
    
    <item>
      <title>NSQ简介</title>
      <link>https://zylhorse.github.io/blog/message-queue/nsq/nsqd/</link>
      <pubDate>Fri, 23 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/message-queue/nsq/nsqd/</guid>
      <description>描述 是一个守护进程，负责接收，排队，投递消息给客户端
参数 -lookupd-tcp-address=: nslookup tcp 监听地址 -broadcast-address=&amp;quot;&amp;quot;: 注册到nslookup地址， 需要显示指定</description>
    </item>
    
    <item>
      <title>Kafka简介</title>
      <link>https://zylhorse.github.io/blog/message-queue/kafka/kafka/</link>
      <pubDate>Thu, 08 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/message-queue/kafka/kafka/</guid>
      <description>简介 </description>
    </item>
    
    <item>
      <title>Docker问题集锦</title>
      <link>https://zylhorse.github.io/blog/docker/%E9%97%AE%E9%A2%98/</link>
      <pubDate>Sat, 15 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/docker/%E9%97%AE%E9%A2%98/</guid>
      <description> docker 解决 x509: certificate signed by unknown authority # vim /etc/docker/daemon.json{ &amp;quot;insecure-registries&amp;quot;: [&amp;quot;registry.svc.xxx.cn&amp;quot;]} Macos Docker Network 模式
Macos不支持host模式，因此需要使用端口映射模式  </description>
    </item>
    
    <item>
      <title>Docker在linux上部署和配置</title>
      <link>https://zylhorse.github.io/blog/docker/docker/</link>
      <pubDate>Tue, 04 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/docker/docker/</guid>
      <description>Docker Ubuntu安装 下载地址
查看容器 $ sudo docker ps -a
查看镜像 $ sudo docker images
设置容器重启策略 $ docker run xxx --restart
 no: 默认策略，在容器退出时不重启容器 on-failure: 在容器非正常退出时（退出状态非0），才会重启容器 on-failure:3，在容器非正常退出时重启容器，最多重启3次 always: 在容器退出时总是重启容器 unless-stopped: 在容器退出时总是重启容器，但是不考虑在Docker守护进程启动时就已经停止了的容器   如果创建时未指定 启动策略， 可以通过update命令: docker update &amp;ndash;restart=always xxx
 运行容器 $ docker exec -it xxx /bin/bash
 xxx 容器ID
 拷贝本地文件到容器 $ docker cp [option] local container:/dir
 -L 保持源文件链接
 提交镜像 $ docker commit -m=message -a=author containerid imagesname</description>
    </item>
    
    <item>
      <title>方法论和世界观</title>
      <link>https://zylhorse.github.io/blog/stories/%E6%96%B9%E6%B3%95%E8%AE%BA%E5%92%8C%E4%B8%96%E7%95%8C%E8%A7%82/</link>
      <pubDate>Mon, 20 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/stories/%E6%96%B9%E6%B3%95%E8%AE%BA%E5%92%8C%E4%B8%96%E7%95%8C%E8%A7%82/</guid>
      <description>方法论 是人们认识世界改变世界的的根本方法。 世界观 通俗讲就是”观世界“， 是人们对世界的总体看法和根本观点。 关系  世界观主要解决世界”是什么“的问题，方法论主要解决”怎么办“的问题。
方法论是一种以解决问题为目标的体系，通常涉及对问题阶段、人物、工具、方法技巧的论述。方法论会对一系列具体的方法进行分析研究、系统总结并最终提出解决问题的较为一般性的规则。
世界观原则在认识和实践的过程中的运用表现为方法。方法论是这些方法的理论，没有和世界观相分离、相分裂的孤立的方法论；也没有不具备方法论意义的纯粹的世界观。
一般来说有什么样的世界观就有什么样的方法论。
 </description>
    </item>
    
    <item>
      <title>MongoDB数据库安装配置</title>
      <link>https://zylhorse.github.io/blog/database/mongo/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/</link>
      <pubDate>Thu, 02 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/database/mongo/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/</guid>
      <description>远程访问 修改 /etc/mongod.conf: bindIpAll:true</description>
    </item>
    
    <item>
      <title>MongoDB数据库常用sql语句</title>
      <link>https://zylhorse.github.io/blog/database/mongo/sql%E8%AF%AD%E5%8F%A5/</link>
      <pubDate>Thu, 02 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/database/mongo/sql%E8%AF%AD%E5%8F%A5/</guid>
      <description>备份数据库 mongodump -h dbhost -d dbname -o dumpdir
备份数据库表 mongoexport -d dbname -c collectionname -o file --type json/csv -f field参数说明：-d ：数据库名-c ：collection名-o ：输出的文件名--type ： 输出的格式，默认为json-f ：输出的字段，如果-type为csv，则需要加上-f &amp;quot;字段名&amp;quot;还原数据库 mongorestore -h dbhost -d dbname dumppath
还原数据库表 mongoimport -d dbname -c collectionname --file filename --headerline --type json/csv -f field参数说明：-d ：数据库名-c ：collection名--type ：导入的格式默认json-f ：导入的字段名--headerline ：如果导入的格式是csv，则可以使用第一行的标题作为导入的字段--file ：要导入的文件还原数据库表json mongoimport &amp;ndash;db meteor &amp;ndash;collection meetings &amp;ndash;type json &amp;ndash;file /asj/meteor-batch/meetings.</description>
    </item>
    
    <item>
      <title>Golang validator应用</title>
      <link>https://zylhorse.github.io/blog/golang/validator/</link>
      <pubDate>Mon, 23 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/golang/validator/</guid>
      <description></description>
    </item>
    
    <item>
      <title>从GW和IM实战描述websocket协议</title>
      <link>https://zylhorse.github.io/blog/network/websocket/</link>
      <pubDate>Fri, 20 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/network/websocket/</guid>
      <description>描述 用于在单个tcp连接上进行全双工通信的协议；RFC6455标准；</description>
    </item>
    
    <item>
      <title>流媒体学习-Flv视频封装格式</title>
      <link>https://zylhorse.github.io/blog/mediastream/flv%E5%B0%81%E8%A3%85%E6%A0%BC%E5%BC%8F%E8%A7%A3%E6%9E%90/</link>
      <pubDate>Thu, 12 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/mediastream/flv%E5%B0%81%E8%A3%85%E6%A0%BC%E5%BC%8F%E8%A7%A3%E6%9E%90/</guid>
      <description>简介 FLV(Flash Video) 是Adobe公司开发的一种流媒体格式，由其封装的视频文件体积小、封装简单。FLV可以使用Flash Player播放。FLV封装的视频文件后缀通常为.flv。
 FLV包含两部分，文件头(file header)和文件体(file body)。文件体由一系列Tag组成。
 FLV Header    字段名 字段大小 字段描述     Signature 3Byte 文件标识(FLV)   Version 1Byte 版本号（0x01)   Flags 1Byte 前5位保留为0，第6位表示是否有音频Tag，第7位保留为0，第8位表示是否有视频Tag。   HeaderSize 4Byte 表示从file header开始到file body开始的字节数，版本1总为9。    FLV Body  间隔包含Previous Tag Size字段，标识前一个Tag大小。
    Previous Tag Size Tag1 &amp;hellip; Previous Tag Size Tagn    Tag    Tag Header Tag Data    Tag Header    字段 字段大小 字段描述     Type 1Byte 标识Tag类型，音频(0x08)、视频(0x09)、script data(0x12),其他值保留   Datasize 3Byte 标识Tag Data数据大小   Timestamp 3Byte 标识Tag时间戳   Timestamp_ex 1Byte 时间戳扩展字节，24字节数值不够时，该字节最高位将时间戳扩展为32位数。   StreamID 3Byte stream id 总是0    Tag Data 不同类型Tag的data部分结构不同；</description>
    </item>
    
    <item>
      <title>流媒体学习-H264视频编解码</title>
      <link>https://zylhorse.github.io/blog/mediastream/h264%E8%A7%86%E9%A2%91%E7%A0%81%E6%B5%81%E8%A7%A3%E6%9E%90/</link>
      <pubDate>Thu, 12 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/mediastream/h264%E8%A7%86%E9%A2%91%E7%A0%81%E6%B5%81%E8%A7%A3%E6%9E%90/</guid>
      <description>H.264 H.264原始码流（“裸流”）的基本单元是NALU。
 NALU之间通过startcode（起始码）分隔。
起始码分为0x000001(3Byte)或0x00000001(4Byte)。
H.264码流的解析步骤就是首先从码流中搜索起始码，分离出NALU，然后在分析NALU的各个字段。
 </description>
    </item>
    
    <item>
      <title>流媒体学习-音频码流格式</title>
      <link>https://zylhorse.github.io/blog/mediastream/aac%E9%9F%B3%E9%A2%91%E7%A0%81%E6%B5%81%E8%A7%A3%E6%9E%90/</link>
      <pubDate>Thu, 12 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/mediastream/aac%E9%9F%B3%E9%A2%91%E7%A0%81%E6%B5%81%E8%A7%A3%E6%9E%90/</guid>
      <description>AAC AAC原始码流（“裸流”）的基本单元是ADTS frame。
 其中每个ADTS frame之间通过syncword（同步字）分隔。
同步字为0xfff。
AAC码流解析的步骤就是从码流中搜索syncword,分离出ADTS frame，然后再解析ADTS frame 字段。
 </description>
    </item>
    
    <item>
      <title>Linux TCP/IP内核参数调优</title>
      <link>https://zylhorse.github.io/blog/linux/core-tcp-ip/</link>
      <pubDate>Wed, 11 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/linux/core-tcp-ip/</guid>
      <description>Sysctl命令 用来配置与查看在/proc/sys目录中的内核参数。如果想使参数长期保存，可以通过编辑/etc/sysctl.conf文件来实现。
命令格式：
 sysctl [-n] [-e] -w variable=valuesysctl [-n] [-e] -p (default /etc/sysctl.conf)sysctl [-n] [-e] –a常用参数的意义：
 -w 临时改变某个指定参数的值，如: $ sysctl -w net.ipv4.ip_forward=1 -a 显示所有的系统参数 -p 从指定的文件加载系统参数,默认从/etc/sysctl.conf 文件中加载，如： echo 1 &amp;gt; /proc/sys/net/ipv4/ip_forward sysctl -w net.ipv4.ip_forward=1   以上两种方法都可能立即开启路由功能，但如果系统重启，或执行了$ service network restart命令，所设置的值即会丢失。
如果想永久保留配置，可以修改/etc/sysctl.conf文件，将 net.ipv4.ip_forward=0改为net.ipv4.ip_forward=1
内核参数调整 内核参数调整有两种方式
  修改/proc下内核参数文件内容，不能使用编辑器来修改内核参数文件，理由是由于内核随时可能更改这些文件中的任意一个， 另外，这些内核参数文件都是虚拟文件，实际中不存在，因此不能使用编辑器进行编辑，而是使用echo命令，然后从命令行将输出重定向至 /proc 下所选定的文件中。 如：将 timeout_timewait 参数设置为30秒：$ echo 30 &amp;gt; /proc/sys/net/ipv4/tcp_fin_timeout。
参数修改后立即生效，但是重启系统后，该参数又恢复成默认值。因此，想永久更改内核参数，需要修改/etc/sysctl.conf文件。
  修改/etc/sysctl.conf文件。检查sysctl.conf文件，如果已经包含需要修改的参数，则修改该参数的值,如果没有需要修改的参数， 在sysctl.conf文件中添加该参数。如：net.ipv4.tcp_fin_timeout=30。保存退出后，可以重启机器使参数生效，如果想使参数马上生效， 也可以执行如下命令：$ sysctl -p。</description>
    </item>
    
    <item>
      <title>Ubuntu Hotspot配置</title>
      <link>https://zylhorse.github.io/blog/linux/ubuntu-hotspot/</link>
      <pubDate>Wed, 11 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/linux/ubuntu-hotspot/</guid>
      <description>背景 配置瘦客户机，进行自组网，摒弃复杂的网络环境
环境配置   网卡Master模式
 安装 $ apt install iw 检查 iw list  Supported interface modes:* IBSS* managed //作为客户端接入AP* AP // 作为无线接入点使用* AP/VLAN* monitor* P2P-client* P2P-GO* P2P-device 如果显示以上内容，则该网卡支持作为无线AP使用
   Wlan Interface
 查看: ifconfig -a enp2s0: flags=4163&amp;lt;UP,BROADCAST,RUNNING,MULTICAST&amp;gt; mtu 1500inet 172.16.3.173 netmask 255.255.255.0 broadcast 172.16.3.255inet6 fe80::6600:6aff:fe02:755a prefixlen 64 scopeid 0x20&amp;lt;link&amp;gt;ether 64:00:6a:02:75:5a txqueuelen 1000 (Ethernet)RX packets 63949 bytes 79546938 (79.</description>
    </item>
    
    <item>
      <title>流媒体学习-开源网站</title>
      <link>https://zylhorse.github.io/blog/mediastream/%E5%BC%80%E6%BA%90%E7%BD%91%E7%AB%99/</link>
      <pubDate>Wed, 11 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/mediastream/%E5%BC%80%E6%BA%90%E7%BD%91%E7%AB%99/</guid>
      <description>golang webrtc https://github.com/pion</description>
    </item>
    
    <item>
      <title>流媒体学习-视频像素格式</title>
      <link>https://zylhorse.github.io/blog/mediastream/%E8%A7%86%E9%A2%91%E5%83%8F%E7%B4%A0%E6%95%B0%E6%8D%AE/</link>
      <pubDate>Wed, 11 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/mediastream/%E8%A7%86%E9%A2%91%E5%83%8F%E7%B4%A0%E6%95%B0%E6%8D%AE/</guid>
      <description>视频像素数据 格式 数据格式为
 Planar(YUV):分量分块存储； Packed(RGB):分量连续村粗。   注：像素的采样位数根据图像不同获取。本文默认采样位数为8bit，所以一个像素采样值为1Byte。
 YUV 分离Y、U、V分量 一帧YUV像素数据得宽和高为w 和 h，那么一帧YUV像素数据大小为:w*h*3/2 Byte;
 Y分量：前w*h Byte
U分量：中间w*h/4 Byte
V分量：后面w*h/4 Byte
 Y、U、V分量功能 更改图像灰度 只需将U、V分量设置为128（无色）
 U、V是图像的色度分量。由于色度分量会进行偏置处理（-128）所以这里的无色为128；
 更改图像亮度 只需将Y分量每个像素点除以2；
 Y是图像的亮度分量。
 PSNR PSNR是最基本的视频质量评价方法。
RGB 分离R、G、B分量 一帧RGB像素数据的宽和高为w和h,那么一帧RGB像素数据大小为w*h*3Byte；
 R、G、B分量连续存储， 存储格式为：R1,G1,B1,&amp;hellip;,Rn,Gn,Bn。
 RGB转换成BMP BMP采用小端存储方式（B、G、R），因此将RGB像素数据中的R和B分量顺序进行交换。
RGB和YUV转换 Y= 0.299*R+0.587*G+0.114*BU=-0.147*R-0.289*G+0.463*BV= 0.615*R-0.515*G-0.100*B</description>
    </item>
    
    <item>
      <title>流媒体学习-音频采样格式</title>
      <link>https://zylhorse.github.io/blog/mediastream/%E9%9F%B3%E9%A2%91%E9%87%87%E6%A0%B7%E6%95%B0%E6%8D%AE/</link>
      <pubDate>Wed, 11 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/mediastream/%E9%9F%B3%E9%A2%91%E9%87%87%E6%A0%B7%E6%95%B0%E6%8D%AE/</guid>
      <description>音频采样数据 保存格式：pcm文件
格式  左声道数据 右声道数据   注：左声道和右声道数据间隔存储，声道的每个样值大小根据采样格式决定。
 增、降音量值 将声道的每个样值做加、减法。
提高速度 根据速度间隔获取样值。
截取音频 从指定采样点截取指定长度的音频
采样数据格式转换 将PCM16LE双声道音频采样数据转换为WAVE格式音频数据  wave格式音频实在pcm文件的前面添加一个文件头，从而封装成wave格式音频。
 </description>
    </item>
    
    <item>
      <title>流媒体学习-流媒体名词解释</title>
      <link>https://zylhorse.github.io/blog/mediastream/%E5%85%A5%E9%97%A8/</link>
      <pubDate>Tue, 10 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/mediastream/%E5%85%A5%E9%97%A8/</guid>
      <description>入门 封装格式 将音频、视频打包成一个文件的规范，主要是把视频码流和音频码流按一定格式存储在一个文件中。
 mp4,flv,mkv,avi,rmvb,mkv
不同封装格式差距不大，支持的音视频编码标准也不一样。如：mkv封装格式支持的音视频编码标准十分广泛；
rmvb封装格式制车的音视频编码标准比较少。
 查看音视频文件信息工具： mediainfo（https://github.com/MediaArea/MediaInfo）。
常见封装格式    名称 推出机构 流媒体 支持的视频编码 支持的音频编码 应用领域     AVI Microsoft Inc. 不支持 几乎所有格式 几乎所有格式 BT下载影视   MP4 MPEG 支持 MPEG-2,MPEG-4,H.264,H.263等 AAC,MPEG-1 Layers I,II,III,AC-3等 互联网视频网站   TS MPEG 支持 MPEG-1,MPEG-2,MPEG-4,H.264 AAC,MPEG-1 Layers I,II,III IPTV,数字电视   FLV Adobe Inc. 支持 Sorenson,VP6,H.264 MP3,ADPCM,Linear PCM,AAC等 互联网视频网站   MKV CoreCodec Inc. 支持 几乎所有格式 几乎所有格式 互联网视频网站   RMVB Real Networks Inc.</description>
    </item>
    
    <item>
      <title>数据结构-RingBuffer</title>
      <link>https://zylhorse.github.io/blog/data-structure/ringbuffer/</link>
      <pubDate>Fri, 23 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/data-structure/ringbuffer/</guid>
      <description></description>
    </item>
    
    <item>
      <title>数据结构-RBTree</title>
      <link>https://zylhorse.github.io/blog/data-structure/rbtree/</link>
      <pubDate>Sat, 18 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/data-structure/rbtree/</guid>
      <description></description>
    </item>
    
    <item>
      <title>数据结构-BTree</title>
      <link>https://zylhorse.github.io/blog/data-structure/btree/</link>
      <pubDate>Sat, 11 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/data-structure/btree/</guid>
      <description></description>
    </item>
    
    <item>
      <title>数据结构-Huffman</title>
      <link>https://zylhorse.github.io/blog/data-structure/huffman/</link>
      <pubDate>Sun, 28 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/data-structure/huffman/</guid>
      <description></description>
    </item>
    
    <item>
      <title>HPACK工作原理</title>
      <link>https://zylhorse.github.io/blog/network/hpack/</link>
      <pubDate>Sat, 27 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/network/hpack/</guid>
      <description>原理  HAPCK使用两个索引表（静态索引表和动态索引表）把http的请求头映射到索引值 如果请求头在静态索引表中不存在， 则对其进行哈夫曼（huffman）编码， 并缓存到动态索引表中， 从而达到压缩headers的效果  </description>
    </item>
    
    <item>
      <title>http2协议解析及解决哪些问题</title>
      <link>https://zylhorse.github.io/blog/network/http2/</link>
      <pubDate>Fri, 26 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/network/http2/</guid>
      <description>http超文本传输协议  http是简单的请求-响应协议，指定客户端发送数据格式以及服务器响应的数据格式 http是一次性连接，每次连接处理一个请求 http是无状态连接，服务器不保留客户信息  http 报文格式  请求报文：  请求行\r\n通用信息头\r\n请求头\r\n实体头\r\n报文主体响应报文：  状态行\r\n通用信息头\r\n响应头\r\n实体头\r\n报文主体http1.1 缺陷 高延迟 网络延迟问题主要由队头阻塞（head-of-line blocking）导致带宽无法被充分利用；
 队头阻塞指当顺序请求序列中的一个请求因为某种原因被阻塞时，后面排队的请求也一并阻塞，导致客户端迟迟收不到数据。
 解决办法：
 合并多张小图为一张大图（雪碧图），前端利用算法进行切割使用 内联： 防止发送很多小图请求， 将图片原始数据嵌入在css的URL中 拼接： 将体量小的js文件使用webpack打包成一个js文件 将同一页面资源分散到不同域名，提升连接上限： 浏览器限制同一域名最多建立6个tcp连接。  无状态 由于http是无状态连接，为了服务器识别同一用户请求，报文header中一般会携带 User Agent、Cookie、Accept、Server等许多固定头字段。header携带内容过大，一定层度上增加传输成本。
不支持服务器推送消息 明文传输的不安全性 HTTP/2 二进制传输  将原来的header+body消息，打散为数个小片的二进制帧（Frame），用HEADERS帧存放头数据，用DATA帧存放主体数据 同域名下所有通信都在单个连接下完成， 该连接可以承载任意数量的双向数据流 每个数据流都是以消息的形式发送，而消息由一个或多个帧组成 多个帧可以乱序发送，根据帧首部的流标识进行重新组装  Header 压缩  建立HPACK索引表， 由客户端和服务器共同渐进更新； 相同的报文头不用每次请求都发送 采用哈夫曼编码来压缩报文头  多路复用  对于同一域名下的多个请求连接，复用一个tcp连接， 消除了tcp建立连接带来的延迟和内存消耗 单个连接可以承载任意数量的双向数据流， 并行交错发送和响应请求， 请求之间互不影响； 每个请求可以携带一个31bit的优先值， 数值越大优先级越低。 客户端和服务器根据优先级采用不同的策略处理流；  server push 服务器可以新建流，主动向客户端发送消息。</description>
    </item>
    
    <item>
      <title>Reactor模式深入浅出</title>
      <link>https://zylhorse.github.io/blog/network/reactor/</link>
      <pubDate>Fri, 26 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/network/reactor/</guid>
      <description>Reactor设计模式是一种事件处理模式，用于Service Handler处理由一个或多个输入发送的并发请求。 Service Handler将传入的请求进行Demultiplex，并将它们同步的分发到关联的Event Handler。
模块 Handle
任何可以提供输入或者消费系统输出的资源,它可以是打开的文件，一个网络连接(socket)等。
Synchronous Event Demultiplexer 使用一个event loop来阻塞所有的Handle. 当可以在一个Handle上非阻塞的开始 同步操作时，Demultiplexer将该Handle发送到Dispatcher上。
 e.g.: 如果Handle没有数据可读时,read()同步调用会阻塞。demultiplexer在Handle上使用select()， 它会阻塞,直到Handle有数据可以读。这种情况下，对read()的同步调用不会阻塞， 并且Demultiplexer可以将Handle发送给Dispatcher。
 Dispatcher
管理对Event Handler的注册和移除。分发从Demultiplexer来的Handle到关联的Event Handler。
Event Handler
事件处理器，以供Dispatcher回调使用。
Concrete Event Handler 具体的Event Handler实现。
下面使用一张图来表现以上各个模块之间的关系:</description>
    </item>
    
    <item>
      <title>Redis发布订阅模式和事件通知</title>
      <link>https://zylhorse.github.io/blog/cache/redis/%E5%8F%91%E5%B8%83%E8%AE%A2%E9%98%85/</link>
      <pubDate>Fri, 12 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/cache/redis/%E5%8F%91%E5%B8%83%E8%AE%A2%E9%98%85/</guid>
      <description>发布订阅 redis发布订阅是一种消息通讯模式， 接收者subscribe channel 消息， 发送者publish channel 消息
语法：subscribe channel1 channel2publish channel messageunsubscribe channel1 channel2pubsub subcommand // eg: pubsub channels 查看订阅channelpsubscribe pattern // 订阅给定模式频道punsubscribe pattern // 退订给定模式频道事件通知（keyspace notification）  keyspace 通知是的客户端可以通过订阅频道或模式，来接收那些以某种方式改动redis数据集的事件； 事件通过redis的订阅发布功能来进行分发； redis的订阅和发布功能采取的是发送即忘（fire and forget）策略， 会导致离线的redis-cli，丢失这部分事件。  事件类型 对每个数据的修改， 键空间都会发送两种不同类型的事件：
 键空间（key-space）通知 键事件（key-event）通知  例如： 当del key命令执行时：1. 键空间频道的订阅者将接收到被执行的事件的名字，在这个例子中，就是 del2. 键事件频道的订阅者将接收到被执行事件的键的名字，在这个例子中，就是 mykey配置 修改 redis.conf 中的notify-keyspace-events， 参数配置如下：
字符	发送的通知K	键空间通知，所有通知以__keyspace@&amp;lt;db&amp;gt;__为前缀，针对KeyE	键事件通知，所有通知以__keyevent@&amp;lt;db&amp;gt;__为前缀，针对eventg	DEL、EXPIRE、RENAME等类型无关的通用命令的通知$	字符串命令的通知l	列表命令的通知s	集合命令的通知h	哈希命令的通知z	有序集合命令的通知x	过期事件：每当有过期键被删除时发送e	驱逐(evict)事件：每当有键因为maxmemory政策而被删除时发送A	参数g$lshzxe的别名，相当于是All输入的参数中至少要有一个K或E， 否则不管其余的参数是什么， 都不会有任何通知被分发。</description>
    </item>
    
    <item>
      <title>代码统计工具</title>
      <link>https://zylhorse.github.io/blog/tools/cloc/</link>
      <pubDate>Wed, 03 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/tools/cloc/</guid>
      <description>Cloc 安装
 npm install -g cloc # https://www.npmjs.com/package/clocsudo apt-get install cloc # Debian, Ubuntusudo yum install cloc # Red Hat, Fedorasudo pacman -S cloc # Archsudo pkg install cloc # FreeBSDsudo port install cloc # Mac OS X with MacPorts基本使用
&amp;gt; cloc ./dir4076 text files.3883 unique files. 1521 files ignored.http://cloc.sourceforge.net v 1.50 T=12.0 s (209.2 files/s, 70472.1 lines/s)-------------------------------------------------------------------------------Language files blank comment code-------------------------------------------------------------------------------Perl 2052 110356 130018 292281C 135 18718 22862 140483C/C++ Header 147 7650 12093 44042Bourne Shell 116 3402 5789 36882Lisp 1 684 2242 7515make 7 498 473 2044C++ 10 312 277 2000XML 26 231 0 1972yacc 2 128 97 1549YAML 2 2 0 489DOS Batch 11 85 50 322HTML 1 19 2 98-------------------------------------------------------------------------------SUM: 2510 142085 173903 529677-------------------------------------------------------------------------------GitStats 待续</description>
    </item>
    
    <item>
      <title>缓存穿透、缓存雪崩、缓存击穿的区别和解决方案</title>
      <link>https://zylhorse.github.io/blog/cache/%E7%BC%93%E5%AD%98/</link>
      <pubDate>Fri, 21 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/cache/%E7%BC%93%E5%AD%98/</guid>
      <description>缓存穿透 描述： 请求不存在的数据， 使得大量请求发送到DB， 增加DB压力；解决方案：　1. 对落在数据库上的请求进行限流， 降低DB压力2. 接口层过滤非法参数；3. 缓存空查询结果。4. 使用布隆过滤器， 将所有可能数据hash到一个足够大的bitmap中， 一个一定不存在的数据会被bitmap拦截掉缓存击穿 描述： 高频访问热点数据，在缓存失效的瞬时，大量请求发送到DB， 来更新缓存， 增加DB压力；解决方案： 1. 设置热点数据永不过期；2. 加分布式全局锁，只允许单线程访问该数据；锁竞争较大。缓存雪崩 描述： 给大量缓存设置同样过期时间， 在某一刻，大量缓存数据过期，导致大量请求发送到DB，增加DB压力；解决方案： 1. 给数据过期时间添加随机数，避免同时过期；2. 将热点数据分不到不同的缓存数据库中3. 设置热点数据永不过期；5. hystrix 限制每秒请求数量， 超出请求引导到降级页面 6. 提高缓存中间件的高可用性</description>
    </item>
    
    <item>
      <title>缓存数据不一致和解决方案</title>
      <link>https://zylhorse.github.io/blog/cache/%E7%BC%93%E5%AD%98%E4%B8%8D%E4%B8%80%E8%87%B4/</link>
      <pubDate>Wed, 12 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/cache/%E7%BC%93%E5%AD%98%E4%B8%8D%E4%B8%80%E8%87%B4/</guid>
      <description>缓存数据不一致  使用缓存来存储热点数据是高并发的常用手段， 通过缓存大大减轻了数据库的压力， 同时减少了响应请求实际时间； 但是引入缓存后，就会导致缓存和db中数据不一致。这个时候就要更新缓存或淘汰缓存；  问题： 如果引入了db读写分离， 还需要考虑到db主从同步时的延迟。 可以监听binlog来异步更新缓存；（阿里canel）
方案一： 先读db后写缓存  请求来了，先读缓存， 为空则访问数据库， 并将数据放入缓存 更新的时候，先删除缓存，在更新数据库  问题：
 更新时， 先删除缓存，导致db还没有写入成功，另一个请求到来会将旧的db数据 更新到缓存中； 造成只有下次更新数据库时，才会更新缓存；造成缓存和数据库数据不一致；  方案二  请求来了，先读缓存， 为空则访问数据库， 并将数据放入缓存 更新的时候，先更新数据库，在删除缓存  问题：
 更新数据库成功， 而删除缓存失败， 造成脏数据； 引入消息队列和binlog监听， 尝试重复删除；  </description>
    </item>
    
    <item>
      <title>Redis源码解读-dict</title>
      <link>https://zylhorse.github.io/blog/cache/redis/dict/</link>
      <pubDate>Sat, 11 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/cache/redis/dict/</guid>
      <description>定义 dict实现通过key查找value的键值对的数据结构，底层通过hash表实现
数据结构 </description>
    </item>
    
    <item>
      <title>心念旧是</title>
      <link>https://zylhorse.github.io/blog/stories/%E5%BF%83%E5%BF%B5%E6%97%A7%E6%98%AF/</link>
      <pubDate>Sat, 04 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/stories/%E5%BF%83%E5%BF%B5%E6%97%A7%E6%98%AF/</guid>
      <description>唯</description>
    </item>
    
    <item>
      <title>数据结构-Bitmap</title>
      <link>https://zylhorse.github.io/blog/data-structure/bitmap/</link>
      <pubDate>Fri, 03 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/data-structure/bitmap/</guid>
      <description></description>
    </item>
    
    <item>
      <title>不同类型代码执行引擎</title>
      <link>https://zylhorse.github.io/blog/software-programming/%E8%99%9A%E6%8B%9F%E6%9C%BA/</link>
      <pubDate>Mon, 23 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/software-programming/%E8%99%9A%E6%8B%9F%E6%9C%BA/</guid>
      <description>概述 代码在物理机器上执行过程：
 代码被编译成二进制文件 二进制文件运行， 加载程序到内存中 CPU通过总线将内存中指令取出并放入指令流水线， 对指令进行 译码、执行、缓冲、回写（参考arm7 三级流水 和 arm9 五级流水）  类似于程序在物理机器上运行， 虚拟机上代码执行过程：
 代码被编译成相关字节码，然后在虚拟机上运行 虚拟机对字节码进行取指令、译码、执行、结果回写  虚拟机实现概念  将源码编译成VM所能执行的字节码 包含指令和操作数的数据结构 一个包含所有函数操作的调用栈 一个指令指针，用于指向下一条要被执行的指令 一个虚拟的CPU（指令派发者）： 取指， 译码，执行  虚拟机分类 主要区别是操作数和结果的存储和检索机制不一样。
栈虚拟机（stack vm）  基于栈的虚拟机有操作数栈的概念，首先从符号表中取出数据然后压入操作数栈 进行真正的运算时都是直接与操作数栈进行交互 运算时指令无需指定操作数， 因为默认操作数存放在操作数栈上， 直接从栈上pop出数据使用即可 运算后的将结果存入操作数栈顶  栈虚拟机优缺点 优点：
 不管任何操作都通过操作数栈进行， 可以无视具体的物理结构 指令紧凑，一两个字节即可存储 编译器实现简单 寄存器由硬件直接提供，不用进行寄存器分配 可移植性强  缺点：
 因为无论什么操作都要通过操作数栈， 所以速度慢  寄存器虚拟机 （register vm）  基于寄存器的虚拟机会分配虚拟寄存器，存放数据 进行运算时， 需要指定操作数的寄存器 虚拟机对寄存器进行解析，找出操作数的位置，然后取出操作数进行运算  寄存器虚拟机优缺点 优点：
 没有栈虚拟机在拷贝数据时进行大量的出入栈操作     栈式 VS 寄存器式 对比     指令条数 栈式 &amp;gt; 寄存器式   代码尺寸 栈式 &amp;lt; 寄存器式   移植性 栈式优于寄存器式   指令优化 栈式更不易优化   解释器执行速度 栈式解释器速度稍慢   代码生成难度 栈式简单   简易实现中的数据移动次数 栈式移动次数多    </description>
    </item>
    
    <item>
      <title>暖与凉</title>
      <link>https://zylhorse.github.io/blog/stories/%E6%9A%96%E4%B8%8E%E5%87%89/</link>
      <pubDate>Thu, 12 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/stories/%E6%9A%96%E4%B8%8E%E5%87%89/</guid>
      <description>谢谢陌生人的关心</description>
    </item>
    
    <item>
      <title>冬风</title>
      <link>https://zylhorse.github.io/blog/stories/%E5%86%AC%E9%A3%8E/</link>
      <pubDate>Mon, 09 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/stories/%E5%86%AC%E9%A3%8E/</guid>
      <description>当风再来，冬已悄至。</description>
    </item>
    
    <item>
      <title>讲诉互联网的概念，区分广义互联网和侠义互联网</title>
      <link>https://zylhorse.github.io/blog/network/%E4%BA%92%E8%81%94%E7%BD%91/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/network/%E4%BA%92%E8%81%94%E7%BD%91/</guid>
      <description>广义互联网 大家所说的互联网一般指广义互联网，由两层组成
 核心层： TCP/IP网络传输层(侠义互联网) 上层： 万维网WWW为代表的应用层  这一层包含多种类型的流量和应用：邮件、软件、在线影视、游戏、电子商务、移动应用 所有的SP(service provider, 服务提供商)提供的都是用户看的见的应用    互联网拥堵问题 关键字：
 ISDN： 综合业务数字网（Integrated Services Digital Network，ISDN）是一个数字电话网络国际标准 ADSL：非对称数字用户线路（ADSL，Asymmetric Digital Subscriber Line）是数字用户线路（xDSL，Digital Subscriber Line）服务中最流行的一种 IDC：互联网数据中心（Internet Data Center，简称IDC）是指一种拥有完善的设备（包括高速互联网接入带宽、高性能局域网络、安全可靠的机房环境等）、专业化的管理、完善的应用的服务平台 收敛比： 就是N对应到M的一个过程,当N&amp;gt;M时被称作收敛.鉴于排队论的原理,当有N个顾客按其概率到达要求服务时,如果在一定的服务质量(收敛条件)被约定,则本系统仅需要有M(M&amp;lt;N)个服务员就够了. 相当于输入的比输出的多   &amp;ldquo;第一公里&amp;rdquo;  万维网流量向用户传送的第一个出口，即网站服务器接入互联网的链路所能提供的带宽。 这个带宽决定了网站能为用户提供的访问速度和并发访问量 一个网站，其服务的用户越多，对其出口带宽要求越大   &amp;ldquo;最后一公里&amp;rdquo;  万维网流量向用户传输的最后一段接入链路，即用户接入带宽 用户的平均接入带宽，是影响互联网上层应用发展的决定性因素之一 互联网初期  主要上网方式为拨号上网和ISDN()等，网络接入速度低。 主要内容是占用带宽非常小的文字为主，主流应用是Telnet、BBS等   万维网出现  多媒体内容开始在互联网上传播 用户接入带宽成为制约用户使用互联网的主要瓶颈 2001年开始，各大电信运营商发展ADSL等带宽服务，随着带宽提升和接入手段丰富(光纤入户、wifi，4G等)，&amp;ldquo;最后一公里&amp;quot;问题得以解决     对等互联关口  不同基础运营商之间的互联互通 一般运营商之间只有两三个互联互通点， 可以想象这两三个点上会产生多大流量 如：  当某个网站部署在运营商A的IDC机房中 运营商B的用户要访问该网站，就必须经过A，B之间的互联互通点进行跨网访问。   不同网络间的互联互通带宽，对于任何一个运营商网络流量来水，占比都比较小，收敛比高，因此这里通常是互联网传输中的拥堵点   长途骨干传输  长距离传输时延问题 从网站服务器到用户之间要经过网站所在的IDC、骨干网、用户所在的城域网、用户所在的接入网等 距离非常遥远，因此不可避免的带来较长的传输时延 由于互联网上的绝大部分流量需要经过骨干网进行传输，所以需要骨干网络的承载能力必须与互联网的应用同步发展  实际两者并不同步，当骨干网络升级和扩容滞后于互联网上应用的发展，就会阶段性的使得大型骨干网的承载能力成为影响互联网性能的瓶颈      8秒定律  当用户访问一个网站时， 如果网页打开等待时间超过8秒，就会由30%用户放弃等待 一个网站10秒后网页打不开，会有40% 的用户跳出该页面。 大部分手机用户愿意等待时间为6-10秒 一秒延迟会导致转化率下降7%  </description>
    </item>
    
    <item>
      <title>一次</title>
      <link>https://zylhorse.github.io/blog/stories/%E4%B8%80%E6%AC%A1/</link>
      <pubDate>Tue, 13 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/stories/%E4%B8%80%E6%AC%A1/</guid>
      <description>往事讲一遍，是最初的感受。
有些事情一次就好。</description>
    </item>
    
    <item>
      <title>Redis的主从同步方式</title>
      <link>https://zylhorse.github.io/blog/cache/redis/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/</link>
      <pubDate>Thu, 01 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/cache/redis/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/</guid>
      <description>概述 为了分担redis读写压力， 支持主从复制； 分为全量同步和增量同步
全量同步 全量同步一般发生在slave 初始化阶段， 这时slave需要将master上的所有数据复制一份，具体步骤：
 slave连接master， 发送SYNC命令 master接收到SYNC命令，开始执行BGSAVE命令生成RDB文件并在缓冲区记录此后执行的所有命令； master执行完BGSAVE命令后， 向所有slave发送快照，并在发送期间继续记录被执行的命令； slave收到快照文件后，丢弃所有数据，并载入新的快照； master快照发送完成后，开始向slave分发缓冲中记录的命令 slave载入快照完成后，开始接收master上缓冲的写命令；  增量同步 增量同步主要发生在slave初始化后，开始正常工作后， 将master上后续发生的写操作同步到slave上。具体过程：
 master每执行一个写命令， 就会向slave发送同样的写命令。  主从同步特点  异步同步，不阻塞master服务器 master要开启持久化，否则master重启很危险 repl-diskless-sync no 默认不使用diskless同步方式  </description>
    </item>
    
    <item>
      <title>Redis高可用方案-集群模式</title>
      <link>https://zylhorse.github.io/blog/cache/redis/%E9%9B%86%E7%BE%A4%E6%A8%A1%E5%BC%8F/</link>
      <pubDate>Sun, 27 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/cache/redis/%E9%9B%86%E7%BE%A4%E6%A8%A1%E5%BC%8F/</guid>
      <description>概述  redis cluster 时redis的分布式解决方案， 在3.0 推出； 当遇到单机内存，并发流量等瓶颈时，可以采用cluster架构达到负载均衡的目的； cluster 将整个数据集，按照分区规则映射到多个节点上，每个节点负责整个数据集的一个子集； 节点之间会相互通信， meet操作时节点之间相互通信的基础， meet 操作有一定的频率和规则； 推荐节点小于1000， 因为节点之间meet操作会占用大量带宽；  原理  redis cluster采用哈希分区中的虚拟槽分区。 虚拟槽分区巧妙的使用哈希空间， 使用分散度良好的哈希函数把所有的数据映射到一个固定范围的整数集合（槽）； 槽的范围时0~16383， 槽是集群内数据管理和迁移的基本单位； 把16384槽按照节点数量进行平均分配，由节点进行管理 对每个key按照CRC16规则进行hash运算 把hash结果对16383进行取余 把余数发送给Redis节点 节点接收到数据，验证是否在自己管理的槽编号的范围 如果在自己管理的槽编号范围内，则把数据保存到数据槽中，然后返回执行结果 如果在自己管理的槽编号范围外，则会把数据发送给正确的节点进行moved重定向，由正确的节点来把数据保存在对应的槽中  增加主节点  redis-trib.rb add-node new-node-addr cluster-node-addr redis-trib.rb reshared cluster-node-addr  增加从节点  redis-trib.rb add-node new-node-addr cluster-node-addr cluster replicate new-node-Id  删除从节点  redis-trib.rb del-node cluster-node-addr del-node-id redis-trib.rb reshared cluster-node-addr redis-trib.rb del-node cluster-node-addr del-node-id  部署  至少需要6台机器， 3个master，3个slave； 每个master至少搭配一个slave；  hashtag  hashtag 解决让相关的key 划分到同一个节点上； 原理： 给相关key 使用{}添加同样的标记；  fail 状态必要条件  某个主节点和所有从节点全部挂掉，我们集群就进入faill状态。 如果集群超过半数以上master挂掉，无论是否有slave，集群进入fail状态.</description>
    </item>
    
    <item>
      <title>MySQL索引详解</title>
      <link>https://zylhorse.github.io/blog/database/mysql/</link>
      <pubDate>Sun, 20 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/database/mysql/</guid>
      <description>是什么 为什么 索引可以大大的提高MySQL的检索速度。
Explain key_len 索引长度限制
INNODB引擎的每个索引列长度限制为767字节（bytes），所有组成索引列的长度和不能大于3072字节
MYISM引擎的每个索引列长度限制为1000字节，所有组成索引列的长度和不能大于1000字节
在MySQL5.5版本，引入了innodb_large_prefix，用来禁用大型前缀索引，以便与不支持大索引键前缀的早期版本的InnoDB兼容。 开启innodb_large_prefix可以使单索引的长度限制达到3072字节（但是联合索引总长度限制还是3072字节），禁用时单索引的长度限制为767字节
在MySQL5.5版本与MySQL5.6版本，innodb_large_prefix是默认关闭的。
在MySQL5.7及以上版本，innodb_large_prefix是默认开启的。
在MySQL8.0版本中，innodb_large_prefix已被移除
key_len的长度计算公式：
TINYINT 允许NULL = 1 + 1(NULL)TINYINT 不允许NULL = 1SMALLINT 允许为NULL = 2+1(NULL)SMALLINT 不允许为NULL = 2INT 允许为NULL = 4+1(NULL)INT 不允许为NULL = 4DATETIME 允许为NULL = 8 + 1(NULL)DATETIME 不允许为NULL = 8TIMESTAMP 允许为NULL = 4 + 1(NULL)TIMESTAMP 不允许为NULL = 4VARCHAR(N) 变长字段且允许NULL = N * ( character set：utf8=3,gbk=2,latin1=1)+1(NULL)+2(变长字段)VARCHAR(N) 变长字段且不允许NULL = N * ( character set：utf8=3,gbk=2,latin1=1)+2(变长字段)CHAR(N) 固定字段且允许NULL = N * ( character set：utf8=3,gbk=2,latin1=1)+1(NULL)CHAR(N) 固定字段且不允许NULL = N * ( character set：utf8=3,gbk=2,latin1=1)</description>
    </item>
    
    <item>
      <title>Redis高可用方案-哨兵模式</title>
      <link>https://zylhorse.github.io/blog/cache/redis/%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F/</link>
      <pubDate>Sat, 12 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/cache/redis/%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F/</guid>
      <description>哨兵模式 哨兵是一个独立的进程， 通过和redis各个节点的通信，监听各节点的状态；并互相监控； 备注： sentinel节点需要2n+1(n&amp;gt;=1)个
sentinel监听  每10秒 sentinel 对 master和slave 进行info； 发现slave节点，确认主从关系 每2秒 sentinel 通过master（pub/sub） 交换信息， 所有的sentinel都订阅master的一个channel， 并每隔2秒向该channel发送信息； 感知新的sentinel， 协商master是否通信失败； 每1秒 sentinel 向其他sentinel/master/slave节点 ping； 用于心跳监测；  主观下线 单个sentinel对redis 节点通信失败的‘偏见’；如果一个redis节点在down-after-millseconds 时间内， 没有回复sentinel心跳包，则该redis节点被sentinel认定为主观下线
客观下线  当redis节点被sentinel标记为主观下线后， 并不意味该redis节点故障了。 该sentinel会询问其他sentinel， 如果sentinel cluster中超过quorum数量的sentinel 认定该节点主观下线， 则该redis 客观下线； 如果该节点为sentinel和slave节点， 则操作到此为止； 如果客观下线的redis节点为master， 则开始故障转移；  故障转移流程 sentinel cluster 选举leader  当一个sentinel 确定master 主观下线后， 会请求其他sentinel将自己选举为leader， 被请求的sentinel 如果没有同意其他sentinel的选举请求， 则同意该请求， 否则为不同意； 如果一个sentinel 获得的选票数达到了leader最低票数（quorum和sentinel节点数/2+1）则该sentinel当选为leader， 否则重新选举；  sentinel leader 决定新的master  过滤故障节点 选择slave-priority配置的优先级别 最高的slave节点， 如不存在继续下一步； 选择复制偏移量最大（复制的最完整）的slave节点， 如不存在继续下一步； 选择run_id 最小的slave节点；  </description>
    </item>
    
    <item>
      <title>Redis高可用解决方案</title>
      <link>https://zylhorse.github.io/blog/cache/redis/%E9%AB%98%E5%8F%AF%E7%94%A8ha-high-available/</link>
      <pubDate>Tue, 08 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/cache/redis/%E9%AB%98%E5%8F%AF%E7%94%A8ha-high-available/</guid>
      <description>高可用扩容  垂直扩容： 提升机器内存配置， 不需要应用程序支持； 水平扩容： 增加节点，需要应用程序支持；  哨兵模式（sentinel） 故障转移后redis客户端将无法感知redis节点的变化；导致无法正常使用；
哨兵模式高可用客户端流程  客户端获取 sentinel 集合； 客户端获取master 信息； 客户端验证获取的master 为真正的master， 防止故障转移期间主节点的变化； 客户端订阅sentinel节点 相关频道， 时刻获取节点去读写；  问题  不能解决读写分离；  集群模式（cluster）  数据异步复制，不能保证强一致性。复制结构只支持一层，从节点只能复制主节点； key 批量操作限制，目前只支持相同槽的key 批量查询， 不允许跨槽查询； key 事务操作优先，当key在多个槽上分布时， 不支持事务功能；  </description>
    </item>
    
    <item>
      <title>Redis的hotkey和bigkey监控和处理</title>
      <link>https://zylhorse.github.io/blog/cache/redis/hotkeybigkey/</link>
      <pubDate>Sun, 23 Oct 2016 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/cache/redis/hotkeybigkey/</guid>
      <description>bigkey  单个key 存储value很大 hash set list zset 等存储元素过多  如何发现  redis-cli &amp;ndash;bigkeys rdbtools 分析rdb 文件 redis-rdb-cli 第三方工具  怎么解决  减少list hash set zset 成员， 对成员过多的数据进行取模分片 string类型的big value 不建议存入 redis， 可以用文档型数据库mongodb或cdn等方式优化。  hotkey  并发访问量很大的热点key  如何发现 收集所有redis请求，统计分析
 redis-cli &amp;ndash;hotkeys 在proxy 层，对每一个redis请求进行收集上报，统计分析 对redis端口的tcp数据包进行抓包统计； 基于lfu（最近最少使用） 根据使用频率进行统计  怎么解决 产生随机值（0-2N, N 为集群节点数），作为key的后缀， 将key分布到集群的多个实例中。并设置随机过期时间；
const M = N * 2//生成随机数random = GenRandom(0, M)//构造备份新keybakHotKey = hotKey + “_” + randomdata = redis.</description>
    </item>
    
    <item>
      <title>什么人都有</title>
      <link>https://zylhorse.github.io/blog/stories/%E4%BB%80%E4%B9%88%E4%BA%BA%E9%83%BD%E6%9C%89/</link>
      <pubDate>Thu, 20 Oct 2016 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/stories/%E4%BB%80%E4%B9%88%E4%BA%BA%E9%83%BD%E6%9C%89/</guid>
      <description>什么人都有
可以这样的歇斯底里</description>
    </item>
    
    <item>
      <title>快乐是一种方式</title>
      <link>https://zylhorse.github.io/blog/stories/%E5%BF%AB%E4%B9%90%E6%98%AF%E4%B8%80%E7%A7%8D%E6%96%B9%E5%BC%8F/</link>
      <pubDate>Thu, 20 Oct 2016 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/stories/%E5%BF%AB%E4%B9%90%E6%98%AF%E4%B8%80%E7%A7%8D%E6%96%B9%E5%BC%8F/</guid>
      <description>快乐是一种方式</description>
    </item>
    
    <item>
      <title>Redis源码阅读-ziplist</title>
      <link>https://zylhorse.github.io/blog/cache/redis/ziplist/</link>
      <pubDate>Mon, 10 Oct 2016 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/cache/redis/ziplist/</guid>
      <description>定义 ziplist由一系列特殊编码的连续内存块组成的顺序存储结构，类似数组， 但是ziplist每个元素占用内存大小不同。
数据结构 type ziplist struct {zlbytes: ziplist的长度（单位: 字节)，是一个32位无符号整数zltail: ziplist最后一个节点的偏移量，反向遍历ziplist或者pop尾部节点的时候有用。zllen: ziplist的节点（entry）个数entry: 节点zlend: 值为0xFF，用于标记ziplist的结尾 }type entry struct {prevlengh: 记录上一个节点的长度，为了方便反向遍历ziplistencoding: 当前节点的编码规则，下文会详细说data: 当前节点的值，可以是数字或字符串}当data小于63字节时(2^6)，节点存为上图的第一种类型，高2位为00，低6位表示data的长度。当data小于16383字节时(2^14)，节点存为上图的第二种类型，高2位为01，后续14位表示data的长度。当data小于4294967296字节时(2^32)，节点存为上图的第二种类型，高2位为10，下一字节起连续32位表示data的长度。应用 ziplist 是list键、hash键、zset键的底层实现之一</description>
    </item>
    
    <item>
      <title>Redis源码阅读-skiplist</title>
      <link>https://zylhorse.github.io/blog/cache/redis/skiplist/</link>
      <pubDate>Tue, 20 Sep 2016 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/cache/redis/skiplist/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Redis自带性能测试命令</title>
      <link>https://zylhorse.github.io/blog/cache/redis/%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/</link>
      <pubDate>Tue, 06 Sep 2016 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/cache/redis/%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/</guid>
      <description>性能测试 redis-benchmark options options value
序号	选项	描述	默认值1	-h	指定服务器主机名	127.0.0.12	-p	指定服务器端口	63793	-s	指定服务器 socket	4	-c	指定并发连接数	505	-n	指定请求数	100006	-d	以字节的形式指定 SET/GET 值的数据大小	27	-k	1=keep alive 0=reconnect	18	-r	SET/GET/INCR 使用随机 key, SADD 使用随机值	9	-P	通过管道传输 &amp;lt;numreq&amp;gt; 请求	110	-q	强制退出 redis。仅显示 query/sec 值	11	--csv	以 CSV 格式输出	12	-l	生成循环，永久执行测试	13	-t	仅运行以逗号分隔的测试命令列表。	14	-I	Idle 模式。仅打开 N 个 idle 连接并等待。性能和网络阻塞  大文本数据需要压缩存储，如果不压缩占用内存大，而且访问时占用流量带宽 线上禁止keys使用正则匹配， keys匹配时效率低， 可以使用scan替代 线上禁止monitor， 存在内存暴增，影响性能  </description>
    </item>
    
    <item>
      <title>Windows系统删除U盘EFI分区</title>
      <link>https://zylhorse.github.io/blog/windows/u-efi/</link>
      <pubDate>Mon, 05 Sep 2016 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/windows/u-efi/</guid>
      <description> 管理员权限启动CMD 输入磁盘分区命令： diskpart C:\Users\Administrator&amp;gt;diskpart DISKPART&amp;gt; 查看所有磁盘： list disk DISKPART&amp;gt; list disk磁盘 ### 状态 大小 可用 Dyn Gpt-------- ------------- ------- ------- --- ---磁盘 0 联机 111 GB 0 B磁盘 1 联机 465 GB 0 B磁盘 2 联机 111 GB 0 B磁盘 3 联机 7648 MB 809 MB 选择要进行操作的磁盘： select disk 3 DISKPART&amp;gt; select disk 3磁盘 3 现在是所选磁盘。 清理磁盘： clean  DISKPART&amp;gt; cleanDiskPart 成功地清除了磁盘。 重新挂载U盘： 进入计算机管理 -&amp;gt; 磁盘管理 -&amp;gt; 找到相应U盘，右键新加卷  </description>
    </item>
    
    <item>
      <title>LRU(Least Recently Used)算法原理和代码实现</title>
      <link>https://zylhorse.github.io/blog/algorithm/lru%E7%AE%97%E6%B3%95/</link>
      <pubDate>Tue, 23 Aug 2016 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/algorithm/lru%E7%AE%97%E6%B3%95/</guid>
      <description>概述 least recently used ： 淘汰最近最少使用页面
技术实现 hashmap + linked list</description>
    </item>
    
    <item>
      <title>Redis有哪些内存淘汰策略</title>
      <link>https://zylhorse.github.io/blog/cache/redis/%E5%86%85%E5%AD%98%E6%B7%98%E6%B1%B0%E7%AD%96%E7%95%A5/</link>
      <pubDate>Thu, 18 Aug 2016 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/cache/redis/%E5%86%85%E5%AD%98%E6%B7%98%E6%B1%B0%E7%AD%96%E7%95%A5/</guid>
      <description>淘汰策略  volatile-lru： 从设置过期事件的数据集合中，对最近最少使用的数据进行淘汰 volitile-ttl： 从设置过期事件的数据集合中，对将要过期数据进行淘汰 allkeys-lru： 在内存不足容纳新的数据时，对最近最少使用的数据进行淘汰； allkeys-random: 从数据集中淘汰任意数据   redis 4.0版本新增
 volatile-lfu: 从设置过期事件的数据集合中，对使用次数最少的数据进行淘汰 allkeys-lru： 在内存不足容纳新的数据时，对使用次数最少的数据进行淘汰  </description>
    </item>
    
    <item>
      <title>Redis源码阅读-SDS动态字符串</title>
      <link>https://zylhorse.github.io/blog/cache/redis/sds%E5%8A%A8%E6%80%81%E5%AD%97%E7%AC%A6%E4%B8%B2/</link>
      <pubDate>Thu, 21 Jul 2016 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/cache/redis/sds%E5%8A%A8%E6%80%81%E5%AD%97%E7%AC%A6%E4%B8%B2/</guid>
      <description>概述  redis 没有直接使用C语言的字符串，而是定义了自己的字符串结构： SDS(simple dynamic string)作为默认字符串； 我们使用的所有键值基本都是SDS类  定义 </description>
    </item>
    
    <item>
      <title>Redis中key过期删除</title>
      <link>https://zylhorse.github.io/blog/cache/redis/key%E8%BF%87%E6%9C%9F%E5%88%A0%E9%99%A4/</link>
      <pubDate>Tue, 12 Jul 2016 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/cache/redis/key%E8%BF%87%E6%9C%9F%E5%88%A0%E9%99%A4/</guid>
      <description>定期删除  redis 默认每个100ms 就会随机抽取一些设置过期时间的key， 检查其是否过期， 如果过期就删除。 随机抽取是为了防止完整遍历增加cpu负载  惰性删除  key在被使用时， 去检查过期时间， 如果过期就删除  </description>
    </item>
    
    <item>
      <title>Redis中key的命名规范</title>
      <link>https://zylhorse.github.io/blog/cache/redis/key%E5%91%BD%E5%90%8D%E8%A7%84%E8%8C%83/</link>
      <pubDate>Thu, 07 Jul 2016 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/cache/redis/key%E5%91%BD%E5%90%8D%E8%A7%84%E8%8C%83/</guid>
      <description> 建议全部大写 key不能太长，太长占用资源，可读性差 key根据命名空间使用： 分开； 命名空间示例： 项目名：表名：字段名：字段id  </description>
    </item>
    
    <item>
      <title>Redis持久化有哪些方式</title>
      <link>https://zylhorse.github.io/blog/cache/redis/%E6%8C%81%E4%B9%85%E5%8C%96/</link>
      <pubDate>Fri, 10 Jun 2016 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/cache/redis/%E6%8C%81%E4%B9%85%E5%8C%96/</guid>
      <description>持久化   RDB:
 redis 会fork一个子进程，将内存数据写磁盘；写完临时文件后， 将旧的rdb文件替换； 实现copy-on-write； 以快照的形式将内存中数据备份到dump.rdb文件中；定时保存； 缺点：  在服务故障时会丢失部分数据； 数据量大会导致服务停止几百毫秒；      AOF：
 将redis 命令都存到一个文件中；redis 每执行一行命令都会将其写入到aof文件中； 配置： appendonly yes appendfsync always # 每次数据修改都会写入AOF文件， 影响redis性能appendfsync everysec # 每秒同步一次， 将更多写命令同步到磁盘appendsync no # 让系统决定何时同步 缺点： 文件会会大一些， 还原速度慢 ；    查看目录 语法： saveconfig get dirredis 4.0 新增  RDB和AOF混合持久， 配置： aof-use-rdb-preamble  如果混合持久打开， AOF重写时会直接吧RDB的内容写到AOF文件开头。 优点： 结合RDB和AOF优点，快速加载同时避免丢失过多数据。 缺点： AOF中的RDB部分时二进制格式， 可读性差；    </description>
    </item>
    
    <item>
      <title>Redis的基本常识和memcache对比</title>
      <link>https://zylhorse.github.io/blog/cache/redis/redis/</link>
      <pubDate>Thu, 02 Jun 2016 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/cache/redis/redis/</guid>
      <description>redis  redis 使用c语言编写的高性能键值对内存数据库； 读速度： 110000/s; 写速度： 81000/s 单进程单线程， 是线程安全的； 采用多路复用机制处理请求； 有5种数据结构strnig、hash、list、set、sort set 使用管道技术，解决客户端发送阻塞； 服务端对多个请求批量处理，一次返回；  redis性能  redis 所有数据都存储在内存中， 读写都非常迅速； redis 采用单线程， 避免了线程调度的上下文切换和资源竞争 redis 多路复用，非阻塞I/O  memecache 区别  memcache 数据全部存储到内存中， 断电会挂掉； memcache 数据不能超出内存大小； redis 部分数据存储到磁盘上，可以保证数据持久性； memcache 仅支持key-value， redis 支持5中数据类型；  </description>
    </item>
    
    <item>
      <title>Nginx Http upstream</title>
      <link>https://zylhorse.github.io/blog/nginx/balance/</link>
      <pubDate>Mon, 23 May 2016 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/nginx/balance/</guid>
      <description>配置目的  负载均衡 多机热备  </description>
    </item>
    
    <item>
      <title>Erlang分布式编程</title>
      <link>https://zylhorse.github.io/blog/erlang/%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%96%E7%A8%8B/</link>
      <pubDate>Tue, 17 May 2016 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/erlang/%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%96%E7%A8%8B/</guid>
      <description>分布式编程 分布式编程需求  性能   通过安排程序的不同部分在不同的机器上并行运行，让程序跑的更快。
 可靠性   通过让系统运行到数台机器上来实现容错系统，如果一台机器故障，可以在另一台机器上继续。
 可扩展性   随着应用程序越做越大，即使机器的处理能力再强大也会被耗尽。这时我们需要添加更多的机器来提升处理能力。添加新机器应当是一次简单的操作，不需对程序架构做大的修改。
 天生分布式的程序   许多应用程序天生分布式。如编写一个聊天系统，就会有来自世界各地的分散用户。如果我们在某个地理位置拥有大量用户，就希望把计算资源放在接近这些用户的地方。
 两种分布式模型 我们构建程序的基本单位是进程，编写分布式 Erlang程序是很容易的，要做的就是在正确的机器上分裂出进程，然后一切就能像之前那样运行。
 分布式Erlang   在分布式Erlang里，我们编写的程序会在Erlang的节点(node)上运行。节点是一个独立的Erlang系统，包含一个自带地址空间和进程组的完整虚拟机。
  可以在任意节点上分裂进程，所有消息传递和错误处理基本函数也都能像在单节点上那样工作。
  分布式Erlang应用程序，运行在一个可信环境中。因为任何节点都可以在其他Erlang节点上执行任意操作，所以这涉及高度的信任。虽然分布式Erlang应用程序可以运行在开放式网络上，但他们通常是运行在属于同一个局域网的集群上，并受防火墙保护。
 基于套接字的分布式模型   可以用Tcp/Ip套接字来编写运行在不可信环境中的分布式应用程序。这个编程模型不如分布式Erlang那样强大，但是更安全。
 编写一个分布式程序 步骤  在一个常规的非分布式Erlang系统上编写和测试程序。 在同一台机器的两个节点上测试程序。 在同一个局域网内分属两台不同机器的节点上测试程序。 在分属不同国家和域的两台机器上测试程序。  最后两步可能会带来问题。如果所运行的机器属于相同的管理域，就很少有问题。但当相关节点属于不同域上的机器时，就可能遇到连接问题，而且必须确保系统防火墙和安全设置都已经正确配置。
创建名称服务器 同一局域网的不同机器上 erl -name NodeName -setcookie Cookie
 用-name参数启动Erlang。我们在同一台机器上运行两个节点时使用了&amp;quot;短&amp;quot;（short）名称（通过-sname标识体现）。但如果它们属于不同的网络，我们就要使用-name。   当两台机器位于同一个子网时我们也可以使用-sname，如果没有DNS服务，-sname是唯一的可行方式。
 确保两个节点拥有相同的cookie。这正是启动两个节点时都使用命令行参数-setcookie abc的原因。 确保相关节点的完全限定主机名可以被DNS解析。 确保两个系统相同版本的代码和相同版本的Erlang。  测试节点互联 net_adm:ping(Node).</description>
    </item>
    
    <item>
      <title>Erlang接口技术</title>
      <link>https://zylhorse.github.io/blog/erlang/%E6%8E%A5%E5%8F%A3%E6%8A%80%E6%9C%AF/</link>
      <pubDate>Thu, 05 May 2016 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/erlang/%E6%8E%A5%E5%8F%A3%E6%8A%80%E6%9C%AF/</guid>
      <description>接口技术 可以多种方式建立外部语言程序与Erlang之间的接口。
 让程序以外部操作系统进程的方式在erlang虚拟机以外运行。这是一种安全的方式，即使外部程序代码有问题，也不会让erlang程序崩溃。   Erlang 通过一种名为端口(port)的对象来控制外部进程，与外部进程的通信则是通过一个面向字节的通信信道。Erlang通过端口，控制外部进程的启动和结束。并监视外部进程，崩溃后启动。
 在Erlang内部运行操作系统命令并捕获结果。 在Erlang虚拟机的内部运行外部语言代码。这涉及链接外部代码和Erlang虚拟机代码。   外部语言代码的错误可能导致Erlang系统崩溃。虽然它不安全，但是这么做比使用外部进程更高效。
  把代码连接到Erlang内核，只适用于C这样能生成目标代码的语言，不适用于Java这种自带虚拟机的语言。
 Erlang如何与外部程序通信  对于程序员而言端口的行为就像一个进程。你可以向它发消息，可以注册它，诸如此类。如果外部程序崩溃，就会有一个退出信号发送给相连进程。如果相连进程挂了，外部程序就会被关闭。 使用端口与外部程序通信和使用套接字有区别。如果使用端口，它会表现的像Erlang进程，可以连接它，从某个远程的分布式Erlang节点上向它发送信息等。如果使用套接字就不会表现出类似进程的行为。 创建端口的进程被称为该端口的相连进程。相连进程有其特殊的重要性，所有发往端口的消息都必须包含相连进程的PID，所有来自外部程序的消息都会发往相连进程。  端口创建和使用 创建端口-spec open_port(PortName, [Opt]) -&amp;gt; Port
 PortName选项如下： {spawn, Command}   启动一个外部程序。Command是这个外部程序的名称。除非能找到一个名为Command的内链驱动，否则Command会在Erlang工作空间之外运行。
  {fd, In, Out}   允许一个Erlang进程访问Erlang使用的任何当前打开文件描述符。文件描述符In可以用作标准输入，文件描述符Out可以用作标准输出。
  Opt选项如下： {packet, N}   数据包(packet)前面有N(1、2、4)个字节的长度计数。
  stream   发送消息时不带数据包长度信息。应用程序必须知道如何处理这些数据包。
  {line, Max}   发送消息时使用一次一行的形式。如果有一行超过了Max字节，就会在Max字节处被拆分。
  {cd, Dir}   只适用于{spawn,Command}选项。外部程序在Dir目录启动。</description>
    </item>
    
    <item>
      <title>防止并发请求重复提交</title>
      <link>https://zylhorse.github.io/blog/web/%E9%98%B2%E6%AD%A2%E9%87%8D%E5%A4%8D%E6%8F%90%E4%BA%A4/</link>
      <pubDate>Sat, 23 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/web/%E9%98%B2%E6%AD%A2%E9%87%8D%E5%A4%8D%E6%8F%90%E4%BA%A4/</guid>
      <description>方案  客户端为每个订单生成deduplicate key，并在前端缓存商品信息及dedupkey 列表 提交订单时，传递dedup key 和订单信息， 客户端则一直等待该订单处理结果； 服务端接收到订单提交， 缓存该信息并设置过期时间； 服务器校验新的订单提交， 去缓存中校验dedupkey， 存在则直接返回。  token  client去server请求token， token 为server端生成的全局唯一标识（业务编码或订单号） client数据请求绑定token server校验：  1. 缓存中token和client请求绑定的token不一致，则拒绝处理2. client请求未绑定token，则拒绝处理3. 缓存中没有token， 则拒绝处理redis atomic  client 每次请求，server端生成一个 userId + request（请求数据） 的唯一标识，放到缓存中； server校验client请求是否已经存在，存在则拒绝处理；  </description>
    </item>
    
    <item>
      <title>Redis使用遇到的问题</title>
      <link>https://zylhorse.github.io/blog/cache/redis/%E9%97%AE%E9%A2%98/</link>
      <pubDate>Sun, 10 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/cache/redis/%E9%97%AE%E9%A2%98/</guid>
      <description></description>
    </item>
    
    <item>
      <title>记录web开发遇到的问题和详细解决方案</title>
      <link>https://zylhorse.github.io/blog/web/%E9%97%AE%E9%A2%98/</link>
      <pubDate>Sat, 09 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/web/%E9%97%AE%E9%A2%98/</guid>
      <description>中文名下载乱码 对文件名进行UTF-8编码
http文件下载 添加报文头: &amp;quot;content-disposition&amp;quot;, &amp;quot;attachment;filename=$fileName&amp;quot;</description>
    </item>
    
    <item>
      <title>Erlang二进制语法</title>
      <link>https://zylhorse.github.io/blog/erlang/%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%92%8C%E4%BD%8D%E8%AF%AD%E6%B3%95/</link>
      <pubDate>Mon, 21 Mar 2016 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/erlang/%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%92%8C%E4%BD%8D%E8%AF%AD%E6%B3%95/</guid>
      <description>二进制型（binary）  用一种节省空间的方式来保存大批量的无结构原始数据。 多数情况二进制型的位数都是8的整数倍，因此对应一个字节串。如果位数不是8的整数倍，我们叫这段数据为位串（bitstring）。 将二进制型、位串、位级模式匹配引入Erlang 是为了简化网络编程。  格式  &amp;laquo;5,9,10&amp;raquo; : 二进制型的编写和打印形式。 在二进制型里面使用整数时，整数范围0~255.  操作二进制型  list_to_binary(L) -&amp;gt; Bin: 将io列表（iolist）L中的所有元素转换成二进制型。 split_binary(Bin, Pos) -&amp;gt; {Bin1, Bin2}: 将二进制型Bin一分为二。 term_to_binary(Term) -&amp;gt; Bin :将任意Erlang数据类型转换成二进制型。此方法使用了所谓的外部数据格式（external term format）。 binary_to_term(Bin) -&amp;gt; Term : 这是term_to_binary的逆向函数。 byte_size(Bin) -&amp;gt; Size: 返回二进制型里面的字节数。  位语法 位语法是一种表示法，用于从二进制数据里提取或加入单独的位或者位串。开发位语法是为了进行协议编程，以及生成操作二进制数据的高效代码。
位语法表达式 &amp;lt;&amp;lt; E1,E2,...,E3&amp;gt;&amp;gt;每个Ei元素都标示出二进制型或位串里的一个片段。单个Ei元素可以有四种形式：Ei = Value |Value:Size |Value/TypeSpecifierList |Value:Size/TypeSpecifierList 如果表达式的总位数是８的倍数则会构建一个二进制型，否则构建一个位串。　 当构建二进制型时，Value必须是已绑定变量、字符串，或是能够得出整数、浮点数或二进制型的表达式。　当它被用来模式匹配时，Value可以是绑定或未绑定的。 Size必须是一个能得出整数的表达式。在模式匹配里，Size必须是一个整数，或是值为整数的已绑定变量。 Size的值指明了片段的位数大小。它的默认值取决于不同的数据类型：  整数：8浮点数：64binary: 1 在模式匹配里面，默认值只对最后的元素有效，如果未指定大小，就采用默认值。 TypeSpecifierList(类型指定列表)是一个用连字符分割的列表，形式是End-Sign-Type-Unit。 End可以是 big | little | native : 机器的字节顺序，默认big。这一项只和从二进制型里面打包和解包整数和浮点数有关。term_to_binary 和 binary_to_term可以解决打包和解包整数的问题。 Sign可以是signed | unsigned, 这个参数只用于模式匹配，默认值是unsigned。 Type可以是integer | float | binary | bytes | bitstring | bits | utf8 | utf16 | utf32,默认值是integer。　 Unit的写法是unit:1|2|&amp;hellip;256 : integer、float和bitstring的Unit默认值是１，binary则是８。utf8、utf16、utf32类型无需提供值。 一个片段的总长度是Size * Unit字节。  </description>
    </item>
    
    <item>
      <title>TCP/UDP端口扫描工具</title>
      <link>https://zylhorse.github.io/blog/network/%E7%AB%AF%E5%8F%A3%E6%89%AB%E6%8F%8F/</link>
      <pubDate>Tue, 15 Mar 2016 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/network/%E7%AB%AF%E5%8F%A3%E6%89%AB%E6%8F%8F/</guid>
      <description>译注 该Nmap参考指南中文版由Fei Yang fyang1024@gmail.com和Lei Lililei_721@6611.org 从英文版本翻译而来。 我们希望这将使全世界使用中文的人们更了解Nmap，但我们不能保证该译本和官方的 英文版本一样完整，也不能保证同步更新。 它可以在Creative Commons Attribution License下被修改并重新发布。
选项概要 当Nmap不带选项运行时，该选项概要会被输出，最新的版本在这里 http://www.insecure.org/nmap/data/nmap.usage.txt。
它帮助人们记住最常用的选项，但不能替代本手册其余深入的文档，一些晦涩的选项甚至不在这里。
Usage: nmap [Scan Type(s)] [Options] {target specification} TARGET SPECIFICATION:
Can pass hostnames, IP addresses, networks, etc.
Ex: scanme.nmap.org, microsoft.com/24, 192.168.0.1; 10.0-255.0-255.1-254
-iL : Input from list of hosts/networks
-iR : Choose random targets
&amp;ndash;exclude &amp;lt;host1[,host2][,host3],&amp;hellip;&amp;gt;: Exclude hosts/networks
&amp;ndash;excludefile &amp;lt;exclude_file&amp;gt;: Exclude list from file
HOST DISCOVERY:
-sL: List Scan - simply list targets to scan</description>
    </item>
    
    <item>
      <title>Redis怎么减少RRT-Pipeline</title>
      <link>https://zylhorse.github.io/blog/cache/redis/pipeline/</link>
      <pubDate>Sun, 06 Mar 2016 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/cache/redis/pipeline/</guid>
      <description>概述 redis client 与server 的每次通信，都会产生一次RTT（round time trip); 并且多次通信会频繁的进行网络IO； 为此pipeline 可以将多条命令请求整合，一次发送；
问题 1. 应当限制pipeline中命令的大小1.1 在pipeline机制中， client不会去读取缓冲数据， 除非pipeline所有命令执行完成。1.2 当缓冲中被应答数据填满， server端调用write 就会阻塞或失败2. pipeline不能保证命令执行的原子性2.1 如果多个命令在执行时发生异常， 则丢失未执行的命令2.2 因此在使用pipeline时， 要自己保证执行命令的数据安全3. 不能进解决多条命令之间的依赖关系</description>
    </item>
    
    <item>
      <title>Redis有没有数据库的概念</title>
      <link>https://zylhorse.github.io/blog/cache/redis/%E6%95%B0%E6%8D%AE%E5%BA%93/</link>
      <pubDate>Tue, 01 Mar 2016 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/cache/redis/%E6%95%B0%E6%8D%AE%E5%BA%93/</guid>
      <description>概述  redis单机支持16个数据库， 每个数据库的数据是隔离的不能共享；redis cluster 是没有数据库概念的 redis 之所以分这么多数据库， 也是为了区分业务， 不同业务存放在不同的数据库中；  </description>
    </item>
    
    <item>
      <title>Erlang并发编程错误</title>
      <link>https://zylhorse.github.io/blog/erlang/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B8%AD%E7%9A%84%E9%94%99%E8%AF%AF/</link>
      <pubDate>Fri, 05 Feb 2016 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/erlang/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B8%AD%E7%9A%84%E9%94%99%E8%AF%AF/</guid>
      <description>错误处理理念  并发Erlang程序里的错误处理建立在远程检测和处理错误的概念上。我们选择让发生错误的进程崩溃，然后在其它进程里面进行纠错处理。 在设计容错式的系统时就假设错误会发生，进程会崩溃。因此能够在错误发生时检测出来，可能的话也需要纠正他们。同时避免系统用户注意到任何故障，或者在错误修复过程中遭受服务终端。 检测错误和找出故障原因是内建于Erlang虚拟机底层的功能，也是Erlang语言编程的一部分。标准OTP库提供了构建互相监视的进程组和检测到错误时采取纠正措施的功能。本章介绍的是语言层面的错误检测和恢复。 总结为两句话：“让其它进程修复错误&amp;quot;和&amp;quot;任其崩溃&amp;quot;  让其它进程修复错误  要让一个进程监控另一个，需要在这两个进程之间建立链接(link)或者(monitor)。如果被链接或者监视的进程挂了，监控进程会收到通知。 监控进程可以实现跨机器的透明运作，因此运行在某一台机器上的进程可以监视运行在不同机器上进程的行为。这是编写容错式系统的基础。不能在一台机器上构建容错式系统，因为崩溃的可能是整台机器。一台机器负责计算，其它的机器负责监控它，并在一台机器崩溃时接管计算。  任其崩溃  在Erlang中，我们把应用程序构建成两部分：一部分负责解决问题，另一部分负责在错误发生时纠正他们。 负责解决问题的部分尽可能少的编写防御性代码，并假设函数所有参数是正确的，程序运行正常。 负责纠正错误的部分往往是通用的，因此同一段错误纠正代码可以用在许多不同的应用程序里面。例如：如果数据库的某个事务出错，就简单终止该事务，让系统把数据库恢复到出错之前的状态；如果操作系统里面的某个进程崩溃，就让操作系统关闭所有打开的文件和套接字，然后让系统恢复到某个稳定状态。  任其崩溃意义  不必编写防御性代码来防止错误，直接崩溃就好。 不必思考应对措施，选择直接崩溃，让别人来修复错误。 不会使错误恶化，无需在知道出错后进行额外的计算。 如果错误发生后第一时间通知，就能得到非常好的错误诊断。错误发生后继续运行会导致更多的错误，让调试更困难。 编写错误恢复代码时不用担心崩溃的原因，只要把注意力放到事后的清理上。 简化系统架构，这样我们就能把应用程序和错误恢复当成两个独立的问题来思考。  错误处理的术语含义  进程   进程有两种：普通进程和系统进程。spawn创建的是普通进程。普通进程可以执行内置函数process_flag（trap_exit,true)变成系统进程。
 连接   进程可以互相连接。如果A和B两个进程有连接，而A出于某种原因终止了，就会向B发送一个错误信号，反之亦然。
 连接组   进程P的连接组是指与进程P相连的一组进程。
 监视   监视和连接相似，但它是单向的。如果A监视B，而B出于某种原因终止了，就会向A发送一个&amp;quot;宕机&amp;quot;的消息，但反过来就不行了。
 消息和错误信号   进程协作的方式是交换消息和错误信号。消息是通过基本函数send发送的，错误信号则是进程崩溃或终止的时候自动发送的。错误信号会发送给终止进程的连接组。
 错误信号的接受   当系统进程收到错误信号时，该信号被转换成{&amp;lsquo;Exit&amp;rsquo;,Pid,Why}形式的信息。Pid是终止进程的标识，Why是终止的原因。如果无错误终止，Why就会是原子normal，否则会是错误描述。当普通进程收到错误信号时，如果退出原因不是normal，该进程就会终止。当它终止时，同样会向它的连接组广播一个退出信号。
 显示错误信号   任何执行exit(Why)的进程都会终止（如果代码不是在catch或者try的范围内执行的话），并向它的连接组广播一个带有原因Why的退出信号。进程可以通过执行exit(Pid,Why)来发送一个&amp;quot;虚假&amp;quot;的错误信号。这种情况Pid会收到一个带有原因Why的退出信号。调用exit/2的进程则不会终止。
 不可捕捉的退出信号   进程收到摧毁信号(kill signal)时会终止。摧毁信号通过调用exit(Pid,kill)生成。这种信号会绕过常规的错误信号处理机制，不会被转换成消息。摧毁信号只应该用在其它错误处理机制无法终止的顽固进程上。
 创建链接 调用接口：link(Pid)。建立调用进程与Pid进程之间的连接。</description>
    </item>
    
    <item>
      <title>Electron-银河麒麟运行和打包环境配置</title>
      <link>https://zylhorse.github.io/blog/electron/kylinos/</link>
      <pubDate>Wed, 03 Feb 2016 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/electron/kylinos/</guid>
      <description>打包环境配置
 安装node, 下载地址 pull项目代码 安装依赖: npm install, 如果慢参考npm install 慢 这里需要科学上网，参考v2ray 安装rpm-build: yum install rpm-builder package.json 配置build:  deb build: {linux: {target: [{target: &amp;quot;rpm&amp;quot;,arch: [&amp;quot;x64&amp;quot;]}]} tar.gz build: {linux: {target: [{target: &amp;quot;tar.gz&amp;quot;,arch: [&amp;quot;x64&amp;quot;]}]}      </description>
    </item>
    
    <item>
      <title>Erlang并发编程</title>
      <link>https://zylhorse.github.io/blog/erlang/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/</link>
      <pubDate>Wed, 03 Feb 2016 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/erlang/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/</guid>
      <description>概述 Erlang的并发是基于进程的。进程是一些独立的小型虚拟机。 在Erlang里面：
 创建和销毁进程是非常迅速的 在进程之间发送消息是非常迅速的 进程在所有操作系统上都具有相同的行为方式 可以生成大量进程 进程不共享内存，完全独立 进程唯一交互方式是消息传递  基本并发函数  Pid = spawn(Mod, Func, Args)   创建一个新的并发进程来执行apply(Mod, Func, Args)。这个新进程和调用进程并列运行。spawn返回一个Pid，可以使用Pid给此进程发送消息。这里参数为Args的Func必须从Mod模块导出。
 Pid = spawn(Fun)   创建一个新的并发进程来执行Fun()。这种形式的spawn总是使用被执行fun的当前值，而且这个Fun无需从模块中导出。 这两种spawn形式的本质区别与动态代码升级有关。
 Pid ! Message   向标识符为Pid的进程发送消息Message,消息发送是异步的。发送方并不等待，而是会继续之前的工作。Pid1 ! Pid2 ! &amp;hellip;. ! Message的意思是把消息Msg发送给Pid1、Pid2等所有进程。
 receive &amp;hellip; end   接受发送给某个进程的消息，阻塞等待。语法如下：
 receivePattern1 [when Guard1] -&amp;gt;Expressions1;Pattern2 [when Guard2] -&amp;gt;Expressions2;...end 当某个消息到达进程后，系统尝试将它与Pattern1进行匹配，如果成功则执行Expressions1。如果不成功则以此类推。如果没有匹配的模式，消息就会被保存起来供以后处理，进程则会开始等待下一条信息。
  当spawn命令被执行时，系统会创建一个新的进程，并给每个进程同步创建一个邮箱。给进程发送消息后，消息会被放入该进程的邮箱，只有程序执行接受语句时才会读取邮箱。</description>
    </item>
    
    <item>
      <title>shadowsocks 使用和配置</title>
      <link>https://zylhorse.github.io/blog/tools/shadowsocks/</link>
      <pubDate>Wed, 03 Feb 2016 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/tools/shadowsocks/</guid>
      <description> 购买服务器Shadowsocks-Store 下载客户端Shadowsocks-Download 配置客户端Shadowsocks-Wiki  </description>
    </item>
    
    <item>
      <title>Erlang大数据存储</title>
      <link>https://zylhorse.github.io/blog/erlang/ets%E5%92%8Cdets%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/</link>
      <pubDate>Fri, 22 Jan 2016 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/erlang/ets%E5%92%8Cdets%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/</guid>
      <description>概述 ets和dets是Erlang用于高效存储大量Erlang数据条目的两个系统模块。提供大型的&amp;quot;键-值&amp;quot;搜索表。
ETS(Erlang Term Storage) ETS驻留在内存，ETS非常高效。
DETS(Disk ETS) DETS驻留在硬盘，DETS要比ETS慢，但是比ETS更省内存。</description>
    </item>
    
    <item>
      <title>Redis基本数据类型</title>
      <link>https://zylhorse.github.io/blog/cache/redis/%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/</link>
      <pubDate>Sun, 10 Jan 2016 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/cache/redis/%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/</guid>
      <description>键 redis 键值为string类型， 最大可为512M语法： get keydel key dump key exists keyexpire key second expireat key timestampkeys pattern move key db // 将key移动到数据库db中randomkey // 随机获取db中keypersist key // 移除过期时间TTL key rename key newnametype key String字符串 string类型是二进制安全的。表示string可以包含任何数据；最大可为512M；语法：set key valueget keygetrange key start endsetrange key offset valuesetex key seconds valuesetnx key value strlen key mset key1 value1 key2 value2append key valueincr keydecr keyincrby key valuedecrby key value应用场景：  常规key-value缓存 分布式锁 计数器： 禁止非法IP访问频率；文档访问频率； 限速： 限制登录接口获取验证码频率 共享session： 使用redis将用户session集中管理  Hash哈希 hash 是一个键值对集合，是string类型的映射表。最大可存储uint32max 个键值对；语法：hset key field1 value1hget key field1hmset key field1 value1 field2 value2hmget key field1 field2hdel key field1 field2hexist key field1hkeys key hvals keyhgetall keyhlen keyhsetnx key field valueshscan key cursor match [pattern] count [count]应用场景： 存储用户id及用户信息</description>
    </item>
    
    <item>
      <title>markdown使用手册</title>
      <link>https://zylhorse.github.io/blog/markdown/markdown/</link>
      <pubDate>Thu, 07 Jan 2016 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/markdown/markdown/</guid>
      <description>简单链接   格式
[zylhorse blog](https://zylhorse.github.io)
  效果
zylhorse blog
  后置链接地址   格式
[zylhorse blog][1][zylhorse about][about]....[1]: https://zylhorse.github.io[about]: https://zylhorse.github.io/about  效果
zylhorse blog
zylhorse about
&amp;hellip;.
  表格   格式
表头|表头|表头:---|:---:|---:左对齐 | 居中 | 右对齐换行&amp;lt;br&amp;gt;换行 | &amp;lt;img width=&amp;quot;100px&amp;quot; height=&amp;quot;100px&amp;quot; src=&amp;quot;/img/main/logo.jpg&amp;quot;/&amp;gt; | ![logo](/img/main/wechat.jpg)   效果
   表头 表头 表头     左对齐 居中 右对齐   换行</description>
    </item>
    
    <item>
      <title>Erlang类型检查</title>
      <link>https://zylhorse.github.io/blog/erlang/%E7%B1%BB%E5%9E%8B%E6%A3%80%E6%9F%A5/</link>
      <pubDate>Tue, 15 Dec 2015 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/erlang/%E7%B1%BB%E5%9E%8B%E6%A3%80%E6%9F%A5/</guid>
      <description>类型检测 9.3　dialyzer(待补充) </description>
    </item>
    
    <item>
      <title>Erlang类型表示法</title>
      <link>https://zylhorse.github.io/blog/erlang/%E7%B1%BB%E5%9E%8B/</link>
      <pubDate>Tue, 01 Dec 2015 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/erlang/%E7%B1%BB%E5%9E%8B/</guid>
      <description>类型 Erlang有一种类型表示法，可以用来定义新的数据类型并给代码添加类型注解。类型注解让代码更容易理解和维护，还可以在编译时检测错误。
指定数据和函数类型 -module(...).-export([plan_route/2]).-spec play_route(point(), point()) -&amp;gt; route().-type direction() :: north | south | east | west.-type point() :: {integer(), integer()}.-type route() :: [{go, direction(), integer()}]. 这个模块导出一个名为plan_route/2的函数。该函数的输入和返回数据类型由类型声明(type)定义了三个新数据类型。该函数由类型规范(spec)指定输入和返回数据类型。 为了增加类型的表达能力，可以添加类型注解： -spec plan_route(From::point(), To::point()) -&amp;gt; ....  类型语法   类型定义可以使用一下的非正式语法： T1 :: A | B | C
 它的意思是T1被定义为A、B或C其中之一。
 用这些表示法，可以定义一些Erlang类型如下：Type :: any() | none() | pid() | port() | reference() | [] | Atom |binary() | float() | Fun | Integer | [Type] | Tuple | Union | UserDefinedUnion :: Type1 | Type2 | .</description>
    </item>
    
    <item>
      <title>Erlang套接字编程</title>
      <link>https://zylhorse.github.io/blog/erlang/%E5%A5%97%E6%8E%A5%E5%AD%97%E7%BC%96%E7%A8%8B%E6%9C%AA%E5%AE%8C/</link>
      <pubDate>Wed, 11 Nov 2015 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/erlang/%E5%A5%97%E6%8E%A5%E5%AD%97%E7%BC%96%E7%A8%8B%E6%9C%AA%E5%AE%8C/</guid>
      <description>客户端  gen_tcp:connect(Host, Port, [Options]) -&amp;gt; {ok, Socket} | {error, Reason}  与指定域名、端口号的服务器建立连接。  gen_tcp: send(Socket, Msg) -&amp;gt; ok | {error, Reason}
向Socket发送消息（二进制字节流）
  接受服务器传递消息
  receive{tcp,Socket, Bin} -&amp;gt; ...;{tcp_closed, Socket} -&amp;gt;...end. gen_tcp:close(Socket) -&amp;gt; ok
关闭Socket  服务器  gen_tcp:listen(Port, [Options]) -&amp;gt; {ok, Listen} | {error, Reason} 监听端口Port。 gen_tcp:accept(Listen) -&amp;gt; {ok, Socket} | {error, Reason}
接受监听的Socket连接，返回当前连接Socket。 gen_tcp:close(Listen) -&amp;gt; ok 关闭监听，不再接受新的连接。  并发套接字编程 注意：</description>
    </item>
    
    <item>
      <title>Redis安装和配置</title>
      <link>https://zylhorse.github.io/blog/cache/redis/%E5%AE%89%E8%A3%85%E5%92%8C%E9%85%8D%E7%BD%AE/</link>
      <pubDate>Fri, 06 Nov 2015 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/cache/redis/%E5%AE%89%E8%A3%85%E5%92%8C%E9%85%8D%E7%BD%AE/</guid>
      <description>安全 语法： config get requirepassconfig set requirepass passwordauth password客户端连接 client list // redis 客户端列表client setname // 设置客户端连接名client getname // 获取客户端连接名client pause // 挂起客户端client kill // 关闭客户端外网访问   注释 redis.conf
# bind 127.0.0.1  添加requirepass
  版本大于3.2 还需要取消保护模式
protected-mode no  修改linux redis最大连接数 修改用户打开文件句柄数 $ sudo vim /etc/security/limits.conf redis soft nofile 65535redis hard nofile	65535修改文件句柄限制 $ sudo vim /lib/systemd/system/redis.</description>
    </item>
    
    <item>
      <title>Erlang单元测试</title>
      <link>https://zylhorse.github.io/blog/erlang/%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95eunit/</link>
      <pubDate>Thu, 22 Oct 2015 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/erlang/%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95eunit/</guid>
      <description>概述 eunit是erlang的测试框架。 eunit使用了很多预处理宏，这些宏被设计成非入侵式的，不会与现有代码冲突。给模块添加eunit的测试集，一般不需要修改现有代码。测试模块导出函数的测试，可以放在完全独立的模块中，避免冲突。
单元测试 单元测试是指对程序相对独立的单元进行测试。一个单元可以是一个函数，一个模块，甚至是完整的应用程序。
为了测试一个单元，指定测试用例，并搭建测试需要的最基本环境。运行测试集并收集结果，为了能够再次测试需要进行必要的清理工作。
单元测试框架就是为了帮助单元测试过程的每个阶段，使单元测试更容易编写，容易运行，容易检查测试错误。
单元测试优点 减少改变程序的风险 大多数程序在生命周期内会被修改：bug修复，功能增加，优化，重构，清理。每次程序修改都会引入新bug风险，而使用一组单元测试用例可以很容易的发现代码是否正常工作（回归测试：对旧代码的修改，进行重新测试，确保不会引入新的问题）。
引导和提高开发进度 编写能通过测试的代码，让程序开发更有效率。通过测试来推动开发的进行（测试驱动开发“TDD”：测试驱动开发）。
帮助实现接口分离 当程序员编写测试集时可以发现依赖关系不存在、哪些依赖需要抽象出来。更多的依赖接口开发，实现松耦合设计。有助于提前消除坏的依赖关系。
简化组件集成 自下而上的测试，从最小单元的测试通过，使集成了若干个这种单元的程序更容易测试。（集成测试）
自文档化 测试集可以被视为使用文档。
入门 包含EUnit头文件 在Erlang模块中使用EUnit的最简单方法是在模块一开始的地方（在模块声明的后面，在函数定义的前面）添加下面这行：
-include_lib(&amp;quot;eunit/include/eunit.hrl&amp;quot;).这会有以下作用：
 创建一个导出函数test(),它可以执行模块中定义的所有单元测试集。（除非测试关闭，或者模块不包含函数test()) 自动导出命名匹配_test() 、 _ test_ ()的所有函数。（除非测试关闭或者定义了EUNIT_NOAUTO宏） 使EUnit所有的预处理宏可用，帮助编写测试集。
注：
为了使 -include_lib(&amp;hellip;)有效，Erlang 模块的搜索路径必须包含 eunit/bin目录（eunit/ebin是EUnit安装目录下的子目录）。如果EUnit安装在Erlang/OTP系统目录的子目录lib/eunit下，eunit/ebin目录在Erlang启动时会被自动添加到搜索路径。其他情况就需要显示添加到搜索路径: 在命令行中添加 -pa &amp;ldquo;path/eunit/ebin&amp;rdquo; 在主目录的.erlang文件中添加:code:add_patha(&amp;ldquo;path/eunit/ebin&amp;rdquo;).  编写简单测试功能 使用EUnit框架可以在Elang中非常简单的编写单元测试。有几种不同的方式来编写。
以_test()名称结尾的函数可以被EUnit识别为测试函数。它没有参数，不需要被导出。执行成功会返回EUnit抛出的任意值，执行失败会抛出异常（如果不停止，过一会会被终止）。
一个简单的测试函数的例子：
reverse_test() -&amp;gt; lists:reverse([1,2,3]).这不是一个好的测试编写方式。
使用异常报告 添加更多的场景测试，如果测试结果不符合预期则报异常。一个简单的方法是使用匹配表达式=去匹配测试结果和预期结果：
reverse_nil_test() -&amp;gt; [] = lists:reverse([]).reverse_one_test() -&amp;gt; [1] = lists:reverse([1]).reverse_two_test() -&amp;gt; [2,1] = lists:reverse([1,2]).使用断言 length_test() -&amp;gt; ?assert(lenght([1,2,3]) =:= 3).</description>
    </item>
    
    <item>
      <title>Erlang文本编程</title>
      <link>https://zylhorse.github.io/blog/erlang/%E6%96%87%E6%9C%AC%E7%BC%96%E7%A8%8B/</link>
      <pubDate>Wed, 07 Oct 2015 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/erlang/%E6%96%87%E6%9C%AC%E7%BC%96%E7%A8%8B/</guid>
      <description>文本编程 操作文件的模块  file   包含打开、关闭、读写文件的方法。
  filename   这个模块的方法能够跨平台的操作文件名，这样可以在不同的操作系统上运行相同的代码。
  filelib   此模块是file的扩展。它包含的许多工具函数能够列出文件、检查文件类型。其中大多数是由file里的函数编写。
  io   这个模块有一些操作已打开文件的方法。它可以解析文件数据，也可以将数据格式化写入文件。
 读取文件的几种方法  file:consult(FileName)   读取erlang数据格式的文件数据。
 code:which(Module) 查看已载入模块源码文件地址
格式命令  ~n 输出换行符 ~p 把参数打印为美观形式 ~s 参数是一个字符串、I/O列表或原子，打印时不带引号 ~w 输出各种Erlang数据类型  </description>
    </item>
    
    <item>
      <title>Erlang顺序编程补遗</title>
      <link>https://zylhorse.github.io/blog/erlang/erlang%E9%A1%BA%E5%BA%8F%E7%BC%96%E7%A8%8B%E8%A1%A5%E9%81%97/</link>
      <pubDate>Mon, 21 Sep 2015 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/erlang/erlang%E9%A1%BA%E5%BA%8F%E7%BC%96%E7%A8%8B%E8%A1%A5%E9%81%97/</guid>
      <description>apply  内置函数apply(mod,func,[arg1,arg2,arg3,&amp;hellip;,argn])。会将参数arg1,arg2,&amp;hellip;,argn应用到模块mod里的函数func上。它等价于：mod:func(arg1,arg2,&amp;hellip;,argn)。 与直接调用函数的区别在于模块名和函数名可以动态的计算得出。 应当尽量避免使用apply。如果使用apply对函数进行调用，许多分析工具就无法得知发生了什么，一些特定的编译器优化也不能进行。  算术表达式  操作符	描述	参数类型	优先级+X	正数	整数	1-X	负数	整数	1X*Y	X乘以Y	整数	2X/Y	X除以Y，浮点数除法	整数	2bnot X	对X执行按位取反	整数	2X div Y	X除以Y的商，整数	整数	2X rem Y	X除以Y的余数	整数	2X band Y	X和Y位与	整数	2X bor Y	X和Y位或	整数	3X bxor Y	X与Y按位异或	整数	3X bsl N	X向左位移N个算术位	整数	3X bsr N	X向右位移N个算术位	整数	3X + Y	X 加 Y	整数	3X - Y	X 减 Y	整数	3 元数  一个函数的元数(arity)是该函数所拥有的参数数量。在Erlang里，同一个模块里的两个名称相同，元数不同的函数是完全不同的函数。 根据惯例Erlang程序员经常将名称相同、元数不同的函数作为辅助函数使用。我们通常通过不导出辅助函数，来隐藏他们。  模块属性  模块属性的语法是 -AtomTag(&amp;hellip;),它们被用来定义文件的某些属性。 模块属性包括预定义型和用户定义型。 预定义型：   模块属性有着预先定义的含义，必须放置在任何函数定义之前。</description>
    </item>
    
    <item>
      <title>Erlang顺序编程错误处理</title>
      <link>https://zylhorse.github.io/blog/erlang/erlang%E9%A1%BA%E5%BA%8F%E7%BC%96%E7%A8%8B%E9%94%99%E8%AF%AF%E5%A4%84%E7%90%86/</link>
      <pubDate>Fri, 11 Sep 2015 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/erlang/erlang%E9%A1%BA%E5%BA%8F%E7%BC%96%E7%A8%8B%E9%94%99%E8%AF%AF%E5%A4%84%E7%90%86/</guid>
      <description>概括  Erlang中当错误出现时，需要发现并纠正，然后继续。 构建真正容错的系统，需要不止一台计算机，毕竟可能整台机器崩溃。因此故障检测和别处重启计算的概念需要扩展到联网的计算机上。  顺序代码里面的错误处理  异常错误发生时，可以显示调用throw(Exception),exit(Exception),error(Exception) 触发。 永远不能让函数对非法的参数返回值，而是抛出一个异常错误。 exit(Why):当你确实想要终止当前进程时就用它。如果此异常没有被捕获，信号{&amp;lsquo;Exit&amp;rsquo;,Pid,Why}就会被广播给当前进程链接的所有进程。 throw(Why):这个函数的作用是抛出一个调用者想要捕获的异常错误。因此我们可以将调用封装到try&amp;hellip;catch表达式里面，然后对错误进行处理。 error(Why):这个函数的作用是指示“崩溃性错误”，调用者没有准备好处理非常严重的问题。  捕获异常错误 两种方法：
 把抛出异常错误的调用函数封装在try&amp;hellip;catch中 把调用封装在一个catch表达式中？？？  try ... catch 结构%执行函数或表达式try FuncOrExpressionSeq of%执行过程无异常则匹配以下模式Pattern1 [when Guard1] -&amp;gt; Expressions1;Pattern2 [when Guard2] -&amp;gt; Expressions2;catch%执行过程出现异常则匹配以下异常模式，ExceptionType：error throw exit其中之一ExceptionType1: ExPattern1 [when ExGuard1] -&amp;gt; ExExpressions1;ExceptionType2: ExPattern2 [when ExGuard2] -&amp;gt; ExExpressions2after%after区域的代码实在FuncorExpressSeq结束后执行清理工作的。这段代码无论是否抛出异常都会在函数调用执行完立刻执行。AfterExpressions返回值会被丢弃。AfterExpressionsendtry ... catch 表达式也有值。注：Erlang里的一切都是表达式，表达式都有值。针对异常处理的编程方式  改进错误消息：内置函数error/1。 经常返回错误时代码：{ok,Value}, {error,Reason} 捕捉一切可能的错误：try Expr of catch : -&amp;gt; &amp;hellip; end %这里处理所有的异常错误。 如果代码漏写标签：try Expr of catch _ -&amp;gt; &amp;hellip; end %这里只处理throw 异常。  栈跟踪 捕获到一个异常错误后，可以调用erlang:get_stacktrace() 来找到最近栈跟踪信息。</description>
    </item>
    
    <item>
      <title>编程范式-函数式编程</title>
      <link>https://zylhorse.github.io/blog/software-programming/%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B/</link>
      <pubDate>Tue, 01 Sep 2015 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/software-programming/%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B/</guid>
      <description>函数式编程（Function Programming）  函数式编程将电脑运算看作是函数运算。 函数式编程的基础是λ 演算（ lambda caculus）。函数可以作为输入（参数）输出（返回值）。 函数式编程最古老的例子： 1958年创造出来的LISP。 #特性  函数是&amp;quot;第一公民&amp;quot;（first class） 函数可以作为变量
”表达式“ not ”语句“  ”表达式“（expression）是运算过程，总有返回值 ”语句“（statement）是操作，无返回值。 函数式编程要求只使用表达式，不使用语句， 每一步运算都有返回值。  无”副作用“（side effect）  ”副作用“：函数内部与外部互动（eg:函数内部修改全局变量），操作外部。 函数式编程强调没有”副作用“，保持独立，所有功能只是返回新值，不做其他行为尤其是不修改外部变量。  不修改&amp;quot;状态&amp;quot;（state)  函数式编程要求使用参数保存状态,状态不能保存在变量中。  引用透明（Referential transparency）  函数运行不依赖外部变量或”状态“，只根据输入参数，任何时候只要参数相同，引用函数所得到的结果总是相同。  闭包（closure capture）  闭包函数： 声明在一个函数中的函数，叫闭包函数 闭包： 闭包函数总是可以访问其所在的外部函数中声明的参数和变量，即使在其外部函数被返回（寿命终结）了之后   问题： 局部变量常驻内存，不被释放造成内存泄漏
 高阶函数 接受一个或多个函数作为输入，输出一个函数。
意义 代码简洁，开发迅速 编码中大量使用函数，减少代码重复。
更方便的代码管理 每一个函数都是独立单元，有利与单元测试（unit test）和除错（debugging），以及模块化组合。
易于并发编程 函数不用考虑”死锁“（deadlock），因为修改变量，不用担心被其他线程修改，可以将工作分摊到多个线程，部署”并发编程“（concurrency）。
代码热升级 因为函数式编程无副作用，只要保证接口不变，内部实现是外部无关的。所以可以在运行状态下直接升级代码，不需要重启。</description>
    </item>
    
    <item>
      <title>Erlang模块和函数</title>
      <link>https://zylhorse.github.io/blog/erlang/erlang%E6%A8%A1%E5%9D%97%E5%92%8C%E5%87%BD%E6%95%B0/</link>
      <pubDate>Thu, 20 Aug 2015 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/erlang/erlang%E6%A8%A1%E5%9D%97%E5%92%8C%E5%87%BD%E6%95%B0/</guid>
      <description>模块  模块是Erlang中代码的基本单元，我们编写的所有函数都存放在模块中，模块文件的扩展名通常为.erl。 编译后的文件扩展名为.beam,   注： beam 是 Erlang虚拟机（Bogdan‘s Erlang Abstract Machine）的所写。Erlang虚拟机最早的版本是 Joe Armstrong编写的基于栈的虚拟机JAM（Joe&amp;rsquo;s Abstract Machine）。后来，Bogumil(Bogdan) Hausman在1993年编写了基于寄存器的虚拟机BEAM（Bogdan&amp;rsquo;t Abstract Machine), 执行效率有了 大幅度提高。
  erlang虚拟机执行代码的原理：http://www.mamicode.com/info-detail-671999.html  函数  函数由子句构成，子句以分号分隔，最后一条子语句以句号结束。每一个函数由函数头和函数体组成，函数头由函数名和随后以括号括起来的模式组成，函数体由一系列表达式组成。 shell中编译模块文件： c(文件名） 引用模块中函数： moduleName:funcName(模式）。 模块中函数调用是顺序的从第一个子句开始进行模式匹配。 在erlang中做相同的事情，只需要编写模式及表达式，erlang编译器会自动生成优化的模式匹配代码。  同名不同目的函数  在Erlang中，同一个模块的两个函数，如果同名但是参数不同，则这两个函数被认为完全不同。 为了方便同名不同目的函数经常被用来作为辅助函数使用。  fun fun就是匿名函数,fun可以有任意参数（目：arity）。
高阶函数（high-order function） 这些能返回fun或接受fun作为参数的函数，被称作高阶函数。
什么时候使用高阶函数  编写返回fun的高阶函数不容易调试 高阶函数可以用来解决延迟求值、可重入的解析器、解析组合子等问题。  -import 和 -export 声明  声明 -import(lists,[map/2,sum/1]) 意味着函数 map/2,sum/1是从lists模块中导入。 声明 -export([total/1]) 意味着total/1能够在模块之外被调用。只有从一个模块中导出的函数才能在模块外调用。  简单的列表处理  lists:map(Fun,List): 将方法Fun应用到列表List的每一个元素中，输出操作后的元素列表。 lists:member(Ele,List): 判断元素Ele是否是列表List中的元素，输出true/false。 lists:filter(Fun,List): 用方法Fun过滤列表List中的每一个元素，输出符合要求的元素列表。 lists: sum(List):计算列表中所有元素的和。 lists: seq(1,N): 返回一个包含1到N的整数列表。 lists:reverse(L) : 将列表中元素顺序反转。  列表推导  列表推导无需使用fun、map或filter等表达式来创建列表。  1&amp;gt;L= [1,2,3,4].</description>
    </item>
    
    <item>
      <title>Erlang记录和映射组</title>
      <link>https://zylhorse.github.io/blog/erlang/%E8%AE%B0%E5%BD%95%E5%92%8C%E6%98%A0%E5%B0%84%E7%BB%84/</link>
      <pubDate>Sat, 15 Aug 2015 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/erlang/%E8%AE%B0%E5%BD%95%E5%92%8C%E6%98%A0%E5%B0%84%E7%BB%84/</guid>
      <description>数据容器 元组（tuple）：保存固定数量的元素列表（list）：保存可变数量的元素记录（record）：是元组的另一种形式，通过记录给元组里面的各个元素关联一个名字，映射组（map）：是键-值对关联性的集合。键可以是任意类型的Erlang数据类型。 使用记录和映射组 记录使用一组固定且预定义的关联名称映射组可以动态添加新的关联名称；映射组比元组占用更多存储空间，查找慢。但是映射组比元祖灵活。 何时使用映射组或记录 记录 -record（Name,{%% 以下两个键带默认值key1 = Default，key2 = Default，...%%下一行Key3 = undefinedkey3,...}).记录既可以保存在源代码的文件里，也可以保存在扩展名为.hrl的文件中，然后包含到源文件中。注意：文件包含是唯一确保多个Erlang模块共享相同记录的方式。命令行中读取记录文件 ：rr(&amp;quot;myrecord.hrl&amp;quot;).命令行中删除记录定义：rf(&amp;quot;myrecord.hrl&amp;quot;). 映射组(R17版本及以上引入) #{Key1 op Val1, Key2 op Val2, Key3 op Val3,...}语法与记录相似，只是散列符号（#）后面少了记录名，而op是符号 =&amp;gt;或者:=中的其中之一。键和值是任何有效的Erlang数据类型。表达式 Key =&amp;gt;Val有两种用途，一种是给映射组添加一个全新的 Key=&amp;gt;Val，另一种是更新 映射组里面Key对应的值。表达式 Key := Val ，作用是将现有键Key的值更新为新值Val。如果被更新的映射组中不包含键Key，则提示更新失败。注： 由于本地Erlang版本为R16B, 映射组（map）数据类型在 Erlang R17版本中才引入，因此此处不予学习，练习，待后续跟进。 </description>
    </item>
    
    <item>
      <title>Erlang基本数据结构</title>
      <link>https://zylhorse.github.io/blog/erlang/erlang%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/</link>
      <pubDate>Sun, 19 Jul 2015 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/erlang/erlang%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/</guid>
      <description>Erlang Erlang 创始人Joe Armstrong，基于Prolog开发。Erlang 是通用的面向并发的编程语言，由瑞典电信设备制造商爱立信所辖CS-Lab开发。于1987年开发，1988年开源。Erlang是运行于虚拟机上的解释型语言。 Erlang 编写的程序运行时通常由大量的轻量级进程组成，并通过消息传递进行通讯。Erlang 目前包含 乌普萨拉大学的高性能计划（Hipe）开发的本地代码编译器，自R11B04版本开始erlang 支持脚本式解释器。 注： erlang 的hipe 相当于jit（Just-in-time compilation），根据语言评测有hipe支持的erlang运算上快2-3倍。
Shell 启动：$&amp;gt; erl停止(受控方式)：1&amp;gt;q().init:stop().立即停止： erlang:halt().切换erl 中shell命令： CTRL + P ， CTRL + N。shell 只能对erlang 的表达式求值，不能在shell中输入Erlang文件中代码（.erl文件中的句法形式不是表达式），不能输入模块注释（如：-module，-export）。编写分布式程序时，集群中会有许多正运行的erlang系统节点，可以将shell随意附着在他们中的任何一个上， 甚至可以用ssh向一个运行着erlang系统的计算机上发起一个直连接，通过这个方法，在erlang 的节点集群中你能与其中的任何节点上的任意一个程序打交道 注释 % ： 代表一行注释的开始，被erlang 和 shell 忽略。 整数运算： 采用不定长整数进行运算，整数运算没有误差不会溢出。 进制表达： 进制#值： 16#1(16进制1)， 2#111(2进制111)。 变量 变量首字母大写变量是单一赋值，只能一次性给定，重复赋值是错误的。一个变量如果被赋值，则被称为绑定变量，否则为自由变量。一开始所有的变量都是自由变量。下划线（_） 是匿名变量，与常规变量不同，在同一模式下_可以绑定不同的值。f() 会释放shell之前进行过绑定的变量。 等号（=） =是一个模式匹配运算符，当变量是自由变量时，其行为相当于赋值运算。 变量绑定表： 变量经过赋值，shell就会形成一个变量绑定表。形如： {X |-&amp;gt; 111, Y |-&amp;gt; 222} 原子 原子是全局有效的，无需使用宏定义或者包含文件。 原子是以小写字母开头，后面跟数字、字母、下划线、邮件符号（@）的字符。使用单引号的字符也是原子。这种形式使得我们可以用大些字母开头或者包含特殊字符。原子的值是原子本身。 元组（tuple） 将若干个以逗号分割的值用一对花括号括起来就形成一个元组。元组是匿名的，元组中的字段没有名字，因此推荐元组的第一个元素用原子来表明这个元组所代表的含义。eg:  Person={person, {name,zyl}, {age,27}, {height,1.</description>
    </item>
    
    <item>
      <title>Erlang编译和运行</title>
      <link>https://zylhorse.github.io/blog/erlang/%E7%BC%96%E8%AF%91%E5%92%8C%E8%BF%90%E8%A1%8C%E7%A8%8B%E5%BA%8F/</link>
      <pubDate>Thu, 16 Jul 2015 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/erlang/%E7%BC%96%E8%AF%91%E5%92%8C%E8%BF%90%E8%A1%8C%E7%A8%8B%E5%BA%8F/</guid>
      <description>代码搜索路径  Erlang运行时系统使用一种代码自动载入机制，要让它正确工作，必须设置一些搜索路径来找到正确版本代码。 代码的载入是按需进行的，当系统尝试调用的函数属于一个尚未加载的模块时，就会出现异常，系统尝试查找缺失模块代码文件。代码载入器会在代码载入路径所有目录里查找缺失模块代码文件。只要找到相符的文件，搜索停止，载入该文件的目标代码。 以下是两个最常用来操作载入路径的函数：   -spec code::add_patha(Dir) =&amp;gt; true | {error, bad_directory}. 向载入路径的开头添加一个新目录Dir。
  -spec code::add_pathz(Dir) =&amp;gt; true | {error, bad_directory}. 向载入路径的末尾添加一个新目录Dir。
  通常的惯例是将这些命令放到主目录下的一个.erlang文件中。 也可以在启动erl时添加代码搜索路径：  $ erl -pa Dir1 -pa Dir2 ... -pz Dirk1 -pz Dirk2-pa: 把Dir添加到搜索路径的开头-pz:把Dir添加到搜索路径的结尾在系统启动时执行.erlang里的命令  启动erlang时，它会首先读取并执行.erlang中的所有命令。当前目录下的.erlang优先级高于主目录下的.erlang Erlang认为的主目录的位置获取:init:get_argument(home). code:clash()会报告代码搜索路径里面所有重复的模块。  运行程序的不同方式 程序 hello.erl-module(hello).-export([start/0]).start() -&amp;gt; io:format(&amp;quot;Hello World ~n&amp;quot;).在erlang shell里面编译运行： 1&amp;gt;c(hello).2&amp;gt;hello:start().快速脚本编程：  在命令行中执行任意的erlang函数：  erl -eval &#39;io:format(&amp;quot;Memory: ~p~n&amp;quot;, [erlang:memory(total)]).</description>
    </item>
    
    <item>
      <title>详解hash</title>
      <link>https://zylhorse.github.io/blog/security/hash/</link>
      <pubDate>Fri, 03 Jul 2015 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/security/hash/</guid>
      <description></description>
    </item>
    
    <item>
      <title>详解安全传输协议SSL TLS</title>
      <link>https://zylhorse.github.io/blog/security/ssl-tls/</link>
      <pubDate>Fri, 03 Jul 2015 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/security/ssl-tls/</guid>
      <description>tls 传输层安全协议 包含两部分：
 握手协议（handshake protocol）： 客户端和服务端进行协商，确定一组用于数据传输加密的密钥串 记录协议（record protocol）： 通过握手协议确定的密钥串进行数据加密传输  握手和密钥协商过程FullHandshake 客户端ClientHello 客户端发起请求，以明文传输请求信息包含：
 version： 支持最高TLS协议版本, 从低到高：SSLV1、SSLV3、TLSV1、TLSV1.1、TLSV1.2 cipher suites： 客户端支持的加密套件列表： Kx = Key Exchange 密钥协商算法Au = Authentication 身份认证算法Enc = Encrypt 加密算法Mac = Message Authentication Code 信息摘要算法 compression methods：压缩算法列表，用于后续信息压缩传输 random_C：客户端随机数，用于后续密钥生成 extensions： 扩展字段，支持协议与算法相关参数及辅助信息 session id： 会话id，后续连接到同一台服务器，可以避免完全握手；  如果客户端时第一次连接服务器，则该字段为空。
   服务器ServerHello 服务端返回协商的结果信息， 包含：
 version： 选择使用的TLS协议版本 cipher suite： 选择使用的加密套件 compression method： 选择使用的压缩算法 random_S: 服务器随机数 ，用于后续密钥生成 session id： 会话id  握手成功，服务器会缓存session 参数到tls缓存中， 并生成对应的session id 返回该session id 给客户端，客户端将session id存储在浏览器并设置时限 后续连接到同一台服务器，则发送session id， 服务器验证后， 使用以前使用过的对称密钥来恢复session</description>
    </item>
    
    <item>
      <title>Extended Backus–Naur form</title>
      <link>https://zylhorse.github.io/blog/software-programming/ebnf/</link>
      <pubDate>Mon, 22 Jun 2015 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/software-programming/ebnf/</guid>
      <description>计算机科学中， EBNF是一组元语法，表达上下文无关的语法。EBNF是用于对正规语言的语法进行描述， 例如计算机编程语言的语法。它是BNF的扩充。
基本要素 EBNF是一种表达正规语言语法的代码。一条EBNF由终结符号和非终结符产生规则组成，规则控制了终结符号如何组成合法的序列。例如： 终端符号包含：字母数字字符，标点符号，空白字符。
EBNF定义了把符号序列分配给非终端的产生规则：
digit excluding zero = &amp;quot;1&amp;quot; | &amp;quot;2&amp;quot; | &amp;quot;3&amp;quot; | &amp;quot;4&amp;quot; | &amp;quot;5&amp;quot; | &amp;quot;6&amp;quot; | &amp;quot;7&amp;quot; | &amp;quot;8&amp;quot; | &amp;quot;9&amp;quot; ;digit = &amp;quot;0&amp;quot; | digit excluding zero ; 这条产生规则定义了在表达式左边的非终结符digist。竖线|表示一种替代，终结符使用双引号&amp;quot;&amp;quot;包起来，后跟分号;作为终结字符。 因此digit 可以是0或者digit excluding zero(1或2或3，等等，直到9)
 产生规则可以包含一系列的终结符和非终结符，每个都用逗号(,)隔开:
twelve = &amp;quot;1&amp;quot;, &amp;quot;2&amp;quot; ;two hundred one = &amp;quot;2&amp;quot;, &amp;quot;0&amp;quot;, &amp;quot;1&amp;quot; ;three hundred twelve = &amp;quot;3&amp;quot;, twelve ;twelve thousand two hundred one = twelve, two hundred one ;可以省略或重复的表达式，用花括号{.</description>
    </item>
    
    <item>
      <title>生成自签名SSL证书</title>
      <link>https://zylhorse.github.io/blog/security/%E7%94%9F%E6%88%90%E8%AF%81%E4%B9%A6/</link>
      <pubDate>Mon, 22 Jun 2015 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/security/%E7%94%9F%E6%88%90%E8%AF%81%E4%B9%A6/</guid>
      <description>#!/bin/sh# create self-signed server certificate:SSLDIR=$PWD/sslSERVERDIR=$SSLDIR/serverCLIENTDIR=$SSLDIR/clientOPENSSLFILE=$PWD/openssl.cnfsu rootsudo rm -rf $SSLDIRsudo mkdir $SSLDIRsudo mkdir $SERVERDIRsudo mkdir $CLIENTDIRsudo mkdir $SSLDIR/demoCAsudo mkdir $SSLDIR/demoCA/newcertssudo touch $SSLDIR/demoCA/index.txtsudo touch $SSLDIR/demoCA/serialsudo echo 01 &amp;gt; $SSLDIR/demoCA/serialcd $SSLDIRread -p &amp;quot;Enter your domain [www.example.com]: &amp;quot; DOMAINsudo sed -e &amp;quot;s|192.168.10.33|$DOMAIN|g&amp;quot; -i $OPENSSLFILESUBJECT=&amp;quot;/C=CN/ST=Beijing/L=Beigjing/O=YongNuo/OU=CEO/CN=$DOMAIN/emailAddress=zylhorse@126.com&amp;quot;echo &amp;quot;Create Ca key / cert ...&amp;quot;sudo openssl req -new -x509 -subj $SUBJECT -keyout $SSLDIR/ca.</description>
    </item>
    
    <item>
      <title>生成自签名SSL免密证书</title>
      <link>https://zylhorse.github.io/blog/security/%E7%94%9F%E6%88%90%E5%85%8D%E5%AF%86%E8%AF%81%E4%B9%A6/</link>
      <pubDate>Sat, 13 Jun 2015 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/security/%E7%94%9F%E6%88%90%E5%85%8D%E5%AF%86%E8%AF%81%E4%B9%A6/</guid>
      <description>#!/bin/sh# create self-signed server certificate:SSLDIR=$PWD/sslSERVERDIR=$SSLDIR/serverCLIENTDIR=$SSLDIR/clientOPENSSLFILE=$PWD/openssl.cnfsudo rm -rf $SSLDIRsudo mkdir $SSLDIRsudo mkdir $SERVERDIRsudo mkdir $CLIENTDIRsudo mkdir $SSLDIR/demoCAsudo mkdir $SSLDIR/demoCA/newcertssudo touch $SSLDIR/demoCA/index.txtsudo touch $SSLDIR/demoCA/serialsudo echo 01 &amp;gt; $SSLDIR/demoCA/serialcd $SSLDIRread -p &amp;quot;Enter your domain [www.example.com]: &amp;quot; DOMAINsudo sed -i &amp;quot;s/subjectAltName=IP.*/subjectAltName=IP:$DOMAIN/g&amp;quot; $OPENSSLFILESUBJECT=&amp;quot;/C=CN/ST=Beijing/L=Beigjing/O=YongNuo/OU=CEO/CN=$DOMAIN/emailAddress=zylhorse@126.com&amp;quot;echo &amp;quot;Create Ca key / cert ...&amp;quot;sudo openssl req -new -x509 -subj $SUBJECT -keyout $SSLDIR/ca.</description>
    </item>
    
    <item>
      <title>lua编译环境搭建和IDE配置</title>
      <link>https://zylhorse.github.io/blog/lua/ide/</link>
      <pubDate>Fri, 05 Jun 2015 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/lua/ide/</guid>
      <description>lua 编译环境安装   linux:
$ curl -R -O http://www.lua.org/ftp/lua-5.3.0.tar.gz$ tar zxf lua-5.3.0.tar.gz$ cd lua-5.3.0$ make linux test$ make install  macos:
$ curl -R -O http://www.lua.org/ftp/lua-5.3.0.tar.gz$ tar zxf lua-5.3.0.tar.gz$ cd lua-5.3.0$ make macosx test$ make install  windows:
下载地址
  sublime text 3 设置tools -&amp;gt; build system -&amp;gt; lua</description>
    </item>
    
    <item>
      <title>Lua语言简介</title>
      <link>https://zylhorse.github.io/blog/lua/lua/</link>
      <pubDate>Thu, 04 Jun 2015 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/lua/lua/</guid>
      <description>概念  轻量小巧的脚本语言 标准c语言编写，且开源 目的： 嵌入宿主语言，并提供灵活的扩展和定制  编程模型  面向过程编程和函数式编程 自动内存管理：值提供一种通用类型的表（table) 内置模式匹配，函数也可以看作值 提供多线程支持 通过闭包和table可以方便的支持面向对象编程的一些机制   参考  The Implementation of Lua 5.0  </description>
    </item>
    
    <item>
      <title>生成公私钥</title>
      <link>https://zylhorse.github.io/blog/security/%E7%94%9F%E6%88%90%E5%85%AC%E7%A7%81%E9%92%A5/</link>
      <pubDate>Wed, 03 Jun 2015 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/security/%E7%94%9F%E6%88%90%E5%85%AC%E7%A7%81%E9%92%A5/</guid>
      <description>$ openssl genrsa -out privatekey.pem 1024$ openssl pkcs8 -topk8 -inform PEM -in privatekey.pem -outform PEM -nocrypt$ openssl rsa -in privatekey.pem -pubout -out publickey.pem</description>
    </item>
    
    <item>
      <title>不同平台常用浏览器的离线下载地址</title>
      <link>https://zylhorse.github.io/blog/browser/download/</link>
      <pubDate>Thu, 02 Apr 2015 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/browser/download/</guid>
      <description>  edge
  chrome-mac
  chrome-win64
  </description>
    </item>
    
    <item>
      <title>Sandboxie（沙箱）网络编程虚拟执行环境</title>
      <link>https://zylhorse.github.io/blog/software-programming/%E6%B2%99%E7%AE%B1/</link>
      <pubDate>Sun, 22 Mar 2015 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/software-programming/%E6%B2%99%E7%AE%B1/</guid>
      <description>关键字 Sandboxie（沙箱）网络编程虚拟执行环境
概念 沙箱是一个虚拟系统程序， 允许程序在沙箱环境中独立运行， 限制沙箱中程序对宿主系统的修改和影响。
有哪些限制 在沙箱中运行的程序，
 不能运行本地的可执行程序 不能从本地计算机文件系统中读取任何文件， 也不能往本地计算机系统中写入任何信息 不能查看本地计算机信息，特别是用户名，E-mail地址等  技术迭代  GreenBorder 为IE和Firefox构建安全的虚拟执行环境，用户对浏览器所作的任何写磁盘操作， 都将重定向到一个临时的文件中 Forcefield由ZoneAlarm开发， 功能雷士GreenBorder;  原理 Sandboxie 通过重定向技术，将程序生成和修改的文件重定向到自身的临时文件中（修改包括注册表和系统的核心数据）。通过加载自身的驱动来保护底层数据， 属于驱动级别保护。</description>
    </item>
    
    <item>
      <title>Ubuntu依赖包的离线打包和安装</title>
      <link>https://zylhorse.github.io/blog/linux/%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85%E6%BA%90/</link>
      <pubDate>Mon, 02 Feb 2015 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/linux/%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85%E6%BA%90/</guid>
      <description>Ubuntu 16.04离线安装步骤 宿主机打包   清理apt 缓冲区
$ sudo rm -rf /var/cache/apt/archives/*
  下载所需组件
$ sudo apt-get -d install &amp;lt;包名&amp;gt;
  创建目录，并拷贝
$ mkdir &amp;lt;your-path&amp;gt;$ cp -r /var/cache/apt/archives &amp;lt;your-path&amp;gt;  修改目录权限
$ chown -R &amp;lt;your-path&amp;gt;
  建立依赖关系
$ sudo apt install dpkg-dev$ cd &amp;lt;your-path&amp;gt;$ sudo dpkg-scanpackages archives /dev/null | gzip &amp;gt; &amp;lt;your-path&amp;gt;/archives/Packages.gz  拷贝到离线系统
$ scp -r &amp;lt;your-path&amp;gt; &amp;lt;离线系统&amp;gt;
  离线系统安装   修改apt源</description>
    </item>
    
    <item>
      <title>并发编程-乐观锁和悲观锁</title>
      <link>https://zylhorse.github.io/blog/concurrence/%E4%B9%90%E8%A7%82%E9%94%81%E5%92%8C%E6%82%B2%E8%A7%82%E9%94%81/</link>
      <pubDate>Fri, 16 Jan 2015 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/concurrence/%E4%B9%90%E8%A7%82%E9%94%81%E5%92%8C%E6%82%B2%E8%A7%82%E9%94%81/</guid>
      <description>乐观锁 乐观锁假设数据一般不会修改， 所以在数据提交修改的时候， 才会对数据冲突进行检查；如果冲突则交给用户决定如何去做；对数据竞争持乐观态度
乐观锁实现 cas（compare and swap）  CAS机制当中使用了3个基本操作数：内存地址V，旧的预期值A，要修改的新值B。 更新一个变量的时候，只有当变量的预期值A和内存地址V当中的实际值相同时，才会将内存地址V对应的值修改为B。 CAS一般需要加for循环，实现类似自旋乐观锁。  mvcc（Multi-Version Concurrency Control）  每行数据都增加两个隐藏字段，一个记录创建的版本号，一个记录删除的版本号 在多版本并发控制中，为了保证数据操作在多线程过程中，保证事务隔离的机制，降低锁竞争的压力，保证较高的并发量。 在每开启一个事务时，会生成一个事务的版本号，被操作的数据会生成一条新的数据行（临时），但是在提交前对其他事务是不可见的，对于数据的更新（包括增删改）操作成功，会将这个版本号更新到数据的行中，事务提交成功，将新的版本号更新到此数据行中，这样保证了每个事务操作的数据，都是互不影响的，也不存在锁的问题。  悲观锁 悲观锁具有强烈的独占性和排他性；一般认为数据被并发修改的概率较大，所以需要在修改前先加锁；对数据竞争持态度。</description>
    </item>
    
    <item>
      <title>并发编程-线程锁和死锁</title>
      <link>https://zylhorse.github.io/blog/concurrence/%E7%BA%BF%E7%A8%8B%E9%94%81/</link>
      <pubDate>Fri, 16 Jan 2015 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/concurrence/%E7%BA%BF%E7%A8%8B%E9%94%81/</guid>
      <description>锁 在多线程编程中， 对共享资源竞争的保护机制；
锁缺点  引起线程阻塞 申请和释放锁， 增加线程的调度切换， 影响系统性能 容易造成死锁和活锁等问题 优先级反转 不公平 效率低  公平锁 在锁上等待时间最长的线程优先获取锁的使用权
非公平锁 线程获取锁的使用权是随机的， cpu时间片轮到哪个线程， 哪个线程就获取到锁；
锁类型  自旋锁（spin lock） ： 自旋锁如果已经被其他线程获取，则调用者就一直循环等待；自旋锁时非阻塞锁， 循环等待时会不断消耗cpu， 不会使线程挂起； 互斥锁（mutex lock）： 互斥锁被其他线程获取， 则调用者会阻塞线程， 线程被挂起， 不会消耗cpu； 读写锁（read write lock）：读写锁允许资源可以同时被多个线程读取， 但是读写时互斥的且同时只能有一个线程去写； 条件锁 （condition lock）：条件锁检查条件，如果条件不满足则线程阻塞等待， 并解锁mutex。当收到其他线程的notify条件状态改变后，线程苏醒，获取mutex并上锁。  响应中断  一个线程霸占锁， 手动中断该线程后，使得该锁发出中断响应； 其他等待线程收到该中断信息，就可以获取到锁；  限时等待 线程在获取锁时， 设置等待时间， 超过该时间， 则停止等待， 获取锁失败；
死锁 多个线程在运行中因争夺共享资源出现互相等待的现象
死锁发生条件  互斥： 资源一次只能被一个进程占用；其他进程请求需要等待； 请求和保持： 一个进程至少占用一个资源， 并等待申请其他资源， 而该资源被其他进程占用。 不剥夺：进程占用的资源只能自己释放， 其他进程不能强行夺取； 循环等待：有一组等待进程 {P0，P1，…，Pn}，P0 等待的资源为 P1 占有，P1 等待的资源为 P2 占有，……，Pn-1 等待的资源为 Pn 占有，Pn 等待的资源为 P0 占有   四个条件必须同时成立才会出现死锁。</description>
    </item>
    
    <item>
      <title>I/O多路复用-select/poll/epoll</title>
      <link>https://zylhorse.github.io/blog/concurrence/io/epoll/</link>
      <pubDate>Fri, 09 Jan 2015 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/concurrence/io/epoll/</guid>
      <description>概述 i/o 多路复用:在单线程中通过记录跟踪多个sock 状态， 来同时管理多路I/O流。用以提高服务器的吞吐能力
select  select会修改传入的参数数组 任何sock状态改变，select只返回并不告诉是哪个sock状态改变，需要手动遍历 最高监听1024个sock连接； 线程不安全，如果在其他线程关闭sock会导致未知错误  poll  poll 修复很多select 问题， 不在修改参数数组；不在限制sock连接数量； poll 仍然线程不安全  epoll epoll 修复大多数select和poll问题， 线程安全， 并通知哪个sock状态改变；
epoll工作过程  epoll_create()系统调用。此调用返回一个句柄，之后所有的使用都依靠这个句柄来标识。 epoll_ctl()系统调用。通过此调用向epoll对象中添加、删除、修改事件，并注册回调函数，返回0标识成功，返回-1表示失败。 epoll_wait()系统调用。通过此调用收集收集在epoll监控中已经发生的事件。  epoll 内部工作原理  创建一个红黑树rbr， 用户存放添加到epoll中的监控事件； 创建双链表rdlist， 存放已触发的事件，返回给用户； 当监控事件被触发时，epoll会给每个事件创建epItem结构体，并使用内核回调函数ep_poll_callback将发生的事件添加到rdlist； 调用epoll_wait， 检查rdlist中是否有epItem；如果rdlist不为空， 则将事件复制到用户态， 并将事件数量返回给用户；  epoll 高效原理 </description>
    </item>
    
    <item>
      <title>制作linux系统服务</title>
      <link>https://zylhorse.github.io/blog/linux/ubuntu%E6%9C%8D%E5%8A%A1/</link>
      <pubDate>Thu, 08 Jan 2015 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/linux/ubuntu%E6%9C%8D%E5%8A%A1/</guid>
      <description>服务制作   在/etc/init.d/ 下以管理员权限新建文件，在本例中为location_server.
  使用以下模板修改启动脚本的内容
#!/bin/bash### BEGIN INIT INFO## Provides: location_server# Required-Start: $local_fs $remote_fs# Required-Stop: $local_fs $remote_fs# Default-Start: 2 3 4 5# Default-Stop: 0 1 6# Short-Description: initscript# Description: This file should be used to construct scripts to be placed in /etc/init.d.#### END INIT INFO## Fill in name of program here.PROG=&amp;quot;location_server&amp;quot;PROG_PATH=&amp;quot;/opt/location_server&amp;quot; ## Not need, but sometimes helpful (if $PROG resides in /opt for example).</description>
    </item>
    
    <item>
      <title>TCP-数据传输可靠性</title>
      <link>https://zylhorse.github.io/blog/network/tcp/%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3/</link>
      <pubDate>Sat, 06 Dec 2014 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/network/tcp/%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3/</guid>
      <description>TCP数据传输 面向字节流， 传输可靠， 面向连接
问题 网络数据不可靠， 丢包， 错包， 重复包， 乱序包；
滑动窗口 提高数据吞吐量， 传输数据块（包含多组数据）
滑动窗口本身可以看做是一个协议，适合于数据传输过程中要求有严格顺序处理的场景
滑动窗口将时间轴上的数据分成了4个部分:
 数据发送且被确认 数据发送但未被确认 数据能够被发送 数据不能发送，等待滑动窗口右移  TCP报文字段 win  报文中win用来描述窗口大小。 接收方窗口大小由接收方控制, 默认4096字节 如果窗口中有未来得及读取的数据， 则响应报文中的win就会减少 如果窗口中的数据被读取， 可能会出现携带ack 但不确认任何数据 而仅仅win变大的包， 这种情况用来更新窗口大小；  确保可靠性方式  校验和  数据发送时， 将数据段当作16位整数， 并将所有数据段相加。 且相加后的进位不丢弃，补到末位， 最后取反，得到校验和； 接收方收到数据后， 以同样方式计算校验和， 与发送方的进行对比；如果校验和不一致则数据传输一定有误。 但是校验和一致，数据传输不一定无误；   序列号  数据传输的每个数据段都进行了编号； 有了序列号， 就能对数据包进行排序和排重；   确认应答  数据传输的每次发送， 接收方都会进行应答， 即发送ack确认报文；   超时重传  基于序列号和确认应答机制，发送方都会等待接收方的ack确认报文。 如果发送方迟迟接收不到ack响应， 则会重新发送该报文，直到达到重传次数限制， 则认为tcp传输异常， 强制关闭； 超时的时间以500ms 为基准， 以指数方式增加； （第一次： 500ms， 第二次： 2*500ms &amp;hellip;);    </description>
    </item>
    
    <item>
      <title>TCP-IP连接限制</title>
      <link>https://zylhorse.github.io/blog/network/tcp/maxport/</link>
      <pubDate>Wed, 03 Dec 2014 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/network/tcp/maxport/</guid>
      <description>在一台系统上，连接到一个远程服务时的本地端口(local_addr)是有限的。根据TCP/IP协议，由于端口是16位整数，也就只能是0到 65535，而0到1023是预留端口， 所以能分配的端口只是1024到65534，也就是64511个。也就是说，一个IP只能创建六万多个长连接。</description>
    </item>
    
    <item>
      <title>TCP-握手和挥手</title>
      <link>https://zylhorse.github.io/blog/network/tcp/handshake/</link>
      <pubDate>Wed, 03 Dec 2014 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/network/tcp/handshake/</guid>
      <description>tcp 状态 tcp连接FLAGS字段表示当前连接状态，FLAGS包含一下几个标识：
 SYN表示建立连接 FIN表示关闭连接 ACK表示响应 PSH表示有 DATA数据传输 RST表示连接重置  三次握手 tcp建立连接的过程，需要三次握手；
 客户端打开连接，主动结束CLOSED阶段； 服务器连接，被动结束CLOSED阶段， 进入LISTEN阶段； 开始握手：   客户端向服务器发送tcp报文
1.1 标记位为SYN， 表示请求建立连接
1.2 序号seq=x (x一般为0)
1.3 客户端进入SYN-SENT 阶段
  服务器接收来自客户端的tcp报文，结束LISTEN阶段，并发送一段tcp报文
2.1 标志位为SYN和ACK， 表示确认客户端报文seq有效，同意创建连接
2.2 序号seq=y（y一般为0）， 确认号ack=x+1, 表示收到客户端序号seq并将其值加1作为自己的确认号ack的值
2.3 服务端进入SYN-RECVD阶段
  客户端接收来自服务器的确认报文后， 结束SYN-SENT阶段，并返回一段tcp报文
3.1 标志位为ACK， 表示确认收到服务器同意连接的信号；
3.2 序号seq=x+1， 表示收到服务器的确认号ack， 并将其作为自己的序号
3.3 确认号ack=y+1， 表示收到服务器的序号seq并将其值加1作为自己的确认号ack的值
3.4 客户端进入ESTABLISHED阶段
  服务器接收到来自客户端的确认报文后， 明确从服务器到客户端的数据传输时正常的
4.1 服务器结束SYN-RECVD阶段， 进入ESTABLISHED阶段
    为什么三次握手  防止服务器开启无用连接，增加服务器开销； 防止失效的请求连接报文传输到服务端， 产生错误；  四次挥手 tcp释放连接，需要四次挥手</description>
    </item>
    
    <item>
      <title>Scalar</title>
      <link>https://zylhorse.github.io/blog/software-programming/scalar/</link>
      <pubDate>Sat, 22 Nov 2014 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/software-programming/scalar/</guid>
      <description>标量(Scalar),在计算机领域用于区分单个值(整数/浮点数/字符串)与数据结构(数组/结构/map)区分开。</description>
    </item>
    
    <item>
      <title>Jmeter部署和配置</title>
      <link>https://zylhorse.github.io/blog/jmeter/%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/</link>
      <pubDate>Tue, 11 Nov 2014 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/jmeter/%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/</guid>
      <description>下载 地址
汉化 jmeter.properties =&amp;gt; language=zh_CN
websocket配置 下载jar包 jetty-http jetty-io jetty-util websocket-api websocket-client websocket-common</description>
    </item>
    
    <item>
      <title>mmap实现原理简述及使用场景</title>
      <link>https://zylhorse.github.io/blog/memory/mmap/</link>
      <pubDate>Fri, 10 Oct 2014 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/memory/mmap/</guid>
      <description>概念  mmap是一种文档映射到内存的方法； 将文件或其他对象映射到进程的内存地址空间；实现文件磁盘地址和进程虚拟地址空间的映射。 映射后， 进程就可以采用指针的方式读写操作这段内存。而系统会自动回写修改内容到磁盘文件中。 同样内核空间对这段内存的修改也会直接映射到用户空间， 从而实现不同进程间的文档共享。  内部原理 struct vm_area_struct {vm_endvm_startvm_protvm_flagsvm_next *vm_area_struct}linux 内核使用vm_area_struct结构来表示一个独立的虚拟内存区域。
工作流程 void *mmap(void *start, size_t length, int prot, int flags,int fd, off_t offset);int munmap( void * addr, size_t len ) int msync( void *addr, size_t len, int flags )优点  对文件的读取操作跨过了页缓存，减少了数据的拷贝次数，用内存读写取代I/O读写，提高了文件读取效率。 常规文件操作需要从磁盘到页缓存再到用户主存的两次数据拷贝 实现了用户空间和内核空间的高校交互；俩个空间的操作可以直接反映到映射的内存区域； 实现进程间共享内存进行通讯； 实现高效大规模数据传输，借助磁盘空间协助内存操作。  </description>
    </item>
    
    <item>
      <title>多类型I/O操作流程</title>
      <link>https://zylhorse.github.io/blog/concurrence/io/io/</link>
      <pubDate>Fri, 03 Oct 2014 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/concurrence/io/io/</guid>
      <description>I/O IO分为两个阶段：
 数据准备阶段 内核空间复制数据到用户进程缓冲区（用户空间）阶段  IO类型   阻塞IO 用户线程进行IO读写操作时发生阻塞，等待数据准备就绪
  非阻塞IO 用户线程进行IO读写操作时不阻塞，但是循环询问内核数据是否就绪
  多路复用IO
 轮询多个IO连接， 只有当真正的事件发生时，采取调用实际的IO操作； 轮询多个IO状态，发生在内核空间；    信号驱动IO
 用户线程发起sigaction 系统调用， 给socket注册信号函数后， 继续执行 内核数据准备就绪后，发送信号给用户线程 用户线程收到信号，再发起recvfrom系统调用，将数据复制到用户空间； 用户下线程操作数据；    异步IO
 用户线程发起aio_read 系统调用后继续执行 内核处理完IO操作，发送信号给用户线程 IO操作完成； 用户线程直接操作数据；    阻塞IO和非阻塞IO 区别在于第一步数据准备阶段是否阻塞；即IO请求是否阻塞；
同步IO和异步IO 区别在于第二部内核空间到用户空间进行数据拷贝都会阻塞用户线程；</description>
    </item>
    
    <item>
      <title>下载安装Visual Studio历史版本</title>
      <link>https://zylhorse.github.io/blog/windows/visual-studio/</link>
      <pubDate>Wed, 10 Sep 2014 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/windows/visual-studio/</guid>
      <description>下载安装 历史版本
2017 激活码   professional
KBJFW-NXHK6-W4WJM-CRMQB-G3CDH
  enterprise
NJVYC-BMHX2-G77MM-4XJMR-6Q8QF
  </description>
    </item>
    
    <item>
      <title>Windows系统配置CMD网络代理</title>
      <link>https://zylhorse.github.io/blog/windows/proxy/</link>
      <pubDate>Fri, 05 Sep 2014 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/windows/proxy/</guid>
      <description>cmd 设置代理 x:&amp;gt;netshnetsh&amp;gt;winhttpnetsh winhttp&amp;gt;netsh winhttp&amp;gt;set proxy 127.0.0.1:1080设置http\https代理 x:&amp;gt;set http_proxy=http://http.proxy.com:12345x:&amp;gt;set https_proxy=http://https.proxy.com:23456x:&amp;gt;set socks5_proxy=socks5://https.proxy.com:23456</description>
    </item>
    
    <item>
      <title>Bind-ubuntu部署配置</title>
      <link>https://zylhorse.github.io/blog/network/dns/bind/</link>
      <pubDate>Wed, 03 Sep 2014 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/network/dns/bind/</guid>
      <description>本文主要讲解bind部署以及配置应用。
docker部署  拉取镜像: docker pull sameersbn/bind:latest 启动容器: mkdir -p ~/bind \docker run --name=&#39;bind&#39; -d --restart=always -p 53:53/udp -p 10000:10000/tcp \-e WEBMIN_ENABLED=true \-v ~/bind:/data \sameersbn/bind:latest参数说明:  -p 53:53/udp DNS默认端口 -p 10000:1000 Webmin图形化管理页面端口 -e WEBMIN_ENABLED=true 开启图形化界面管理器 -v ~/bind:/data 配置DNS存储目录   备注: 确认53端口不被占用。ubuntu系统中容器启动前需要禁用system-resolved服务。 sudo systemctl disable systemd-resolvedsudo systemctl stop systemd-resolved
  检查服务端口状态  检查53端口 $ ss -lnupState Recv-Q Send-Q Local Address:Port Peer Address:Port Process UNCONN 0 0 0.</description>
    </item>
    
    <item>
      <title>Windows下Wireshark抓包问题</title>
      <link>https://zylhorse.github.io/blog/windows/%E6%9C%AC%E5%9C%B0%E6%8A%93%E5%8C%85/</link>
      <pubDate>Wed, 03 Sep 2014 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/windows/%E6%9C%AC%E5%9C%B0%E6%8A%93%E5%8C%85/</guid>
      <description>windows 本地抓包 在进行通信开发的过程中，我们往往会把本机既作为客户端又作为服务器端来调试代码，使得本机自己和自己通信。 但是wireshark此时是无法抓取到数据包的，需要通过简单的设置才可以。
具体方法如下：
  方法一
 以管理员身份运行cmd route add 本机ip mask 255.255.255.255 网关ip 如：route add 172.16.51.115 mask 255.255.255.255 172.16.1.1 使用完毕后用route delete 172.16.51.115 mask 255.255.255.255 172.16.1.1删除，否则所有本机报文都经过网卡出去走一圈回来很耗性能。 此时再利用wireshark进行抓包便可以抓到本机自己同自己的通信包，这样配置的原因是将发往本机的包发送到网关，而此时wireshark可以捕获到网卡驱动的报文实现抓包。   但这样有一个缺点，那就是本地请求的URL的IP只能写本地的IP地址，不能写localhost或127.0.0.1，写localhost或127.0.0.1还是抓不到包。
   方法二
windows系统没有提供本地回环网络的接口，用wireshark监控网络的话只能看到经过网卡的流量，看不到访问localhost的流量， 因为wireshark在windows系统上默认使用的是WinPcap来抓包的，现在可以用Npcap来替换掉WinPcap， Npcap是基于WinPcap 4.1.3开发的，api兼容WinPcap。
 下载安装包 Npcap项目主页，它采用的是MIT开源协议，Npcap下载 安装 安装时要勾选 Use DLT_NULL protocol sa Loopback &amp;hellip; 和 install npcap in winpcap api-compat mode，如下所示。    方法三
RawCap
  </description>
    </item>
    
    <item>
      <title>Ubuntu安装配置shadowsocks</title>
      <link>https://zylhorse.github.io/blog/linux/shadowsocks/shadowsocks/</link>
      <pubDate>Sat, 12 Jul 2014 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/linux/shadowsocks/shadowsocks/</guid>
      <description>ubuntu shadowsocks 描述 ubuntu 下 shadowssocks 安装
安装shadowsocks-libev $ sudo apt-get install software-properties-common -y $ sudo add-apt-repository ppa:max-c-lv/shadowsocks-libev -y $ sudo apt-get update $ sudo apt install shadowsocks-libev 编写配置文件 配置文件需要写入你的shadowsocks账号的信息，启动shadowsocks时需要加载这些信息，具体如下： 创建配置文件： $ sudo vi /etc/shadowsocks-libev.json 在配置文件中输入以下信息： { &amp;quot;server&amp;quot;:&amp;quot;XXXX服务器地址&amp;quot;, &amp;quot;server_port&amp;quot;:XXXX端口, &amp;quot;local_address&amp;quot;:&amp;quot;127.0.0.1&amp;quot;, &amp;quot;local_port&amp;quot;:1080, &amp;quot;password&amp;quot;:&amp;quot;XXXX密码&amp;quot;, &amp;quot;timeout&amp;quot;:60, &amp;quot;method&amp;quot;:&amp;quot;chacha20-ietf-poly1305&amp;quot;, &amp;quot;fast_open&amp;quot;:false, &amp;quot;workers&amp;quot;:1 }  XXXX需要改成你的账号对应的具体信息，method就是加密方式，这里就是chacha20-ietf-poly1305,这个要看你的账号具体要求的加密方式。
 运行shadowsocks $ ss-local -c /etc/shadowsocks-libev.json &amp;amp;  其中 &amp;amp;是将其放在后台运行
 设置全局代理 进入 系统设置 -&amp;gt; 网络 -&amp;gt; 网络代理，方法选择手动，然后设置Socks主机127.0.0.1， 后面端口这是1080， 然后点击应用到整个系统，输入密码即可。
 缺点： 这样你使用的网络都是通过代理访问的，比如说我在登录微信的时候，居然提示我在未知地点登录，这样比较浪费流量，访问国内网络也使用代理，会导致访问国内网络网速较慢。所以可以使用浏览器代理，只在浏览器访问中使用代理。</description>
    </item>
    
    <item>
      <title>Ubuntu安装配置v2ray</title>
      <link>https://zylhorse.github.io/blog/linux/shadowsocks/v2raya/</link>
      <pubDate>Sat, 12 Jul 2014 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/linux/shadowsocks/v2raya/</guid>
      <description>从软件源安装  debian/ubuntu 请确保已正确安装 v2ray-core
我们提供了 Linux 下的一键安装脚本：
 运行下面的指令下载并安装 V2Ray。当 yum 或 apt-get 可用的情况下，此脚本会自动安装 unzip 和 daemon。 这两个组件是安装 V2Ray 的必要组件。如果你使用的系统不支持 yum 或 apt-get，请自行安装 unzip 和 daemon
 # download scriptcurl -O https://cdn.jsdelivr.net/gh/v2rayA/v2rayA@master/install/go.sh# install v2ray-core from jsdelivrsudo bash go.sh准备完毕后：
# add public keywget -qO - https://raw.fastgit.org/v2rayA/v2raya-apt/master/key/public-key.asc | sudo apt-key add -# add V2RayA&#39;s repositoryecho &amp;quot;deb https://raw.fastgit.org/v2rayA/v2raya-apt/master/ v2raya main&amp;quot; | sudo tee /etc/apt/sources.list.d/v2raya.listsudo apt update# install V2RayAsudo apt install v2raya部署完毕后，访问该机器的2017端口即可使用，如http://localhost:2017。</description>
    </item>
    
    <item>
      <title>VMWare之Linux系统磁盘扩容</title>
      <link>https://zylhorse.github.io/blog/vmware/vmware-ubuntu-%E6%89%A9%E5%AE%B9%E7%A3%81%E7%9B%98/</link>
      <pubDate>Fri, 11 Jul 2014 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/vmware/vmware-ubuntu-%E6%89%A9%E5%AE%B9%E7%A3%81%E7%9B%98/</guid>
      <description>在VMWARE中扩容虚拟机磁盘大小 需要删除快照， 最好先克隆备份；
查看扩容磁盘 调整完后，重新打开虚拟机，使用fdisk -l查看，可以看到我们刚刚扩容的空间已经可以看到，但没有分区，还不能使用。/dev/sda已经拥有了扩大的空间。
分区 使用Linux的fdisk分区工具给磁盘/dev/sda分区，更可以根据提示输入m查看帮助信息，再输入n(表示增加分区)，回车后输入p(创建主分区)， 回车后partition number输入3(因为上面已经有两个分区sda1和sda2)，回车会提示输入分区的start值(通过fdisk -l 可以看出sda2的end值为3917)， 我们可以根据提示指定start值为3917，end值为默认即可(即当前最大值)，回车后输入W进行保存，分区划分完毕。
修改分区ID 可以看到/dev/sda3的Id号为83，我们要将其改成8e(LVM卷文件系统的Id)，具体方法同上根上部中的磁盘分区大同小异，输入fdisk /dev/sda, 选择t(change a partition&#39;s system id 改变一个分区的系统ID)回车，然后选择分区3回车，然后输入L回车。然后输入8e回车，然后输入w，保存修改的分区信息。 最后输入fdisk -l ,查看ID是否修改成功。修改成功后必须重新启动linux系统才能进行后面的操作。
格式化分区 系统重启后，格式化新的分区为ext4格式。
初始化物理卷 格式化后，创建PV. 用pvdisplay查看当前的物理卷。然后用pvcreate指令用于将物理硬盘分区初始化为物理卷，以便被LVM使用。 要创建物理卷必须首先对硬盘进行分区，并且将硬盘分区的类型设置为8e后，才能使用pvcreat指令将分区初始化为物理卷。pvcreate /dev/sda3,创建完后， 我们可以再用pvdisplay查看到新创建的物理卷。
扩展VG 扩展VG：当前需要查看扩充的lvm组名，可以通过vgdisplay查看，在此例中我们的组名为 VolGroup,并可以看到里面的空间只有20多G。 然后用vgextend指令用于动态的扩展卷组，它通过向卷组中添加物理卷来增加卷组的容量。vgextend VolGroup /dev/sda3,添加成功后， 我们可以用vgdisplay再次查看，容量已经添加进去。
扩容root lvextend -L+269.95G /dev/VolGroup/lv_root /dev/sda3命令扩展空间到root下，扩容的空间要略小于VG的free空间，因此这里只输入了269.95G. 然后通过df -h查看，root空间还是没变，因为我们差最后最关键的一部。
扩容文件系统 使用使用resize2fs命令，用于扩大或者缩小未挂载的ext2,ext3或者是ext4文件系统。具体命令为：resize2fs -p /dev/mapper/VolGroup-lv_root 290G 。 然后再用df -h查看，扩容成功。</description>
    </item>
    
    <item>
      <title>Ubuntu安装配置无线网卡</title>
      <link>https://zylhorse.github.io/blog/linux/ubuntu-wlan/</link>
      <pubDate>Wed, 11 Jun 2014 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/linux/ubuntu-wlan/</guid>
      <description>查看所有网络 $ ifconfig -a
打开无线网卡 $ ifconfig wlan0 up
wlan 工具 $ apt-get install wpasupplicant
连接无线网络 wpa_passphrase 无线网络SSID无线网络密码 &amp;gt; 配置文件名
配置无线网络  $ auto wlan0 $ iface wlan0 inet dhcp $ wpa-conf /etc/wpa_config.conf  修改网卡名称   $ vim /etc/default/grubGRUB_CMDLINE_LINUX=&amp;quot;net.ifnames=0 biosdevname=0&amp;quot; $ update-grub  若提示没有此命令，请先输入安装命令 $ apt-get install grub2-common</description>
    </item>
    
    <item>
      <title>Linux Shell 常用命令记录</title>
      <link>https://zylhorse.github.io/blog/linux/shell/</link>
      <pubDate>Sun, 08 Jun 2014 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/linux/shell/</guid>
      <description>命令 grep 作用: 查询匹配条件的文件
使用: grep [OPTION]... PATTERN [FILE]...
OPTION: -r #递归查询目录-n #打印匹配行号-l #打印匹配文件-L #打印不匹配文件-c #打印匹配数量-I #过滤二进制文件 --binary-files=without-match-a #只查询文本文件 --binary-files=text--binary-files=Type # Type: binary,text,without-matchsed 作用: 替换文本内容
使用: sed [OPTION]... {script-only-if-no-other-script} [input-file]...
OPTION:-e # 使用脚本处理文本内容-i # 直接将处理结果写入文件script:a # 在下一行增加内容c # 替换当前行内容d # 删除当前行内容i # 在上一行增加内容s # 替换匹配内容示例   查找目录下所有包含查找内容的文件
$ grep -rnI &amp;quot;查找内容&amp;quot; ./  替换新的内容到目录下所有包含查找内容的文件</description>
    </item>
    
    <item>
      <title>记录linux常规问题和解决方案</title>
      <link>https://zylhorse.github.io/blog/linux/%E5%B8%B8%E8%A7%84%E9%97%AE%E9%A2%98/</link>
      <pubDate>Sun, 08 Jun 2014 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/linux/%E5%B8%B8%E8%A7%84%E9%97%AE%E9%A2%98/</guid>
      <description>Ubuntu国内源 清华大学 https://mirrors.tuna.tsinghua.edu.cn/help/ubuntu/
问题：
ubuntu:~$ sudo apt update Ign:1 https://mirrors.tuna.tsinghua.edu.cn/ubuntu bionic InRelease Ign:2 https://mirrors.tuna.tsinghua.edu.cn/ubuntu bionic-updates InRelease Ign:3 https://mirrors.tuna.tsinghua.edu.cn/ubuntu bionic-backports InRelease Hit:4 https://apt.releases.hashicorp.com bionic InRelease Ign:5 https://mirrors.tuna.tsinghua.edu.cn/ubuntu bionic-security InRelease Err:6 https://mirrors.tuna.tsinghua.edu.cn/ubuntu bionic ReleaseCertificate verification failed: The certificate is NOT trusted. The certificate chain uses expired certificate. Could not handshake: Error in the certificate verification. [IP: 101.6.15.130 443]Err:7 https://mirrors.tuna.tsinghua.edu.cn/ubuntu bionic-updates ReleaseCertificate verification failed: The certificate is NOT trusted. The certificate chain uses expired certificate.</description>
    </item>
    
    <item>
      <title>常用的正则表达式</title>
      <link>https://zylhorse.github.io/blog/regexp/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/</link>
      <pubDate>Sat, 03 May 2014 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/regexp/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/</guid>
      <description>语法 替换文件名中非法字符 #include &amp;lt;regex&amp;gt;string fname = regex_replace(filename, &amp;quot;[\\s\\\\/:\\*\\?\\\&amp;quot;&amp;lt;&amp;gt;\\|]&amp;quot;, &amp;quot;&amp;quot;)用户名合法性  字母数字开头，字母数字@.-_组成
 ^[A-Za-z0-9][A-Za-z0-9.@-_]{3,32}$</description>
    </item>
    
    <item>
      <title>Makefile是怎样让make工作的</title>
      <link>https://zylhorse.github.io/blog/compilation/makefile/</link>
      <pubDate>Sat, 26 Apr 2014 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/compilation/makefile/</guid>
      <description>make版本 GNU make 3.8.1
Makefile文件告诉make命令怎样去编译和链接程序
Makefile的规则 target ... : prerequisites ...command... target就是一个目标文件，可以是中间文件，也可以时目标文件。 prerequisites就是生成target所依赖的文件 command就是make需要执行的命令  一个例子 edit : main.o kbd.o command.o display.o \insert.o search.o files.o utils.occ -o edit main.o kbd.o command.o display.o \insert.o search.o files.o utils.omain.o : main.c defs.hcc -c main.ckbd.o : kbd.c defs.h command.hcc -c kbd.ccommand.o : command.c defs.h command.hcc -c command.cdisplay.o : display.c defs.h buffer.hcc -c display.</description>
    </item>
    
    <item>
      <title>常见的开源许可协议和注意事项</title>
      <link>https://zylhorse.github.io/blog/software-programming/%E5%BC%80%E6%BA%90%E8%AE%B8%E5%8F%AF%E5%8D%8F%E8%AE%AE/</link>
      <pubDate>Fri, 11 Apr 2014 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/software-programming/%E5%BC%80%E6%BA%90%E8%AE%B8%E5%8F%AF%E5%8D%8F%E8%AE%AE/</guid>
      <description>GPL(GNU General Public License) GPL 出发点是代码的开源/免费使用和引用/修改/衍生代码的开源/免费使用， 不允许修改/衍生后的代码作为商业软件发布和销售。 代表： linux
BSD BSD开源协议允许自由的使用/修改源代码， 也可以将修改后的代码作为开源/专有软件发布。但是要满足三个条件：
 源码发布，需要在源码中携带原有代码的BSD协议 类库/软件发布， 需要在类库/软件的文档和版权声明中包含原有代码的BSD协议 不可以使用开源代码的作者/机构名字做市场推广  Apache license 2.0 类似BSD协议,Apache license 是对商业应用友好的许可
MIT 类似BSD协议,必须在修改/衍生的代码中保留原许可协议的声明。</description>
    </item>
    
    <item>
      <title>Windows中文件的最新图标刷新不出来问题</title>
      <link>https://zylhorse.github.io/blog/windows/%E6%B8%85%E7%90%86%E7%B3%BB%E7%BB%9F%E7%BC%93%E5%AD%98%E5%9B%BE%E6%A0%87/</link>
      <pubDate>Sat, 15 Mar 2014 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/windows/%E6%B8%85%E7%90%86%E7%B3%BB%E7%BB%9F%E7%BC%93%E5%AD%98%E5%9B%BE%E6%A0%87/</guid>
      <description>磁盘上的图片被覆盖后文件预览还是旧的 reseticon.bat
//rem 关闭Windows外壳程序explorertaskkill /f /im explorer.exe//rem 清理系统图标缓存数据库attrib -h -s -r &amp;quot;%userprofile%AppDataLocalIconCache.db&amp;quot;del /f &amp;quot;%userprofile%AppDataLocalIconCache.db&amp;quot;attrib /s /d -h -s -r &amp;quot;%userprofile%AppDataLocalMicrosoftWindowsExplorer*&amp;quot;del /f &amp;quot;%userprofile%AppDataLocalMicrosoftWindowsExplorerthumbcache_32.db&amp;quot;del /f &amp;quot;%userprofile%AppDataLocalMicrosoftWindowsExplorerthumbcache_96.db&amp;quot;del /f &amp;quot;%userprofile%AppDataLocalMicrosoftWindowsExplorerthumbcache_102.db&amp;quot;del /f &amp;quot;%userprofile%AppDataLocalMicrosoftWindowsExplorerthumbcache_256.db&amp;quot;del /f &amp;quot;%userprofile%AppDataLocalMicrosoftWindowsExplorerthumbcache_1024.db&amp;quot;del /f &amp;quot;%userprofile%AppDataLocalMicrosoftWindowsExplorerthumbcache_idx.db&amp;quot;del /f &amp;quot;%userprofile%AppDataLocalMicrosoftWindowsExplorerthumbcache_sr.db&amp;quot;//rem 清理 系统托盘记忆的图标echo y|reg delete &amp;quot;HKEY_CLASSES_ROOTLocal SettingsSoftwareMicrosoftWindowsCurrentVersionTrayNotify&amp;quot; /v IconStreamsecho y|reg delete &amp;quot;HKEY_CLASSES_ROOTLocal SettingsSoftwareMicrosoftWindowsCurrentVersionTrayNotify&amp;quot; /v PastIconsStream//rem 重启Windows外壳程序explorerstart explorer</description>
    </item>
    
    <item>
      <title>linux磁盘管理和lvm磁盘扩容</title>
      <link>https://zylhorse.github.io/blog/linux/%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86/</link>
      <pubDate>Tue, 11 Mar 2014 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/linux/%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86/</guid>
      <description>reference
磁盘管理 硬盘分区 | Hard disk add new partition   显示硬盘及所属分区情况。在终端窗口中输入如下命令： $ sudo fdisk -l
 显示当前的硬盘及所属分区的情况。 系统提示：DIsk /dev/sdb doesn&amp;rsquo;t contain a valid partition table。 如图所示    对硬盘进行分区。在终端窗口中输入如下命令： $ sudo fdisk /dev/sdb
 在Command (m for help)提示符后面输入m显示一个帮助菜单， 如图所示。 在Command (m for help)提示符后面输入n，执行 add a new partition指令给硬盘增加一个新分区。 出现Command action时，输入e，指定分区为扩展分区（extended）。 出现Partition number(1-4)时，输入１表示只分一个区。 后续指定起启柱面（cylinder）号完成分区, 如图所示。    在Command (m for help)提示符后面输入p，显示分区表。
 系统提示如图所示：  Device Boot Start End Blocks Id System/dev/sdb1 1 26108 209712478+ 5 Extended  在Command (m for help)提示符后面输入w，保存分区表。</description>
    </item>
    
    <item>
      <title>ubutnu本地安装实操</title>
      <link>https://zylhorse.github.io/blog/linux/ubuntu%E5%AE%89%E8%A3%85/</link>
      <pubDate>Tue, 11 Mar 2014 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/linux/ubuntu%E5%AE%89%E8%A3%85/</guid>
      <description>ubuntu U盘安装 遇到类似加载镜像文件问题，最简单粗暴的解决方案就是把挂载ubuntu server镜像文件至cdrom目录
具体步骤如下：
  复制安装镜像至U盘
  进入ubuntu控制台，可以直接通过Alt+F2进入终端环境
  查看u盘设备号 通过命令：ls /dev/sd*
查看U盘设备，通常U盘设备为sdb,sdc,sdd等名称或以此为前缀名称。
 如果不确定，可以将U盘拔出，然后再用 ls /dev/sd*命令查看设备，发现少了的那个就是U盘。 但一般情况下，再次插入，U盘设备号会有所改变，例如原来是sdb4，重新插入，查看一下可能是sdb5，以最后插入查看的设备号为准。    查看到U盘设备号后，卸载设备，如下：
umount /dev/sdb4 #sdb4就是当前查看得到U盘设备  重新挂载U盘,可以创建一个目录，然后将U盘挂载至新建目录，目的是为了找到U盘里的ubuntu server安装镜像文件，操作命令如下：
mkdir /mnt/usbmount /dev/sdb4 /mnt/usb # 将U盘挂载到该目录下  挂载ubuntu server安装镜像文件至cdrom目录, 进入U盘目录(/mnt/usb )，找到ubuntu server安装镜像文件，并挂载镜像，操作参考如下：
cd /mnt/usbmount ubuntu-16.04.4-server-amd64.iso /cdrom #挂载镜像文件位于U盘根目录  退出shell，进入安装向导界面安装系统。可以通过Alt+F1或者输入exit退出shell
  </description>
    </item>
    
    <item>
      <title>Ubuntu升级指定版本nginx</title>
      <link>https://zylhorse.github.io/blog/nginx/%E5%8D%87%E7%BA%A7/</link>
      <pubDate>Mon, 10 Mar 2014 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/nginx/%E5%8D%87%E7%BA%A7/</guid>
      <description> 添加nginx apt-key $ wget http://nginx.org/keys/nginx_signing.key $ sudo apt-key add nginx_signing.key 将下面内容中codename替换为 Ubuntu版本号(点击查看)，并将以下代码附加到/etc/apt/sources.list文件末尾： deb http://nginx.org/packages/ubuntu/ codename nginx deb-src http://nginx.org/packages/ubuntu/ codename nginx 安装和升级 $ sudo apt-get update$ sudo apt-get install nginx  </description>
    </item>
    
    <item>
      <title>git工作原理、常用命令、常见问题及解决方案</title>
      <link>https://zylhorse.github.io/blog/github/git/</link>
      <pubDate>Tue, 28 Jan 2014 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/github/git/</guid>
      <description>git 使用方法 创建commit tag git tag -a &amp;lt;tagname&amp;gt; &amp;lt;commitId&amp;gt; -m &amp;quot;&amp;lt;备注信息&amp;gt;&amp;quot;git push origin &amp;lt;tagname&amp;gt;创建commit branch git branch  
创建tag branch tag名称和branch名称不能相同git checkout -b &amp;lt;branchname&amp;gt; &amp;lt;tagname&amp;gt;删除tag git tag -d &amp;lt;tagname&amp;gt;git push origin :&amp;lt;tagname&amp;gt;删除错误合并 git reset --hard merge前的版本号记住用户名密码 git config --global credential.helper store
修改tag名 新版本： v2.2.2
错误版本： v0.0.0
git tag v2.2.2 v0.0.0 git tag -d v0.0.0git push origin :refs/tags/v0.0.0git push --tags问题 游离版本解决方案（HEAD detached from）  git branch -v //查询最后一次提交版本 git branch temp //创建临时分支 git checkout xxx // 切换到要回去的分支 git merge temp //合并临时分支 git push // 推送 git branch -d temp // 删除临时分支  github 图片加载问题 修改hosts文件,在C:\Windows\System32\drivers\etc\hosts 文件中添加以下内容:</description>
    </item>
    
    <item>
      <title>从每层协议及物理设备了解网络模型</title>
      <link>https://zylhorse.github.io/blog/network/%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/</link>
      <pubDate>Mon, 16 Dec 2013 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/network/%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/</guid>
      <description>OSI七层模型  物理层Physical： IEEE 802.1A、IEEE 802.2、IEEE 802.11 物理链路层Data Link: FDDI、Ethernet、Arpanet、PDN、SLP、PPP 网络层Network：IP、ICMP、ARP、RARP、AKP、UUCP 传输层Transport：TCP、UDP 会话层Session：SMTP、DNS 表示层Presentation：Telnet、rlogin、SNMP、Gopher 应用层Application：TFTP、FTP、NFS、WAIS、HTTP  TCP/IP 五层模型  物理层：中继器，集线器 数据链路层： 二层交换机 网络层： 路由器，三层交换机 传输层： 四层交换机 应用层  </description>
    </item>
    
    <item>
      <title>Nginx配置ssl证书</title>
      <link>https://zylhorse.github.io/blog/nginx/%E8%AF%81%E4%B9%A6%E9%85%8D%E7%BD%AE/</link>
      <pubDate>Wed, 11 Dec 2013 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/nginx/%E8%AF%81%E4%B9%A6%E9%85%8D%E7%BD%AE/</guid>
      <description>  nginx 配置
$ vim /etc/nginx/config.dlisten 443 ssl;listen [::]:443 ssl;ssl_certificate /etc/nginx/fullchain1.pem;ssl_certificate_key /etc/nginx/privkey1.pem;  配置生效 $ nginx -s reload
  </description>
    </item>
    
    <item>
      <title>软件设计模式详解和代码示例</title>
      <link>https://zylhorse.github.io/blog/software-programming/%E8%BD%AF%E4%BB%B6%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/</link>
      <pubDate>Sun, 01 Dec 2013 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/software-programming/%E8%BD%AF%E4%BB%B6%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/</guid>
      <description>概念 设计模式是在面向对象开发设计中反复出现问题的解决方案的总结。
设计原则  对接口编程而不是对实现编程 优先使用对象编程而不是继承  设计模式原则  针对接口编程而不是对实现编程 优先使用对象组合而不是继承  开闭原则（Open Close Principle）  对扩展开放， 对修改关闭 为使程序的扩展性好，易于维护和升级， 在程序需要进行扩展的时候，不去修改原有代码，使用接口和抽象类。  里氏代换原则（Liskov Substitution Principle）  任何基类可以出现的地方， 子类都可以出现。 只有当派生类可以替换掉基类，且软件的功能不受影响时， 基类才是真正被复用，而派生类也能够在基类的基础上增加新的行为。 里氏代换原则是对开闭原则的补充  依赖倒转原则（Dependence Inversion Principle）  针对接口编程，依赖于抽象而不依赖于具体 依赖倒转原则是开闭原则的基础  接口隔离原则（Interface Segregation Principle）  使用多个隔离的接口，比使用单个接口要好。降低类之间的耦合  迪米特原则，又称最少知道原则（Demeter Principle）  一个实体应当尽量地减少与其他实体之间发生相互作用， 使得系统模块相对独立  合成复用原则（Composite Reuse Principle）  尽量使用合成/聚合的方式，而不是使用继承  </description>
    </item>
    
    <item>
      <title>编译器为什么要对代码做自动优化</title>
      <link>https://zylhorse.github.io/blog/compilation/%E7%BC%96%E8%AF%91%E4%BC%98%E5%8C%96/</link>
      <pubDate>Thu, 07 Nov 2013 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/compilation/%E7%BC%96%E8%AF%91%E4%BC%98%E5%8C%96/</guid>
      <description>概括  高级编程语言提供的函数、条件语句、循环这样的抽象编程结构极大的提高了编程效率，然而，这也潜在的使性能显著下降。 编译器尝试自动优化代码以提高性能，编译器可以转化循环、条件语句和递归函数、消除代码快和利用目标指令集的优势让代码变得高效而简洁。 因此对于程序员来说写出可读性高的代码比手动优化后变得神秘而难以维护更加可贵。事实上手工优化的代码可能让编译器难以进行额外和更加有效的优化。 比起手动优化代码，程序员更应该考虑程序设计的各个方面，比如使用更快算法，引入线程级并行机制和框架特性。  </description>
    </item>
    
    <item>
      <title>内存溢出的场景及解决方案</title>
      <link>https://zylhorse.github.io/blog/memory/%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA/</link>
      <pubDate>Sun, 03 Nov 2013 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/memory/%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA/</guid>
      <description>栈溢出 压栈内存超出系统上限，导致溢出
 函数递归调用层次较深 局部变量体积过大  解决办法  将递归使用循环语句实现 进行尾递归优化： 这样执行的递归函数指挥占用一个栈帧，不会引起栈溢出 增加系统对进程栈分配大小 使用堆内存， 使用全局变量  尾递归  仅在函数的尾位置调用自身 通过优化，使得计算仅占产量栈空间；  常规递归：function fact(n) {if (n &amp;lt;= 0) {return 1;} else {return n * fact(n - 1);}}展开： 6 * fact(5)6 * (5 * fact(4))6 * (5 * (4 * fact(3))))// two thousand years later...6 * (5 * (4 * (3 * (2 * (1 * 1)))))) // &amp;lt;= 最终的展开尾递归：function fact(n, r) {if (n &amp;lt;= 0) {return 1 * r;} else {return fact(n - 1, r * n);}}展开：fact(6, 1) // 1 是 fact(0) 的值，我们需要手动写一下fact(5, 6)fact(4, 30)fact(3, 120)fact(2, 360)fact(1, 720)720 // &amp;lt;= 最终的结果堆溢出 用户动态分配内存，超出系统内存管理器限制。</description>
    </item>
    
    <item>
      <title>struct为什么会有字节对齐这个概念</title>
      <link>https://zylhorse.github.io/blog/compilation/%E5%86%85%E5%AD%98%E5%AF%B9%E9%BD%90/</link>
      <pubDate>Sun, 13 Oct 2013 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/compilation/%E5%86%85%E5%AD%98%E5%AF%B9%E9%BD%90/</guid>
      <description>结构体struct  struct 是一种复合数据类型， 它是由基本数据类型组合而成(char, int, float, ...) 编译器将struct中的成员按其alignment分配空间，各个成员在内存中顺序存储 struct中的第一个成员地址为struct的首地址 struct中的每个成员地址具有对齐的特性，如int32其起始地址应该为4的倍数  字节对齐  计算机内存空间按照byte划分 各种类型数据按照规则在内存空间上排列，数据只能从特定的内存地址进行存取  为什么  某些cpu在访问没有进行对齐的变量时，会报错。比如oracle sparc系统 比较常见的没有字节对齐，会损失数据的存取效率。  大部分平台读内存都是从偶地址开始 如果int32存放在偶地址，则一个读周期就可以读出数据 如果放在奇地址，则需要2个读周期    规则  基本类型自身的对齐值  char 1byte short 2byte int/float/double 等 4byte   结构体对齐值 为其成员中对齐值最大的那个 指定/取消对齐值  指定：  #pragma pack (value) __attribute__ ((__packed__))   取消: #pragma pack ()    代码示例 struct A{int a;char b;short c;};struct B{char b;int a;short c;};#pragma pack (2)struct C{char b;int a;short c;};#pragma pack ()#pragma pack (1)struct D{char b;int a;short c;};#pragma pack ()结果是:sizeof(strcut A)值为8sizeof(struct B)的值却是12sizeof(struct C)值是8。sizeof(struct D)值为7。</description>
    </item>
    
    <item>
      <title>十封信</title>
      <link>https://zylhorse.github.io/blog/stories/%E5%8D%81%E5%B0%81%E4%BF%A1/</link>
      <pubDate>Thu, 10 Oct 2013 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/stories/%E5%8D%81%E5%B0%81%E4%BF%A1/</guid>
      <description>《第一封》 写给你
假如人生不曾相遇，我还是那个我，偶尔做做梦，然后，开始日复一日的奔波，淹没在这喧嚣的城市里。我不会了解，这个世界还有这样的一个你，让人回味，令我心醉。假如人生不曾相遇，我不会相信，有一种人一认识就觉得温馨，有一种人可以百看不厌。
《第二封》 写给幸福
一直以为幸福在远方，在可以追逐的未来。后来才发现，那些拥抱过的人，握过的手、唱过的歌、流过的泪、爱过的人、所谓的曾经，就是幸福。在无数的夜里，说过的话、打过的电话，看过的电影、流过的眼泪……看见的或看不见的感动，我们都曾经有过，然后在时间的穿梭中，一切成为了永恒！
《第三封》 写给努力
不要抱怨你没有一个好爸爸，不要抱怨你的工作差，不要抱怨怀才不遇无人赏识。现实有太多的不如意，就算生活给你的是垃圾，你同样能把垃圾踩在脚底下登上世界之巅。这个世界只在乎你是否在到达了一定的高度，而不在乎你是踩在巨人的肩膀上上去的，还是踩在垃圾上上去的。
《第四封》 写给修为
看别人不顺眼，是自己修养不够。人愤怒的那一瞬间，智商是零，过一分钟后恢复正常。人的优雅关键在于控制自己的情绪，用嘴伤害人，是最愚蠢的一种行为。
《第五封》 写给了解
有个懂你的人，是最大的幸福。这个人，不一定十全十美，但他能读懂你，能走进你的心灵深处，能看懂你心里的一切。最懂你的人，总是会一直的在你身边，默默守护你，不让你受一点点的委屈。真正爱你的人不会说许多爱你的话，却会做许多爱你的事。
《第六封》 写给独自
一个人久了，会感觉朋友越来越重要；一个人久了，会越来越喜欢在家听歌；一个人久了，就变得成熟起来，会比以前越来越爱父母；一个人久了，会独自去很多很远的地方旅游；一个人久了，就不经意悄悄流泪，但会在众人面前什么都无所谓。
《第七封》 写给宿命
每一段记忆，都有一个密码。只要时间，地点，人物组合正确，无论尘封多久，那人那景都将在遗忘中重新拾起。你也许会说“不是都过去了吗？” 其实过去的只是时间，你依然逃不出，想起了就微笑或悲伤的宿命，那种宿命本叫“无能为力” 。
《第八封》 写给成长
有时候，莫名的心情不好，不想和任何人说话，只想一个人静静的发呆。有时候，想一个人躲起来脆弱，不愿别人看到自己的伤口。有时候，走过熟悉的街角，看到熟悉的背影，突然想起一个人的脸。有时候，别人误解了自己有口无心的话，心里郁闷的发慌。有时候，发现自己一夜之间就长大了。
《第九封》 写给来生
如果有来生，要做一棵树，站成永恒，没有悲欢的姿势。一半在土里安详，一半在风里飞扬，一半洒落阴凉，一半沐浴阳光，非常沉默非常骄傲，不依靠不寻找。
《第十封》 写给本真
身边总有些人，你看见她整天都开心，率真得像个小孩，人人都羡慕她；其实，你哪里知道：前一秒人后还伤心地流着泪的她，后一秒人前即刻洋溢灿烂。他们就像向日葵，向着太阳的正面永远明媚鲜亮，在照不到的背面却将悲伤深藏。
　亲爱的，请好好善待自己，一辈子不长！</description>
    </item>
    
    <item>
      <title>高级语言编译类型</title>
      <link>https://zylhorse.github.io/blog/compilation/%E7%BC%96%E8%AF%91%E7%B1%BB%E5%9E%8B/</link>
      <pubDate>Fri, 04 Oct 2013 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/compilation/%E7%BC%96%E8%AF%91%E7%B1%BB%E5%9E%8B/</guid>
      <description>概述 高级语言所编制的程序不能直接被计算机识别，必须经过转换才能被执行
类型  静态编译（static compilation）  静态编译的程序在执行前全部被翻译成机器码。   解释型（interpretation）  解释型的程序在执行时一句一句的解释执行。   即时编译（Just-in-time compilation）  又称动态翻译，混合static compilation 和 interpretation，运行时将中间码转换成机器码编译。 JIT 首先是compilation，对代码有优化，某个函数或者任意代码第一次调用时进行编译并cache，再次遇到该函数时直接从cache中执行已经编译好的机器码，也不用像interpretation一样对代码重复解释。    </description>
    </item>
    
    <item>
      <title>linux系统信号</title>
      <link>https://zylhorse.github.io/blog/linux/%E7%B3%BB%E7%BB%9F%E4%BF%A1%E5%8F%B7/</link>
      <pubDate>Sun, 22 Sep 2013 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/linux/%E7%B3%BB%E7%BB%9F%E4%BF%A1%E5%8F%B7/</guid>
      <description>信号列表   SIGHUP
本信号在用户终端连接(正常或非正常)结束时发出, 通常是在终端的控制进程结束时, 通知同一 session 内的各个作业, 这时它们与控制终端不再关联。 登录 Linux 时，系统会分配给登录用户一个终端( Session )。在这个终端运行的所有程序，包括前台进程组和后台进程组，一般都属于这个 Session 。 当用户退出 Linux 登录时，前台进程组和后台有对终端输出的进程将会收到 SIGHUP 信号。这个信号的默认操作为终止进程，因此前台进程组和后台有终端输出的进程就会中止。 不过可以捕获这个信号，比如 wget 能捕获 SIGHUP 信号，并忽略它，这样就算退出了Linux 登录，wget 也能继续下载。 此外，对于与终端脱离关系的守护进程，这个信号用于通知它重新读取配置文件。
  SIGINT
程序终止( interrupt )信号, 在用户键入 INTR 字符(通常是 Ctrl + C )时发出，用于通知前台进程组终止进程。
  SIGQUIT
和 SIGINT 类似, 但由 QUIT 字符(通常是 Ctrl + / )来控制. 进程在因收到 SIGQUIT 退出时会产生 core 文件, 在这个意义上类似于一个程序错误信号。
  SIGILL
执行了非法指令. 通常是因为可执行文件本身出现错误, 或者试图执行数据段. 堆栈溢出时也有可能产生这个信号。
  SIGTRAP</description>
    </item>
    
    <item>
      <title>进程启动后怎样申请和分配内存空间</title>
      <link>https://zylhorse.github.io/blog/compilation/%E8%BF%9B%E7%A8%8B%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D/</link>
      <pubDate>Mon, 02 Sep 2013 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/compilation/%E8%BF%9B%E7%A8%8B%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D/</guid>
      <description>栈区 stack 由编译器自动分配和释放， 存放程序运行时函数分配的局部变量、函数参数、返回数据等。操作类似数据结构中的栈。
堆区 heap 由程序分配和手动释放。 如果程序没有主动释放，程序结束后OS回收。 分配类似于数据结构中的链表
全局区 存放全局变量、静态数据。程序结束由OS回收。 分为已初始化全局区（data）和未初始化全局区（bss）
常量区 存放常量字符串。程序结束后由OS回收
代码区 存放函数体的二进制代码
堆栈区别 申请  栈： 只要系统栈内存空间大于申请空间， 系统将为程序提供内存，否则报异常提示栈溢出； 堆： 操作系统会记录空闲内存地址的链表， 系统收到程序的申请时遍历该链表，找到大于申请空间的堆节点，将其从量表删除并分配给程序同时在该内存空间的首地址标记大小用于delete。 另外由于分配的空间不一定正好等于申请的空间大小， 系统会自动将多余的空间重新放入空闲内存地址列表；  大小限制  栈： 是向低地址扩展的数据结构， 是一块连续的内存区域。栈顶地址和栈的容量由系统预先设定。 堆： 是向高地址扩展的数据结构， 是不连续的内存区域。堆大小受限于计算机系统中有效的虚拟内存。  申请效率  栈： 由系统自动分配， 速度快。程序无法控制 堆： 由new 等分配， 速度慢，且内存不连续容易产生碎片。但是容易管理。  </description>
    </item>
    
    <item>
      <title>人生如戏</title>
      <link>https://zylhorse.github.io/blog/stories/%E4%BA%BA%E7%94%9F%E5%A6%82%E6%88%8F/</link>
      <pubDate>Sat, 31 Aug 2013 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/stories/%E4%BA%BA%E7%94%9F%E5%A6%82%E6%88%8F/</guid>
      <description>有些人导演生活，有些人是生活的演员， 你是哪一个。。。。</description>
    </item>
    
    <item>
      <title>你是真正的快乐</title>
      <link>https://zylhorse.github.io/blog/stories/%E4%BD%A0%E6%98%AF%E7%9C%9F%E6%AD%A3%E7%9A%84%E5%BF%AB%E4%B9%90/</link>
      <pubDate>Sat, 31 Aug 2013 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/stories/%E4%BD%A0%E6%98%AF%E7%9C%9F%E6%AD%A3%E7%9A%84%E5%BF%AB%E4%B9%90/</guid>
      <description>体会到真正的快乐，不会再轻易地感伤</description>
    </item>
    
    <item>
      <title>编程语言分类</title>
      <link>https://zylhorse.github.io/blog/software-programming/%E8%AF%AD%E8%A8%80%E7%B1%BB%E5%9E%8B/</link>
      <pubDate>Tue, 27 Aug 2013 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/software-programming/%E8%AF%AD%E8%A8%80%E7%B1%BB%E5%9E%8B/</guid>
      <description>Program Errors  trapped errors：出错后程序终止执行，如：除0。 untrapped errors：出错后程序继续执行，会出现任意行为，如：缓冲区溢出。  Forbidden Behavious 语言设计时定义一组 Forbidden Behavious， 它必须包含所有的 untrapped errors，但可能包含 trapped errors。
Well behaved,ill behaved  well behaved:如果程序执行不出现forbidden behavious，则为 well behaved ill behaved： 否则是ill behaved。  动态、静态类型 静态类型 编译时拒绝 ill behaved 的语言是 statically  静态类型分为两种： 显式类型explicitly typed：类型是语言的一部分。隐式类型implicitly typed：类型通过编译推 动态类型 dynamically 运行时拒绝ill behaved的语言是 dynamically typed 类型安全： 是否在运行时进行类型检查，是否类型错误。 </description>
    </item>
    
    <item>
      <title>编程的基本风格或典范模式(programming paradigm)</title>
      <link>https://zylhorse.github.io/blog/software-programming/%E7%BC%96%E7%A8%8B%E8%8C%83%E5%BC%8F/</link>
      <pubDate>Mon, 26 Aug 2013 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/software-programming/%E7%BC%96%E7%A8%8B%E8%8C%83%E5%BC%8F/</guid>
      <description>编程范式（programming paradigm） 概念  编程的基本风格或典范模式，是如何编写程序的方法论。 哲学观点：编程者在创造虚拟世界，而编程范式就是他们置身其中不自觉采用的世界观和方法论。 编程是为了解决问题，而解决问题可以有多种视角和思路，其中普适且行之有效的模式被归结为范式。 由于着眼点和思维方式不同，相应的范式有自己的侧重和偏向，因此范式常用&amp;rsquo;oriented&amp;rsquo;描述。换言之每种范式都引导编程者带着某种倾向去分析问题、解决问题，这不就是‘导向’吗？ 编程范式是抽象的，必须通过具体的编程语言来体现。任何编程语言在设计中都会倾向于某些编程范式，一种编程范式可以在不同的编程语言中体现，一种编程语言也可以适用多种范式。  常见编程范式  命令式（Imperative Programming）
命令“机器”如何去做(how)，这样不管你想要的是什么(what)，它都会按照命令实现。 声明式（Declarative Programming) 告诉“机器”你想要的是什么(what)，让“机器”推导如何去做(how).  函数式（Function Programming） 将机器运算当作是函数运算，并且避免使用程序状态及易变对象 逻辑编程（Logic programming） 设置答案需要匹配的规则解决问题，而不是设置步骤解决问题。编程语言：Prolog 过程式（Procedural Programming) 主要采用程序调用（Procedure call）或函数调用（Function call）来进行流程控制。 面向对象(Object Programming） 对象作为程序的单元，将程序和数据封装其中。对象是相互独立和相互调用。 </description>
    </item>
    
    <item>
      <title>忧郁</title>
      <link>https://zylhorse.github.io/blog/stories/%E5%BF%A7%E9%83%81/</link>
      <pubDate>Tue, 06 Aug 2013 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/stories/%E5%BF%A7%E9%83%81/</guid>
      <description>性格使然， 总是很忧郁。。。</description>
    </item>
    
    <item>
      <title>离开前</title>
      <link>https://zylhorse.github.io/blog/stories/%E7%A6%BB%E5%BC%80%E5%89%8D/</link>
      <pubDate>Tue, 06 Aug 2013 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/stories/%E7%A6%BB%E5%BC%80%E5%89%8D/</guid>
      <description>有一天 你会发现当离开这个有爱的地方时，最后 会再做些什么 。。。</description>
    </item>
    
    <item>
      <title>Nginx-Http配置</title>
      <link>https://zylhorse.github.io/blog/nginx/http/</link>
      <pubDate>Thu, 23 May 2013 00:00:00 +0000</pubDate>
      
      <guid>https://zylhorse.github.io/blog/nginx/http/</guid>
      <description>真实IP location / {proxy_set_header X-Real-IP $remote_addr;proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;proxy_set_header Host $http_host;proxy_set_header X-NginX-Proxy true;proxy_pass http://127.0.0.1:4567/;proxy_redirect off;}</description>
    </item>
    
  </channel>
</rss>
